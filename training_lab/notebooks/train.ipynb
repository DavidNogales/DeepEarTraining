{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def load_dataframe(relative_path,dataframe_name):\n",
    "    df = pd.read_pickle(f'{relative_path}/{dataframe_name}.pkl')    \n",
    "    return df\n",
    "\n",
    "def read_file(relative_path,file_name):\n",
    "    text= \"\"\n",
    "    with open(f'{relative_path}/{file_name}.abc','r') as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unit_note_length', 'tuneBook', 'title', 'reference_number',\n",
       "       'original_header', 'original_body', 'meter', 'key', 'clean_song',\n",
       "       'clean_header', 'clean_body', 'chord_progression', '\"fm\"', '\"ff'\"',\n",
       "       '\"f7\"', '\"em\"', '\"ee'\"', '\"e7\"', '\"e\"', '\"dm\"', '\"dd'\"', '\"d7\"', '\"d\"',\n",
       "       '\"cm\"', '\"cc'\"', '\"c7\"', '\"c#m\"', '\"c#7\"', '\"c\"', '\"Gm\"', '\"Gg\"',\n",
       "       '\"Gd'\"', '\"G7\"', '\"G#m\"', '\"G#7\"', '\"G\"', '\"Fm\"', '\"Ff\"', '\"Fc'\"',\n",
       "       '\"F7\"', '\"F#m\"', '\"F#7\"', '\"F\"', '\"Em\"', '\"Eb\"', '\"E7\"', '\"E#m\"',\n",
       "       '\"E#7\"', '\"E\"', '\"Dm\"', '\"Da\"', '\"D7\"', '\"D#m\"', '\"D#7\"', '\"D\"', '\"Cm\"',\n",
       "       '\"Cg\"', '\"C7\"', '\"C#m\"', '\"C#7\"', '\"C\"', '\"Bm\"', '\"Bf\"', '\"Bb\"', '\"B7\"',\n",
       "       '\"B#m\"', '\"B#7\"', '\"B\"', '\"Am\"', '\"Ae'\"', '\"Aa\"', '\"A7\"', '\"A#m\"',\n",
       "       '\"A#7\"', '\"A\"'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_path =\"notebooks/data/final_dataset\"\n",
    "filename_name = 'clean_augmented_data'\n",
    "#filename_name = 'clean_original_training_data'\n",
    "#relative_path =\"notebooks/data/original_dataset\"\n",
    "training_data_df = load_dataframe(relative_path,filename_name)\n",
    "training_data_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_note_length</th>\n",
       "      <th>tuneBook</th>\n",
       "      <th>title</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>original_header</th>\n",
       "      <th>original_body</th>\n",
       "      <th>meter</th>\n",
       "      <th>key</th>\n",
       "      <th>clean_song</th>\n",
       "      <th>clean_header</th>\n",
       "      <th>...</th>\n",
       "      <th>\"B#m\"</th>\n",
       "      <th>\"B#7\"</th>\n",
       "      <th>\"B\"</th>\n",
       "      <th>\"Am\"</th>\n",
       "      <th>\"Ae'\"</th>\n",
       "      <th>\"Aa\"</th>\n",
       "      <th>\"A7\"</th>\n",
       "      <th>\"A#m\"</th>\n",
       "      <th>\"A#7\"</th>\n",
       "      <th>\"A\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9491</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Grandpa's</td>\n",
       "      <td>78</td>\n",
       "      <td>X:78\\nT:Grandpa's\\nM:4/4\\nL:1/4\\nK:Amajor</td>\n",
       "      <td>E/2D/2|\"A,\"CE\"E7\"FG|\"A,\"A/2G/2A/2B/2ce|\"B,m\"dc...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9492</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>The Girl With The Green Hat On</td>\n",
       "      <td>79</td>\n",
       "      <td>X:79\\nT:The Girl With The Green Hat On\\nM:4/4\\...</td>\n",
       "      <td>(3E/2F/2G/2|\"A,\"AE\"E7\"E/2F/2E/2D/2|\"A,\"C/2D/2E...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9493</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Green Meadow</td>\n",
       "      <td>80</td>\n",
       "      <td>X:80\\nT:Green Meadow\\nM:4/4\\nL:1/4\\nK:Dmajor</td>\n",
       "      <td>(3A,/2B,/2C/2|\"D\"DD/2E/2F/2D/2F/2A/2|\"G,\"B/2c/...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>D</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9494</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>The Old Grey Cat</td>\n",
       "      <td>82</td>\n",
       "      <td>X:82\\nT:The Old Grey Cat\\nM:4/4\\nL:1/4\\nK:Bminor</td>\n",
       "      <td>F|\"B,m\"BBB,B,/2C/2|\"B,m\"D/2C/2D/2E/2F/2E/2F/2^...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>Bm</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9495</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Gyre And Gimble</td>\n",
       "      <td>84</td>\n",
       "      <td>X:84\\nT:Gyre And Gimble\\nM:4/4\\nL:1/4\\nK:Amajor</td>\n",
       "      <td>E|\"A,\"AECE|\"B,m\"FD\"E7\"B,D|\"A,\"CEA3/2B/2|\"E7\"c/...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unit_note_length          tuneBook                           title  \\\n",
       "9491              1/4  dataset_min5.abc                       Grandpa's   \n",
       "9492              1/4  dataset_min5.abc  The Girl With The Green Hat On   \n",
       "9493              1/4  dataset_min5.abc                    Green Meadow   \n",
       "9494              1/4  dataset_min5.abc                The Old Grey Cat   \n",
       "9495              1/4  dataset_min5.abc                 Gyre And Gimble   \n",
       "\n",
       "     reference_number                                    original_header  \\\n",
       "9491               78          X:78\\nT:Grandpa's\\nM:4/4\\nL:1/4\\nK:Amajor   \n",
       "9492               79  X:79\\nT:The Girl With The Green Hat On\\nM:4/4\\...   \n",
       "9493               80       X:80\\nT:Green Meadow\\nM:4/4\\nL:1/4\\nK:Dmajor   \n",
       "9494               82   X:82\\nT:The Old Grey Cat\\nM:4/4\\nL:1/4\\nK:Bminor   \n",
       "9495               84    X:84\\nT:Gyre And Gimble\\nM:4/4\\nL:1/4\\nK:Amajor   \n",
       "\n",
       "                                          original_body meter key  \\\n",
       "9491  E/2D/2|\"A,\"CE\"E7\"FG|\"A,\"A/2G/2A/2B/2ce|\"B,m\"dc...   4/4   A   \n",
       "9492  (3E/2F/2G/2|\"A,\"AE\"E7\"E/2F/2E/2D/2|\"A,\"C/2D/2E...   4/4   A   \n",
       "9493  (3A,/2B,/2C/2|\"D\"DD/2E/2F/2D/2F/2A/2|\"G,\"B/2c/...   4/4   D   \n",
       "9494  F|\"B,m\"BBB,B,/2C/2|\"B,m\"D/2C/2D/2E/2F/2E/2F/2^...   4/4  Bm   \n",
       "9495  E|\"A,\"AECE|\"B,m\"FD\"E7\"B,D|\"A,\"CEA3/2B/2|\"E7\"c/...   4/4   A   \n",
       "\n",
       "                                             clean_song  \\\n",
       "9491  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...   \n",
       "9492  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...   \n",
       "9493  M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...   \n",
       "9494  M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...   \n",
       "9495  M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...   \n",
       "\n",
       "                                           clean_header  ... \"B#m\" \"B#7\"  \"B\"  \\\n",
       "9491  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...  ...     0     0    0   \n",
       "9492  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...  ...     0     0    0   \n",
       "9493  M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...  ...     0     0    0   \n",
       "9494  M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...  ...     0     0    0   \n",
       "9495  M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...  ...     0     0    0   \n",
       "\n",
       "      \"Am\"  \"Ae'\"  \"Aa\"  \"A7\"  \"A#m\"  \"A#7\"  \"A\"  \n",
       "9491     0      0     0     0      0      0    9  \n",
       "9492     0      0     0     0      0      0    9  \n",
       "9493     0      0     0     7      0      0    0  \n",
       "9494     0      0     0     0      0      0    5  \n",
       "9495     0      0     0     0      0      0   12  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124.49420808761583"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df[\"clean_header\"].str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301.346251053075"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df[\"clean_body\"].str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab:  \n",
      "\"#'(),-/1234567=ABCDEFG[]^_abcdefgmz|~\n",
      "vocab_size 39\n",
      "silences  516\n"
     ]
    }
   ],
   "source": [
    "bodies = \"\"\n",
    "silences = 0\n",
    "for body in training_data_df[\"clean_body\"]:\n",
    "    if 'z' in body:\n",
    "        silences +=1 \n",
    "    bodies += body+\"\\n\"\n",
    "chars = sorted(list(set(bodies)))\n",
    "vocab_size = len(chars)\n",
    "print('vocab: ',''.join(chars))\n",
    "print('vocab_size',vocab_size)\n",
    "print(\"silences \",silences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chars: 4062773\n"
     ]
    }
   ],
   "source": [
    "training_data_text = read_file(relative_path,filename_name)\n",
    "\n",
    "print(\"number of chars:\",len(training_data_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"#'(),-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(training_data_text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.28.0.dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14.2\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import tiktoken\n",
    "\n",
    "print(wandb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile  docker-compose.yaml  overrides.json\n",
      "README.md   notebooks\t\t requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "nano_path = 'notebooks/nanoGPT'\n",
    "os.chdir(nano_path)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE      assets\t      data\t  out-abc-char\twandb\n",
      "README.md    config\t      model.py\t  sample.py\n",
      "__pycache__  configurator.py  older_ckpt  train.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with multiple voices present\n",
    "#length of dataset in characters: 4,149,703\n",
    "#all the unique characters: \n",
    "#\"#'()+,-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
    "#vocab size: 46\n",
    "#train has 3,734,732 tokens\n",
    "#val has 414,971 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 4,062,773\n",
      "all the unique characters: \n",
      "\"#'(),-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
      "vocab size: 45\n",
      "train has 3,656,495 tokens\n",
      "val has 406,278 tokens\n"
     ]
    }
   ],
   "source": [
    "!python3 data/abc_char/prepare.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding config with config/train_abc_char.py:\n",
      "# train a miniature character-level shakespeare model\n",
      "# good for debugging and playing on macbooks and such\n",
      "\n",
      "out_dir = 'out-abc-char'\n",
      "eval_interval = 10 # keep frequent because we'll overfit\n",
      "eval_iters = 500\n",
      "log_interval = 5 # don't print too too often\n",
      "\n",
      "# we expect to overfit on this small dataset, so only save when val improves\n",
      "always_save_checkpoint = False\n",
      "\n",
      "wandb_log = True # override via command line if you like\n",
      "wandb_project = 'abc-char'\n",
      "wandb_run_name = 'mini-char-gpt-hd-8-ly-12-bt-4-ctx-1024'\n",
      "\n",
      "dataset = 'abc_char'\n",
      "batch_size = 4\n",
      "block_size = 1024 # context of up to 512 previous characters\n",
      "\n",
      "# baby GPT model :)\n",
      "n_layer = 12\n",
      "n_head = 8\n",
      "n_embd = 384\n",
      "dropout = 0.2\n",
      "\n",
      "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
      "max_iters = 5000\n",
      "lr_decay_iters = 5000 # make equal to max_iters usually\n",
      "min_lr = 1e-4 # learning_rate / 10 usually\n",
      "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
      "\n",
      "warmup_iters = 5 # not super necessary potentially\n",
      "\n",
      "# on macbook also add\n",
      "# device = 'cpu'  # run on cpu only\n",
      "# compile = False # do not torch compile the model\n",
      "\n",
      "found vocab_size = 45 (inside data/abc_char/meta.pkl)\n",
      "Initializing a new model from scratch\n",
      "number of parameters: 21.26M\n",
      "using fused AdamW: True\n",
      "compiling the model... (takes a ~minute)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavidnogales\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/pt-env/notebooks/nanoGPT/wandb/run-20230428_122849-7ifhn3bb\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmini-char-gpt-hd-8-ly-12-bt-4-ctx-1024\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char/runs/7ifhn3bb\u001b[0m\n",
      "step 0: train loss 3.7937, val loss 3.8142\n",
      "[2023-04-28 12:29:16,208] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 12:29:16,612] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 12:29:17,041] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 12:29:17,216] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 12:29:17,453] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 12:29:17,626] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 12:29:17,926] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 12:29:18,109] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 12:29:18,352] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 12:29:18,528] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 12:29:18,776] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 12:29:18,961] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 12:29:19,311] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 12:29:19,493] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 12:29:19,742] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 12:29:19,935] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 12:29:20,255] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 12:29:20,440] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 12:29:20,688] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 12:29:20,863] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 12:29:21,107] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 12:29:21,288] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 12:29:21,542] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 12:29:21,725] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "iter 0: loss 3.8277, time 37491.57ms, mfu -100.00%\n",
      "iter 5: loss 3.0359, time 2590.61ms, mfu 3.73%\n",
      "step 10: train loss 2.8329, val loss 2.8099\n",
      "saving checkpoint to out-abc-char\n",
      "iter 10: loss 2.8075, time 21938.49ms, mfu 3.40%\n",
      "iter 15: loss 2.4778, time 2594.57ms, mfu 3.44%\n",
      "step 20: train loss 2.4121, val loss 2.3598\n",
      "saving checkpoint to out-abc-char\n",
      "iter 20: loss 2.3453, time 21900.52ms, mfu 3.14%\n",
      "iter 25: loss 2.0450, time 2499.80ms, mfu 3.21%\n",
      "step 30: train loss 2.2502, val loss 2.2730\n",
      "saving checkpoint to out-abc-char\n",
      "iter 30: loss 2.2582, time 21694.05ms, mfu 2.93%\n",
      "iter 35: loss 2.0292, time 2511.41ms, mfu 3.03%\n",
      "step 40: train loss 2.1305, val loss 2.2171\n",
      "saving checkpoint to out-abc-char\n",
      "iter 40: loss 2.1482, time 22046.76ms, mfu 2.77%\n",
      "iter 45: loss 2.0976, time 2524.18ms, mfu 2.87%\n",
      "step 50: train loss 2.0143, val loss 2.0576\n",
      "saving checkpoint to out-abc-char\n",
      "iter 50: loss 2.0127, time 21722.41ms, mfu 2.63%\n",
      "iter 55: loss 1.9778, time 2610.81ms, mfu 2.74%\n",
      "step 60: train loss 1.9559, val loss 1.9898\n",
      "saving checkpoint to out-abc-char\n",
      "iter 60: loss 1.8967, time 21953.21ms, mfu 2.51%\n",
      "iter 65: loss 1.6783, time 2877.81ms, mfu 2.59%\n",
      "step 70: train loss 1.8782, val loss 1.9276\n",
      "saving checkpoint to out-abc-char\n",
      "iter 70: loss 1.8626, time 21626.55ms, mfu 2.38%\n",
      "iter 75: loss 1.9375, time 2496.83ms, mfu 2.53%\n",
      "step 80: train loss 1.8434, val loss 1.8908\n",
      "saving checkpoint to out-abc-char\n",
      "iter 80: loss 1.8036, time 21932.76ms, mfu 2.32%\n",
      "iter 85: loss 1.8079, time 2513.03ms, mfu 2.47%\n",
      "step 90: train loss 1.8122, val loss 1.8452\n",
      "saving checkpoint to out-abc-char\n",
      "iter 90: loss 1.9501, time 21954.80ms, mfu 2.27%\n",
      "iter 95: loss 1.6555, time 2491.15ms, mfu 2.43%\n",
      "step 100: train loss 1.7863, val loss 1.8065\n",
      "saving checkpoint to out-abc-char\n",
      "iter 100: loss 1.6347, time 21552.70ms, mfu 2.23%\n",
      "iter 105: loss 1.7063, time 2521.69ms, mfu 2.39%\n",
      "step 110: train loss 1.7557, val loss 1.8086\n",
      "iter 110: loss 1.7924, time 21870.84ms, mfu 2.20%\n",
      "iter 115: loss 1.7418, time 2502.38ms, mfu 2.36%\n",
      "step 120: train loss 1.7456, val loss 1.7645\n",
      "saving checkpoint to out-abc-char\n",
      "iter 120: loss 1.7651, time 21534.53ms, mfu 2.17%\n",
      "iter 125: loss 1.6747, time 2493.80ms, mfu 2.34%\n",
      "step 130: train loss 1.6941, val loss 1.7331\n",
      "saving checkpoint to out-abc-char\n",
      "iter 130: loss 1.6005, time 21468.19ms, mfu 2.15%\n",
      "iter 135: loss 1.6933, time 2493.78ms, mfu 2.33%\n",
      "step 140: train loss 1.6614, val loss 1.7011\n",
      "saving checkpoint to out-abc-char\n",
      "iter 140: loss 1.6739, time 21921.22ms, mfu 2.14%\n",
      "iter 145: loss 1.7665, time 2513.60ms, mfu 2.31%\n",
      "step 150: train loss 1.6435, val loss 1.6895\n",
      "saving checkpoint to out-abc-char\n",
      "iter 150: loss 1.7677, time 21512.91ms, mfu 2.12%\n",
      "iter 155: loss 1.4851, time 2494.28ms, mfu 2.30%\n",
      "step 160: train loss 1.6073, val loss 1.6564\n",
      "saving checkpoint to out-abc-char\n",
      "iter 160: loss 1.5335, time 21618.14ms, mfu 2.11%\n",
      "iter 165: loss 1.6087, time 2493.95ms, mfu 2.29%\n",
      "step 170: train loss 1.5925, val loss 1.6323\n",
      "saving checkpoint to out-abc-char\n",
      "iter 170: loss 1.7285, time 21662.64ms, mfu 2.11%\n",
      "iter 175: loss 1.5479, time 2499.32ms, mfu 2.28%\n",
      "step 180: train loss 1.5647, val loss 1.5889\n",
      "saving checkpoint to out-abc-char\n",
      "iter 180: loss 1.8025, time 21729.47ms, mfu 2.10%\n",
      "iter 185: loss 1.6026, time 2516.86ms, mfu 2.27%\n",
      "step 190: train loss 1.5690, val loss 1.5827\n",
      "saving checkpoint to out-abc-char\n",
      "iter 190: loss 1.3643, time 21810.85ms, mfu 2.09%\n",
      "iter 195: loss 1.5597, time 2517.15ms, mfu 2.27%\n",
      "step 200: train loss 1.5404, val loss 1.5708\n",
      "saving checkpoint to out-abc-char\n",
      "iter 200: loss 1.4994, time 21402.98ms, mfu 2.08%\n",
      "iter 205: loss 1.5869, time 2490.71ms, mfu 2.26%\n",
      "step 210: train loss 1.5256, val loss 1.5540\n",
      "saving checkpoint to out-abc-char\n",
      "iter 210: loss 1.6068, time 21815.95ms, mfu 2.08%\n",
      "iter 215: loss 1.4627, time 2570.42ms, mfu 2.25%\n",
      "step 220: train loss 1.5153, val loss 1.5434\n",
      "saving checkpoint to out-abc-char\n",
      "iter 220: loss 1.5309, time 21468.27ms, mfu 2.07%\n",
      "iter 225: loss 1.4961, time 2489.92ms, mfu 2.25%\n",
      "step 230: train loss 1.4913, val loss 1.5126\n",
      "saving checkpoint to out-abc-char\n",
      "iter 230: loss 1.3191, time 21485.83ms, mfu 2.07%\n",
      "iter 235: loss 1.4208, time 2516.70ms, mfu 2.25%\n",
      "step 240: train loss 1.4902, val loss 1.4993\n",
      "saving checkpoint to out-abc-char\n",
      "iter 240: loss 1.5380, time 21889.73ms, mfu 2.07%\n",
      "iter 245: loss 1.3198, time 2575.35ms, mfu 2.24%\n",
      "step 250: train loss 1.4733, val loss 1.4814\n",
      "saving checkpoint to out-abc-char\n",
      "iter 250: loss 1.5605, time 22057.24ms, mfu 2.06%\n",
      "iter 255: loss 1.4620, time 2513.49ms, mfu 2.24%\n",
      "step 260: train loss 1.4437, val loss 1.4728\n",
      "saving checkpoint to out-abc-char\n",
      "iter 260: loss 1.1733, time 21731.83ms, mfu 2.06%\n",
      "iter 265: loss 1.4371, time 2496.79ms, mfu 2.24%\n",
      "step 270: train loss 1.4340, val loss 1.4466\n",
      "saving checkpoint to out-abc-char\n",
      "iter 270: loss 1.3719, time 21718.22ms, mfu 2.06%\n",
      "iter 275: loss 1.5259, time 2542.68ms, mfu 2.23%\n",
      "step 280: train loss 1.4309, val loss 1.4408\n",
      "saving checkpoint to out-abc-char\n",
      "iter 280: loss 1.5345, time 21719.19ms, mfu 2.05%\n",
      "iter 285: loss 1.2843, time 2544.56ms, mfu 2.23%\n",
      "step 290: train loss 1.4118, val loss 1.4232\n",
      "saving checkpoint to out-abc-char\n",
      "iter 290: loss 1.4543, time 21739.69ms, mfu 2.05%\n",
      "iter 295: loss 1.2636, time 2523.90ms, mfu 2.23%\n",
      "step 300: train loss 1.4007, val loss 1.4182\n",
      "saving checkpoint to out-abc-char\n",
      "iter 300: loss 1.4013, time 21819.97ms, mfu 2.05%\n",
      "iter 305: loss 1.5081, time 2525.17ms, mfu 2.23%\n",
      "step 310: train loss 1.3895, val loss 1.4039\n",
      "saving checkpoint to out-abc-char\n",
      "iter 310: loss 1.4909, time 21643.51ms, mfu 2.05%\n",
      "iter 315: loss 1.2155, time 2525.43ms, mfu 2.23%\n",
      "step 320: train loss 1.3559, val loss 1.3797\n",
      "saving checkpoint to out-abc-char\n",
      "iter 320: loss 1.5306, time 21624.09ms, mfu 2.05%\n",
      "iter 325: loss 1.3175, time 2518.05ms, mfu 2.23%\n",
      "step 330: train loss 1.3607, val loss 1.3782\n",
      "saving checkpoint to out-abc-char\n",
      "iter 330: loss 1.4214, time 21533.30ms, mfu 2.05%\n",
      "iter 335: loss 1.4984, time 2497.35ms, mfu 2.23%\n",
      "step 340: train loss 1.3254, val loss 1.3454\n",
      "saving checkpoint to out-abc-char\n",
      "iter 340: loss 1.3676, time 21866.46ms, mfu 2.05%\n",
      "iter 345: loss 1.3684, time 2509.11ms, mfu 2.23%\n",
      "step 350: train loss 1.3295, val loss 1.3591\n",
      "iter 350: loss 1.4990, time 21372.42ms, mfu 2.06%\n",
      "iter 355: loss 1.3392, time 2487.48ms, mfu 2.24%\n",
      "step 360: train loss 1.2920, val loss 1.3187\n",
      "saving checkpoint to out-abc-char\n",
      "iter 360: loss 1.4162, time 21528.46ms, mfu 2.06%\n",
      "iter 365: loss 1.2571, time 2501.99ms, mfu 2.24%\n",
      "step 370: train loss 1.2542, val loss 1.2708\n",
      "saving checkpoint to out-abc-char\n",
      "iter 370: loss 1.2296, time 21574.84ms, mfu 2.06%\n",
      "iter 375: loss 1.3079, time 2489.32ms, mfu 2.24%\n",
      "step 380: train loss 1.2335, val loss 1.2643\n",
      "saving checkpoint to out-abc-char\n",
      "iter 380: loss 1.2513, time 21516.83ms, mfu 2.06%\n",
      "iter 385: loss 1.1428, time 2496.46ms, mfu 2.25%\n",
      "step 390: train loss 1.2150, val loss 1.2414\n",
      "saving checkpoint to out-abc-char\n",
      "iter 390: loss 1.4570, time 21617.90ms, mfu 2.07%\n",
      "iter 395: loss 1.3248, time 2507.12ms, mfu 2.24%\n",
      "step 400: train loss 1.1665, val loss 1.2069\n",
      "saving checkpoint to out-abc-char\n",
      "iter 400: loss 1.2825, time 21602.08ms, mfu 2.07%\n",
      "iter 405: loss 1.2147, time 2514.68ms, mfu 2.24%\n",
      "step 410: train loss 1.1703, val loss 1.2038\n",
      "saving checkpoint to out-abc-char\n",
      "iter 410: loss 1.1997, time 21320.92ms, mfu 2.06%\n",
      "iter 415: loss 1.2598, time 2485.86ms, mfu 2.25%\n",
      "step 420: train loss 1.1412, val loss 1.1740\n",
      "saving checkpoint to out-abc-char\n",
      "iter 420: loss 1.2476, time 21386.07ms, mfu 2.07%\n",
      "iter 425: loss 1.1175, time 2487.95ms, mfu 2.25%\n",
      "step 430: train loss 1.1307, val loss 1.1469\n",
      "saving checkpoint to out-abc-char\n",
      "iter 430: loss 1.2773, time 21363.67ms, mfu 2.07%\n",
      "iter 435: loss 1.1416, time 2487.29ms, mfu 2.25%\n",
      "step 440: train loss 1.0997, val loss 1.1465\n",
      "saving checkpoint to out-abc-char\n",
      "iter 440: loss 1.0538, time 21561.69ms, mfu 2.07%\n",
      "iter 445: loss 1.2359, time 2523.63ms, mfu 2.25%\n",
      "step 450: train loss 1.1032, val loss 1.1348\n",
      "saving checkpoint to out-abc-char\n",
      "iter 450: loss 1.1225, time 21581.76ms, mfu 2.07%\n",
      "iter 455: loss 1.0521, time 2512.13ms, mfu 2.25%\n",
      "step 460: train loss 1.0769, val loss 1.1109\n",
      "saving checkpoint to out-abc-char\n",
      "iter 460: loss 1.1086, time 21534.86ms, mfu 2.07%\n",
      "iter 465: loss 1.1821, time 2488.12ms, mfu 2.25%\n",
      "step 470: train loss 1.0648, val loss 1.1017\n",
      "saving checkpoint to out-abc-char\n",
      "iter 470: loss 1.0357, time 21504.62ms, mfu 2.07%\n",
      "iter 475: loss 1.0800, time 2507.99ms, mfu 2.25%\n",
      "step 480: train loss 1.0451, val loss 1.0813\n",
      "saving checkpoint to out-abc-char\n",
      "iter 480: loss 1.0643, time 21476.29ms, mfu 2.07%\n",
      "iter 485: loss 1.1865, time 2549.34ms, mfu 2.24%\n",
      "step 490: train loss 1.0251, val loss 1.0692\n",
      "saving checkpoint to out-abc-char\n",
      "iter 490: loss 1.1274, time 21488.07ms, mfu 2.06%\n",
      "iter 495: loss 0.9544, time 2496.58ms, mfu 2.24%\n",
      "step 500: train loss 1.0140, val loss 1.0480\n",
      "saving checkpoint to out-abc-char\n",
      "iter 500: loss 1.0744, time 21579.29ms, mfu 2.06%\n",
      "iter 505: loss 1.0993, time 2504.93ms, mfu 2.24%\n",
      "step 510: train loss 0.9929, val loss 1.0278\n",
      "saving checkpoint to out-abc-char\n",
      "iter 510: loss 1.0268, time 21499.88ms, mfu 2.06%\n",
      "iter 515: loss 1.0572, time 2487.56ms, mfu 2.25%\n",
      "step 520: train loss 0.9873, val loss 1.0346\n",
      "iter 520: loss 0.9201, time 21353.35ms, mfu 2.07%\n",
      "iter 525: loss 0.9129, time 2489.74ms, mfu 2.25%\n",
      "step 530: train loss 0.9662, val loss 1.0119\n",
      "saving checkpoint to out-abc-char\n",
      "iter 530: loss 0.9407, time 22151.53ms, mfu 2.07%\n",
      "iter 535: loss 0.9507, time 2478.21ms, mfu 2.25%\n",
      "step 540: train loss 0.9551, val loss 1.0031\n",
      "saving checkpoint to out-abc-char\n",
      "iter 540: loss 0.9270, time 21482.52ms, mfu 2.07%\n",
      "iter 545: loss 0.8645, time 2566.74ms, mfu 2.24%\n",
      "step 550: train loss 0.9306, val loss 0.9756\n",
      "saving checkpoint to out-abc-char\n",
      "iter 550: loss 0.9806, time 20896.96ms, mfu 2.06%\n",
      "iter 555: loss 1.0962, time 2491.71ms, mfu 2.24%\n",
      "step 560: train loss 0.9277, val loss 0.9661\n",
      "saving checkpoint to out-abc-char\n",
      "iter 560: loss 0.8915, time 20978.94ms, mfu 2.07%\n",
      "iter 565: loss 0.8351, time 2425.07ms, mfu 2.26%\n",
      "step 570: train loss 0.9119, val loss 0.9614\n",
      "saving checkpoint to out-abc-char\n",
      "iter 570: loss 0.9304, time 20930.88ms, mfu 2.08%\n",
      "iter 575: loss 0.8999, time 2428.98ms, mfu 2.27%\n",
      "step 580: train loss 0.8907, val loss 0.9321\n",
      "saving checkpoint to out-abc-char\n",
      "iter 580: loss 0.9273, time 20921.77ms, mfu 2.09%\n",
      "iter 585: loss 0.9411, time 2481.79ms, mfu 2.27%\n",
      "step 590: train loss 0.8846, val loss 0.9346\n",
      "iter 590: loss 0.8990, time 20624.65ms, mfu 2.09%\n",
      "iter 595: loss 0.8376, time 2452.30ms, mfu 2.27%\n",
      "step 600: train loss 0.8663, val loss 0.9085\n",
      "saving checkpoint to out-abc-char\n",
      "iter 600: loss 0.9481, time 20915.77ms, mfu 2.09%\n",
      "iter 605: loss 0.7998, time 2418.86ms, mfu 2.28%\n",
      "step 610: train loss 0.8668, val loss 0.9152\n",
      "iter 610: loss 0.7457, time 20646.33ms, mfu 2.10%\n",
      "iter 615: loss 0.8436, time 2433.45ms, mfu 2.29%\n",
      "step 620: train loss 0.8407, val loss 0.8855\n",
      "saving checkpoint to out-abc-char\n",
      "iter 620: loss 0.8725, time 21073.75ms, mfu 2.11%\n",
      "iter 625: loss 0.8166, time 2427.77ms, mfu 2.29%\n",
      "step 630: train loss 0.8252, val loss 0.8760\n",
      "saving checkpoint to out-abc-char\n",
      "iter 630: loss 0.8935, time 20848.97ms, mfu 2.11%\n",
      "iter 635: loss 0.8559, time 2420.64ms, mfu 2.30%\n",
      "step 640: train loss 0.8166, val loss 0.8647\n",
      "saving checkpoint to out-abc-char\n",
      "iter 640: loss 0.8640, time 20887.40ms, mfu 2.12%\n",
      "iter 645: loss 0.7810, time 2423.64ms, mfu 2.30%\n",
      "step 650: train loss 0.8007, val loss 0.8494\n",
      "saving checkpoint to out-abc-char\n",
      "iter 650: loss 0.7617, time 21209.26ms, mfu 2.12%\n",
      "iter 655: loss 0.8212, time 2442.49ms, mfu 2.30%\n",
      "step 660: train loss 0.7966, val loss 0.8368\n",
      "saving checkpoint to out-abc-char\n",
      "iter 660: loss 0.8096, time 20961.70ms, mfu 2.12%\n",
      "iter 665: loss 0.8242, time 2417.76ms, mfu 2.31%\n",
      "step 670: train loss 0.7837, val loss 0.8319\n",
      "saving checkpoint to out-abc-char\n",
      "iter 670: loss 0.8641, time 20705.67ms, mfu 2.12%\n",
      "iter 675: loss 0.7310, time 2419.96ms, mfu 2.31%\n",
      "step 680: train loss 0.7719, val loss 0.8211\n",
      "saving checkpoint to out-abc-char\n",
      "iter 680: loss 0.7791, time 20802.90ms, mfu 2.13%\n",
      "iter 685: loss 0.8181, time 2416.45ms, mfu 2.31%\n",
      "step 690: train loss 0.7527, val loss 0.8093\n",
      "saving checkpoint to out-abc-char\n",
      "iter 690: loss 0.7719, time 20691.43ms, mfu 2.13%\n",
      "iter 695: loss 0.7691, time 2420.94ms, mfu 2.32%\n",
      "step 700: train loss 0.7380, val loss 0.7834\n",
      "saving checkpoint to out-abc-char\n",
      "iter 700: loss 0.8304, time 20725.57ms, mfu 2.13%\n",
      "iter 705: loss 0.7949, time 2418.98ms, mfu 2.32%\n",
      "step 710: train loss 0.7211, val loss 0.7742\n",
      "saving checkpoint to out-abc-char\n",
      "iter 710: loss 0.7687, time 20743.34ms, mfu 2.13%\n",
      "iter 715: loss 0.7957, time 2419.79ms, mfu 2.32%\n",
      "step 720: train loss 0.7082, val loss 0.7546\n",
      "saving checkpoint to out-abc-char\n",
      "iter 720: loss 0.7328, time 20741.30ms, mfu 2.13%\n",
      "iter 725: loss 0.7527, time 2416.88ms, mfu 2.32%\n",
      "step 730: train loss 0.6953, val loss 0.7473\n",
      "saving checkpoint to out-abc-char\n",
      "iter 730: loss 0.7716, time 20687.27ms, mfu 2.14%\n",
      "iter 735: loss 0.6663, time 2521.27ms, mfu 2.31%\n",
      "step 740: train loss 0.6804, val loss 0.7343\n",
      "saving checkpoint to out-abc-char\n",
      "iter 740: loss 0.7353, time 20738.54ms, mfu 2.12%\n",
      "iter 745: loss 0.6247, time 2417.62ms, mfu 2.31%\n",
      "step 750: train loss 0.6634, val loss 0.7228\n",
      "saving checkpoint to out-abc-char\n",
      "iter 750: loss 0.8335, time 20701.02ms, mfu 2.13%\n",
      "iter 755: loss 0.7624, time 2417.55ms, mfu 2.31%\n",
      "step 760: train loss 0.6554, val loss 0.7052\n",
      "saving checkpoint to out-abc-char\n",
      "iter 760: loss 0.7052, time 20698.77ms, mfu 2.13%\n",
      "iter 765: loss 0.6025, time 2419.32ms, mfu 2.32%\n",
      "step 770: train loss 0.6470, val loss 0.6967\n",
      "saving checkpoint to out-abc-char\n",
      "iter 770: loss 0.6491, time 20733.19ms, mfu 2.13%\n",
      "iter 775: loss 0.6087, time 2419.78ms, mfu 2.32%\n",
      "step 780: train loss 0.6335, val loss 0.6804\n",
      "saving checkpoint to out-abc-char\n",
      "iter 780: loss 0.6689, time 20740.49ms, mfu 2.13%\n",
      "iter 785: loss 0.6482, time 2421.38ms, mfu 2.32%\n",
      "step 790: train loss 0.6238, val loss 0.6741\n",
      "saving checkpoint to out-abc-char\n",
      "iter 790: loss 0.7337, time 20724.02ms, mfu 2.13%\n",
      "iter 795: loss 0.7028, time 2423.22ms, mfu 2.32%\n",
      "step 800: train loss 0.6094, val loss 0.6571\n",
      "saving checkpoint to out-abc-char\n",
      "iter 800: loss 0.5760, time 20679.55ms, mfu 2.13%\n",
      "iter 805: loss 0.7147, time 2405.32ms, mfu 2.32%\n",
      "step 810: train loss 0.6021, val loss 0.6585\n",
      "iter 810: loss 0.6557, time 20360.17ms, mfu 2.14%\n",
      "iter 815: loss 0.5965, time 2404.48ms, mfu 2.33%\n",
      "step 820: train loss 0.5996, val loss 0.6490\n",
      "saving checkpoint to out-abc-char\n",
      "iter 820: loss 0.6700, time 20644.57ms, mfu 2.14%\n",
      "iter 825: loss 0.6059, time 2407.77ms, mfu 2.33%\n",
      "step 830: train loss 0.5862, val loss 0.6455\n",
      "saving checkpoint to out-abc-char\n",
      "iter 830: loss 0.6041, time 20585.50ms, mfu 2.14%\n",
      "iter 835: loss 0.6608, time 2404.46ms, mfu 2.33%\n",
      "step 840: train loss 0.5772, val loss 0.6351\n",
      "saving checkpoint to out-abc-char\n",
      "iter 840: loss 0.5767, time 20621.00ms, mfu 2.14%\n",
      "iter 845: loss 0.5969, time 2406.51ms, mfu 2.33%\n",
      "step 850: train loss 0.5700, val loss 0.6219\n",
      "saving checkpoint to out-abc-char\n",
      "iter 850: loss 0.5237, time 20680.78ms, mfu 2.15%\n",
      "iter 855: loss 0.5207, time 2405.04ms, mfu 2.33%\n",
      "step 860: train loss 0.5758, val loss 0.6360\n",
      "iter 860: loss 0.6725, time 20388.21ms, mfu 2.15%\n",
      "iter 865: loss 0.5694, time 2409.04ms, mfu 2.33%\n",
      "step 870: train loss 0.5541, val loss 0.6116\n",
      "saving checkpoint to out-abc-char\n",
      "iter 870: loss 0.5085, time 20602.49ms, mfu 2.15%\n",
      "iter 875: loss 0.5893, time 2402.79ms, mfu 2.34%\n",
      "step 880: train loss 0.5486, val loss 0.6118\n",
      "iter 880: loss 0.6417, time 20408.17ms, mfu 2.15%\n",
      "iter 885: loss 0.6288, time 2408.20ms, mfu 2.34%\n",
      "step 890: train loss 0.5367, val loss 0.6030\n",
      "saving checkpoint to out-abc-char\n",
      "iter 890: loss 0.4710, time 20597.29ms, mfu 2.15%\n",
      "iter 895: loss 0.5867, time 2403.04ms, mfu 2.34%\n",
      "step 900: train loss 0.5374, val loss 0.6054\n",
      "iter 900: loss 0.5096, time 20359.97ms, mfu 2.15%\n",
      "iter 905: loss 0.4753, time 2407.93ms, mfu 2.34%\n",
      "step 910: train loss 0.5268, val loss 0.5907\n",
      "saving checkpoint to out-abc-char\n",
      "iter 910: loss 0.4977, time 20619.03ms, mfu 2.15%\n",
      "iter 915: loss 0.5849, time 2403.95ms, mfu 2.34%\n",
      "step 920: train loss 0.5207, val loss 0.5818\n",
      "saving checkpoint to out-abc-char\n",
      "iter 920: loss 0.5090, time 20641.18ms, mfu 2.15%\n",
      "iter 925: loss 0.5424, time 2406.71ms, mfu 2.34%\n",
      "step 930: train loss 0.5189, val loss 0.5785\n",
      "saving checkpoint to out-abc-char\n",
      "iter 930: loss 0.4821, time 20593.55ms, mfu 2.15%\n",
      "iter 935: loss 0.5182, time 2413.10ms, mfu 2.34%\n",
      "step 940: train loss 0.5161, val loss 0.5831\n",
      "iter 940: loss 0.5852, time 20395.41ms, mfu 2.15%\n",
      "iter 945: loss 0.4852, time 2398.96ms, mfu 2.34%\n",
      "step 950: train loss 0.5079, val loss 0.5791\n",
      "iter 950: loss 0.5236, time 20378.51ms, mfu 2.15%\n",
      "iter 955: loss 0.5566, time 2408.26ms, mfu 2.34%\n",
      "step 960: train loss 0.4993, val loss 0.5719\n",
      "saving checkpoint to out-abc-char\n",
      "iter 960: loss 0.4147, time 20625.15ms, mfu 2.15%\n",
      "iter 965: loss 0.5176, time 2404.94ms, mfu 2.34%\n",
      "step 970: train loss 0.4936, val loss 0.5628\n",
      "saving checkpoint to out-abc-char\n",
      "iter 970: loss 0.5314, time 20583.27ms, mfu 2.15%\n",
      "iter 975: loss 0.5103, time 2407.83ms, mfu 2.34%\n",
      "step 980: train loss 0.4889, val loss 0.5607\n",
      "saving checkpoint to out-abc-char\n",
      "iter 980: loss 0.4725, time 20573.81ms, mfu 2.15%\n",
      "iter 985: loss 0.5561, time 2405.85ms, mfu 2.34%\n",
      "step 990: train loss 0.4807, val loss 0.5530\n",
      "saving checkpoint to out-abc-char\n",
      "iter 990: loss 0.4977, time 20614.75ms, mfu 2.15%\n",
      "iter 995: loss 0.4742, time 2406.50ms, mfu 2.34%\n",
      "step 1000: train loss 0.4745, val loss 0.5527\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1000: loss 0.4691, time 20581.25ms, mfu 2.15%\n",
      "iter 1005: loss 0.4965, time 2405.02ms, mfu 2.34%\n",
      "step 1010: train loss 0.4697, val loss 0.5454\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1010: loss 0.4214, time 20594.06ms, mfu 2.15%\n",
      "iter 1015: loss 0.5944, time 2403.79ms, mfu 2.34%\n",
      "step 1020: train loss 0.4640, val loss 0.5402\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1020: loss 0.5360, time 20654.55ms, mfu 2.15%\n",
      "iter 1025: loss 0.4787, time 2409.07ms, mfu 2.34%\n",
      "step 1030: train loss 0.4620, val loss 0.5415\n",
      "iter 1030: loss 0.5159, time 20374.13ms, mfu 2.15%\n",
      "iter 1035: loss 0.4934, time 2401.96ms, mfu 2.34%\n",
      "step 1040: train loss 0.4576, val loss 0.5406\n",
      "iter 1040: loss 0.4168, time 20385.21ms, mfu 2.15%\n",
      "iter 1045: loss 0.4607, time 2414.04ms, mfu 2.34%\n",
      "step 1050: train loss 0.4498, val loss 0.5279\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1050: loss 0.4826, time 20636.59ms, mfu 2.15%\n",
      "iter 1055: loss 0.4366, time 2402.12ms, mfu 2.34%\n",
      "step 1060: train loss 0.4494, val loss 0.5374\n",
      "iter 1060: loss 0.4914, time 20351.30ms, mfu 2.15%\n",
      "iter 1065: loss 0.4670, time 2408.53ms, mfu 2.34%\n",
      "step 1070: train loss 0.4342, val loss 0.5251\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1070: loss 0.4563, time 20590.89ms, mfu 2.15%\n",
      "iter 1075: loss 0.4952, time 2406.89ms, mfu 2.34%\n",
      "step 1080: train loss 0.4342, val loss 0.5209\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1080: loss 0.5119, time 20659.82ms, mfu 2.15%\n",
      "iter 1085: loss 0.4652, time 2407.37ms, mfu 2.34%\n",
      "step 1090: train loss 0.4292, val loss 0.5241\n",
      "iter 1090: loss 0.3985, time 20399.41ms, mfu 2.15%\n",
      "iter 1095: loss 0.4632, time 2406.02ms, mfu 2.34%\n",
      "step 1100: train loss 0.4255, val loss 0.5261\n",
      "iter 1100: loss 0.4986, time 20365.68ms, mfu 2.15%\n",
      "iter 1105: loss 0.4900, time 2408.47ms, mfu 2.34%\n",
      "step 1110: train loss 0.4188, val loss 0.5165\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1110: loss 0.4776, time 20621.98ms, mfu 2.15%\n",
      "iter 1115: loss 0.4413, time 2408.51ms, mfu 2.34%\n",
      "step 1120: train loss 0.4094, val loss 0.5119\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1120: loss 0.4490, time 20572.83ms, mfu 2.15%\n",
      "iter 1125: loss 0.5083, time 2405.14ms, mfu 2.34%\n",
      "step 1130: train loss 0.4054, val loss 0.5044\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1130: loss 0.4354, time 20638.95ms, mfu 2.15%\n",
      "iter 1135: loss 0.4108, time 2409.45ms, mfu 2.34%\n",
      "step 1140: train loss 0.4009, val loss 0.5141\n",
      "iter 1140: loss 0.4103, time 20364.16ms, mfu 2.15%\n",
      "iter 1145: loss 0.4999, time 2402.40ms, mfu 2.34%\n",
      "step 1150: train loss 0.3954, val loss 0.4982\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1150: loss 0.3902, time 20583.04ms, mfu 2.15%\n",
      "iter 1155: loss 0.4018, time 2405.37ms, mfu 2.34%\n",
      "step 1160: train loss 0.3947, val loss 0.5036\n",
      "iter 1160: loss 0.3901, time 20372.64ms, mfu 2.15%\n",
      "iter 1165: loss 0.3088, time 2410.36ms, mfu 2.34%\n",
      "step 1170: train loss 0.3879, val loss 0.4942\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1170: loss 0.5027, time 20593.28ms, mfu 2.15%\n",
      "iter 1175: loss 0.3913, time 2407.68ms, mfu 2.34%\n",
      "step 1180: train loss 0.3809, val loss 0.4933\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1180: loss 0.4148, time 20627.30ms, mfu 2.15%\n",
      "iter 1185: loss 0.3805, time 2403.95ms, mfu 2.34%\n",
      "step 1190: train loss 0.3717, val loss 0.4862\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1190: loss 0.3420, time 20653.19ms, mfu 2.15%\n",
      "iter 1195: loss 0.4945, time 2408.16ms, mfu 2.34%\n",
      "step 1200: train loss 0.3748, val loss 0.4909\n",
      "iter 1200: loss 0.4463, time 20382.38ms, mfu 2.15%\n",
      "iter 1205: loss 0.4052, time 2407.18ms, mfu 2.34%\n",
      "step 1210: train loss 0.3671, val loss 0.4852\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1210: loss 0.3883, time 20603.34ms, mfu 2.15%\n",
      "iter 1215: loss 0.4006, time 2406.24ms, mfu 2.34%\n",
      "step 1220: train loss 0.3587, val loss 0.4875\n",
      "iter 1220: loss 0.4097, time 20412.53ms, mfu 2.15%\n",
      "iter 1225: loss 0.3803, time 2404.77ms, mfu 2.34%\n",
      "step 1230: train loss 0.3491, val loss 0.4737\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1230: loss 0.3785, time 20595.90ms, mfu 2.15%\n",
      "iter 1235: loss 0.4125, time 2408.21ms, mfu 2.34%\n",
      "step 1240: train loss 0.3457, val loss 0.4678\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1240: loss 0.3829, time 20574.97ms, mfu 2.15%\n",
      "iter 1245: loss 0.3596, time 2404.00ms, mfu 2.34%\n",
      "step 1250: train loss 0.3416, val loss 0.4718\n",
      "iter 1250: loss 0.4091, time 20430.06ms, mfu 2.15%\n",
      "iter 1255: loss 0.4291, time 2403.33ms, mfu 2.34%\n",
      "step 1260: train loss 0.3363, val loss 0.4656\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1260: loss 0.3668, time 20629.68ms, mfu 2.15%\n",
      "iter 1265: loss 0.3939, time 2401.58ms, mfu 2.34%\n",
      "step 1270: train loss 0.3323, val loss 0.4671\n",
      "iter 1270: loss 0.3642, time 20358.63ms, mfu 2.15%\n",
      "iter 1275: loss 0.3953, time 2409.33ms, mfu 2.34%\n",
      "step 1280: train loss 0.3336, val loss 0.4601\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1280: loss 0.3668, time 20618.91ms, mfu 2.15%\n",
      "iter 1285: loss 0.3578, time 2404.67ms, mfu 2.34%\n",
      "step 1290: train loss 0.3258, val loss 0.4580\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1290: loss 0.3741, time 20602.17ms, mfu 2.15%\n",
      "iter 1295: loss 0.3642, time 2409.39ms, mfu 2.34%\n",
      "step 1300: train loss 0.3186, val loss 0.4599\n",
      "iter 1300: loss 0.4148, time 20388.23ms, mfu 2.15%\n",
      "iter 1305: loss 0.3043, time 2407.39ms, mfu 2.34%\n",
      "step 1310: train loss 0.3142, val loss 0.4514\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1310: loss 0.3607, time 20614.07ms, mfu 2.15%\n",
      "iter 1315: loss 0.3625, time 2408.88ms, mfu 2.34%\n",
      "step 1320: train loss 0.3065, val loss 0.4548\n",
      "iter 1320: loss 0.3264, time 20347.07ms, mfu 2.15%\n",
      "iter 1325: loss 0.3786, time 2403.54ms, mfu 2.34%\n",
      "step 1330: train loss 0.3072, val loss 0.4593\n",
      "iter 1330: loss 0.3423, time 20370.85ms, mfu 2.15%\n",
      "iter 1335: loss 0.3742, time 2407.79ms, mfu 2.34%\n",
      "step 1340: train loss 0.2956, val loss 0.4433\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1340: loss 0.3063, time 20606.81ms, mfu 2.15%\n",
      "iter 1345: loss 0.3096, time 2409.68ms, mfu 2.34%\n",
      "step 1350: train loss 0.2938, val loss 0.4515\n",
      "iter 1350: loss 0.3567, time 20409.47ms, mfu 2.15%\n",
      "iter 1355: loss 0.3439, time 2399.22ms, mfu 2.34%\n",
      "step 1360: train loss 0.2874, val loss 0.4412\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1360: loss 0.3391, time 20672.33ms, mfu 2.15%\n",
      "iter 1365: loss 0.3016, time 2408.27ms, mfu 2.34%\n",
      "step 1370: train loss 0.2838, val loss 0.4308\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1370: loss 0.2860, time 20579.89ms, mfu 2.15%\n",
      "iter 1375: loss 0.3440, time 2403.31ms, mfu 2.34%\n",
      "step 1380: train loss 0.2816, val loss 0.4351\n",
      "iter 1380: loss 0.3332, time 20345.84ms, mfu 2.15%\n",
      "iter 1385: loss 0.3507, time 2403.85ms, mfu 2.34%\n",
      "step 1390: train loss 0.2741, val loss 0.4266\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1390: loss 0.3303, time 20657.76ms, mfu 2.15%\n",
      "iter 1395: loss 0.3139, time 2405.27ms, mfu 2.34%\n",
      "step 1400: train loss 0.2662, val loss 0.4294\n",
      "iter 1400: loss 0.3196, time 20357.16ms, mfu 2.15%\n",
      "iter 1405: loss 0.3330, time 2400.93ms, mfu 2.34%\n",
      "step 1410: train loss 0.2646, val loss 0.4157\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1410: loss 0.3428, time 20590.34ms, mfu 2.15%\n",
      "iter 1415: loss 0.2649, time 2408.48ms, mfu 2.34%\n",
      "step 1420: train loss 0.2594, val loss 0.4283\n",
      "iter 1420: loss 0.3412, time 20418.90ms, mfu 2.15%\n",
      "iter 1425: loss 0.3343, time 2400.04ms, mfu 2.34%\n",
      "step 1430: train loss 0.2594, val loss 0.4174\n",
      "iter 1430: loss 0.2949, time 20541.90ms, mfu 2.15%\n",
      "iter 1435: loss 0.3230, time 2455.06ms, mfu 2.33%\n",
      "step 1440: train loss 0.2536, val loss 0.4166\n",
      "iter 1440: loss 0.2638, time 20870.89ms, mfu 2.15%\n",
      "iter 1445: loss 0.2590, time 2465.22ms, mfu 2.32%\n",
      "step 1450: train loss 0.2480, val loss 0.4100\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1450: loss 0.2880, time 21739.44ms, mfu 2.14%\n",
      "^C\n",
      "Process ForkProcess-14:\n",
      "Process ForkProcess-15:\n",
      "Process ForkProcess-9:\n",
      "Process ForkProcess-12:\n",
      "Process ForkProcess-19:\n",
      "Process ForkProcess-5:\n",
      "Process ForkProcess-1:\n",
      "Process ForkProcess-3:\n",
      "Process ForkProcess-10:\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-6:\n",
      "Process ForkProcess-20:\n",
      "Process ForkProcess-13:\n",
      "Process ForkProcess-18:\n",
      "Process ForkProcess-16:\n",
      "Process ForkProcess-17:\n",
      "Process ForkProcess-4:\n",
      "Process ForkProcess-11:\n",
      "Process ForkProcess-8:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Process ForkProcess-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 97, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 293, in <module>\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\", line 487, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\", line 200, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 255).\u001b[0m Press Control-C to abort syncing.\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py config/train_abc_char.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./older_ckpt/hd-8-ly-12-bt-4-ctx-1024/'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_name = 'hd-8-ly-12-bt-4-ctx-1024/'\n",
    "examples_folder = f'./older_ckpt/{folder_name}'\n",
    "examples_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_roman_num_prog = '|\"I\"|\"I\"|\"IV\"|\"V\"|\"V\"|\"I\"|\"IV\"|\"V\"|\"I\"|'\n",
    "G_roman_chord_progression = f''\n",
    "\n",
    "songs_start = {\n",
    "    'G' :'M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]',\n",
    "    'C' :'M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]',\n",
    "    'Am':'M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]'\n",
    "    }\n",
    "\n",
    "songs_roman_start = {\n",
    "    'G' :'M:4/4L:1/4K:G|\"I\"|\"IV\"|\"V\"|\"V\"|\"I\"|\"IV\"|\"V\"|\"I\"|]',\n",
    "    'C' :'M:4/4L:1/4K:C|\"I\"|\"IV\"|\"V\"|\"V\"|\"I\"|\"IV\"|\"V\"|\"I\"|]',\n",
    "    'Am':'M:4/4L:1/4K:Am|\"i\"|\"iv\"|\"V\"|\"V\"|\"i\"|\"iv\"|\"V\"|\"i\"|]'\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test key with most occurrences: G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start='M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]' > {examples_folder}/examples_G.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test major key with low samples: C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start='M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]' > {examples_folder}/examples_C.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test minor key with low samples: Am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start='M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]' > {examples_folder}/examples_Am.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move checkpoint files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = './data/abc_char/meta.pkl'\n",
    "target_folder = examples_folder\n",
    "!mv {source} {target_folder}/meta.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_folder = './out-abc-char/ckpt.pt'\n",
    "!mv {source} {target_folder}/ckpt.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = './config/train_abc_char.py'\n",
    "!cp {source} {target_folder}/config.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test older checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " !python3 sample.py --out_dir=older_ckpt/m_voices --path_meta=older_ckpt/m_voices --start='M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat older_ckpt/m_voices/ckpt.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l older_ckpt/m_voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l out-abc-char/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
