{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def load_dataframe(relative_path,dataframe_name):\n",
    "    df = pd.read_pickle(f'{relative_path}/{dataframe_name}.pkl')    \n",
    "    return df\n",
    "\n",
    "def read_file(relative_path,file_name):\n",
    "    text= \"\"\n",
    "    with open(f'{relative_path}/{file_name}.abc','r') as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unit_note_length', 'tuneBook', 'title', 'reference_number',\n",
       "       'original_header', 'original_body', 'meter', 'key', 'clean_song',\n",
       "       'clean_header', 'clean_body', 'chord_progression', '\"fm\"', '\"ff'\"',\n",
       "       '\"f7\"', '\"em\"', '\"ee'\"', '\"e7\"', '\"e\"', '\"dm\"', '\"dd'\"', '\"d7\"', '\"d\"',\n",
       "       '\"cm\"', '\"cc'\"', '\"c7\"', '\"c#m\"', '\"c#7\"', '\"c\"', '\"Gm\"', '\"Gg\"',\n",
       "       '\"Gd'\"', '\"G7\"', '\"G#m\"', '\"G#7\"', '\"G\"', '\"Fm\"', '\"Ff\"', '\"Fc'\"',\n",
       "       '\"F7\"', '\"F#m\"', '\"F#7\"', '\"F\"', '\"Em\"', '\"Eb\"', '\"E7\"', '\"E#m\"',\n",
       "       '\"E#7\"', '\"E\"', '\"Dm\"', '\"Da\"', '\"D7\"', '\"D#m\"', '\"D#7\"', '\"D\"', '\"Cm\"',\n",
       "       '\"Cg\"', '\"C7\"', '\"C#m\"', '\"C#7\"', '\"C\"', '\"Bm\"', '\"Bf\"', '\"Bb\"', '\"B7\"',\n",
       "       '\"B#m\"', '\"B#7\"', '\"B\"', '\"Am\"', '\"Ae'\"', '\"Aa\"', '\"A7\"', '\"A#m\"',\n",
       "       '\"A#7\"', '\"A\"'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_path =\"notebooks/data/final_dataset\"\n",
    "filename_name = 'clean_augmented_data'\n",
    "#filename_name = 'clean_original_training_data'\n",
    "#relative_path =\"notebooks/data/original_dataset\"\n",
    "training_data_df = load_dataframe(relative_path,filename_name)\n",
    "training_data_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_note_length</th>\n",
       "      <th>tuneBook</th>\n",
       "      <th>title</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>original_header</th>\n",
       "      <th>original_body</th>\n",
       "      <th>meter</th>\n",
       "      <th>key</th>\n",
       "      <th>clean_song</th>\n",
       "      <th>clean_header</th>\n",
       "      <th>...</th>\n",
       "      <th>\"B#m\"</th>\n",
       "      <th>\"B#7\"</th>\n",
       "      <th>\"B\"</th>\n",
       "      <th>\"Am\"</th>\n",
       "      <th>\"Ae'\"</th>\n",
       "      <th>\"Aa\"</th>\n",
       "      <th>\"A7\"</th>\n",
       "      <th>\"A#m\"</th>\n",
       "      <th>\"A#7\"</th>\n",
       "      <th>\"A\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9491</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Grandpa's</td>\n",
       "      <td>78</td>\n",
       "      <td>X:78\\nT:Grandpa's\\nM:4/4\\nL:1/4\\nK:Amajor</td>\n",
       "      <td>E/2D/2|\"A,\"CE\"E7\"FG|\"A,\"A/2G/2A/2B/2ce|\"B,m\"dc...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9492</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>The Girl With The Green Hat On</td>\n",
       "      <td>79</td>\n",
       "      <td>X:79\\nT:The Girl With The Green Hat On\\nM:4/4\\...</td>\n",
       "      <td>(3E/2F/2G/2|\"A,\"AE\"E7\"E/2F/2E/2D/2|\"A,\"C/2D/2E...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9493</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Green Meadow</td>\n",
       "      <td>80</td>\n",
       "      <td>X:80\\nT:Green Meadow\\nM:4/4\\nL:1/4\\nK:Dmajor</td>\n",
       "      <td>(3A,/2B,/2C/2|\"D\"DD/2E/2F/2D/2F/2A/2|\"G,\"B/2c/...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>D</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9494</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>The Old Grey Cat</td>\n",
       "      <td>82</td>\n",
       "      <td>X:82\\nT:The Old Grey Cat\\nM:4/4\\nL:1/4\\nK:Bminor</td>\n",
       "      <td>F|\"B,m\"BBB,B,/2C/2|\"B,m\"D/2C/2D/2E/2F/2E/2F/2^...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>Bm</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9495</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Gyre And Gimble</td>\n",
       "      <td>84</td>\n",
       "      <td>X:84\\nT:Gyre And Gimble\\nM:4/4\\nL:1/4\\nK:Amajor</td>\n",
       "      <td>E|\"A,\"AECE|\"B,m\"FD\"E7\"B,D|\"A,\"CEA3/2B/2|\"E7\"c/...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unit_note_length          tuneBook                           title  \\\n",
       "9491              1/4  dataset_min5.abc                       Grandpa's   \n",
       "9492              1/4  dataset_min5.abc  The Girl With The Green Hat On   \n",
       "9493              1/4  dataset_min5.abc                    Green Meadow   \n",
       "9494              1/4  dataset_min5.abc                The Old Grey Cat   \n",
       "9495              1/4  dataset_min5.abc                 Gyre And Gimble   \n",
       "\n",
       "     reference_number                                    original_header  \\\n",
       "9491               78          X:78\\nT:Grandpa's\\nM:4/4\\nL:1/4\\nK:Amajor   \n",
       "9492               79  X:79\\nT:The Girl With The Green Hat On\\nM:4/4\\...   \n",
       "9493               80       X:80\\nT:Green Meadow\\nM:4/4\\nL:1/4\\nK:Dmajor   \n",
       "9494               82   X:82\\nT:The Old Grey Cat\\nM:4/4\\nL:1/4\\nK:Bminor   \n",
       "9495               84    X:84\\nT:Gyre And Gimble\\nM:4/4\\nL:1/4\\nK:Amajor   \n",
       "\n",
       "                                          original_body meter key  \\\n",
       "9491  E/2D/2|\"A,\"CE\"E7\"FG|\"A,\"A/2G/2A/2B/2ce|\"B,m\"dc...   4/4   A   \n",
       "9492  (3E/2F/2G/2|\"A,\"AE\"E7\"E/2F/2E/2D/2|\"A,\"C/2D/2E...   4/4   A   \n",
       "9493  (3A,/2B,/2C/2|\"D\"DD/2E/2F/2D/2F/2A/2|\"G,\"B/2c/...   4/4   D   \n",
       "9494  F|\"B,m\"BBB,B,/2C/2|\"B,m\"D/2C/2D/2E/2F/2E/2F/2^...   4/4  Bm   \n",
       "9495  E|\"A,\"AECE|\"B,m\"FD\"E7\"B,D|\"A,\"CEA3/2B/2|\"E7\"c/...   4/4   A   \n",
       "\n",
       "                                             clean_song  \\\n",
       "9491  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...   \n",
       "9492  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...   \n",
       "9493  M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...   \n",
       "9494  M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...   \n",
       "9495  M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...   \n",
       "\n",
       "                                           clean_header  ... \"B#m\" \"B#7\"  \"B\"  \\\n",
       "9491  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...  ...     0     0    0   \n",
       "9492  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...  ...     0     0    0   \n",
       "9493  M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...  ...     0     0    0   \n",
       "9494  M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...  ...     0     0    0   \n",
       "9495  M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...  ...     0     0    0   \n",
       "\n",
       "      \"Am\"  \"Ae'\"  \"Aa\"  \"A7\"  \"A#m\"  \"A#7\"  \"A\"  \n",
       "9491     0      0     0     0      0      0    9  \n",
       "9492     0      0     0     0      0      0    9  \n",
       "9493     0      0     0     7      0      0    0  \n",
       "9494     0      0     0     0      0      0    5  \n",
       "9495     0      0     0     0      0      0   12  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df[\"clean_header\"].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1257"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df[\"clean_body\"].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab:  \n",
      "\"#'(),-/1234567=ABCDEFG[]^_abcdefgmz|~\n",
      "vocab_size 39\n",
      "silences  516\n"
     ]
    }
   ],
   "source": [
    "bodies = \"\"\n",
    "silences = 0\n",
    "for body in training_data_df[\"clean_body\"]:\n",
    "    if 'z' in body:\n",
    "        silences +=1 \n",
    "    bodies += body+\"\\n\"\n",
    "chars = sorted(list(set(bodies)))\n",
    "vocab_size = len(chars)\n",
    "print('vocab: ',''.join(chars))\n",
    "print('vocab_size',vocab_size)\n",
    "print(\"silences \",silences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chars: 4062773\n"
     ]
    }
   ],
   "source": [
    "training_data_text = read_file(relative_path,filename_name)\n",
    "\n",
    "print(\"number of chars:\",len(training_data_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chars \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(training_data_text)))\n\u001b[1;32m      2\u001b[0m vocab_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(chars)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(chars))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_data_text' is not defined"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(training_data_text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.28.0.dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14.2\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import tiktoken\n",
    "\n",
    "print(wandb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile  docker-compose.yaml  overrides.json\n",
      "README.md   notebooks\t\t requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "nano_path = 'notebooks/nanoGPT'\n",
    "os.chdir(nano_path)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE      config\t      out-abc-char\t    transformer_sizing.ipynb\n",
      "README.md    configurator.py  out-shakespeare-char  wandb\n",
      "__pycache__  data\t      sample.py\n",
      "assets\t     model.py\t      scaling_laws.ipynb\n",
      "bench.py     older_ckpt       train.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with multiple voices present\n",
    "#length of dataset in characters: 4,149,703\n",
    "#all the unique characters: \n",
    "#\"#'()+,-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
    "#vocab size: 46\n",
    "#train has 3,734,732 tokens\n",
    "#val has 414,971 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 4,062,773\n",
      "all the unique characters: \n",
      "\"#'(),-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
      "vocab size: 45\n",
      "train has 3,656,495 tokens\n",
      "val has 406,278 tokens\n"
     ]
    }
   ],
   "source": [
    "!python3 data/abc_char/prepare.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding config with config/train_abc_char.py:\n",
      "# train a miniature character-level shakespeare model\n",
      "# good for debugging and playing on macbooks and such\n",
      "\n",
      "out_dir = 'out-abc-char'\n",
      "eval_interval = 10 # keep frequent because we'll overfit\n",
      "eval_iters = 500\n",
      "log_interval = 5 # don't print too too often\n",
      "\n",
      "# we expect to overfit on this small dataset, so only save when val improves\n",
      "always_save_checkpoint = False\n",
      "\n",
      "wandb_log = True # override via command line if you like\n",
      "wandb_project = 'abc-char'\n",
      "wandb_run_name = 'mini-char-gpt'\n",
      "\n",
      "dataset = 'abc_char'\n",
      "batch_size = 32\n",
      "block_size = 512 # context of up to 512 previous characters\n",
      "\n",
      "# baby GPT model :)\n",
      "n_layer = 12\n",
      "n_head = 12\n",
      "n_embd = 384\n",
      "dropout = 0.2\n",
      "\n",
      "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
      "max_iters = 5000\n",
      "lr_decay_iters = 5000 # make equal to max_iters usually\n",
      "min_lr = 1e-4 # learning_rate / 10 usually\n",
      "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
      "\n",
      "warmup_iters = 5 # not super necessary potentially\n",
      "\n",
      "# on macbook also add\n",
      "# device = 'cpu'  # run on cpu only\n",
      "# compile = False # do not torch compile the model\n",
      "\n",
      "found vocab_size = 45 (inside data/abc_char/meta.pkl)\n",
      "Initializing a new model from scratch\n",
      "number of parameters: 21.26M\n",
      "using fused AdamW: True\n",
      "compiling the model... (takes a ~minute)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavidnogales\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/pt-env/notebooks/nanoGPT/wandb/run-20230411_170214-yd7ifmh2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmini-char-gpt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char/runs/yd7ifmh2\u001b[0m\n",
      "step 0: train loss 3.9199, val loss 3.9150\n",
      "[2023-04-11 17:03:17,778] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-11 17:03:18,084] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-11 17:03:18,388] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-11 17:03:18,564] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-11 17:03:18,810] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-11 17:03:18,994] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-11 17:03:19,242] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-11 17:03:19,431] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-11 17:03:19,678] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-11 17:03:19,871] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-11 17:03:20,139] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-11 17:03:20,321] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-11 17:03:20,672] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-11 17:03:20,862] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-11 17:03:21,110] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-11 17:03:21,290] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-11 17:03:21,541] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-11 17:03:21,720] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-11 17:03:21,970] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-11 17:03:22,150] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-11 17:03:22,403] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-11 17:03:22,587] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-11 17:03:22,842] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-11 17:03:23,024] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "iter 0: loss 3.9261, time 77276.28ms, mfu -100.00%\n",
      "iter 5: loss 3.1229, time 7470.73ms, mfu 4.38%\n",
      "step 10: train loss 2.6556, val loss 2.6615\n",
      "saving checkpoint to out-abc-char\n",
      "iter 10: loss 2.6391, time 62966.43ms, mfu 4.00%\n",
      "iter 15: loss 2.4912, time 7396.63ms, mfu 4.04%\n",
      "step 20: train loss 2.2555, val loss 2.2880\n",
      "saving checkpoint to out-abc-char\n",
      "iter 20: loss 2.2558, time 64060.35ms, mfu 3.69%\n",
      "iter 25: loss 2.1751, time 7376.54ms, mfu 3.76%\n",
      "step 30: train loss 2.1399, val loss 2.1573\n",
      "saving checkpoint to out-abc-char\n",
      "iter 30: loss 2.0511, time 62827.50ms, mfu 3.44%\n",
      "iter 35: loss 2.0056, time 7394.27ms, mfu 3.54%\n",
      "step 40: train loss 2.0384, val loss 2.0611\n",
      "saving checkpoint to out-abc-char\n",
      "iter 40: loss 1.9966, time 62672.27ms, mfu 3.24%\n",
      "iter 45: loss 2.0841, time 7488.05ms, mfu 3.35%\n",
      "step 50: train loss 1.9518, val loss 1.9822\n",
      "saving checkpoint to out-abc-char\n",
      "iter 50: loss 1.9905, time 63093.90ms, mfu 3.07%\n",
      "iter 55: loss 1.9718, time 7412.09ms, mfu 3.20%\n",
      "step 60: train loss 1.8608, val loss 1.8796\n",
      "saving checkpoint to out-abc-char\n",
      "iter 60: loss 1.8938, time 62648.24ms, mfu 2.93%\n",
      "iter 65: loss 1.9202, time 7464.92ms, mfu 3.08%\n",
      "step 70: train loss 1.8015, val loss 1.8094\n",
      "saving checkpoint to out-abc-char\n",
      "iter 70: loss 1.7980, time 62170.97ms, mfu 2.82%\n",
      "iter 75: loss 1.7845, time 7382.01ms, mfu 2.98%\n",
      "step 80: train loss 1.7312, val loss 1.7479\n",
      "saving checkpoint to out-abc-char\n",
      "iter 80: loss 1.7217, time 62096.20ms, mfu 2.74%\n",
      "iter 85: loss 1.7495, time 7379.79ms, mfu 2.91%\n",
      "step 90: train loss 1.6839, val loss 1.7065\n",
      "saving checkpoint to out-abc-char\n",
      "iter 90: loss 1.7034, time 62093.50ms, mfu 2.67%\n",
      "iter 95: loss 1.6163, time 7396.78ms, mfu 2.85%\n",
      "step 100: train loss 1.6591, val loss 1.6901\n",
      "saving checkpoint to out-abc-char\n",
      "iter 100: loss 1.6118, time 63025.39ms, mfu 2.61%\n",
      "iter 105: loss 1.6317, time 7379.43ms, mfu 2.80%\n",
      "step 110: train loss 1.6252, val loss 1.6576\n",
      "saving checkpoint to out-abc-char\n",
      "iter 110: loss 1.6872, time 63098.85ms, mfu 2.57%\n",
      "iter 115: loss 1.6356, time 7484.58ms, mfu 2.75%\n",
      "step 120: train loss 1.5943, val loss 1.6249\n",
      "saving checkpoint to out-abc-char\n",
      "iter 120: loss 1.5973, time 62454.22ms, mfu 2.53%\n",
      "iter 125: loss 1.5919, time 7436.34ms, mfu 2.71%\n",
      "step 130: train loss 1.5447, val loss 1.5751\n",
      "saving checkpoint to out-abc-char\n",
      "iter 130: loss 1.6063, time 63186.16ms, mfu 2.49%\n",
      "iter 135: loss 1.5402, time 7511.92ms, mfu 2.68%\n",
      "step 140: train loss 1.5303, val loss 1.5646\n",
      "saving checkpoint to out-abc-char\n",
      "iter 140: loss 1.5087, time 62926.31ms, mfu 2.46%\n",
      "iter 145: loss 1.4634, time 7445.31ms, mfu 2.66%\n",
      "step 150: train loss 1.5120, val loss 1.5319\n",
      "saving checkpoint to out-abc-char\n",
      "iter 150: loss 1.4603, time 63216.62ms, mfu 2.44%\n",
      "iter 155: loss 1.5762, time 7484.36ms, mfu 2.64%\n",
      "step 160: train loss 1.5031, val loss 1.5167\n",
      "saving checkpoint to out-abc-char\n",
      "iter 160: loss 1.4704, time 63012.56ms, mfu 2.43%\n",
      "iter 165: loss 1.5377, time 7381.51ms, mfu 2.63%\n",
      "step 170: train loss 1.4876, val loss 1.4967\n",
      "saving checkpoint to out-abc-char\n",
      "iter 170: loss 1.4518, time 62085.41ms, mfu 2.42%\n",
      "iter 175: loss 1.5643, time 7378.72ms, mfu 2.62%\n",
      "step 180: train loss 1.4656, val loss 1.4897\n",
      "saving checkpoint to out-abc-char\n",
      "iter 180: loss 1.4847, time 62812.78ms, mfu 2.41%\n",
      "iter 185: loss 1.4812, time 7386.95ms, mfu 2.61%\n",
      "step 190: train loss 1.4533, val loss 1.4672\n",
      "saving checkpoint to out-abc-char\n",
      "iter 190: loss 1.4566, time 62088.86ms, mfu 2.40%\n",
      "iter 195: loss 1.4168, time 7382.35ms, mfu 2.61%\n",
      "step 200: train loss 1.4392, val loss 1.4581\n",
      "saving checkpoint to out-abc-char\n",
      "iter 200: loss 1.4596, time 62078.91ms, mfu 2.40%\n",
      "iter 205: loss 1.5025, time 7378.00ms, mfu 2.60%\n",
      "step 210: train loss 1.4260, val loss 1.4401\n",
      "saving checkpoint to out-abc-char\n",
      "iter 210: loss 1.4624, time 62184.86ms, mfu 2.39%\n",
      "iter 215: loss 1.4622, time 7387.20ms, mfu 2.60%\n",
      "step 220: train loss 1.4328, val loss 1.4428\n",
      "iter 220: loss 1.5102, time 62020.74ms, mfu 2.39%\n",
      "iter 225: loss 1.4155, time 7436.20ms, mfu 2.59%\n",
      "step 230: train loss 1.4120, val loss 1.4240\n",
      "saving checkpoint to out-abc-char\n",
      "iter 230: loss 1.4394, time 62153.16ms, mfu 2.39%\n",
      "iter 235: loss 1.4046, time 7378.94ms, mfu 2.59%\n",
      "step 240: train loss 1.3996, val loss 1.4180\n",
      "saving checkpoint to out-abc-char\n",
      "iter 240: loss 1.4122, time 62410.85ms, mfu 2.38%\n",
      "iter 245: loss 1.4454, time 7377.95ms, mfu 2.59%\n",
      "step 250: train loss 1.3761, val loss 1.3886\n",
      "saving checkpoint to out-abc-char\n",
      "iter 250: loss 1.4301, time 62192.45ms, mfu 2.38%\n",
      "iter 255: loss 1.3533, time 7344.76ms, mfu 2.59%\n",
      "step 260: train loss 1.3707, val loss 1.3842\n",
      "saving checkpoint to out-abc-char\n",
      "iter 260: loss 1.3975, time 62811.94ms, mfu 2.38%\n",
      "iter 265: loss 1.3903, time 7389.84ms, mfu 2.59%\n",
      "step 270: train loss 1.3453, val loss 1.3569\n",
      "saving checkpoint to out-abc-char\n",
      "iter 270: loss 1.3291, time 63141.03ms, mfu 2.38%\n",
      "iter 275: loss 1.3326, time 7436.07ms, mfu 2.58%\n",
      "step 280: train loss 1.3202, val loss 1.3438\n",
      "saving checkpoint to out-abc-char\n",
      "iter 280: loss 1.3804, time 63320.92ms, mfu 2.38%\n",
      "iter 285: loss 1.3425, time 7388.14ms, mfu 2.58%\n",
      "step 290: train loss 1.2985, val loss 1.3236\n",
      "saving checkpoint to out-abc-char\n",
      "iter 290: loss 1.3107, time 64305.55ms, mfu 2.38%\n",
      "iter 295: loss 1.3403, time 7644.64ms, mfu 2.57%\n",
      "step 300: train loss 1.2651, val loss 1.2830\n",
      "saving checkpoint to out-abc-char\n",
      "iter 300: loss 1.3180, time 61985.11ms, mfu 2.36%\n",
      "iter 305: loss 1.2965, time 7375.35ms, mfu 2.57%\n",
      "step 310: train loss 1.2553, val loss 1.2737\n",
      "saving checkpoint to out-abc-char\n",
      "iter 310: loss 1.3522, time 62460.93ms, mfu 2.37%\n",
      "iter 315: loss 1.2134, time 7375.53ms, mfu 2.57%\n",
      "step 320: train loss 1.2111, val loss 1.2345\n",
      "saving checkpoint to out-abc-char\n",
      "iter 320: loss 1.2790, time 61994.68ms, mfu 2.37%\n",
      "iter 325: loss 1.2022, time 7372.09ms, mfu 2.58%\n",
      "step 330: train loss 1.1899, val loss 1.2267\n",
      "saving checkpoint to out-abc-char\n",
      "iter 330: loss 1.2690, time 62607.43ms, mfu 2.37%\n",
      "iter 335: loss 1.2388, time 7456.91ms, mfu 2.57%\n",
      "step 340: train loss 1.1628, val loss 1.1920\n",
      "saving checkpoint to out-abc-char\n",
      "iter 340: loss 1.1674, time 62688.90ms, mfu 2.37%\n",
      "iter 345: loss 1.1469, time 7433.93ms, mfu 2.57%\n",
      "step 350: train loss 1.1397, val loss 1.1652\n",
      "saving checkpoint to out-abc-char\n",
      "iter 350: loss 1.1280, time 63159.42ms, mfu 2.37%\n",
      "iter 355: loss 1.1790, time 7423.66ms, mfu 2.57%\n",
      "step 360: train loss 1.1203, val loss 1.1465\n",
      "saving checkpoint to out-abc-char\n",
      "iter 360: loss 1.1367, time 62137.76ms, mfu 2.37%\n",
      "iter 365: loss 1.1646, time 7414.93ms, mfu 2.57%\n",
      "step 370: train loss 1.1088, val loss 1.1375\n",
      "saving checkpoint to out-abc-char\n",
      "iter 370: loss 1.1887, time 62197.48ms, mfu 2.37%\n",
      "iter 375: loss 1.1878, time 7414.53ms, mfu 2.57%\n",
      "step 380: train loss 1.0827, val loss 1.1261\n",
      "saving checkpoint to out-abc-char\n",
      "iter 380: loss 1.1002, time 62772.25ms, mfu 2.37%\n",
      "iter 385: loss 1.0744, time 7490.15ms, mfu 2.57%\n",
      "step 390: train loss 1.0555, val loss 1.0889\n",
      "saving checkpoint to out-abc-char\n",
      "iter 390: loss 1.0794, time 62068.59ms, mfu 2.36%\n",
      "iter 395: loss 1.0903, time 7398.17ms, mfu 2.57%\n",
      "step 400: train loss 1.0394, val loss 1.0861\n",
      "saving checkpoint to out-abc-char\n",
      "iter 400: loss 1.0995, time 63179.50ms, mfu 2.36%\n",
      "iter 405: loss 1.0197, time 7459.82ms, mfu 2.57%\n",
      "step 410: train loss 1.0098, val loss 1.0469\n",
      "saving checkpoint to out-abc-char\n",
      "iter 410: loss 1.0915, time 63101.30ms, mfu 2.36%\n",
      "iter 415: loss 0.9910, time 7374.43ms, mfu 2.57%\n",
      "step 420: train loss 0.9894, val loss 1.0329\n",
      "saving checkpoint to out-abc-char\n",
      "iter 420: loss 1.0129, time 62754.32ms, mfu 2.36%\n",
      "iter 425: loss 0.9874, time 7586.68ms, mfu 2.56%\n",
      "step 430: train loss 0.9693, val loss 1.0107\n",
      "saving checkpoint to out-abc-char\n",
      "iter 430: loss 0.9818, time 62567.49ms, mfu 2.36%\n",
      "iter 435: loss 0.9914, time 7518.44ms, mfu 2.56%\n",
      "step 440: train loss 0.9547, val loss 0.9914\n",
      "saving checkpoint to out-abc-char\n",
      "iter 440: loss 1.0208, time 62279.19ms, mfu 2.35%\n",
      "iter 445: loss 0.9810, time 7457.38ms, mfu 2.56%\n",
      "step 450: train loss 0.9408, val loss 0.9909\n",
      "saving checkpoint to out-abc-char\n",
      "iter 450: loss 0.9533, time 62259.33ms, mfu 2.35%\n",
      "iter 455: loss 0.9766, time 7405.62ms, mfu 2.56%\n",
      "step 460: train loss 0.9160, val loss 0.9556\n",
      "saving checkpoint to out-abc-char\n",
      "iter 460: loss 0.9560, time 62426.98ms, mfu 2.36%\n",
      "iter 465: loss 0.9456, time 7383.93ms, mfu 2.56%\n",
      "step 470: train loss 0.9036, val loss 0.9449\n",
      "saving checkpoint to out-abc-char\n",
      "iter 470: loss 0.9568, time 62141.89ms, mfu 2.36%\n",
      "iter 475: loss 0.8720, time 7390.62ms, mfu 2.57%\n",
      "step 480: train loss 0.8935, val loss 0.9332\n",
      "saving checkpoint to out-abc-char\n",
      "iter 480: loss 0.9429, time 62328.06ms, mfu 2.36%\n",
      "iter 485: loss 0.9563, time 7388.54ms, mfu 2.57%\n",
      "step 490: train loss 0.8589, val loss 0.9067\n",
      "saving checkpoint to out-abc-char\n",
      "iter 490: loss 0.8761, time 62155.82ms, mfu 2.37%\n",
      "iter 495: loss 0.9031, time 7382.33ms, mfu 2.57%\n",
      "step 500: train loss 0.8572, val loss 0.9049\n",
      "saving checkpoint to out-abc-char\n",
      "iter 500: loss 0.8745, time 62025.03ms, mfu 2.37%\n",
      "iter 505: loss 0.8730, time 7368.69ms, mfu 2.58%\n",
      "step 510: train loss 0.8289, val loss 0.8812\n",
      "saving checkpoint to out-abc-char\n",
      "iter 510: loss 0.8387, time 62325.77ms, mfu 2.37%\n",
      "iter 515: loss 0.8810, time 7387.92ms, mfu 2.58%\n",
      "step 520: train loss 0.8139, val loss 0.8660\n",
      "saving checkpoint to out-abc-char\n",
      "iter 520: loss 0.8593, time 62382.51ms, mfu 2.37%\n",
      "iter 525: loss 0.8484, time 7618.96ms, mfu 2.56%\n",
      "step 530: train loss 0.7997, val loss 0.8525\n",
      "saving checkpoint to out-abc-char\n",
      "iter 530: loss 0.8197, time 62177.33ms, mfu 2.36%\n",
      "iter 535: loss 0.8337, time 7384.76ms, mfu 2.57%\n",
      "step 540: train loss 0.7804, val loss 0.8305\n",
      "saving checkpoint to out-abc-char\n",
      "iter 540: loss 0.7968, time 63219.97ms, mfu 2.36%\n",
      "iter 545: loss 0.8155, time 7417.97ms, mfu 2.57%\n",
      "step 550: train loss 0.7596, val loss 0.8120\n",
      "saving checkpoint to out-abc-char\n",
      "iter 550: loss 0.8138, time 62263.07ms, mfu 2.36%\n",
      "iter 555: loss 0.8205, time 7387.89ms, mfu 2.57%\n",
      "step 560: train loss 0.7468, val loss 0.8000\n",
      "saving checkpoint to out-abc-char\n",
      "iter 560: loss 0.7499, time 62101.65ms, mfu 2.37%\n",
      "iter 565: loss 0.7400, time 7386.41ms, mfu 2.57%\n",
      "step 570: train loss 0.7358, val loss 0.7809\n",
      "saving checkpoint to out-abc-char\n",
      "iter 570: loss 0.7524, time 62060.49ms, mfu 2.37%\n",
      "iter 575: loss 0.6794, time 7453.75ms, mfu 2.57%\n",
      "step 580: train loss 0.7100, val loss 0.7683\n",
      "saving checkpoint to out-abc-char\n",
      "iter 580: loss 0.7754, time 62269.60ms, mfu 2.37%\n",
      "iter 585: loss 0.7076, time 7416.50ms, mfu 2.57%\n",
      "step 590: train loss 0.6974, val loss 0.7559\n",
      "saving checkpoint to out-abc-char\n",
      "iter 590: loss 0.7046, time 62198.38ms, mfu 2.37%\n",
      "iter 595: loss 0.6926, time 7436.23ms, mfu 2.57%\n",
      "step 600: train loss 0.6819, val loss 0.7380\n",
      "saving checkpoint to out-abc-char\n",
      "iter 600: loss 0.7224, time 62214.44ms, mfu 2.37%\n",
      "iter 605: loss 0.6664, time 7386.72ms, mfu 2.57%\n",
      "step 610: train loss 0.6577, val loss 0.7208\n",
      "saving checkpoint to out-abc-char\n",
      "iter 610: loss 0.6544, time 62161.33ms, mfu 2.37%\n",
      "iter 615: loss 0.6458, time 7419.86ms, mfu 2.57%\n",
      "step 620: train loss 0.6447, val loss 0.7073\n",
      "saving checkpoint to out-abc-char\n",
      "iter 620: loss 0.7056, time 62554.78ms, mfu 2.37%\n",
      "iter 625: loss 0.6720, time 7410.78ms, mfu 2.57%\n",
      "step 630: train loss 0.6367, val loss 0.6954\n",
      "saving checkpoint to out-abc-char\n",
      "iter 630: loss 0.6575, time 62278.13ms, mfu 2.37%\n",
      "iter 635: loss 0.6222, time 7379.24ms, mfu 2.57%\n",
      "step 640: train loss 0.6143, val loss 0.6756\n",
      "saving checkpoint to out-abc-char\n",
      "iter 640: loss 0.6532, time 62456.41ms, mfu 2.37%\n",
      "iter 645: loss 0.6160, time 7545.51ms, mfu 2.57%\n",
      "step 650: train loss 0.6040, val loss 0.6663\n",
      "saving checkpoint to out-abc-char\n",
      "iter 650: loss 0.6248, time 62556.29ms, mfu 2.36%\n",
      "iter 655: loss 0.6421, time 7386.66ms, mfu 2.57%\n",
      "step 660: train loss 0.5903, val loss 0.6580\n",
      "saving checkpoint to out-abc-char\n",
      "iter 660: loss 0.6007, time 62171.91ms, mfu 2.37%\n",
      "iter 665: loss 0.5943, time 7383.35ms, mfu 2.57%\n",
      "step 670: train loss 0.5758, val loss 0.6408\n",
      "saving checkpoint to out-abc-char\n",
      "iter 670: loss 0.6128, time 62236.70ms, mfu 2.37%\n",
      "iter 675: loss 0.5761, time 7384.83ms, mfu 2.57%\n",
      "step 680: train loss 0.5629, val loss 0.6309\n",
      "saving checkpoint to out-abc-char\n",
      "iter 680: loss 0.5835, time 62264.32ms, mfu 2.37%\n",
      "iter 685: loss 0.5973, time 7404.85ms, mfu 2.57%\n",
      "step 690: train loss 0.5505, val loss 0.6214\n",
      "saving checkpoint to out-abc-char\n",
      "iter 690: loss 0.5630, time 62572.61ms, mfu 2.37%\n",
      "iter 695: loss 0.5951, time 7426.75ms, mfu 2.57%\n",
      "step 700: train loss 0.5480, val loss 0.6255\n",
      "iter 700: loss 0.5490, time 62632.58ms, mfu 2.37%\n",
      "iter 705: loss 0.5847, time 7587.48ms, mfu 2.56%\n",
      "step 710: train loss 0.5343, val loss 0.6051\n",
      "saving checkpoint to out-abc-char\n",
      "iter 710: loss 0.5664, time 62455.85ms, mfu 2.36%\n",
      "iter 715: loss 0.5642, time 7389.55ms, mfu 2.57%\n",
      "step 720: train loss 0.5179, val loss 0.5977\n",
      "saving checkpoint to out-abc-char\n",
      "iter 720: loss 0.5506, time 62524.76ms, mfu 2.36%\n",
      "iter 725: loss 0.5583, time 7397.11ms, mfu 2.57%\n",
      "step 730: train loss 0.5155, val loss 0.6021\n",
      "iter 730: loss 0.5555, time 62067.04ms, mfu 2.36%\n",
      "iter 735: loss 0.5294, time 7405.71ms, mfu 2.57%\n",
      "step 740: train loss 0.4990, val loss 0.5854\n",
      "saving checkpoint to out-abc-char\n",
      "iter 740: loss 0.5217, time 62779.05ms, mfu 2.37%\n",
      "iter 745: loss 0.5190, time 7426.17ms, mfu 2.57%\n",
      "step 750: train loss 0.4828, val loss 0.5742\n",
      "saving checkpoint to out-abc-char\n",
      "iter 750: loss 0.5086, time 62760.76ms, mfu 2.36%\n",
      "iter 755: loss 0.5307, time 7521.20ms, mfu 2.56%\n",
      "step 760: train loss 0.4827, val loss 0.5800\n",
      "iter 760: loss 0.5413, time 62472.65ms, mfu 2.36%\n",
      "iter 765: loss 0.5500, time 7452.90ms, mfu 2.56%\n",
      "step 770: train loss 0.4690, val loss 0.5631\n",
      "saving checkpoint to out-abc-char\n",
      "iter 770: loss 0.5125, time 62600.19ms, mfu 2.36%\n",
      "iter 775: loss 0.5061, time 7440.78ms, mfu 2.56%\n",
      "step 780: train loss 0.4580, val loss 0.5575\n",
      "saving checkpoint to out-abc-char\n",
      "iter 780: loss 0.4937, time 62452.04ms, mfu 2.36%\n",
      "iter 785: loss 0.4705, time 7503.31ms, mfu 2.56%\n",
      "step 790: train loss 0.4466, val loss 0.5474\n",
      "saving checkpoint to out-abc-char\n",
      "iter 790: loss 0.5040, time 62324.01ms, mfu 2.36%\n",
      "iter 795: loss 0.5114, time 7383.14ms, mfu 2.56%\n",
      "step 800: train loss 0.4415, val loss 0.5487\n",
      "iter 800: loss 0.5061, time 61974.34ms, mfu 2.36%\n",
      "iter 805: loss 0.4862, time 7380.81ms, mfu 2.57%\n",
      "step 810: train loss 0.4308, val loss 0.5397\n",
      "saving checkpoint to out-abc-char\n",
      "iter 810: loss 0.4495, time 62219.18ms, mfu 2.36%\n",
      "iter 815: loss 0.4715, time 7339.23ms, mfu 2.57%\n",
      "step 820: train loss 0.4268, val loss 0.5469\n",
      "iter 820: loss 0.4855, time 61462.34ms, mfu 2.37%\n",
      "iter 825: loss 0.4625, time 7340.74ms, mfu 2.58%\n",
      "step 830: train loss 0.4085, val loss 0.5288\n",
      "saving checkpoint to out-abc-char\n",
      "iter 830: loss 0.4431, time 61696.83ms, mfu 2.37%\n",
      "iter 835: loss 0.4274, time 7341.09ms, mfu 2.58%\n",
      "step 840: train loss 0.3981, val loss 0.5287\n",
      "saving checkpoint to out-abc-char\n",
      "iter 840: loss 0.4374, time 61671.38ms, mfu 2.38%\n",
      "iter 845: loss 0.4402, time 7337.44ms, mfu 2.59%\n",
      "step 850: train loss 0.3916, val loss 0.5183\n",
      "saving checkpoint to out-abc-char\n",
      "iter 850: loss 0.4139, time 61691.19ms, mfu 2.38%\n",
      "iter 855: loss 0.4073, time 7337.49ms, mfu 2.59%\n",
      "step 860: train loss 0.3810, val loss 0.5170\n",
      "saving checkpoint to out-abc-char\n",
      "iter 860: loss 0.4228, time 61672.71ms, mfu 2.38%\n",
      "iter 865: loss 0.3968, time 7340.14ms, mfu 2.59%\n",
      "step 870: train loss 0.3689, val loss 0.5028\n",
      "saving checkpoint to out-abc-char\n",
      "iter 870: loss 0.4257, time 61682.66ms, mfu 2.38%\n",
      "iter 875: loss 0.4194, time 7342.00ms, mfu 2.59%\n",
      "step 880: train loss 0.3557, val loss 0.5004\n",
      "saving checkpoint to out-abc-char\n",
      "iter 880: loss 0.3917, time 61691.84ms, mfu 2.39%\n",
      "iter 885: loss 0.3884, time 7339.46ms, mfu 2.59%\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 253, in <module>\n",
      "    losses = estimate_loss()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"train.py\", line 214, in estimate_loss\n",
      "    losses[k] = loss.item()\n",
      "KeyboardInterrupt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 255).\u001b[0m Press Control-C to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.027 MB of 0.027 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       iter ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         lr ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        mfu ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/loss █▅▄▄▄▃▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val/loss █▅▄▄▃▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       iter 880\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         lr 0.00093\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        mfu 2.59204\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/loss 0.35575\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val/loss 0.50045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmini-char-gpt\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char/runs/yd7ifmh2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230411_170214-yd7ifmh2/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py config/train_abc_char.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test key with most occurrences: G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-abc-char\n",
      "Overriding: start = M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "number of parameters: 21.26M\n",
      "abc_char\n",
      "Loading meta from data/abc_char/meta.pkl...\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "Bc|\"G\"d2dB|dBGB|\"C\"cBAG|E2E2|\"C\"e2ee|ecAG|\"D\"FAAB|A2D2|\"D\"DFAB|dAFA|\"D\"d4-|\"G\"d4|d4|\"C\"efee|ecAG|E4|\"D\"D2F2|\"G\"B2d2|d2B|\"C\"cBAG|E2E2|\"D\"FABc|\"D\"d2d2|\"G\"d2d2|\"C\"efed|\"D\"d4|\"G\"B4|\"C\"c4|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"G\"\"C\"|\"G\"|\"D\"|\"Em\"\"D\"|\"D\"|\"G\"\"C\"|\"G\"|\"G\"\"C\"|\"G\"\"C\"|\"G\"\"D\"|\"Em\"\"D\"|\"D\"|\"Em\"\"D\"|\"Em\"\"D\"|]\n",
      "D|\"G\"GB/2G/2B/2G/2B/2G/2|\"G\"d/2B/2\"C\"e/2c/2\"G\"B/2G/2B/2G/2|\"D\"Ac/2A/2F/2A/2c/2|\"Em\"BB/2G/2\"D\"A/2F/2D/2F/2|\"D\"D/2E/2F/2G/2A/2B/2c/2|\"G\"d/2B/2\"C\"e/2c/2\"G\"B/2G/2B/2d/2|\"G\"d\"C\"e/2c/2\"G\"B/2G/2B/2d/2|\"D\"aa/2f/\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "Bc|\"G\"dBd^c/2d/2|d/2B/2GG^^G|\"C\"A2EF|A/2E/2G/2A/2GE|\"D\"D=^CB,B,|D/2E/2DB,=B,|\"D\"A,B,^B,=B,|\"D\"A,4|\"D\"A/2^^C/2AA|A/2^G/2A/2G/2A/2B/2A/2|g/2A/2G/2A/2BA/2G/2|\"G\"B/2^A/2GG|\"C\"A/2^^G/2A/2G/2E/2D/2E/2|A/2E/2G/2A/2G/2A/2G/2A/2|\"D\"D4|\"D\"A/2^C/2D/2A/2D/2A/2D/2|A/2D/2F/2D/2A/2D/2|A/2D/2F/2A/2D/2A/2|\"G\"G/2^^GE|\"C\"A/2^G/2A/2G/2A/2G/2A/2|A/2E/2G/2A/2G/2A/2|\"D\"A/2^^G/2A/2D/2A/2D/2|\"G\"GG|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:C\n",
      "|\"C\"|\"F\"|\"C\"|\"C\"|\"F\"|\"F\"\"Dm\"|\"G\"\"C\"|\"F\"|\"F\"|\"C\"\"F\"|\"Dm\"|\"G\"\"C\"|\"C\"|\"F\"\"B\"|\"C\"|\"F\"|\"F\"|\"G\"\"C\"|\"F\"|]\n",
      "C/2D/\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "B/2c/2|\"G\"d/2B/2B/2G/2B/2|d/2B/2B/2GB/2c/2|\"G\"d/2B/2G/2B/2G/2B/2c/2|d/2B/2B/2GB/2c/2|\"C\"d/2B/2G/2B/2c/2A/2B/2c/2|\"D\"d/2B/2A/2F/2A/2B/2c/2|\"D\"d/2B/2A/2F/2DB/2c/2|\"D\"d/2B/2A/2F/2DB/2c/2|\"G\"dGG|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:F\n",
      "|\"C\"|\"F\"\"C7\"|\"F\"|\"Gm\"\"C7\"|\"F\"\"C7\"|\"F\"\"C7\"|\"C7\"\"F\"|\"F\"|\"F\"|\"B\"|\"F\"|\"Gm\"|\"Gm\"\"C7\"|\"F\"|\"F\"|\"B\"|\"F\"\"C7\"|\"F\"|\"F\"|\"B\"|\"F\"|\"Gm\"\"C7\"|\"F\"|\"F\"|\"B\"|\"F\"|]\n",
      "G|\"C\"GGGA|\"F\"BA\"C7\"GA/2G/2|\"F\"FFF|c/2B/2|\"F\"Ac\"C7\"cB|\"F\"A2\"C7\"AG|\"F\"F2\"C7\"G2|\"F\"Ac\"C7\"cB|\"F\"Ac-cB/2A/2|\"F\"BAGF|\"B\"BABc|d2-d2|\"F\"c3/2B/2AB|\"Gm\"c2\"C\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "\"G\"B2B2|BAG|\"G\"BAGE|D2|\"C\"E2A2|\"D\"A2A2|\"D\"A2A2|\"D\"A4|\"D\"A2A2|\"G\"BB3|BAGA|BAGE|\"C\"D2D2|E2G2|\"G\"G2G2|z2B2|\"C\"AG3|z2E2|\"D\"F2F2|\"D\"F4|z2E2|\"G\"zEzE|z2G2|\"C\"zG3|z2E2|z2E2|\"D\"zEzE2|\"G\"zzEz|z2Ez|z2E2|z2E2|z2F2|z2E2|z2E2|z2EzE2|\"F\"z4z2|z2zz2|z2E3/2F/2|\"C\"G2zz|z2E2|z2E2|z2Ez2|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:F\n",
      "|\"F\"|\"B\"|\"F\"|\"C7\"|\"F\"|\"F\"\"C7\"|\"F\"|\"B\"|\"F\"|\"C7\"|\"F\"\"C7\"|\"F\"|\"B\"|\"F\"|\"C7\"|\"F\"\"C7\"|\"F\"|\"F\"|\"B\"|\"F\"|\"C7\"|\"F\"|]\n",
      "c/2B/2|\"F\"Ac/2B/2Ac/2A/2|\"B\"Bd/2B/2GB/2G/2|\"F\"A/2D/2CD/2FF/2F/2|\"C7\"GGGc/2B/2|\"F\"Ac/2B/2Ac/2A/2|\"F\"F/2G/2A\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "B/2c/2|\"G\"d/2B/2G/2d/2B/2G/2B/2|G/4d/2G/2B/2d/2|\"C\"c/2c/2e/2G/2c/2|\"D\"A/4A/4A/2F/2A/2B/2|\"D\"c/2A/2F/2A/2B/2|\"D\"d/2B/2c/2A/2B/2|\"G\"G/2d/2G/2B/2d/2|\"C\"c/2c/2G/2E/2G/2|\"D\"A/2D/2F/2A/2B/2|\"D\"c/2A/2F/2A/2B/2|\"G\"G/2d/2G/2B/2d/2|\"C\"c/2c/2G/2E/2G/2|\"D\"A/2F/2D/2F/2A/2B/2|\"D\"c/2A/2F/2D/2F/2A/2|\"G\"G/2B/2D/2G/2B/2|\"C\"c/2c/2G/2E/2G/2|\"D\"A/2D/2F/2A/2B/2|\"G\"G/2B/2D/2G/2B/2|\"C\"c/2E/2G/2E/2G/2|\"D\"A/2D/2F/2A/2B/2|\"G\"G/2B/2D/2G/2B/2|\"C\"c/2E/2G/2E/2G/2|\"D\"A/2D/2F/2A/2B/2|\"G\"G/2B/2D/2G/2B/2|\"C\"c/2E/2G/2E/2G/2|\"D\"A/\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "(3d/2e/2d/2|\"G\"BGG|(3d/2e/2dB|d/2e/2d/2B/2G/2B/2d(3d/2e/2d/2|\"C\"e/2d/2c/2d/2B/2c/2G/2E/2|\"D\"DFAB|\"D\"A/2B/2d/2e/2f/2e/2d/2c/2B/2A/2|\"G\"BGG|d/2c/2|\"G\"B/2d/2G/2B/2d/2G/2B/2d/2G/2d/2|\"C\"e/2d/2c/2e/2c/2G/2c/2e/2c/2|\"D\"d/2B/2G/2A/2B/2d/2c/2B/2A/2|\"G\"BGG|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:C\n",
      "|\"C\"|\"C\"|\"F\"|\"Dm\"|\"G\"|\"C\"|\"F\"|\"Dm\"|\"G\"|\"C\"|\"C\"|\"F\"|\"Dm\"|\"G\"|\"C\"|\"F\"|\"Dm\"|\"G\"|\"C\"|\"D\"|\"C\"|\"F\"|\"G\"|\"C\"|\"C\"|\"F\"|]\n",
      "e|\"C\"g/2e/2c/2e/2c/2e/2G/2c/2|B/2c/2d/2c/2d/2e/2c/2|\"C\"e/2g/2e/2c/2e/2c/2e/2d/2|c/2G/2G/2c/2e/2d/2c/2|\"F\"A/2F/2A/2c/2d/2c\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "B/2c/2|\"G\"dGB3/2B/2|d/2B/2d/2B/2B/2A/2G/2|\"C\"cGd3/2e/2|\"D\"ff3/2e/2|\"D\"ddc/2d/2e/2d/2|\"G\"BGG3/2B/2|\"C\"cGe3/2d/2|\"D\"cAA3/2A/2|\"G\"BGG|[2G2|GABG|\"C\"cGeG|cGeG|\"D\"FA3/2A/2|\"G\"BGfG|\"C\"eGeG|\"D\"FAA3/2A/2|\"G\"BgBG|\"C\"cGeG|\"D\"FA3|\"G\"BGBG|\"G\"G/2A/2B/2c/2B/2d/2c/2B/2|\"C\"c2cD|\"C\"cGeG|cGeG|F/2G/2|\"D\"AA/2A/2A/2dA|\"G\"BGBG|\"C\"cGeG|F/2G/2E/2F/2GB|\"D\"AAFA|\"G\"G2z|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:D\n",
      "|\"D\"|\"A7\"|\"D\"|\"D\"|\"D\"|\"A7\"|\"D\"|\"D\"|\"Em\"\"A7\"|\"D\"|\"D\"|\"D\"|\"D\"\"Bm\"|\"Em\"\"A7\"|\"D\"|\"D\"D\"|\"A\"|\"D\"\"G\"|\"A7\"|\"D\"|\"D\"|\"Em\"\"A7\"|\"D\"|\"D\"|\"G\"\"A7\"|\"D\"|\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "g/2f/2|\"G\"ed/2B/2|G/2B/2d/2g/2|\"C\"e/2c/2e/2g/2|\"Dm\"f/2d/2c/2d/2|\"D\"cA/2g/2|\"D\"f/2d/2c/2d/2|\"G\"e/2B/2G/2d/2|\"C\"e/2c/2e/2g/4|\"D\"f/2d/2c/2d/2|\"G\"B/2G/2B/2|\"C\"c/2e/2g/2|\"D\"f/2d/2c/2d/2|\"G\"B/2G/2B/2|\"C\"c/2e/2g/2|\"D\"f/2d/2c/2d/2|\"G\"B/2G/2B/2|\"C\"c/2e/2g/2|\"D\"f/2d/2c/2d/2|\"G\"B/2G/2B/2|\"C\"c/2e/2g/2|\"D\"f/2d/2c/2d/2|\"G\"B/2G/2B/2d/2|\"C\"e/2c/2e/2g/2|\"D\"f/2d/2c/2d/2|\"G\"B/2G/2B/2d/2|\"C\"e/2c/2e/2g/2|\"D\"f/2d/2c/2d/2|\"G\"B/2G/2B/2d/2|\"C\"g/2c/2e/2g/2|\"D\"f/2d/2c/2d/2|\"G\"B/2G/2B/2d/2|\"C\"e/2c/2e/2g/2|\"D\"f/2d/2c/2d/2|\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d|\"G\"d/2B/4B/4B/4G/2d/2|d/4B/4B/4B/4G/2d/2|\"C\"c/4d/4c/4B/4A/2c/2|\"D\"B/4A/4B/4c/4B/4A/2D/2|\"D\"A,/2D/2D/2c/2|\"G\"B/4G/4G/4F/4G/2G|\"C\"c/4d/4e/4f/4e/4c/4c/4e/4c/4|\"D\"d/4B/4c/4A/4F/2A/2|\"D\"f/4d/4A/4F/4A/4d/2|\"D\"f/4d/4A/4F/4A/2d/2|\"G\"B/4G/4F/4G/4B/4G/4B/4G/4|\"C\"c/4d/4e/4f/4e/4c/4G/2|\"D\"f/4d/4A/4F/4A/2|\"G\"B/4G/4F/4G/4B/4G/4B/4|\"C\"c/4d/4e/4f/4e/4c/4G/4|\"D\"f/4d/4A/4F/4A/2|\"G\"B/4G/4B/4d/4B/4G/4B/4|\"C\"c/4d/4e/4f/4e/4c/4G/4|\"D\"f/4d/4A/4F/4A/4d/4|\"D\"f/4d/4A/4F/2D/2|\"G\"G/4B/4G/4B/4d/4B/4|\"C\"c/4d/4e/4f/4e/4c/4\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "\"G\"B/4B/4B/4B/2B/4B/4|G/2B/2B/2|G/2B/2B/2|\"C\"e/2d/2c/2c/2|cA|\"D\"d/2e/2d/4c/4d/2|\"G\"B/2B/2B/2|B/2B/2B/2|\"C\"e/2d/2c/2c/2|c/2B/2B/4c/4B/4|\"D\"A/2A/2D/2E/2|\"D\"F/2A/2E/2D/2|F/2D/2F/2|\"G\"G/2B/2B/2B/2|G/2B/2B/2|\"C\"e/2d/2c/2c/2|\"D\"A/2d/2c/2d/2|F/2A/2D/2|\"G\"B/2B/2B/2A/4B/4|\"C\"d/2c/2c/2B/4c/4|c/2B/2B/4c/4|\"D\"d/2d/2c/4d/4|F/2A/2D/2|F/2D/2F/2|\"G\"B/2B/2A/4B/4|G/2B/2B/4G/4|\"C\"e/2d/2c/2|c/2G/2B/2|\"D\"D3/2|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:F\n",
      "|\"F\"|\"B\"|\"F\"|\"C\"|\"C\"|\"C\"|\"B\"|\"F\"|\"B\"|\"F\"|\"B\"|\"Dm\"\"Gm\"|\"C\"|\"F\"|\"C\"|\"F\"|\"B\"|\"F\"|\"B\"|\"F\"|\"B\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start='M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test major key with low samples: C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-abc-char\n",
      "Overriding: start = M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "number of parameters: 21.26M\n",
      "abc_char\n",
      "Loading meta from data/abc_char/meta.pkl...\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "EF|\"C\"CE/2G/2cB/2A/2G/2|\"F\"AFF/2A/2F/2A/2|\"G\"Ggg^f|\"G\"d/2^c/2d/2e/2d/2c/2B/2G/2|\"C\"CE\"CEF/2A/2|\"C\"Ggec/2G/2c/2E/2|\"F\"CDFA|\"G\"GgGf|\"G\"d/2^c/2d/2e/2d/2c/2B/2A/2G/2|\"C\"CEFG|\"F\"AFF|\"C\"Egg^f/2g/2|\"F\"a/2g/2e/2f/2d/2c/2B/2c/2|\"G\"d/2^c/2d/2e/2d/2c/2B/2G/2|\"C\"Cgfe/2c/2|\"F\"Aff^f|\"G\"d/2^c/2d/2e/2d/2c/2B/2c/2|\"C\"Egg^f|\"F\"AFF|\"C\"Egg^^F/2G/2|\"F\"Acf^f|\"G\"d/2^c/2d/2e/2d/2c/2B/2c/2|\"C\"Egg^f|\"F\"AFFe/2d/2|\"G\"GGf^^F|\"C\"Egg^^F/2G/2|\"F\"Aff^^F|\"Bb\"GDFA|\"C\"Ggg^^F/2G/2A/2B/2|\"F\"cFF|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"Gg\"|\"Cg\"|\"Gg\"\"D7\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "G|\"C\"e/2d/4c/4B/2G/2|\"F\"A/2c/2c/2A/2|A/2c/2G/2F/2|\"F\"A/2c/2d/2c/2|A/2c/2G/2F/2|\"G\"B/2B/2B/2A/2G/4A/4|\"C\"G/2c/2c/2G/2|E/2G/2C/2c/2|\"F\"A/2c/2c/2d/2c/2|A/2c/2G/2F/2|\"G\"G/2B/2B/2D/2G/2|\"C\"E/2G/2C|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:D\n",
      "|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"|\"A7\"|\"D\"|\"G\"\"D\"|\"G\"|\"A7\"|\"D\"|\"D\"\"D\"|\"Em\"\"A7\"|\"D\"|\"G\"|\"A7\"|\"D\"|\"D\"\"D7\"|\"G\"\"D\"|\"A7\"|\"D\"|\"D\"\"D7\"|\"G\"|\"A7\"|\"D\"|\"G\"\"D\"|\"A7\"\"D\"|]\n",
      "A,|\"D\"DD/2E/2F/2A/2d/2e/2|f/2e/2d/2c/2B/2A/2F/2|\"G\"DG/2B/2\"D\"AF/2A/2|\"Em\"GEEF/2G/2|\"A7\"A/2B/2A/2G/2EA,|\"D\"DD/2E/2F/2A/2d/2e/2|\"G\"f/2e/2d/2c/2B\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "B/2c/2|\"C\"g/2e/2c/2G/2c/2|g/2e/2c/2G/2c/2|\"F\"a/2f/2d/2c/2|\"G\"B/2c/2d/2B/2|G/2GB/2c/2|\"G\"d/2B/2G/2B/2c/2|\"C\"g/2e/2c/2G/2c/2|\"F\"a/2f/2d/2c/2|\"G\"B/2c/2d/4B/4G/2B/2|\"C\"g/2e/2c/2G/2|\"F\"a/2f/2d/2c/2|\"G\"B/2G/2B/2G/2|\"C\"g3/2e/2|\"F\"f3/2e/2|]\n",
      "\n",
      "M:2/4\n",
      "L:1/4\n",
      "K:C\n",
      "|\"F\"|\"F\"|\"B\"|\"F\"|\"Dm\"|\"G\"|\"C\"|\"F\"|\"B\"|\"F\"|\"C\"|\"F\"|\"C\"|\"F\"|\"F\"|\"B\"|\"F\"|\"C\"|\"C\"|\"F\"|\"C\"|\"F\"|\"Dm\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|\"F\"|\"B\"|\"F\"|\"C\"|\"F\"|]\n",
      "\"F\"c2c|\"B\"f2f|\"F\"c2A|\"Dm\"f2c|\"G\"e2d|\"C\"c3|\"F\"c2c|\"B\"f2d|\"F\"c2A|\"C\"G2F|\"F\"F3-|\"F\"FGA|\"B\"BAB|\"F\"c2d|\"C\"c2G|\"F\"A2B|\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "\"C\"C/2G/2A/2G/2E/2G/2E/2|G/2A/2G/2E/2CE|\"F\"A/2F/2A/2c/2f/2e/2d/2c/2|\"G\"BGGB/2A/2|\"G\"G/2B/2d/2c/2B/2A/2G/2|\"C\"c/2B/2A/2G/2E/2C/2E/2G/2E/2|G/2A/2G/2E/2C/2E/2G/2A/2|\"F\"A/2F/2A/2c/2f/2e/2d/2c/2|\"G\"B/2G/2B/2d/2c/2B/2A/2G/2|\"G\"BGG/2F/2|\"C\"E/2G/2c/2d/2e/2c/2G/2c/2|\"F\"A/2F/2A/2c/2f/2e/2d/2c/2|\"G\"B/2G/2B/2d/2c/2B/2A/2G/2|\"C\"E/2G/2c/2d/2e/2c/2G/2|\"F\"A/2F/2A/2c/2f/2e/2d/2c/2|\"G\"B/2G/2B/2d/2c/2B/2A/2G/2|\"C\"E/2G/2c/2d/2e/2c/2G/2|\"F\"A/2F/2A/2c/2f/2e/2d/2c/2|\"G\"BGG|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"D7\"|\"G\"|\"D7\"|\"G\"\"D7\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "E/2F/2|\"C\"GG/2B/2c/2d/2e/2|c/2G/2c/2G/2c/2|d/4e/4c/2G/2E/2G/2|\"F\"F/2A/2A/2G/2F/2|\"G\"d/2B/2G/2B/2A/2G/2|\"G\"d/2B/2G/2A/2G/2F/2|\"C\"E/2G/2G/2G/2c/2d/2e/2|c/2G/2c/2d/2e/2d/2c/2|\"F\"A/2F/2A/2G/2F/2|\"G\"B/2G/2D/2G/2B/2c/2d/2|\"C\"e/2c/2G/2c/2d/2e/2d/2c/2|\"F\"A/2F/2A/2c/2c/2f/2c/2A/2|\"G\"G/2B/2D/2G/2B/2G/2d/2G/2|\"C\"e/2c/2G/2c/2e/2c/2G/2c/2|e/2G/2c/2e/2G/2c/2e/2G/2|c/2G/2c/2e/2G/2c/2G/2c/2G/2|e/2G/2c/2e/2c/2G/2c/2G/2|e/2G/2c/2G/2e/2G/2c/2G/2|e/2c/2G/2e/2c/2G/2c/2G/2|e/2G/2c/2G/2e/2G/2c/2G/2|e/2c/2g/2c/2e/2c/2\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "(3G/2A/2B/2|\"C\"cGEG(3G/2A/2B/2|c/2G/2E/2G/2d/2G/2(3G/2A/2B/2|\"F\"cFF/2G/2A/2B/2c/2|\"G\"d/2G/2A/2B/2c/2d/2G/2A/2B/2|\"G\"G/2A/2G/2A/2B/2c/2B/2A/2G/2|\"C\"c/2G/2E/2G/2c/2G/2d/2G/2(3G/2A/2B/2|\"F\"cFF/2G/2A/2B/2c/2|\"G\"d/2G/2(3G/2A/2G/2e/2G/2d/2G/2|\"C\"cEC|e/2f/2|\"C\"g/2e/2c/2e/2g/2c/2e/2g/2c/2|\"F\"A/2F/2c/2A/2f/2c/2f/2c/2|\"G\"d/2B/2g/2B/2g/2d/2g/2d/2|\"C\"e/2c/2e/2g/2c/2e/2g/2c/2|\"F\"A/2F/2c/2A/2f/2c/2a/2f/2|\"G\"g/2B/2d/2g/2d/2B/2g/2d/2|\"C\"e/2c/2e/2g/2c/2e/2g/2c/2|\"F\"A/2F/2c/2A/2f/2c/2A/2|\"G\"d/2B/2g/2B/2g/2d/2B/2\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "G/2F/2|\"C\"EG/2F/2EG/2E/2|Gc/2G/2E/2c/2G/2C/2|\"F\"FA/2F/2AF/2A/2|\"G\"Gc/2=B/2\"G\"G/2A/2B/2G/2|\"C\"EG/2F/2EG/2E/2C/2|Gc/2G/2EG/2C/2|\"F\"FA/2F/2AF/2A/2|\"G\"Gc/2=B/2A/2B/2c/2d/2|\"C\"ec/2G/2EG/2E/2|Gc/2G/2EG/2C/2|\"F\"FA/2F/2AF/2A/2|\"G\"Gc/2=B/2A/2B/2c/2d/2|\"C\"ec/2G/2EG/2C/2|Gc/2G/2EG/2C/2|\"F\"FA/2F/2AF/2A/2|\"G\"Gc/2=B/2A/2B/2c/2d/2|\"C\"ec/2G/2EG/2C/2|Gc/2G/2EG/2C/2|\"F\"FA/2F/2AF/2A/2|\"G\"Gc/2G/2EG/2C/2|\"C\"Gc/2G/2EG/2C/2|\"F\"AF/2A/2C/2F/2A/2|\"G\"Gc/2G/2EG/2C/2|\"C\"Gc/2G/2EG/2C/2|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:C\n",
      "|\"C\"|\"F\"|\"F\"|\"C\"|\"C\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "g/2|\"C\"g/2e/4d/4c/2|G/2G/2G/2|\"F\"A/2A/2A/2z/4c/4|\"G\"B/2B/2B/2|B3/2A/4B/4|\"C\"c/2G/2G/2z/2|\"F\"A/2A/2A/2z/4c/4|\"G\"B3/2B/2|\"C\"c/2G/2G/2z/2|\"F\"A/2A/2A/2z/4c/4|\"G\"BB/2B/2|B3/2B/2|\"C\"c/2G/2E/2G/2|FE/2G/2z/4c/4|\"F\"A/2A/2A/2z/2|\"G\"B/2G/2D/2E/2|FB/2G/2|\"C\"cc|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:F\n",
      "|\"F\"|\"F\"|\"C\"|\"G\"|\"C\"|\"C\"|\"F\"|\"F\"|\"F\"|\"G\"|\"C\"|\"C\"|\"F\"|\"F\"|\"F\"|\"C\"|\"F\"|\"F\"|\"G\"|\"C\"|\"C\"|\"F\"|\"F\"|\"F\"|\"B\"|\"C\"|\"F\"|\"B\"|\"F\"|\"C\"|\"F\"|\"F\"|\"F\"|\"B\"|\"C\"|\"F\"|]\n",
      "|(3c/2d/2e/2|\"F\"f/2c/2Af/2d/2|f/2A/2f/2Gf/2c/2|d/2A/2f/2A/2f/2A/2|\"F\"f/2d/2c/2A/2f/2\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "c/2d/4|\"C\"e/2e/2e/2c/2|E/2G/2A/2G/2|\"F\"A/2c/2c/2A/2|\"G\"G/2B/2B/2B/2c/2|\"G\"d3/2B/4c/4|\"G\"B/2d/2G/2|\"C\"E/2G/2A/2G/2|\"F\"A/2c/2c/2A/2|\"G\"G/2B/2B/2c/2|\"C\"E/2G/2A/2G/2|\"F\"A/2c/2A/2c/2|\"G\"B/2d/2G/2B/2|\"C\"E/2G/2A/2G/2|\"F\"A/2c/2c/2A/2|\"G\"G//2B/2d/2c/2|\"C\"E/2G/2A/2G/2|\"F\"A/2c/2c/2A/2|\"G\"G/2B/2d/2G/2|\"C\"E/2G/2A/2G/2|\"F\"A/2c/2c/2A/2|\"G\"G/2B/2d/2c/2|\"C\"E/2G/2A/2G/2|\"F\"A/2c/2c/2A/2|\"G\"G/2B/2d/2c/2|\"C\"E/2G/2A/2G/2|\"F\"A/2c/2c/2A/2|\"G\"B/2d/2G/2B/2|\"C\"E/2G/2A/2G/2|\"F\"A/2c/2c/2A/2|\"G\"B/2d/2G/2B/2|\"C\"c/2A/2G/2E/2|\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "\"C\"E/2G/2A/2c3/4d/4|e/2c/2G/2G/2|\"C\"E/2G/2A/2c/2|\"F\"c/2A/2c/2A/2|\"G\"G/2B3/2G/4F/4|\"G\"D/2E/2F/2G/2|\"C\"E/2G/2A/2c/2|\"G\"B/2B/2G/2F/2|\"C\"E/2G/2C/2E/2G/2|\"F\"A/2A/2C/2A/2G/2|\"G\"A/2B/2G/2F/2|\"C\"E/2G/2C/2E/2G/2|\"F\"A/2A/2C/2F/2|\"G\"D/2B,/2D/2C/2|\"C\"E/2G/2C/2E/2G/2|\"F\"A/2c/2A/2c/2|\"G\"B/2G/2B/2c/2|\"C\"E/2G/2C|]\n",
      "\n",
      "M:6/8\n",
      "L:1/8\n",
      "K:F\n",
      "|\"F\"|\"B\"|\"F\"\"C\"|\"F\"|\"F\"|\"F\"\"C\"|\"F\"\"B\"|\"C\"\"F\"|\"F\"|\"F\"|\"F\"\"C\"|\"F\"|\"F\"|\"F\"|\"B\"\"C\"|\"F\"|\"F\"|\"B\"\"C\"|\"F\"|\"D\"\"Gm\"|\"C\"\"F\"|\"F\"|\"F\"|\"F\"|\"B\"\"C\"|\"F\"|\"F\"|\"F\"\"C\"|\"F\"\"C\"|\"F\"|]\n",
      "F/2|\"F\"F/2G/2A/2c/2B/2\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start='M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test minor key with low samples: Am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-abc-char\n",
      "Overriding: start = M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "number of parameters: 21.26M\n",
      "abc_char\n",
      "Loading meta from data/abc_char/meta.pkl...\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "E|\"Am\"C/2A/2B/4A/4G/2|A/2c/2c/4B/4A/2|\"Am\"C/2A/2B/4A/2G/2|\"Dm\"F/2A/2G/2F/2|\"E\"EE|\"Am\"A/2c/4B/4A/2G/2|A/2c/2c/4B/4A/2|\"Dm\"F/2A/2G/2F/2|D/2F/2A/4G/4|\"E\"E/2E/2E\"Am\"A/4B/4c/4B/2A/2|\"Am\"A/2c/2c/4B/4A/2|\"Dm\"F/2A/2G/2F/2|D/2F/2A/4G/4F/2|\"E\"E/2E/2E|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:C\n",
      "|\"C\"\"G7\"|\"C\"\"G7\"|\"C\"|\"Am\"\"G7\"|\"C\"\"G7\"|\"C\"\"G7\"|\"C\"|\"G\"|\"F\"\"Am\"|\"G7\"|\"C\"\"D7\"|\"G\"|\"F\"\"G7\"|\"C\"\"G7\"|\"C\"|\"G\"|\"F\"\"Am\"|\"E#m\"\"Am\"|\"D7\"\"G7\"|\"C\"|\"G\"|]\n",
      "G/2A/2|\"C\"cc\"G7\"Bc/2d/2|\"C\"ee\"G7\"dc/2B/2|\"C\"cc/2A/2G/2E/2G/2|\"Am\"cc\"G7\"Bc/2d/2|\"C\"ee/2f/2eg|\"Am\"a/2\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "\"Am\"ae/2d/2c/2B/2A/2|\"Dm\"d/2^c/2d/2e/2f/2e/2d/2c/2|\"E\"^B/2E/2EE/2F/2G/2E/2|\"Am\"c/2B/2A/2G/2A/2B/2c/2d/2|\"E\"^B/2E/2EE/2^F/2G/2|\"Am\"A/2^G/2A/2B/2c/2d/2e/2^f/2|\"Dm\"g/2f/2e/2c/2\"Dm\"d/2^c/2d/2c/2|\"E\"^B/2ED/2E/2^F/2G/2E/2|^F/2G/2B/2E/2^F/2G/2B/2A/2|^G/2E/2G/2B/2e^f/2g/2|\"Am\"a/2^g/2a/2b/2a/2g/2f/2e/2|\"Dm\"c/2A/2A/2B/2c/2d/2^c/2|\"E\"B/2E/2Ee/2^F/2G/2|\"Am\"A/2^G/2A/2B/2c/2d/2e/2|\"E\"^G/2E/2G/2B/2e/2^f/2g/2|\"Am\"a/2^g/2a/2b/2a/2g/2f/2e/2|\"Dm\"c/2A/2A/2B/2c/2d/2e/2|^f/2^f/2g/2a/2^g/2f/2|\"E\"^G/2G/2G/2B/2e/2^f/2|\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "\"Am\"A/2B/2c/2B/2A/2|E/2A/2c/2B/2A/2|\"Dm\"d3/4e/4f/2e/2|\"E\"B/2G/2G/2F/2|E/2G/2B/2A/2|\"E\"B3/2B/2|\"Am\"A3/2B/4c/4|\"Dm\"d/2e/2f/2e/2|\"E\"B/2G/2G/2F/2|E/2G/2B/2A/2|\"Am\"c3/2B/2|\"Dm\"A/2d/22e/2|\"E\"B/2G/2G/2F/2|E/2G/2B/2A/2|\"Am\"c3/4B/4c/2|\"Dm\"d/2e/2f/2e/2|f/2e/2d/2|\"E\"B/2G/2G/2F/2|E/2G/2B/2|\"Am\"c3/4B/4c/2|\"Dm\"d/2e/2f/2e/2|f/2e/2d/2c/2|\"E\"B/2G/2E/2G/2|E/2G/2B/2A/2|\"Am\"c3/2B/2|]\n",
      "\n",
      "M:2/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"Em\"|\"D\"|\"G\"|\"D\"|\"D\"|\"G\"\"D\"|\"Em\"\"Bm\"|\"Em\"|\"Em\"|\"Am\"\"D\"|\"Em\"\"Bm\"|\"Em\"|\"Em\"|\"Em\"|\"D\"|\"G\"\"D\"|\"Em\"\"Bm\"|\"Em\"|\"Em\"|\"\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "\"Am\"A3/4B/4c3/4B/4|\"Am\"c3/4B/4c3/4B/4|\"Dm\"A3/4B/4c3/4B/4|\"E\"G3/4B/4B/2G3/4F/4|\"E\"E3/2d/2|\"Am\"c3/4B/4c3/4B/4|\"Dm\"A3/4B/4c/4B3/4A/4|\"E\"G3/4B/4c3/4B/4|\"Am\"A3/4B/4c3/4B/4|\"Dm\"A3/4B/4c3/4B/4|\"E\"G3/4B/4e3/4d/4|\"Am\"c3/4B/4c3/4B/4|\"Dm\"A3/4B/4c3/4B/4|\"E\"G3/4B/4e3/4d/4|\"Am\"c3/4B/4c3/4B/4|\"D\"A3/4B/4c3/4B/4|\"E\"G3/4B/4e3/4d/4|\"Am\"c3/4B/4\"D\"A3/4c/4|\"G\"B3/4d/4c3/4B/4|\"Am\"A3/4B/4c3/4B/4|\"D\"A3/2c/2|\"Em\"G3/4B/4e3/4d/4|\"Am\"c3/4B/4a3/4|\"Am\"c3/4B/4a3/4g/4|\"D\"f3/4e/4g3/4f/4|\"Em\"e3/4d/4c3/4B/4|\"Am\"A3/2c/2|\"Em\"G3/2B/2\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "F/2G/2|\"Am\"A/2B/4c/2A/2c/2|e/2c/2A/2c/2|\"Dm\"d/2A/2F/2d/2|\"E\"e(3e/2d/2e/2B/2e/2^d/2|e/2c/2A/2c/2B/2A/2|\"Am\"c/2e/2A/2c/2c/2|\"Dm\"d/2e/2d/2c/2d/2e/2|a/2g/2f/2e/2d/2c/2|\"E\"^B/2EG/2EF/2G/2|\"Am\"A/2B/2c/2d/2e/2^d/2c/2|\"Dm\"d/2e/2d/2c/2d/2e/2f/2g/2|\"E\"e/2^d/2e/2B/2e/2^d/2e/2^d/2|e/2c/2A/2c/2A/2e/2A/2|\"Am\"c/2e/2d/2c/2e/2d/2c/2|c/2e/2d/2c/2e/2a/2d/2c/2|\"Dm\"d/2e/2d/2c/2\"E\"^B/2E/2F/2G/2|A/2B/2c/2d/2c/2d/2e/2^d/2|\"Am\"c/2A/2(3E/2F/2E/2E|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:F#\n",
      "|\"F\"|\"E\"|\"F\"|\"F\"|\"F\"|\"F\"|\"F\"|\"C\"|\"F\"|\"E\"|\"F\"|\"F\"|\"B\"|\"\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "(3E/2F/2G/2|\"Am\"(3A/2B/2A/2(3G/2A/2A/2A/2(3G/2A/2G/2|A/2B/2c/2e/2d/2c/2B/2A/2|\"Am\"G/2A/2B/2A/2G/2A/2B/2|\"Dm\"(3c/2B/2A/2(3c/2B/2A/2a/2f/2B/2e/2^f/2|\"E\"e/2^d/2e/2f/2g/2\"Am\"a/2A/2(3E/2F/2G/2|\"Am\"(3A/2B/2A/2(3c/2B/2A/2a/2A/2(3G/2A/2B/2|A/2g/2A/2(3F/2G/2a/2A/2(3g/2f/2e/2A/2|\"Dm\"d/2A/2(3F/2G/2a/2d/2(3c/2B/2A/2|\"E\"e/2^d/2e/2f/2g/2e/2^f/2|b/2^a/2b/2c'/2b/2a/2g/2|\"Am\"a/2c'/2a/2b/2c'/2b/2a/2^g/2|\"Dm\"a/2g/2a/2g/2a/2b/2a/2=g/2|\"E\"e/2^d/2e/2f/2g/2a/2b/2|\"Am\"c'/2a^g/2a/2b/2a/2=g/2|a/2c'/2a/2b/2a/2(g/2)f/2e/2\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "\"Am\"A3/2B/2G/2|A/2B/2G/2E/2|\"Dm\"F/2E/2F/2G/2|A3/4B/4G/2E/2|\"E\"E/2F/2G/2E/2|\"E\"E3/2F/2|\"Am\"A3/4B/4c/2B/2|\"Dm\"A3/4B/4G/2E/2|\"E\"E3/2F/2|[/4F/4G/2E/2B/2|\"Am\"A3/2B/2|\"Dm\"A/2A/2G/2E/2|\"E\"E3/2F/2G/2|\"Am\"A3/4B/4c/2B/2|\"Dm\"A/2D/2C/2E/2|G/2E/2\"E\"E/2F/2|\"Am\"A3/4B/4c/2B/2|\"Dm\"A3/4B/4c/2A/2|\"E\"E/2F/2G/2E/2|\"Am\"A3/4B/4c/2B/2|\"Dm\"A/2D/2C/2E/2|\"E\"E3/2|F/4G/4|\"Am\"A/2C/2C/2B/2|A/2C/2c/2|\"Dm\"A/2D/2C/2B/2|A3/4B/4c/2B/2|\"E\"E/2F/2G/2|E/2B/2E/2|\"Am\"A3/2B/2|]\n",
      "\n",
      "M:2/4\n",
      "L:1/4\n",
      "K:B\n",
      "|\"B\"|\"Cm\"\"F7\"|\"B\"|\"F7\"\"B\"|\"E\"|\"F\"\"C7\"|\"F\"|\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "c/2d/2|\"Am\"e/2A/2a/2A/2e/2|a/4A/4A/4A/2a/2|\"E\"g/2g/2g/4e/2d/2|\"Am\"e/2A/2g/2A/2|\"Dm\"f/2f/2d/4B/4A/2|\"E\"^G/2E/\"E\"e|\"Am\"e/2e/2e/4d/4c/2|a/4A/4A/2A/2g/2|\"Dm\"f/2f/2f/4d/4B/2|\"E\"^G/2E/2G/2B/2|\"Am\"A/2G/2A|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:F#\n",
      "|\"F\"|\"F\"|\"Gm\"|\"C\"|\"C\"|\"C7\"|\"F\"|\"F\"|\"F\"\"C\"|\"Gm\"\"C7\"|\"F\"|\"F\"|\"C\"|\"Gm\"|\"C\"|\"C\"|\"C7\"|\"F\"\"C7\"|\"F\"|\"Gm\"\"C7\"|\"F\"|]\n",
      "A/2B/2|\"F\"c/2d/2c/2B/2A/2F/2A/2B/2|c/2d/2c/2A/2FA|\"F\"F/2G/2A/2B/2cc|\"Gm\"d/2c/2B/2A/2GG/2A/2|\"C\"B/2A/2G/2F/2E/2CA,/2B,/2|\"C\"G,/2C/2D/2E/2GG/2A/2|\"C7\"B/2A/2G/2F/2E/2G/2c/2B/2|\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "c/2d/4|\"Am\"e/2A/2e/2c/2|A/4G/4A/4B/2c/2|\"Dm\"d3/2c/2|\"E\"B/2E/2e/2d/4c/2|\"E\"B/2E/2B/2d/2|\"Am\"c/2A/2c/2B/2|\"Dm\"A3/2c/4B/4|A/2G/2F/2E/2|\"E\"E3/2G/2|\"Am\"A/2A/4A/4|\"Dm\"d/2d/2d/2c/2|\"E\"B/2E/2e/2d/2c/2|\"Am\"A/2A/4A/4A/2B/2|\"Dm\"d/2d/2d/2c/4B/4|\"E\"e/2E/2e/2d/2|\"Am\"c/2A/2c/2B/4G/4|\"Dm\"AF|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:D\n",
      "|\"D\"|\"D\"|\"D\"|\"A\"|\"A\"|\"D\"|\"D\"|\"D\"|\"D\"|\"A\"|\"A\"|\"A\"|\"A\"|\"D\"|\"A\"|\"D\"|\"D\"\"A\"|\"D\"|\"D\"|]\n",
      "a/2g/2|\"D\"ff/2e/2dA/2B/2|A/2G/2A/2B/2df/2a/2|\"D\"f/2d/2A/2B/2d/2f/2a/2|\"A\"g/2e/2c/2AA/2B/2|\"A\"c/2A/2B/2c/2e/2a/2g/2|\"D\"f/2d\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "\"Am\"a/2a/4a/4e/4c/2|a/2a/2e/4f/4|\"Dm\"dd|\"G\"B/2d/4c/4c/2B/2|\"Am\"AA|\"E\"b/2b/2b/4a/4f/2|\"Am\"e/2a/4a/4e/4f/2|\"E\"g/2g/2g/2e/4f/4|\"E\"g/2g/2g/2f/4g/4|\"Am\"a/2a/2a/4e/4f/2|\"Dm\"dd|\"Am\"a/2a/4a/4a/4a/4f/4e/4|\"Dm\"dd|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"Am\"|\"Am\"\"D7\"|\"G\"|\"Am\"|\"D7\"|\"G\"|\"Am\"|\"G\"\"Am\"|\"Am\"|\"Am\"\"D7\"|\"G\"|\"Am\"\"D7\"|\"G\"|\"Am\"\"D7\"|\"G\"\"Am\"|\"G\"\"Am\"|\"Am\"|\"G\"|\"Am\"|\"D\"|]\n",
      "B/2c/2|\"G\"dBBd|\"Am\"dcAc/2B/2|\"Am\"AA\"D7\"AB/2c/2|\"G\"dBBd|bagf|\"Am\"e/2d/2c/2B/2\"D7\"AB/2c/2|\"G\"dBBd|\"Am\"dccB/2c/2|\"D7\"dcBA|\"G\"G2G|d|\"Am\"ee/2e/2ee|\"G\"gf/2g/\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start='M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test older checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = older_ckpt/m_voices\n",
      "Overriding: path_meta = older_ckpt/m_voices\n",
      "Overriding: start = M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "number of parameters: 14.18M\n",
      "shakespeare_char\n",
      "Loading meta from older_ckpt/m_voices/meta.pkl...\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]G/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]G/2E\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d2|\"G\"B3/2g/2d3/2B/2G3/2B/2d3/2B/2|\"D\"c3/2e/2a3/2g/2f3/2d/2e3/2f/2|\"G\"B3/2g/2d3/2B/2g3/2d/2B3/2d/2|\"D\"c3/2A/2d3/2A/2e3/2A/2f3/2A/2|\"G\"g3/2d/2B3/2d/2g3/2b/2a3/2g/2|\"D\"f3/2d/2A3/2d/2f3/2a/2g3/2f/2|\"C\"e3/2d/2c3/2B/2\"D\"c3/2e/2d3/2c/2|\"G\"B2G2G2d2|\"D\"ADBDcDdc|\"G\"BGcG^cGdG|\"D\"ADBDcDd2|\"G\"edd^cd4|\"D\"ADBDcDdc|\"G\"BGcG^cGd2|\"C\"ecgc\"D\"fcac|\"G\"g2b2g4|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:Eb\n",
      "|\"D\"|\"G\"\"A\"|\"D\"|\"Em\"\"A\"|\"D\"|\"G\"\"A\"|\"G\"\"A\"|\"D\"|\"G\"\"D\"|\"G\"\"D\"|\"G\"\"D\"|\"E\"\"A\"|\"G\"\"D\"|\"G\"\"D\"|\"G\"\"D\"|\"E\"\"A\"|\"A\"\"D\"|]\n",
      "A/2|\"D\"d/2c/2d/2e/2fA|\"G\"Be\"\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2f/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d2|\"G\"G/2B/2d3/4d/4|\"C\"e/2e/2c/2A/2|\"D\"F/2A/2D/2|\"D\"F/2A/2D/2d/2|\"D\"=c/2d/2A/2^G/2A/2|\"G\"B/2G/2d3/2e/4|\"G\"d/2B/2G/2A/2|\"C\"E/2G/2D/2=CD/2|\"D\"F/2A/2d/4d/4f/4e/4|\"G\"g/2G/2G/2|\"C\"c/2G/2c/2e|\"D\"d/4c/4B/4A/2f/4|\"G\"g/2d/2B/2G/2|\"D\"F/2A/2D/2A/4d/4|\"G\"B/2G/2d/4d3/4d/4|\"D\"A/2d/4c/4B/4A/2|\"G\"G/2B/2G/2|\"C\"E/2G/2\"G\"G|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:B\n",
      "|\"A\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"A\"\"Bm\"|\"E\"\"A\"\"A\"|\"D\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"D\"|\"A\"\"Bm\"|\"E\"\"A\"|\"A\"\"Bm\"|\"E\"\"A\"|]\n",
      "z/2|\"A\"z/2A/2-A/2G/2AA|\"Bm\"B/2c/2B/2A/2\"E\"GE|\"A\"z/2A/2-\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d/2|\"G\"B3/2G/2G/2|\"C\"cBc|\"D\"d2d|\"G\"G2B/2c/2|\"G\"d3/2B/2GG|\"C\"cB\"D\"AB/2c/2|\"G\"d2\"C\"e/2c/2|\"G\"d2g3/2B/2|\"D\"cABc|\"G\"d2\"C\"e3/2d/2|\"D\"fzde/2f/2|\"G\"g3/2e/2d3/2e/2|g/2c/2B/2A/2G2|\"D\"A2g3/2f/2|\"G\"g3/2d/2B/2\"C\"cB|\"D\"Ad\"G\"g3/2f/2|\"Em\"g/2e/2\"A\"^c/2\"D\"d2|\"A\"e/2d/2c/2d/2eA/2c/2|\"D\"d2\"G\"B/2A/2G/2A/2|\"D\"FDD|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"A\"|\"E\"|\"E\"|\"A\"|\"E\"\"A\"|\"A\"|\"F#m\"|\"Bm\"\"E\"|\"Bm\"\"E\"|\"A\"\"Bm\"|\"A\"\"E\"|\"A\"\"A\"|]\n",
      "e|\"A\"a3/2g/2a/2e/2c/2A/2|\"E\"BGE3/2E/2|\"/2F/2A/2AB/2c/2|\"Bm\"dc\"E\"e3/2d/2|\"A\"c3/2B/2A\"E\"B/2^G/2E/2B/2d/2c/2B/2|\"A\"A\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2e/2|\"G\"g/2d/2B/2|GB/2A/2|\"G\"G/4A/4B/4c/4d/2g/2|d/2B/2B/2g/2|\"F\"=f/2A/2A/2B/2|cA\"G\"G/4A/4B/4c/4d/2B/2|\"C\"e/2d/4c/4\"G\"d/2B/2|\"G\"G/4A/4B/4c/4d/2B/2|dB|\"G\"G/4A/4B/4c/4d/2B/2|\"C\"e/2d/4c/4d/2e/2|\"F\"=f/2A/2A/2B/2|cA\"G\"g/2d/2B/4c/4d/4B/4|g/2d/2B/4c/4d/4B/4|\"G\"g/2d/2B/4c/4d/4B/4|gd|\"G\"g/2d/2B/4c/4d/4B/4|g/2d/2B/4c/4d/4B/4|\"D\"a/4d/4A/2A/2B/2|\"D7\"cA|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:F\n",
      "|\"D\"|\"C\"|\"D\"|\"D\"|\"G\"\"A\"|\"D\"|\"G\"|\"D\"|\"E\"|\"A\"|\"G\"|\"D\"|\"G\"\"A\"|\"D\"|]\n",
      "a/2g/2|\"D\"fdfd|f/2af/2ag/2f/2|\"C\"e=cec|e/2ge/2ga/2g/2|\"D\"fdfd|\"D\"f/2af/\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d2|\"G\"B3/2g/2d3/4e/4d/2B/2|\"G\"g/2d/2B/2G/2A/2|B3/4B/4B/2A/2|\"G\"G3/2|\"C\"E/2G/2D/2E/2G/2A/2|\"D\"B3/4B/4B/2A/2G/2|\"G\"G3/2B/2A/2G/2|\"C\"E/2G/2D/2E/2G/2A/2|\"D\"B3/2B/4B/4A/2G/2|\"G\"G2|]\n",
      "\n",
      "M:3/4\n",
      "L:1/4\n",
      "K:Gb\n",
      "|\"D\"|\"D\"|\"G\"|\"D\"|\"D\"|\"Em\"\"A\"|\"D\"|\"D\"|\"A\"|\"Bm\"|\"A7\"|\"D\"|\"A\"|\"E7\"|\"A\"|\"G\"|\"D\"|\"A\"|\"D\"|\"D\"|\"Em\"|\"A7\"|\"D\"|]\n",
      "|A|\"D\"f3/2e/2d|\"D\"AFA|\"G\"BGB|\"D\"AFA|\"D\"f3/2e/2d|\"D\"AFA|\"Em\"Be\"A\"c|\"D\"d2|A|\"D\"f2a|\"A\"e2a|\"Bm\"d3/2e/2d|\"A7\"cBA|\"D\"f2a|\"A\"e2a|\"E7\"^gfg|\"A\"a2a|\"G\"b2b|\"D\"a2a|\"A\"ggg|\"D\"fed|\"D\"f3/2e/2d|\"Em\"Bgf|\"A7\"edc|\"D\"d2\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"D\"f/2e/2f/2g/2a/2b/2|\"D\"c'/2a/2f/2dd|\"G\"g/2f/2g/2a/2b/2g/2e/2d/2|\"C\"c/2g/2f/2g/2a/2g/2e/2d/2c/2|\"G\"B/2g/2f/2g/2d/2g/2d/2B/2|\"D\"cAA|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"G\"|\"G\"\"D7\"|\"G\"\"D7\"|\"G\"|\"D\"|\"G\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    " !python3 sample.py --out_dir=older_ckpt/m_voices --path_meta=older_ckpt/m_voices --start='M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat older_ckpt/m_voices/ckpt.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l older_ckpt/m_voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l out-abc-char/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
