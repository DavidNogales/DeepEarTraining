{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def load_dataframe(relative_path,dataframe_name):\n",
    "    df = pd.read_pickle(f'{relative_path}/{dataframe_name}.pkl')    \n",
    "    return df\n",
    "\n",
    "def read_file(relative_path,file_name):\n",
    "    text= \"\"\n",
    "    with open(f'{relative_path}/{file_name}.abc','r') as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unit_note_length', 'tuneBook', 'title', 'reference_number',\n",
       "       'original_header', 'original_body', 'meter', 'key', 'clean_song',\n",
       "       'clean_header', 'clean_body', 'chord_progression', '\"fm\"', '\"ff'\"',\n",
       "       '\"f7\"', '\"em\"', '\"ee'\"', '\"e7\"', '\"e\"', '\"dm\"', '\"dd'\"', '\"d7\"', '\"d\"',\n",
       "       '\"cm\"', '\"cc'\"', '\"c7\"', '\"c#m\"', '\"c#7\"', '\"c\"', '\"Gm\"', '\"Gg\"',\n",
       "       '\"Gd'\"', '\"G7\"', '\"G#m\"', '\"G#7\"', '\"G\"', '\"Fm\"', '\"Ff\"', '\"Fc'\"',\n",
       "       '\"F7\"', '\"F#m\"', '\"F#7\"', '\"F\"', '\"Em\"', '\"Eb\"', '\"E7\"', '\"E#m\"',\n",
       "       '\"E#7\"', '\"E\"', '\"Dm\"', '\"Da\"', '\"D7\"', '\"D#m\"', '\"D#7\"', '\"D\"', '\"Cm\"',\n",
       "       '\"Cg\"', '\"C7\"', '\"C#m\"', '\"C#7\"', '\"C\"', '\"Bm\"', '\"Bf\"', '\"Bb\"', '\"B7\"',\n",
       "       '\"B#m\"', '\"B#7\"', '\"B\"', '\"Am\"', '\"Ae'\"', '\"Aa\"', '\"A7\"', '\"A#m\"',\n",
       "       '\"A#7\"', '\"A\"'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_path =\"notebooks/data/final_dataset\"\n",
    "filename_name = 'clean_augmented_data'\n",
    "#filename_name = 'clean_original_training_data'\n",
    "#relative_path =\"notebooks/data/original_dataset\"\n",
    "training_data_df = load_dataframe(relative_path,filename_name)\n",
    "training_data_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_note_length</th>\n",
       "      <th>tuneBook</th>\n",
       "      <th>title</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>original_header</th>\n",
       "      <th>original_body</th>\n",
       "      <th>meter</th>\n",
       "      <th>key</th>\n",
       "      <th>clean_song</th>\n",
       "      <th>clean_header</th>\n",
       "      <th>...</th>\n",
       "      <th>\"B#m\"</th>\n",
       "      <th>\"B#7\"</th>\n",
       "      <th>\"B\"</th>\n",
       "      <th>\"Am\"</th>\n",
       "      <th>\"Ae'\"</th>\n",
       "      <th>\"Aa\"</th>\n",
       "      <th>\"A7\"</th>\n",
       "      <th>\"A#m\"</th>\n",
       "      <th>\"A#7\"</th>\n",
       "      <th>\"A\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9491</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Grandpa's</td>\n",
       "      <td>78</td>\n",
       "      <td>X:78\\nT:Grandpa's\\nM:4/4\\nL:1/4\\nK:Amajor</td>\n",
       "      <td>E/2D/2|\"A,\"CE\"E7\"FG|\"A,\"A/2G/2A/2B/2ce|\"B,m\"dc...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9492</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>The Girl With The Green Hat On</td>\n",
       "      <td>79</td>\n",
       "      <td>X:79\\nT:The Girl With The Green Hat On\\nM:4/4\\...</td>\n",
       "      <td>(3E/2F/2G/2|\"A,\"AE\"E7\"E/2F/2E/2D/2|\"A,\"C/2D/2E...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9493</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Green Meadow</td>\n",
       "      <td>80</td>\n",
       "      <td>X:80\\nT:Green Meadow\\nM:4/4\\nL:1/4\\nK:Dmajor</td>\n",
       "      <td>(3A,/2B,/2C/2|\"D\"DD/2E/2F/2D/2F/2A/2|\"G,\"B/2c/...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>D</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9494</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>The Old Grey Cat</td>\n",
       "      <td>82</td>\n",
       "      <td>X:82\\nT:The Old Grey Cat\\nM:4/4\\nL:1/4\\nK:Bminor</td>\n",
       "      <td>F|\"B,m\"BBB,B,/2C/2|\"B,m\"D/2C/2D/2E/2F/2E/2F/2^...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>Bm</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9495</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Gyre And Gimble</td>\n",
       "      <td>84</td>\n",
       "      <td>X:84\\nT:Gyre And Gimble\\nM:4/4\\nL:1/4\\nK:Amajor</td>\n",
       "      <td>E|\"A,\"AECE|\"B,m\"FD\"E7\"B,D|\"A,\"CEA3/2B/2|\"E7\"c/...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unit_note_length          tuneBook                           title  \\\n",
       "9491              1/4  dataset_min5.abc                       Grandpa's   \n",
       "9492              1/4  dataset_min5.abc  The Girl With The Green Hat On   \n",
       "9493              1/4  dataset_min5.abc                    Green Meadow   \n",
       "9494              1/4  dataset_min5.abc                The Old Grey Cat   \n",
       "9495              1/4  dataset_min5.abc                 Gyre And Gimble   \n",
       "\n",
       "     reference_number                                    original_header  \\\n",
       "9491               78          X:78\\nT:Grandpa's\\nM:4/4\\nL:1/4\\nK:Amajor   \n",
       "9492               79  X:79\\nT:The Girl With The Green Hat On\\nM:4/4\\...   \n",
       "9493               80       X:80\\nT:Green Meadow\\nM:4/4\\nL:1/4\\nK:Dmajor   \n",
       "9494               82   X:82\\nT:The Old Grey Cat\\nM:4/4\\nL:1/4\\nK:Bminor   \n",
       "9495               84    X:84\\nT:Gyre And Gimble\\nM:4/4\\nL:1/4\\nK:Amajor   \n",
       "\n",
       "                                          original_body meter key  \\\n",
       "9491  E/2D/2|\"A,\"CE\"E7\"FG|\"A,\"A/2G/2A/2B/2ce|\"B,m\"dc...   4/4   A   \n",
       "9492  (3E/2F/2G/2|\"A,\"AE\"E7\"E/2F/2E/2D/2|\"A,\"C/2D/2E...   4/4   A   \n",
       "9493  (3A,/2B,/2C/2|\"D\"DD/2E/2F/2D/2F/2A/2|\"G,\"B/2c/...   4/4   D   \n",
       "9494  F|\"B,m\"BBB,B,/2C/2|\"B,m\"D/2C/2D/2E/2F/2E/2F/2^...   4/4  Bm   \n",
       "9495  E|\"A,\"AECE|\"B,m\"FD\"E7\"B,D|\"A,\"CEA3/2B/2|\"E7\"c/...   4/4   A   \n",
       "\n",
       "                                             clean_song  \\\n",
       "9491  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...   \n",
       "9492  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...   \n",
       "9493  M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...   \n",
       "9494  M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...   \n",
       "9495  M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...   \n",
       "\n",
       "                                           clean_header  ... \"B#m\" \"B#7\"  \"B\"  \\\n",
       "9491  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...  ...     0     0    0   \n",
       "9492  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...  ...     0     0    0   \n",
       "9493  M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...  ...     0     0    0   \n",
       "9494  M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...  ...     0     0    0   \n",
       "9495  M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...  ...     0     0    0   \n",
       "\n",
       "      \"Am\"  \"Ae'\"  \"Aa\"  \"A7\"  \"A#m\"  \"A#7\"  \"A\"  \n",
       "9491     0      0     0     0      0      0    9  \n",
       "9492     0      0     0     0      0      0    9  \n",
       "9493     0      0     0     7      0      0    0  \n",
       "9494     0      0     0     0      0      0    5  \n",
       "9495     0      0     0     0      0      0   12  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df[\"clean_header\"].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1257"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df[\"clean_body\"].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab:  \n",
      "\"#'(),-/1234567=ABCDEFG[]^_abcdefgmz|~\n",
      "vocab_size 39\n",
      "silences  516\n"
     ]
    }
   ],
   "source": [
    "bodies = \"\"\n",
    "silences = 0\n",
    "for body in training_data_df[\"clean_body\"]:\n",
    "    if 'z' in body:\n",
    "        silences +=1 \n",
    "    bodies += body+\"\\n\"\n",
    "chars = sorted(list(set(bodies)))\n",
    "vocab_size = len(chars)\n",
    "print('vocab: ',''.join(chars))\n",
    "print('vocab_size',vocab_size)\n",
    "print(\"silences \",silences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chars: 4062773\n"
     ]
    }
   ],
   "source": [
    "training_data_text = read_file(relative_path,filename_name)\n",
    "\n",
    "print(\"number of chars:\",len(training_data_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"#'(),-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(training_data_text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.28.0.dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14.2\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import tiktoken\n",
    "\n",
    "print(wandb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile  docker-compose.yaml  overrides.json\n",
      "README.md   notebooks\t\t requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "nano_path = 'notebooks/nanoGPT'\n",
    "os.chdir(nano_path)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE      config\t      out-abc-char\t    transformer_sizing.ipynb\n",
      "README.md    configurator.py  out-shakespeare-char  wandb\n",
      "__pycache__  data\t      sample.py\n",
      "assets\t     model.py\t      scaling_laws.ipynb\n",
      "bench.py     older_ckpt       train.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with multiple voices present\n",
    "#length of dataset in characters: 4,149,703\n",
    "#all the unique characters: \n",
    "#\"#'()+,-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
    "#vocab size: 46\n",
    "#train has 3,734,732 tokens\n",
    "#val has 414,971 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 4,062,773\n",
      "all the unique characters: \n",
      "\"#'(),-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
      "vocab size: 45\n",
      "train has 3,656,495 tokens\n",
      "val has 406,278 tokens\n"
     ]
    }
   ],
   "source": [
    "!python3 data/abc_char/prepare.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding config with config/train_abc_char.py:\n",
      "# train a miniature character-level shakespeare model\n",
      "# good for debugging and playing on macbooks and such\n",
      "\n",
      "out_dir = 'out-abc-char'\n",
      "eval_interval = 10 # keep frequent because we'll overfit\n",
      "eval_iters = 500\n",
      "log_interval = 5 # don't print too too often\n",
      "\n",
      "# we expect to overfit on this small dataset, so only save when val improves\n",
      "always_save_checkpoint = False\n",
      "\n",
      "wandb_log = True # override via command line if you like\n",
      "wandb_project = 'abc-char'\n",
      "wandb_run_name = 'mini-char-gpt'\n",
      "\n",
      "dataset = 'abc_char'\n",
      "batch_size = 64\n",
      "block_size = 512 # context of up to 512 previous characters\n",
      "\n",
      "# baby GPT model :)\n",
      "n_layer = 8\n",
      "n_head = 6\n",
      "n_embd = 384\n",
      "dropout = 0.2\n",
      "\n",
      "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
      "max_iters = 5000\n",
      "lr_decay_iters = 5000 # make equal to max_iters usually\n",
      "min_lr = 1e-4 # learning_rate / 10 usually\n",
      "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
      "\n",
      "warmup_iters = 5 # not super necessary potentially\n",
      "\n",
      "# on macbook also add\n",
      "# device = 'cpu'  # run on cpu only\n",
      "# compile = False # do not torch compile the model\n",
      "\n",
      "found vocab_size = 45 (inside data/abc_char/meta.pkl)\n",
      "Initializing a new model from scratch\n",
      "number of parameters: 14.18M\n",
      "using fused AdamW: True\n",
      "compiling the model... (takes a ~minute)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavidnogales\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/pt-env/notebooks/nanoGPT/wandb/run-20230410_155627-5xythsn4\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmini-char-gpt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char/runs/5xythsn4\u001b[0m\n",
      "step 0: train loss 3.9505, val loss 3.9607\n",
      "[2023-04-10 15:57:44,154] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-10 15:57:44,378] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-10 15:57:44,700] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-10 15:57:44,887] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-10 15:57:45,152] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-10 15:57:45,337] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-10 15:57:45,688] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-10 15:57:45,882] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-10 15:57:46,137] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-10 15:57:46,323] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-10 15:57:46,589] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-10 15:57:46,768] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-10 15:57:47,031] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-10 15:57:47,210] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-10 15:57:47,467] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-10 15:57:47,652] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "iter 0: loss 3.9310, time 91037.29ms, mfu -100.00%\n",
      "iter 5: loss 2.9915, time 9844.45ms, mfu 4.44%\n",
      "step 10: train loss 2.6086, val loss 2.5974\n",
      "saving checkpoint to out-abc-char\n",
      "iter 10: loss 2.6568, time 82022.92ms, mfu 4.05%\n",
      "iter 15: loss 2.3923, time 9945.14ms, mfu 4.08%\n",
      "step 20: train loss 2.2378, val loss 2.2961\n",
      "saving checkpoint to out-abc-char\n",
      "iter 20: loss 2.2908, time 81402.16ms, mfu 3.73%\n",
      "iter 25: loss 2.1725, time 9847.55ms, mfu 3.80%\n",
      "step 30: train loss 2.0922, val loss 2.1381\n",
      "saving checkpoint to out-abc-char\n",
      "iter 30: loss 2.0560, time 80968.95ms, mfu 3.47%\n",
      "iter 35: loss 2.0140, time 9889.74ms, mfu 3.57%\n",
      "step 40: train loss 1.9999, val loss 2.0297\n",
      "saving checkpoint to out-abc-char\n",
      "iter 40: loss 2.0002, time 81025.99ms, mfu 3.26%\n",
      "iter 45: loss 1.9283, time 9827.52ms, mfu 3.38%\n",
      "step 50: train loss 1.8948, val loss 1.9223\n",
      "saving checkpoint to out-abc-char\n",
      "iter 50: loss 1.8157, time 80937.48ms, mfu 3.10%\n",
      "iter 55: loss 1.9176, time 9899.45ms, mfu 3.23%\n",
      "step 60: train loss 1.8196, val loss 1.8473\n",
      "saving checkpoint to out-abc-char\n",
      "iter 60: loss 1.8419, time 81097.41ms, mfu 2.96%\n",
      "iter 65: loss 1.7906, time 9939.91ms, mfu 3.10%\n",
      "step 70: train loss 1.7630, val loss 1.7990\n",
      "saving checkpoint to out-abc-char\n",
      "iter 70: loss 1.7902, time 81431.63ms, mfu 2.85%\n",
      "iter 75: loss 1.7788, time 9841.47ms, mfu 3.01%\n",
      "step 80: train loss 1.6886, val loss 1.7154\n",
      "saving checkpoint to out-abc-char\n",
      "iter 80: loss 1.7422, time 81481.17ms, mfu 2.76%\n",
      "iter 85: loss 1.7325, time 9810.06ms, mfu 2.93%\n",
      "step 90: train loss 1.6608, val loss 1.6862\n",
      "saving checkpoint to out-abc-char\n",
      "iter 90: loss 1.7359, time 81202.83ms, mfu 2.69%\n",
      "iter 95: loss 1.6476, time 9849.10ms, mfu 2.86%\n",
      "step 100: train loss 1.6219, val loss 1.6420\n",
      "saving checkpoint to out-abc-char\n",
      "iter 100: loss 1.6680, time 81327.02ms, mfu 2.63%\n",
      "iter 105: loss 1.6030, time 9851.50ms, mfu 2.81%\n",
      "step 110: train loss 1.5935, val loss 1.6058\n",
      "saving checkpoint to out-abc-char\n",
      "iter 110: loss 1.5931, time 81760.23ms, mfu 2.58%\n",
      "iter 115: loss 1.6124, time 9879.14ms, mfu 2.77%\n",
      "step 120: train loss 1.5666, val loss 1.5856\n",
      "saving checkpoint to out-abc-char\n",
      "iter 120: loss 1.5785, time 81234.73ms, mfu 2.54%\n",
      "iter 125: loss 1.5454, time 10162.69ms, mfu 2.72%\n",
      "step 130: train loss 1.5378, val loss 1.5645\n",
      "saving checkpoint to out-abc-char\n",
      "iter 130: loss 1.5640, time 82265.78ms, mfu 2.50%\n",
      "iter 135: loss 1.5392, time 9832.90ms, mfu 2.69%\n",
      "step 140: train loss 1.5152, val loss 1.5322\n",
      "saving checkpoint to out-abc-char\n",
      "iter 140: loss 1.5612, time 80630.33ms, mfu 2.48%\n",
      "iter 145: loss 1.4794, time 9900.75ms, mfu 2.67%\n",
      "step 150: train loss 1.4986, val loss 1.5116\n",
      "saving checkpoint to out-abc-char\n",
      "iter 150: loss 1.5427, time 81606.15ms, mfu 2.46%\n",
      "iter 155: loss 1.5199, time 9911.56ms, mfu 2.65%\n",
      "step 160: train loss 1.4865, val loss 1.5007\n",
      "saving checkpoint to out-abc-char\n",
      "iter 160: loss 1.5423, time 81466.76ms, mfu 2.44%\n",
      "iter 165: loss 1.4967, time 9727.37ms, mfu 2.65%\n",
      "step 170: train loss 1.4847, val loss 1.5049\n",
      "iter 170: loss 1.5002, time 80561.90ms, mfu 2.44%\n",
      "iter 175: loss 1.4894, time 9832.33ms, mfu 2.64%\n",
      "step 180: train loss 1.4923, val loss 1.5210\n",
      "iter 180: loss 1.5744, time 80092.12ms, mfu 2.43%\n",
      "iter 185: loss 1.4498, time 9826.48ms, mfu 2.63%\n",
      "step 190: train loss 1.4560, val loss 1.4614\n",
      "saving checkpoint to out-abc-char\n",
      "iter 190: loss 1.4756, time 80788.12ms, mfu 2.42%\n",
      "iter 195: loss 1.4500, time 9814.22ms, mfu 2.62%\n",
      "step 200: train loss 1.4298, val loss 1.4455\n",
      "saving checkpoint to out-abc-char\n",
      "iter 200: loss 1.4506, time 81022.21ms, mfu 2.41%\n",
      "iter 205: loss 1.4295, time 9955.43ms, mfu 2.61%\n",
      "step 210: train loss 1.4182, val loss 1.4263\n",
      "saving checkpoint to out-abc-char\n",
      "iter 210: loss 1.4478, time 81335.54ms, mfu 2.40%\n",
      "iter 215: loss 1.5018, time 9777.94ms, mfu 2.61%\n",
      "step 220: train loss 1.4052, val loss 1.4175\n",
      "saving checkpoint to out-abc-char\n",
      "iter 220: loss 1.4553, time 81194.64ms, mfu 2.40%\n",
      "iter 225: loss 1.4671, time 9932.42ms, mfu 2.60%\n",
      "step 230: train loss 1.3861, val loss 1.3978\n",
      "saving checkpoint to out-abc-char\n",
      "iter 230: loss 1.4373, time 81513.66ms, mfu 2.40%\n",
      "iter 235: loss 1.4060, time 10085.12ms, mfu 2.59%\n",
      "step 240: train loss 1.3655, val loss 1.3829\n",
      "saving checkpoint to out-abc-char\n",
      "iter 240: loss 1.4397, time 82771.72ms, mfu 2.38%\n",
      "iter 245: loss 1.3908, time 9822.04ms, mfu 2.59%\n",
      "step 250: train loss 1.3508, val loss 1.3635\n",
      "saving checkpoint to out-abc-char\n",
      "iter 250: loss 1.3652, time 80641.44ms, mfu 2.38%\n",
      "iter 255: loss 1.3742, time 9617.44ms, mfu 2.60%\n",
      "step 260: train loss 1.3279, val loss 1.3439\n",
      "saving checkpoint to out-abc-char\n",
      "iter 260: loss 1.3669, time 79220.42ms, mfu 2.40%\n",
      "iter 265: loss 1.3820, time 9683.99ms, mfu 2.61%\n",
      "step 270: train loss 1.3084, val loss 1.3160\n",
      "saving checkpoint to out-abc-char\n",
      "iter 270: loss 1.2880, time 81007.29ms, mfu 2.40%\n",
      "iter 275: loss 1.3464, time 9973.27ms, mfu 2.60%\n",
      "step 280: train loss 1.2726, val loss 1.2947\n",
      "saving checkpoint to out-abc-char\n",
      "iter 280: loss 1.3329, time 79073.39ms, mfu 2.39%\n",
      "iter 285: loss 1.3232, time 9617.27ms, mfu 2.61%\n",
      "step 290: train loss 1.2395, val loss 1.2640\n",
      "saving checkpoint to out-abc-char\n",
      "iter 290: loss 1.2959, time 80178.19ms, mfu 2.40%\n",
      "iter 295: loss 1.2501, time 9894.48ms, mfu 2.60%\n",
      "step 300: train loss 1.2103, val loss 1.2294\n",
      "saving checkpoint to out-abc-char\n",
      "iter 300: loss 1.2275, time 83853.85ms, mfu 2.39%\n",
      "iter 305: loss 1.2138, time 9893.15ms, mfu 2.60%\n",
      "step 310: train loss 1.2048, val loss 1.2298\n",
      "iter 310: loss 1.2483, time 80901.20ms, mfu 2.39%\n",
      "iter 315: loss 1.2110, time 9631.86ms, mfu 2.61%\n",
      "step 320: train loss 1.1615, val loss 1.1875\n",
      "saving checkpoint to out-abc-char\n",
      "iter 320: loss 1.2174, time 80000.46ms, mfu 2.40%\n",
      "iter 325: loss 1.1396, time 9661.06ms, mfu 2.61%\n",
      "step 330: train loss 1.1448, val loss 1.1778\n",
      "saving checkpoint to out-abc-char\n",
      "iter 330: loss 1.2022, time 79359.51ms, mfu 2.41%\n",
      "iter 335: loss 1.1874, time 9636.59ms, mfu 2.62%\n",
      "step 340: train loss 1.1285, val loss 1.1595\n",
      "saving checkpoint to out-abc-char\n",
      "iter 340: loss 1.1971, time 79258.93ms, mfu 2.41%\n",
      "iter 345: loss 1.1296, time 9718.25ms, mfu 2.62%\n",
      "step 350: train loss 1.1158, val loss 1.1447\n",
      "saving checkpoint to out-abc-char\n",
      "iter 350: loss 1.1386, time 79632.83ms, mfu 2.41%\n",
      "iter 355: loss 1.1488, time 9670.13ms, mfu 2.62%\n",
      "step 360: train loss 1.0910, val loss 1.1293\n",
      "saving checkpoint to out-abc-char\n",
      "iter 360: loss 1.1387, time 79637.39ms, mfu 2.42%\n",
      "iter 365: loss 1.1134, time 9693.56ms, mfu 2.62%\n",
      "step 370: train loss 1.0701, val loss 1.1005\n",
      "saving checkpoint to out-abc-char\n",
      "iter 370: loss 1.0769, time 80423.45ms, mfu 2.42%\n",
      "iter 375: loss 1.0941, time 9647.98ms, mfu 2.63%\n",
      "step 380: train loss 1.0460, val loss 1.0841\n",
      "saving checkpoint to out-abc-char\n",
      "iter 380: loss 1.0816, time 79596.69ms, mfu 2.42%\n",
      "iter 385: loss 1.1187, time 9714.92ms, mfu 2.63%\n",
      "step 390: train loss 1.0251, val loss 1.0562\n",
      "saving checkpoint to out-abc-char\n",
      "iter 390: loss 1.0321, time 80076.52ms, mfu 2.42%\n",
      "iter 395: loss 1.0637, time 9635.39ms, mfu 2.63%\n",
      "step 400: train loss 0.9985, val loss 1.0350\n",
      "saving checkpoint to out-abc-char\n",
      "iter 400: loss 1.0048, time 79969.07ms, mfu 2.42%\n",
      "iter 405: loss 1.0333, time 9595.88ms, mfu 2.63%\n",
      "step 410: train loss 0.9827, val loss 1.0198\n",
      "saving checkpoint to out-abc-char\n",
      "iter 410: loss 0.9681, time 79900.86ms, mfu 2.43%\n",
      "iter 415: loss 0.9950, time 9583.37ms, mfu 2.64%\n",
      "step 420: train loss 0.9687, val loss 1.0043\n",
      "saving checkpoint to out-abc-char\n",
      "iter 420: loss 1.0102, time 78781.23ms, mfu 2.43%\n",
      "iter 425: loss 0.9805, time 9626.96ms, mfu 2.64%\n",
      "step 430: train loss 0.9461, val loss 0.9859\n",
      "saving checkpoint to out-abc-char\n",
      "iter 430: loss 0.9483, time 78255.31ms, mfu 2.43%\n",
      "iter 435: loss 0.9694, time 9477.86ms, mfu 2.65%\n",
      "step 440: train loss 0.9222, val loss 0.9541\n",
      "saving checkpoint to out-abc-char\n",
      "iter 440: loss 0.9867, time 78211.99ms, mfu 2.44%\n",
      "iter 445: loss 0.9566, time 9481.54ms, mfu 2.66%\n",
      "step 450: train loss 0.8981, val loss 0.9427\n",
      "saving checkpoint to out-abc-char\n",
      "iter 450: loss 0.9623, time 78198.43ms, mfu 2.45%\n",
      "iter 455: loss 0.9240, time 9497.33ms, mfu 2.66%\n",
      "step 460: train loss 0.8795, val loss 0.9174\n",
      "saving checkpoint to out-abc-char\n",
      "iter 460: loss 0.8964, time 78070.56ms, mfu 2.45%\n",
      "iter 465: loss 0.8890, time 9489.86ms, mfu 2.67%\n",
      "step 470: train loss 0.8568, val loss 0.8987\n",
      "saving checkpoint to out-abc-char\n",
      "iter 470: loss 0.9400, time 78277.83ms, mfu 2.46%\n",
      "iter 475: loss 0.8800, time 9454.46ms, mfu 2.67%\n",
      "step 480: train loss 0.8494, val loss 0.8960\n",
      "saving checkpoint to out-abc-char\n",
      "iter 480: loss 0.8869, time 78199.47ms, mfu 2.46%\n",
      "iter 485: loss 0.8485, time 9499.70ms, mfu 2.67%\n",
      "step 490: train loss 0.8254, val loss 0.8699\n",
      "saving checkpoint to out-abc-char\n",
      "iter 490: loss 0.8466, time 78263.07ms, mfu 2.46%\n",
      "iter 495: loss 0.8327, time 9660.81ms, mfu 2.67%\n",
      "step 500: train loss 0.8073, val loss 0.8543\n",
      "saving checkpoint to out-abc-char\n",
      "iter 500: loss 0.8646, time 78966.01ms, mfu 2.46%\n",
      "iter 505: loss 0.8176, time 9493.30ms, mfu 2.67%\n",
      "step 510: train loss 0.7914, val loss 0.8357\n",
      "saving checkpoint to out-abc-char\n",
      "iter 510: loss 0.8193, time 78689.74ms, mfu 2.46%\n",
      "iter 515: loss 0.7935, time 9593.03ms, mfu 2.67%\n",
      "step 520: train loss 0.7686, val loss 0.8146\n",
      "saving checkpoint to out-abc-char\n",
      "iter 520: loss 0.8014, time 79129.51ms, mfu 2.46%\n",
      "iter 525: loss 0.7750, time 9533.27ms, mfu 2.67%\n",
      "step 530: train loss 0.7419, val loss 0.7911\n",
      "saving checkpoint to out-abc-char\n",
      "iter 530: loss 0.7748, time 78228.77ms, mfu 2.46%\n",
      "iter 535: loss 0.7972, time 9503.87ms, mfu 2.67%\n",
      "step 540: train loss 0.7353, val loss 0.7815\n",
      "saving checkpoint to out-abc-char\n",
      "iter 540: loss 0.7456, time 79398.24ms, mfu 2.46%\n",
      "iter 545: loss 0.7448, time 9655.39ms, mfu 2.67%\n",
      "step 550: train loss 0.7099, val loss 0.7637\n",
      "saving checkpoint to out-abc-char\n",
      "iter 550: loss 0.7446, time 78101.07ms, mfu 2.46%\n",
      "iter 555: loss 0.7376, time 9545.31ms, mfu 2.67%\n",
      "step 560: train loss 0.6990, val loss 0.7507\n",
      "saving checkpoint to out-abc-char\n",
      "iter 560: loss 0.7493, time 78831.04ms, mfu 2.46%\n",
      "iter 565: loss 0.6981, time 9716.55ms, mfu 2.66%\n",
      "step 570: train loss 0.6763, val loss 0.7259\n",
      "saving checkpoint to out-abc-char\n",
      "iter 570: loss 0.7328, time 78650.64ms, mfu 2.45%\n",
      "iter 575: loss 0.6959, time 9487.37ms, mfu 2.66%\n",
      "step 580: train loss 0.6664, val loss 0.7212\n",
      "saving checkpoint to out-abc-char\n",
      "iter 580: loss 0.7024, time 78604.63ms, mfu 2.45%\n",
      "iter 585: loss 0.7284, time 9503.88ms, mfu 2.67%\n",
      "step 590: train loss 0.6465, val loss 0.6999\n",
      "saving checkpoint to out-abc-char\n",
      "iter 590: loss 0.6644, time 78619.29ms, mfu 2.46%\n",
      "iter 595: loss 0.6625, time 9527.09ms, mfu 2.67%\n",
      "step 600: train loss 0.6358, val loss 0.6885\n",
      "saving checkpoint to out-abc-char\n",
      "iter 600: loss 0.6626, time 78774.80ms, mfu 2.46%\n",
      "iter 605: loss 0.6605, time 9518.95ms, mfu 2.67%\n",
      "step 610: train loss 0.6251, val loss 0.6835\n",
      "saving checkpoint to out-abc-char\n",
      "iter 610: loss 0.6817, time 78389.01ms, mfu 2.46%\n",
      "iter 615: loss 0.6624, time 9553.04ms, mfu 2.67%\n",
      "step 620: train loss 0.6061, val loss 0.6606\n",
      "saving checkpoint to out-abc-char\n",
      "iter 620: loss 0.6520, time 78449.07ms, mfu 2.46%\n",
      "iter 625: loss 0.6228, time 9596.80ms, mfu 2.67%\n",
      "step 630: train loss 0.5970, val loss 0.6550\n",
      "saving checkpoint to out-abc-char\n",
      "iter 630: loss 0.5991, time 78465.52ms, mfu 2.46%\n",
      "iter 635: loss 0.6305, time 9509.29ms, mfu 2.67%\n",
      "step 640: train loss 0.5818, val loss 0.6398\n",
      "saving checkpoint to out-abc-char\n",
      "iter 640: loss 0.6303, time 79128.43ms, mfu 2.46%\n",
      "iter 645: loss 0.5953, time 9908.99ms, mfu 2.65%\n",
      "step 650: train loss 0.5670, val loss 0.6270\n",
      "saving checkpoint to out-abc-char\n",
      "iter 650: loss 0.6263, time 78460.64ms, mfu 2.44%\n",
      "iter 655: loss 0.6074, time 9590.03ms, mfu 2.65%\n",
      "step 660: train loss 0.5606, val loss 0.6218\n",
      "saving checkpoint to out-abc-char\n",
      "iter 660: loss 0.5853, time 79324.16ms, mfu 2.44%\n",
      "iter 665: loss 0.5866, time 9502.86ms, mfu 2.66%\n",
      "step 670: train loss 0.5481, val loss 0.6174\n",
      "saving checkpoint to out-abc-char\n",
      "iter 670: loss 0.5955, time 78309.78ms, mfu 2.45%\n",
      "iter 675: loss 0.5925, time 9548.42ms, mfu 2.66%\n",
      "step 680: train loss 0.5342, val loss 0.6020\n",
      "saving checkpoint to out-abc-char\n",
      "iter 680: loss 0.5455, time 78336.44ms, mfu 2.45%\n",
      "iter 685: loss 0.5552, time 9500.94ms, mfu 2.67%\n",
      "step 690: train loss 0.5279, val loss 0.5995\n",
      "saving checkpoint to out-abc-char\n",
      "iter 690: loss 0.5674, time 82166.91ms, mfu 2.45%\n",
      "iter 695: loss 0.5616, time 9519.97ms, mfu 2.67%\n",
      "step 700: train loss 0.5203, val loss 0.5952\n",
      "saving checkpoint to out-abc-char\n",
      "iter 700: loss 0.5707, time 78611.42ms, mfu 2.45%\n",
      "iter 705: loss 0.5431, time 9576.19ms, mfu 2.67%\n",
      "step 710: train loss 0.5100, val loss 0.5857\n",
      "saving checkpoint to out-abc-char\n",
      "iter 710: loss 0.5497, time 78890.19ms, mfu 2.45%\n",
      "iter 715: loss 0.5500, time 9534.40ms, mfu 2.67%\n",
      "step 720: train loss 0.5054, val loss 0.5832\n",
      "saving checkpoint to out-abc-char\n",
      "iter 720: loss 0.5523, time 78341.77ms, mfu 2.46%\n",
      "iter 725: loss 0.5660, time 9476.44ms, mfu 2.67%\n",
      "step 730: train loss 0.4928, val loss 0.5742\n",
      "saving checkpoint to out-abc-char\n",
      "iter 730: loss 0.5254, time 80263.64ms, mfu 2.46%\n",
      "iter 735: loss 0.5397, time 9513.65ms, mfu 2.67%\n",
      "step 740: train loss 0.4831, val loss 0.5663\n",
      "saving checkpoint to out-abc-char\n",
      "iter 740: loss 0.5121, time 78442.30ms, mfu 2.46%\n",
      "iter 745: loss 0.5203, time 9539.92ms, mfu 2.67%\n",
      "step 750: train loss 0.4838, val loss 0.5737\n",
      "iter 750: loss 0.5275, time 78160.86ms, mfu 2.46%\n",
      "iter 755: loss 0.5179, time 9453.24ms, mfu 2.68%\n",
      "step 760: train loss 0.4726, val loss 0.5666\n",
      "iter 760: loss 0.5090, time 78569.93ms, mfu 2.46%\n",
      "iter 765: loss 0.5010, time 9543.96ms, mfu 2.68%\n",
      "step 770: train loss 0.4634, val loss 0.5565\n",
      "saving checkpoint to out-abc-char\n",
      "iter 770: loss 0.4982, time 79388.79ms, mfu 2.46%\n",
      "iter 775: loss 0.4876, time 9600.72ms, mfu 2.67%\n",
      "step 780: train loss 0.4570, val loss 0.5547\n",
      "saving checkpoint to out-abc-char\n",
      "iter 780: loss 0.4982, time 78802.41ms, mfu 2.46%\n",
      "iter 785: loss 0.4724, time 9733.05ms, mfu 2.66%\n",
      "step 790: train loss 0.4439, val loss 0.5465\n",
      "saving checkpoint to out-abc-char\n",
      "iter 790: loss 0.4840, time 78691.48ms, mfu 2.45%\n",
      "iter 795: loss 0.4833, time 9531.24ms, mfu 2.66%\n",
      "step 800: train loss 0.4339, val loss 0.5412\n",
      "saving checkpoint to out-abc-char\n",
      "iter 800: loss 0.4798, time 81757.93ms, mfu 2.45%\n",
      "iter 805: loss 0.4734, time 9528.51ms, mfu 2.66%\n",
      "step 810: train loss 0.4247, val loss 0.5343\n",
      "saving checkpoint to out-abc-char\n",
      "iter 810: loss 0.4754, time 78554.05ms, mfu 2.45%\n",
      "iter 815: loss 0.4767, time 9685.48ms, mfu 2.66%\n",
      "^C\n",
      "Process ForkProcess-2:\n",
      "Process ForkProcess-11:\n",
      "Process ForkProcess-10:\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-20:\n",
      "Process ForkProcess-14:\n",
      "Process ForkProcess-4:\n",
      "Process ForkProcess-13:\n",
      "Process ForkProcess-6:\n",
      "Process ForkProcess-3:\n",
      "Process ForkProcess-17:\n",
      "Process ForkProcess-12:\n",
      "Process ForkProcess-5:\n",
      "Process ForkProcess-15:\n",
      "Process ForkProcess-8:\n",
      "Process ForkProcess-18:\n",
      "Process ForkProcess-16:\n",
      "Process ForkProcess-19:\n",
      "Process ForkProcess-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Process ForkProcess-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 97, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 293, in <module>\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\", line 487, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\", line 200, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py config/train_abc_char.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test key with most occurrences: G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-abc-char\n",
      "Overriding: start = M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "number of parameters: 14.18M\n",
      "abc_char\n",
      "Loading meta from data/abc_char/meta.pkl...\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d|\"G\"ggf|e/2d/2c/2|\"G\"B3/2A/2B/2|\"C\"c3/2B/2c/2d/2|\"D\"ec|\"D\"d3/2d/2e/2|\"G\"f/2gf|e/2d/2B/2A/2B/2|\"C\"c3/2B/2c/2d/2|\"D\"e2|\"G\"d3/2e/2d/2|\"C\"ec|\"D\"d3/2d/2e/2|\"G\"f/2gf|e/2d/2B/2A/2G/2|\"C\"c3/2B/2c/2d/2|\"D\"ecA|\"G\"g3/2a/2g/2f/2|edB/2c/2|\"C\"de|\"D\"f/2g/2a/2g/2f/2e/2|\"G\"d/2B/2G/2B/2d/2|\"C\"c3/2B/2c/2B/2c/2|\"D\"d3/2d/2e/2|\"G\"f/2g/2a/2g/2f/2e/2|d/2B/2G/2B/2d/2|\"C\"c3/2B/2c/2d/2|\"D\"e/2d/2B/2A/2B/2A/2d/2|\"G\"B/2G/2B/2d/2B/2d/2|\"C\"c3/2B/2c/2d/2|\"D\"ecA|\"G\"g/2a/2g/2f/2e/2|\"C\"g/2f/2g/2e/2d/2|\"D\"B/2G/2B/2G/2B/2d/2|\"D\"cA\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d/2|\"G\"B/2A/2B/2G/2B/2d/2c/2B/2|\"Am\"A/2G/2F/2E/2F/2A/2B/2A/2c/2|\"D\"d/2c/2B/2A/2\"G\"G/2B/2G/2B/2|\"C\"c/2B/2c/2d/2ed/2c/2|\"D\"d/2c/2B/2A/2G/2^Fg/2f/2|\"G\"g/2^f/2g/2a/2b/2\"D\"a/2g/2f/2g/2|\"G\"g/2^f/2g/2a/2b/2g/2g/2d/2|\"C\"c/2B/2c/2d/2ed/2c/2|\"D\"d/2c/2B/2A/2G/2^Fg/2f/2|\"G\"g/2^f/2g/2a/2b/2g/2d/2g/2e/2|\"C\"c/2B/2c/2d/2ed/2c/2|\"D\"d/2c/2B/2A/2G/2^Fg/2f/2|\"G\"g/2^f/2g/2a/2b/2g/2d/2|\"C\"c/2B/2c/2d/2ed/2c/2|\"D\"d/2c/2B/2A/2G/2A/2Fg/2f/2|\"G\"g/2^f/2g/2a/2b/2g/2d/2g/2e/2|\"C\"c/2B/2c/2d/2ed/2c/2|\"D\"d/2c/2B/2A/2G/2^Fg/2f/\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "G|\"G\"d3/2e/2d|edB|G2G|\"C\"edB|\"D\"A3-|A|\"D\"A2A|\"G\"Bdd|\"C\"e2d|e2G|\"D\"A2A|\"G\"Bdd|\"C\"e2d|\"D\"cAF|\"G\"G3|]\n",
      "\n",
      "M:3/4\n",
      "L:1/4\n",
      "K:Db\n",
      "|\"D\"|\"G\"|\"C\"|\"D\"|\"A\"|\"Em\"|\"A\"|\"A\"|\"D\"|\"C\"|\"G\"|\"D\"|\"D\"|\"C\"|\"G\"|\"D\"|\"A\"|\"D\"|\"A\"|\"D\"|\"G\"|\"D\"|\"A\"|\"D\"|\"A\"|\"D\"|\"C\"|\"G\"|\"D\"|\"G\"|\"D\"|\"C\"|\"G\"|\"G\"|\"C\"|\"G\"|\"D\"|\"D\"|\"G\"|\"G\"|\"C\"|\"G\"|\"G\"|\"D\"|\"G\"|\"G\"|\"C\"|\"C\"|\"G\"|\"D\"|\"G\"|\"G\"|\"C\"|\"G\"|\"G\"|\"D\"|\"G\"|\"G\"|\"C\"|\"G\"|]\n",
      "ABc|\"D\"dAF|\"G\"G3/2A/2B|\"C\"edc|\"D\"cAF|\"A\"EGC|\"Em\"B,E|\"A\"A3/2B/2c/2d/2|\"D\"cBA|\"C\"E2D|\"G\"G3/2A/2B|\"D\"c2d|\"D\"dAF|\"C\"EGC|\"G\"B,EG|\"D\"A3/2B/2c/2d\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d|\"G\"GG/2D/2GG/2D/2|BG/2DG/2D/2|\"C\"e/2c/2A/2E/2CE/2D/2|\"D\"DD/2D/2DG/2D/2|\"G\"BG/2D/2GG/2D/2|BG/2D/2GG/2D/2|\"C\"e/2c/2A/2E/2CE/2D/2|\"D\"DD/2D/2D/2c/2D/2A/2D/2A/2D/2|\"G\"BG/2D/2GG/2D/2|\"C\"e/2c/2A/2E/2CE/2D/2E/2G/2|\"D\"B/2A/2A/2G/2F/2D/2A/2D/2A/2D/2|\"G\"BG/2D/2GG/2D/2|\"C\"e/2c/2A/2E/2CE/2D/2|\"D\"B/2A/2G/2F/2D/2A/2D/2A/2D/2|\"G\"BG/2D/2GG/2D/2|\"C\"e/2c/2A/2E/2CE/2D/2C/2E/2|\"D\"B/2A/2G/2F/2D/2A/2D/2A/2D/2|\"G\"BG/2D/2GG/2D/2|\"C\"e/2c/2A/2E/2CE/2D/2E/2G/2|\"D\"B/2A/2G/2F/2D/2A/2D/2A/2D/2A/2D/2|\"G\"BG/2D/2GG/2D/2|\"C\"e/\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d|\"G\"ggf/2g/2|\"C\"edcB|\"D\"A2d2|\"D\"ff/2df|\"C\"e/2c/2B/2A/2G/2F/2E|\"D\"D2d|\"G\"ggf/2g/2|\"C\"edcB|\"D\"A2d2|\"D\"ff/2d/2fa|\"G\"b/2a/2g/2f/2e/2d/2e/2|\"C\"dcB|\"D\"A2de|\"D\"ff/2d/2fa|\"G\"b/2a/2g/2f/2e/2d2|\"C\"edcd|\"D\"ff/2d/2fa|\"G\"b/2a/2g/2f/2e/2d/2e/2d/2|\"C\"dcBc|\"D\"A2d|\"D\"f/2e/2d/2f/2a/2g/2f/2e/2|\"G\"d/2B/2A/2B/2d/2e/2d/2c/2B/2|\"C\"AGG|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:F\n",
      "|\"F\"\"B\"|\"F\"\"B\"|\"F\"|\"C7\"|\"F\"\"C7\"|\"F\"\"B\"|\"F\"\"B\"|\"F\"\"B\"|\"F\"\"B\"|\"F\"|\"C7\"|\"F\"\"C7\"|\"F\"|\"F\"\"B\"|\"F\"\"C7\"|\"F\"|\"F\"|\"C7\"|\"F\"|\"C7\"|\"F\"\"B\"|\"F\"\"B\"|\"F\"\"C7\"|\"F\"|\"F\"|\"B\"\"C7\"|\"F\"\"C7\"|\"\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d/2|\"G\"a/2g/2d/2a/2d/2|b/2g/2a/2b3/2a/2|\"C\"g/2e/2c/2c/2e/2g/2e/2c/2|\"D\"a/2g/2f/2d/2a/2d/2a/2^f/2|\"G\"g/2a/2g/2d/2a/2d/2b/2d/2|g/2a/2b(3c'/2b/2a/2g/2f/2e/2|\"C\"g/2e/2c/2g/2\"D\"a/2g/2d/2d/2|\"D\"a/2g/2f/2d/2a/2d/2e/2|\"G\"g/2a/2b/2a/2b3/2a/2|\"C\"g/2e/2c/2g/2e/2c/2e/2g/2e/2c/2|\"D\"a/2g/2f/2d/2a/2d/2f/2a/2d/2|\"G\"g/2a/2b/2a/2b3/2a/2|\"C\"g/2e/2c/2g/2e/2c/2e/2g/2e/2c/2|\"D\"a/2g/2f/2d/2a/2d/2f/2a/2d/2|\"G\"g/2a/2b/2a/2b3/2a/2|\"C\"g/2e/2c/2g/2e/2c/2g/2e/2c/2e/2|\"D\"a/2g/2f/2d/2a/2d/2f/2a/2d/2|\"G\"g/2f/2g/2a/2b3/2a/2|\"C\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d/2c/2|\"G\"B/2d/2B/2A/2GB/2c/2|d/2B/2G/2d/2B/2A/2G/2|\"C\"e/2d/2c/2B/2A/2GB/2c/2|\"D\"d/2c/2B/2A/2\"G\"Gd/2c/2|\"G\"B/2d/2B/2A/2GB/2c/2|\"D\"d/2c/2d/2e/2d/2B/2A/2G/2|\"G\"B/2G/2B/2A/2G/2A/2B/2A/2G/2|\"C\"e/2f/2e/2d/2e/2f/2e/2d/2c/2|\"D\"d/2c/2B/2A/2\"G\"G|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:F\n",
      "|\"F\"|\"C\"|\"F\"|\"C\"|\"F\"|\"F\"|\"C\"|\"C\"|\"F\"|\"C\"|\"C\"|\"F\"|\"F\"|\"B\"|\"F\"|\"C\"|\"C\"|\"F\"|\"F\"|\"B\"|\"F\"|\"C\"|\"F\"|]\n",
      "c/2|\"F\"c2c3/2c/2|\"C\"B3/2A/2G3/2G/2|\"F\"AF2c3/2c/2|\"C\"B3/2A/2G3/2G/2|\"F\"F2a3/2g/2|\"F\"fcc2|\"C\"B3/2A/2G3/2G/2|\"C\"EFGA|\"F\"F2a3/2g/2|\"C\"fcc2|\"F\"f2a3/2g/2|\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "B/2c/2|\"G\"d/2B/2e/2B/2dg/2f/2|g/2d/2B/2dg/2f/2e/2|\"D\"f/2g/2f/2e/2d/2c/2B/2A/2|\"G\"G/2B/2d/2g/2f/2e/2d/2B/2|\"C\"c/2B/2c/2d/2e/2c/2A/2c/2e/2|\"D\"f/2g/2f/2e/2dc/2d/2|\"G\"g/2d/2B/2g/2dg/2f/2|g/2d/2B/2g/2d/2B/2dg/2f/2|\"C\"e/2d/2c/2e/2g/2e/2c'/2e/2g/2e/2|\"D\"f/2g/2f/2e/2dc/2d/2|\"G\"g/2d/2B/2g/2d/2b/2g/2d/2B/2|\"C\"c/2B/2c/2d/2e/2c'/2e/2g/2e/2|\"D\"f/2g/2f/2e/2dc/2d/2|\"G\"g/2d/2B/2g/2d/2b/2g/2d/2B/2|\"C\"cec|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:C\n",
      "|\"C\"|\"Dm\"|\"G\"|\"C\"|\"Dm\"|\"G\"|\"C\"\"G7\"|\"C\"|\"Dm\"|\"G\"|\"C\"|\"C\"|\"Dm\"|\"G\"|\"G\"|\"C\"|\"C\"|\"Dm\"|\"G\"|\"G\"\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "B/4c/4|\"G\"d/2d/2B/4d/4|\"C\"e/2e/2e/4e/4e/4d/4c/4|\"D\"B/2d/2d/4d/4d/4d/4|\"D\"e/2d/2d/2|\"G\"g/2B/4B/4d/4d/4|\"C\"e/2e/4e/4e/4d/4c/4|\"D\"B/2d/2d/2|\"G\"g/2d/2B/4d/4|\"C\"f/2e/2e/4e/4d/4c/4|\"D\"B/2d/2d/2B/4d/4|\"G\"g/2B/4B/4d/4g/4|\"C\"e/2e/2e/4d/4e/4c/4|\"D\"B/2d/2\"G\"g/2B/4d/4|\"C\"c/2c/2c/2e/4g/4|\"D\"f/2A/2a/4a/4a/4a/4|\"G\"g/2B/4B/4d/4g/4|\"C\"f/2c/2c/2e/4g/4|\"D\"f/2A/2a/4a/4a/4a/4a/4|\"G\"g/2B/2B/2d/4d/4|\"C\"g/2e/2e/4g/4e/2g/4|\"D\"f/2A/2a/4a/4a/4a/4|\"G\"g/2B/2B/4d/4|\"C\"g/2c/2c/4e/4g/4|\"D\"f/2A/2a/4a/4a/4a/4a/4|\"G\"a/2b/2b/4d/4\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d|\"G\"G/2A/2B/2A/2G(3B/2c/2B/2|\"G\"d/2e/2d/2B/2A/2G(3B/2c/2B/2|\"C\"c/2d/2e/2d/2B/2A/2(3B/2c/2B/2|\"D\"A/2d/2c/2A/2d(3B/2c/2B/2A/2|\"G\"G/2A/2B/2A/2G(3F/2G/2|\"G\"G/2A/2B/2c/2dd|\"C\"g/2f/2g/2a/2g/2f/2g/2a/2g/2f/2|\"D\"d/2c/2d/2e/2ff/2g/2|\"G\"a/2g/2f/2a/2g/2f/2g/2a/2g/2f/2|\"C\"e/2g/2f/2a/2g/2f/2g/2f/2g/2a/2g/2f/2|\"D\"d/2c/2d/2e/2ff/2g/2|\"G\"a/2g/2f/2a/2g/2f/2g/2a/2g/2f/2|\"C\"g/2f/2g/2a/2g/2f/2g/2a/2g/2f/2|\"D\"d/2c/2d/2e/2ff/2g/2|\"G\"a/2g/2f/2a/2g/2f/2g/2a/2g/2f/2|\"C\"g/2f/2a/2g/2f/2g/2a/2g/2f/2|\"D\"d/2c/2d/2e/2ff/2g/\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start='M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test major key with low samples: C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-abc-char\n",
      "Overriding: start = M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "number of parameters: 14.18M\n",
      "abc_char\n",
      "Loading meta from data/abc_char/meta.pkl...\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "\"G\"d3/2e/2d/2c/2B/2A/2G/2|\"F\"c3/2A/4c3/4A/4c3/4A/4c3/4c/4|\"G\"d3/4e/2d3/4e/4fg|\"F\"c3/4A/4c3/4f/4e3/4d/4c/4|\"G\"d3/4d/2e3/4f/4e3/4d/4|\"G\"d3/4e/4d3/4e/4d3/4c/4B3/4A/4|\"G\"G3/2B/2d3/4e/4d3/4c/4|\"C\"e3/4d/4e3/4f/4e3/4d/4c3/4|\"G\"B3/4d/4f3/4e/4d3/4c/4B/4|\"C\"c2z2|\"F\"A3/4c/4f3/4e/4d3/4c/4|f3/4e/4d3/4c/4B3/4A/4B3/4c/4|\"G\"d3/4c/4B3/4A/4B3/4d/4|\"C\"d3/4e/4d3/4c/4B/4f3/4e/4|\"G\"d3/4c/4B3/4c/4|\"C\"e3/4d/4e3/4d/4c3/4B/4|\"F\"A3/4c/4f3/4e/4d3/4c/4|\"G\"d3/4e/4d3/4c/4B3/4A/4|\"C\"c2c2|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"G\"|\"C\"|\"D7\"|\"\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "e/2d/2|\"C\"e/2d/2c/2d/2e/2d/2c/2d/2e/2f/2|g/2c/2c/2e/2gf/2e/2d/2c/2|\"G\"B/2d/2G/2B/2d/2G/2B/2d/2G/2|\"C\"e/2d/2c/2d/2e/2d/2c/2d/2e/2f/2|\"F\"g/2f/2e/2f/2c/2d/2c/2A/2c/2|\"G\"B/2d/2G/2B/2d/2g/2d/2g/2d/2|\"G\"B/2d/2G/2B/2d/2G/2B/2d/2G/2B/2|\"C\"c/2A/2G/2E/2G/2c/2d/2e/2f/2|g/2c/2(3f/2e/2d/2c/2d/2c/2e/2f/2|g/2a/2d/2(3f/2e/2d/2c/2d/2(3e/2d/2c/2d/2c/2|\"G\"B/2d/2G/2B/2d/2G/2B/2d/2G/2|\"C\"e/2d/2c/2d/2e/2d/2c/2d/2e/2f/2|g/2c/2(3f/2e/2d/2c/2e/2f/2a/2g/2f/2e/2|g/2c/2(3f/2e/2d/2c/2d/2c/2e/2f/2|g/2c/2(3a/2d/2c/2g/2d/2(3b\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "G|\"C\"c3/2d/2c/2d/2|\"F\"A3/2d/2c/2|\"G\"B3/2g/2f/2d/2|\"C\"c3/2d/2c/2d/2|\"C\"c3/2d/2c/2d/2|\"F\"cAF|\"G\"G3/2g/2f/2d/2|\"C\"c3/2d/2c/2d/2|\"F\"cAF|\"G\"G3/2g/2f/2d/2|\"C\"c3/2d/2c/2d/2|\"C\"e/2f/2g/2e/2d/2c/2|\"F\"fAf|\"G\"d3/2g/2f/2d/2|\"C\"c3/2d/2c/2d/2|\"F\"cAF|\"G\"G3/2g/2f/2d/2|\"C\"c3/2d/2c/2d/2|\"C\"e/2d/2c/2d/2|\"F\"cAF|\"G\"G3/2G/2g/2f/2|\"C\"e/2f/2g/2a/2g/2a/2g/2|\"F\"fAf|\"G\"d/2e/2f/2g/2a/2g/2f/2d/2|\"C\"c3/2d/2c/2d/2|\"F\"cAF|\"G\"G3/2G/2g/2f/2d/2|\"C\"c3/2d/2c/2d/2|\"C\"e/2d/2c/2G/2d/2|\"F\"cAF|\"G\"G3/2G/2g/2f/2d/2|\"C\"cAF|\"F\"FAF|\"G\"G3/2G\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "G|\"C\"cc/2c/2\"G7\"d/2c/2B/2A/2|\"C\"c/2d/2e/2f/2g/2e/2d/2c/2|\"F\"AA/2A/2\"G\"GG/2A/2|\"G\"B/2dd/2dd/2d/2|\"C\"ee/2f/2e/2d/2c/2d/2|\"C\"ee/2f/2ef/2e/2|\"F\"df/2f/2fe/2f/2|\"G\"d/2dd/2dd/2d/2|\"C\"ee/2f/2ee/2f/2|\"F\"df/2f/2fe/2f/2|\"G\"d/2df/2fg/2f/2d/2|\"C\"e/2e/2e/2f/2ef/2e/2|\"F\"df/2ff/2ff/2|\"G\"f/2d/2dd/2dd/2d/2|\"C\"e/2e/2e/2e/2f/2ee/2e/2|\"F\"d/2A/2A/2A/2A/2AA/2c/2|\"G\"B/2dd/2dd/2d/2|\"C\"e/2e/2e/2f/2e/2d/2e/2e/2f/2|\"F\"df/2fe/2f/2|\"G\"d/2dd/2dd/2d/2d/2|\"C\"e/2e/2f/2e/2d/2eg/2|\"F\"c/2c/2c/2c/2c/2\"G\"B/2A/2G/2D/2G/2|\"C\"E/2G/2G/2\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "c/2d/2|\"C\"e/2G/2c/2d/2e/2d/2c/2B/2|\"F\"A/2F/2F/2c/2F/2f/2F/2|\"G\"f/2f/2f/2d/2f/2g/2f/2d/2|\"G\"e/2c/2d/2e/2d/2G/2A/2|\"C\"G/2c/2d/2e/2d/2c/2B/2c/2c/2d/2|\"F\"e/2g/2f/2e/2f/2c/2f/2F/2|\"G\"f/2f/2f/2d/2f/2g/2f/2d/2|\"C\"e/2c/2d/2e/2f/2g/2e/2c/2d/2|\"C\"e/2f/2g/2f/2c/2e/2c/2d/2e/2|\"F\"f/2f/2f/2f/2f/2f/2d/2f/2g/2f/2|\"G\"a/2g/2f/2g/2f/2g/2f/2d/2|\"C\"e/2c/2d/2e/2f/2g/2f/2e/2c/2d/2|\"C\"e/2f/2g/2f/2c/2e/2c/2d/2e/2c/2d/2|\"F\"f/2f/2f/2e/2f/2c/2f/2d/2f/2g/2f/2|\"G\"a/2g/2f/2g/2f/2g/2f/2d/2f/2d/2|\"C\"e/2c/2d/2e/2f/2g/2f/2e/2c/2\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "c/2|\"C\"a/2g/2e/2a/2ge|c/2d/2e/2d/2ee|\"F\"fedc|\"G\"GG(3G/2A/2B/2|\"G\"d/2c/2B/2G/2G/2A/2B/2c/2|d/2G/2d/2G/2e/2d/2e/2d/2c/2|\"G\"d/2G/2e/2dd|\"C\"aa/2g/2f/2ec|\"F\"fedc|\"G\"GG(3G/2A/2B/2|\"G\"BGG(3G/2A/2B/2|\"C\"cc/2d/2ed|\"F\"fedc|\"G\"G(3G/2A/2B/2B/2A/2BB|\"C\"cc/2d/2ee|\"F\"fedc|\"G\"d/2G/2e/2dd|\"C\"ag/2f/2ee|\"F\"fedc|\"G\"d/2G/2e/2dd|\"C\"ag/2f/2g/2ee|\"F\"fedc|\"G\"G(3G/2A/2B/2A/2BB|\"C\"cc/2d/2ed|\"F\"fedc|\"G\"(3G/2A/2B/2G/2d/2e/2dd|\"C\"C(3G/2A/2B/2B/2A/2BB|\"F\"fedc|\"G\"(3G/2A/2B/2d/2ed|\"C\"g2ed|\"F\"fedc|\"G\"g/2e/2dd/2e/2dd|\"C\"ecAc|\"F\"\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "G/2|\"C\"c/2c/4c/4c/2c/2|\"F\"A/4A/4A/4A/4A/2A/2|\"G\"G/2G/2G/2G/2|\"G\"G/2B/2B/2B/2B/4B/4|\"C\"c/2c/4c/4c/4c/2c/2|\"F\"A/4A/4A/4A/4A/2A/2|\"G\"G/2G/2G/2G/2|\"G\"d/4d/4B/4G/2G/2|\"C\"c/4c/4c/4c/2c/2|\"F\"A/4A/4A/4A/2A/2|\"G\"G/2G/2G/2|\"C\"c/4c/4c/4c/4c/2c/2c/2|\"F\"A/4A/4A/2A/2A/2|\"G\"G/2G/2G/2G/2|\"C\"c/4c/4c/4c/4c/4c/4c/2|\"F\"A/4A/4A/4A/2A/2|\"G\"G/2G/2G/2G/2|\"C\"c/4c/4c/4c/2c/2|\"F\"A/4A/4A/4A/4A/2A/2|\"G\"G/2G/2G/2|\"C\"c/4c/4c/4c/4c/2c/2|\"F\"A/4A/4A/4A/2A/2|\"C\"G/2G/2G/2|\"C\"c/4c/4c/4c/4c/2c/2|\"F\"A/4A/4A/4A/4A/2A/2|\"G\"G/2G/2G/2|\"\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "c/2d/2|\"C\"e/2d/2e/2f/2eg|\"F\"f/2e/2f/2g/2fc|\"G\"d/2e/2f/2gg|\"G\"f/2e/2d/2c/2BG|\"C\"c/2d/2e/2f/2ee|\"F\"f/2e/2f/2g/2fc|\"G\"d/2e/2f/2gg|\"C\"g2ge|\"F\"f/2e/2f/2g/2fc|\"G\"d/2e/2f/2gg|\"C\"c'3/2b/2aa|\"C\"g2ge|\"F\"f/2e/2f/2g/2fc|\"G\"d/2e/2f/2gg|\"C\"c'3b|\"F\"af3|\"G\"f/2e/2f/2gg|\"C\"c'\"C\"c'|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:C\n",
      "|\"C\"|\"F\"\"C\"|\"F\"|\"G7\"|\"C\"|\"C\"\"G7\"|\"C\"\"G7\"|\"C\"|\"C\"|\"F\"|\"Dm\"|\"G7\"|\"C\"|\"C\"\"G7\"|\"C\"|\"C\"\"G7\"|\"C\"|\"C\"|\"F\"|\"G7\"|\"G7\"|\"C\"|\"G7\"|\"C\"|\"C\"\"G7\"|\"C\"|\"C\"|]\n",
      "g/2f/2|\"C\"ecGE|\"F\"FAA/2B/2c/2d/2|\"G7\"BGGE|\"C\"C2\"C\"c3/2c/2d/2c/2d/2|\"C\"ecGE|\"\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "c/4d/4|\"C\"e/2d/2c/2d/2|\"F\"e/2d/2c/2B/2|\"G\"d/2c/2B/2A/2|\"G\"G/2A/2G/2B/2|\"C\"c2|\"F\"a/2g/2f/2|\"G\"gg/4a/4|\"G\"b/2g/2d/2|\"C\"g/2f/2e/2c/2|\"F\"a/2g/2f/2|\"G\"gg/2a/4|\"C\"g/2f/2e/2|\"F\"a/2g/2f/2|\"G\"gg/2a/4|\"C\"g/2f/2g/4a/4|\"G\"g/2f/2e/2d/2|\"C\"e/2d/2c/2|\"F\"a/2g/2f/2|\"G\"gg/2a/4|\"G\"b/2g/2d/2|\"C\"e/2f/2e/2c/4|\"C\"g/2f/2e/2|\"F\"a/2g/2a/2|\"G\"g/2f/2g/4a/4|\"C\"g/2a/2a/2|\"G\"b/2g/2d/2|\"C\"e/2f/2g/4a/4|\"F\"a/2g/2f/2|\"G\"gg/2a/4|\"G\"b/2g/2d/2|\"C\"e/2f/2e/2|\"F\"a/2g/2f/2|\"C\"g/2f/2e/2c/4|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:D\n",
      "|\"D\"\"A7\"|\"D\"\"A7\"|\"D\"\"A7\"|\"D\"\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "e|\"C\"g/2e/2Gc/2d/2c/2B/2A/2|G/2c/2e/2Gc/2d/2c/2B/2A/2|\"F\"A/2B/2c/2A/2F/2A/2F/2A/2F/2|\"G\"G/2B/2d/2B/2d/2g/2d/2B/2|\"G\"d/2B/2d/2g/2d/2B/2d/2g/2d/2B/2|\"G\"d/2B/2d/2g/2d/2B/2d/2g/2d/2B/2|\"C\"c/2B/2c/2d/2e/2c/2Gc/2d/2c/2B/2A/2|\"F\"A/2F/2c/2A/2F/2A/2c/2F/2A/2F/2A/2F/2A/2|\"G\"G/2B/2d/2g/2d/2B/2d/2g/2d/2B/2g/2d/2|\"C\"c/2B/2c/2d/2e/2c/2G/2e/2c/2G/2|\"F\"A/2F/2c/2A/2F/2A/2c/2F/2A/2F/2A/2F/2A/2|\"G\"Gg/2d/2B/2d/2g/2d/2B/2d/2g/2d/2B/2|\"C\"c/2B/2c/2d/2e/2c/2G/2e/2c/2G/2|\"G\"B/2c/2d/2e/2d/2B/2d/2g/2d/2B/2d/2|\"C\"c/2B/2c/\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start='M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test minor key with low samples: Am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-abc-char\n",
      "Overriding: start = M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "number of parameters: 14.18M\n",
      "abc_char\n",
      "Loading meta from data/abc_char/meta.pkl...\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "\"Am\"ae3/2b/2|c'/2b/2a/2g/2f/2e/2f/2g/2|\"Dm\"d/2c/2d/2e/2f/2e/2d/2c/2|\"E\"d/2c/2B/2A/2G/2F/2E/2G/2|\"Am\"ae3/2a/2|\"Dm\"g/2f/2e/2d/2f/2e/2d/2c/2|\"E\"d/2c/2B/2A/2G/2F/2E/2F/2G/2|\"E\"A/2/2G/2F/2E/2F/2G/2c/2B/2A/2|\"Am\"c/2A/2a/2A/2a/2A/2g/2A/2|\"Dm\"f/2d/2e/2f/2e/2d/2c/2d/2e/2|\"E\"f/2d/2e/2f/2e/2d/2c/2B/2e/2|\"Am\"c/2A/2e/2A/2a/2A/2g/2A/2|\"Dm\"f/2d/2e/2f/2e/2d/2c/2d/2e/2|\"E\"f/2d/2e/2f/2e/2d/2c/2B/2|\"Am\"c/2A/2a/2A/2a/2A/2g/2A/2|\"Dm\"f/2d/2e/2f/2e/2d/2c/2d/2e/2|\"E\"f/2d/2e/2f/2e/2d/2c/2B/2e/2|\"E\"d/2c/2B/2A/2G/2F/2E/2\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "e'/4d3/2c'/2|\"Am\"a/2e/2c'/2a3/2g/2|\"Dm\"d/2a/2b/2a/2g/2f/2|\"E\"ee/2c'/2e/2a3/2e/2|\"C\"e/2g/2c'/2g3/2c'/2|\"Dm\"d/2a/2b/2a3/2g/2|\"E\"f/2g/2a/2g/2f/2e/2d/2|\"E\"c/2B/2A/2G/2F/2E/2F/2G/2|\"E\"E/2G/2B/2d3/2c/2|\"Am\"c3/2e/2a3/2g/2|\"Dm\"d/2a/2b/2a3/2g/2|\"E\"f/2g/2a/2g3/2f/2|\"Am\"e/2g/2c'/2g3/2c'/2|\"Dm\"d/2a/2b/2a3/2g/2|\"E\"f/2g/2a/2g/2f/2g/2f/2e/2d/2|\"Am\"c/2A/2c/2d3/2g/2|\"Dm\"\"A\"d/2a/2b/2a3/2g/2|\"E\"f/2g/2a/2g/2f/2e/2d/2|\"E\"c/2B/2A/2G/2F/2E/2F/2G/2|\"Am\"A3/2B/2A3/2g/2|\"Dm\"\"F\"d/2a/2b/2a3/2g/2|\"Dm\"\"E\"a/2g/2e/2g/2f/2e/2d/\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "E|\"Am\"A/2^G/2A/2E/2A/2A3/2^G/2|e3/2d/2e3/2d/2c3/2d/2|\"Am\"e3/2d/2c3/2A/2G|\"Dm\"f3/2e/2d3/2A/2G3/2A/2|\"E\"^G3/2A/2G3/2A/2E3/2^B/2|e3/2d/2c3/2B/2G3/2B/2G3/2e/2|\"E\"e3/2c/2d3/2f/2e3/2d/2c3/2B/2|\"E\"e3/2d/2c3/2B/2^A3/2G/2E3/2d/2|e3/2B/2G3/2e/2^e3/2d/2c3/2B/2|\"Am\"A3/2A/2G3/2^F/2E3/2d/2|\"Dm\"d3/2A/2c3/2A/2G3/2A/2|\"E\"^G3/2B/2^A3/2G3/2B/2G3/2e/2|e3/2E/2d3/2B/2G3/2B/2G3/2e/2B3/2d/2|\"Am\"c3/2A/2G3/2A/2B3/2A/2G3/2A/2|\"Dm\"d3/2A/2c3/2A/2\"E\"B3/2G/2B3/2e/2|\"E\"g3/2f/2e3/2d/2c3/2B/2|\"E\"E3/2f/2e3/2B/2G3/2e/2B3/2d/2|\"Am\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "e|\"Am\"e/2e/2\"G/2e/2c/2B/2c/2|\"E\"e/2e/2e/2e/2d/2ee|\"E\"^f/2e/2e/2d/2e/2f/2g/2f/2e/2|\"E\"d/2e/2d/2e/2\"E7\"fe|\"Am\"e/2e/2e/2e/2A/2e/2e/2A/2e/2|\"Dm\"ff/2e/2f/2g/2f/2e/2|\"E\"e/2e/2e/2^d/2ee|\"E\"^f/2e/2e/2d/2ee|^f/2e/2d/2e/2f/2g/2f/2e/2d/2|\"E\"^f/2e/2d/2e/2Be|^f/2e/2d/2e/2f/2g/2f/2e/2|\"Am\"a/2A/2a/2^g/2a/2b/2a/2g/2|\"Dm\"f/2e/2e/2d/2e/2f/2g/2f/2e/2|\"E\"^d/2e/2^d/2e/2f/2g/2f/2e/2d/2|\"Am\"f/2a/2g/2a/2b/2a/2g/2f/2e/2|\"Dm\"\"Gm\"dd/2e/2f/2g/2f/2e/2|\"Am\"\"Dm\"e/2d/2e/2f/2g/2f/2e/2d/2|\"E\"^f/2e/2d/2e/2f/2e/2d/2e/2f/2|\"Am\"\"C\"\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "c/2d/2|\"Am\"e/2c/2e/2aa/2g/2|\"Dm\"f/2d/2e/2d/2e/2c/2A/2d/2e/2|\"E\"f/2e/2^d/2e/2f/2g/2e/2|\"E\"d/2c/2B/2A/2Bc/2d/2|\"E\"e/2=d/2e/2f/2g/2e/2f/2g/2e/2|\"Am\"a/2g/2a/2b/2a/2g/2a/2b/2a/2g/2|\"Dm\"f/2d/2e/2d/2e/2c/2A/2A/2d/2e/2|\"E\"f/2e/2^d/2e/2f/2g/2e/2f/2g/2e/2|\"E\"d/2e/2^d/2e/2f/2e/2f/2g/2e/2|\"Am\"a/2^g/2a/2b/2a/2g/2a/2b/2a/2g/2a/2b/2|\"Am\"a/2^g/2a/2b/2a/2g/2a/2b/2a/2g/2a/2b/2|\"Dm\"c'/2a/2b/2a/2g/2a3/2g/2|\"E\"\"E\"d/2e/2f/2g/2a/2b/2a/2g/2e/2f/2|\"Am\"\"E2\"Am\"a3/2g/2f/2|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:D\n",
      "|\"D\"|\"G\"|\"A\"|\"D\"|\"G\"|\"A\"\"D\"|\"D\"\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "\"Am\"A/4a/4A/4e/2a/2|e/2A/2A/2a/2|\"Dm\"e/2d/2e/2|\"E\"^d/2e/2d/2|\"E\"e/2=d/2e/4B/4|\"E\"e/2^d/2B/2|\"E\"e/2=d/2B/2|\"Am\"=c/2c/2B/2A/2|\"Dm\"F/2D/2e/2|\"E\"e/2^d/2B/2|\"Am\"c/2A/2E|\"Dm\"D/2D/2e/2|\"E\"e/2^d/2B/2|\"Am\"A/2E|\"Dm\"d/2/2^c/2|\"E\"e/2^d/2B/2B/2|\"E\"e/4=d/4B/4|\"Am\"c/2A/2E|\"Dm\"F/2D/2e/2|\"E\"d/2B/2B/2|\"Am\"c/2A/2E|\"Dm\"F/2D/2e/2|\"E\"e/2^d/2B/2|\"Am\"c/2A/2E|\"Dm\"F/2D/2e/2|\"E\"e/2^d/2B/2|\"Am\"c/2A/2E|\"Dm\"F/2D/2|]\n",
      "\n",
      "M:3/4\n",
      "L:1/4\n",
      "K:Bb\n",
      "|\"B\"|\"B\"|\"F7\"|\"F7\"|\"B\"|\"F7\"|\"B\"|\"B\"|\"F7\"|\"B\"|\"B\"|\"B\"|\"E\"|\"Cm\"|\"F7\"|\"B\"|\"E\"|\"Cm\"|\"F7\"|\"B\"|\"B\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "A/2B/2|\"Am\"cc/2d/2ea/2g/2|\"Dm\"f/2e/2d/2c/2d/2e/2d/2c/2|\"E\"B/2c/2B/2A/2GB/2G/2|\"E\"Be/2f/2ga/2b/2|\"Am\"c'a/2g/2f/2e/2d/2c/2|\"Dm\"d/2e/2d/2c/2d|a|\"E\"g/2f/2e/2f/2ga/2b/2|\"Am\"c'a/2g/2f/2e/2c/2|\"Dm\"d/2e/2d/2c/2\"E\"dc/2d/2|\"Am\"e/2c/2A/2A|z|\"Am\"e/2a/2a/2a/2b/2aa/2b/2|\"Dm\"a/2b/2a/2g/2f/2dd/2e/2|\"E\"fe/2f/2ga/2b/2|\"Am\"c'/2b/2a/2g/2f/2ee/2f/2|\"Dm\"d/2e/2d/2c/2\"E\"dc/2d/2|\"Am\"e/2a/2a/2a/2b/2aa/2b/2|\"Dm\"a/2b/2a/2g/2f/2dd/2e/2|\"Am\"f/2a/2a/2g/2f/2ee/2f/2|\"E\"e/2e/2g/2b/2a/2g/2f/2e/2|\"Am\"\"E\"d/2e/2e/2e/2^f/2g/2b/2a/2|\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "c/2d/2|\"Am\"e/2a/2A/2a/2Ag/2e/2|\"Dm\"d/2e/2d/2f/2e/2d/2e/2c/2|\"E\"d/2B/2A/2G/2EF/2G/2|\"E\"Ed/2e/2\"Dm\"d/2e/2f/2d/2|\"E\"e/2d/2e/2B/2e/2d/2e/2c/2d/2|\"Am\"e/2a/2a/2Ag/2e/2|\"Dm\"d/2e/2d/2f/2e/2d/2e/2c/2|\"E\"d/2B/2G/2e/2d/2e/2c/2d/2e/2c/2|\"Am\"e/2a/2a/2a/2f/2\"E\"g/2e/2d/2e/2c/2d/2|\"Am\"e/2a/2a/2a/2f/2\"Dm\"e/2d/2e/2f/2d/2|\"E\"e/2d/2B/2G/2Ed/2e/2c/2|\"Am\"A/2a/2a/2A/2g/2A/2B/2c/2d/2e/2c/2|\"Dm\"d/2e/2d/2d/2f/2e/2d/2e/2d/2e/2c/2|\"E\"d/2B/2G/2e/2d/2e/2c/2d/2e/2c/2|\"Am\"e/2a/2a/2a/2b/2a/2f/2e/2d/2e/2c/2|\"Dm\"d/2e/2d/2f/2e/2d\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "c/4B/4|\"Am\"A/2A/2A/2A/2|\"Dm\"d3/4e/4f/2e/2|\"E\"c/2B/2E/2c/2|\"E\"e/2d/2B/2|\"Am\"A3/4B/4|\"Dm\"A/2D/2\"G7\"A/2G/2|\"C\"c/2e/2d/2e/4d/4|\"Am\"c/2B/2G/2|\"Dm\"d3/2e/4|\"E\"d/2e/2B/2e/2|\"E\"d/2e/2B/2d/2|\"Am\"c/2B/2G/2|\"Dm\"A3/4B/4|\"E\"A/2G/2c/2|\"Am\"c/2B/2G/2|\"Dm\"d3/4e/4|\"E\"d/2e/2B/2|\"E\"d/2B/2e/2|\"Am\"c/2B/2G/2|\"Dm\"d3/4e/4|\"E\"d/2B/2e/2|\"Am\"c/2B/2G/2|\"Dm\"d3/4e/4|\"E\"B/2e/2B/2|\"E\"d/2B/2e/2|\"E\"D/2e/2B/2|\"Am\"c/2B/2G/2|\"Dm\"A3/2e/4|\"Am\"c/2B/2G/2|\"Dm\"d3/4e/4|\"E\"d/2c/2B/2|\"E\"d/2B/2e/2|\"Am\"c/2B/2G/2|\"Dm\"A3/4B/4|\"Cm\"c/2B/2G/2|\"Dm\"A\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "A|\"Am\"A/2B/2c/2d/2c/2B/2A/2|\"Dm\"A/2B/2d/2c/2B/2A/2G/2|\"E\"E/2G/2B/2d/2c/2B/2A/2G/2|\"Dm\"A/2B/2d/2c/2B/2A/2G/2F/2|\"E\"E/2G/2B/2d/2c/2B/2A/2G/2|\"Dm\"A/2B/2d/2c/2B/2A/2G/2F/2|\"E\"E/2F/2G/2B/2d/2c/2B/2A/2G/2|\"Am\"A3/2e/2d/2c/2B/2A/2G/2F/2|\"Dm\"A/2B/2d/2c/2B/2A/2G/2F/2|\"E\"E/2G/2B/2d/2c/2B/2A/2G/2A/2|\"Am\"A3/2e/2d/2c/2B/2A/2G/2F/2|\"Dm\"A/2d/2c/2B/2A/2G/2F/2G/2A/2|\"E\"E3/2e/2d/2c/2B/2A/2G/2|\"Am\"A3/2e/2d/2c/2B/2A/2G/2F/2|\"Dm\"A/2d/2c/2B/2A/2G/2F/2G/2A/2|\"E\"B/2e/2e/2d/2c/2B/2A/2G/2|\"Am\"A3/2e/2d/2c/2B/2A/2G/2F/2|E/\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start='M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test older checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = older_ckpt/m_voices\n",
      "Overriding: path_meta = older_ckpt/m_voices\n",
      "Overriding: start = M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "number of parameters: 14.18M\n",
      "shakespeare_char\n",
      "Loading meta from older_ckpt/m_voices/meta.pkl...\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]G/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]G/2E\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d2|\"G\"B3/2g/2d3/2B/2G3/2B/2d3/2B/2|\"D\"c3/2e/2a3/2g/2f3/2d/2e3/2f/2|\"G\"B3/2g/2d3/2B/2g3/2d/2B3/2d/2|\"D\"c3/2A/2d3/2A/2e3/2A/2f3/2A/2|\"G\"g3/2d/2B3/2d/2g3/2b/2a3/2g/2|\"D\"f3/2d/2A3/2d/2f3/2a/2g3/2f/2|\"C\"e3/2d/2c3/2B/2\"D\"c3/2e/2d3/2c/2|\"G\"B2G2G2d2|\"D\"ADBDcDdc|\"G\"BGcG^cGdG|\"D\"ADBDcDd2|\"G\"edd^cd4|\"D\"ADBDcDdc|\"G\"BGcG^cGd2|\"C\"ecgc\"D\"fcac|\"G\"g2b2g4|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:Eb\n",
      "|\"D\"|\"G\"\"A\"|\"D\"|\"Em\"\"A\"|\"D\"|\"G\"\"A\"|\"G\"\"A\"|\"D\"|\"G\"\"D\"|\"G\"\"D\"|\"G\"\"D\"|\"E\"\"A\"|\"G\"\"D\"|\"G\"\"D\"|\"G\"\"D\"|\"E\"\"A\"|\"A\"\"D\"|]\n",
      "A/2|\"D\"d/2c/2d/2e/2fA|\"G\"Be\"\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2f/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d2|\"G\"G/2B/2d3/4d/4|\"C\"e/2e/2c/2A/2|\"D\"F/2A/2D/2|\"D\"F/2A/2D/2d/2|\"D\"=c/2d/2A/2^G/2A/2|\"G\"B/2G/2d3/2e/4|\"G\"d/2B/2G/2A/2|\"C\"E/2G/2D/2=CD/2|\"D\"F/2A/2d/4d/4f/4e/4|\"G\"g/2G/2G/2|\"C\"c/2G/2c/2e|\"D\"d/4c/4B/4A/2f/4|\"G\"g/2d/2B/2G/2|\"D\"F/2A/2D/2A/4d/4|\"G\"B/2G/2d/4d3/4d/4|\"D\"A/2d/4c/4B/4A/2|\"G\"G/2B/2G/2|\"C\"E/2G/2\"G\"G|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:B\n",
      "|\"A\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"A\"\"Bm\"|\"E\"\"A\"\"A\"|\"D\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"D\"|\"A\"\"Bm\"|\"E\"\"A\"|\"A\"\"Bm\"|\"E\"\"A\"|]\n",
      "z/2|\"A\"z/2A/2-A/2G/2AA|\"Bm\"B/2c/2B/2A/2\"E\"GE|\"A\"z/2A/2-\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d/2|\"G\"B3/2G/2G/2|\"C\"cBc|\"D\"d2d|\"G\"G2B/2c/2|\"G\"d3/2B/2GG|\"C\"cB\"D\"AB/2c/2|\"G\"d2\"C\"e/2c/2|\"G\"d2g3/2B/2|\"D\"cABc|\"G\"d2\"C\"e3/2d/2|\"D\"fzde/2f/2|\"G\"g3/2e/2d3/2e/2|g/2c/2B/2A/2G2|\"D\"A2g3/2f/2|\"G\"g3/2d/2B/2\"C\"cB|\"D\"Ad\"G\"g3/2f/2|\"Em\"g/2e/2\"A\"^c/2\"D\"d2|\"A\"e/2d/2c/2d/2eA/2c/2|\"D\"d2\"G\"B/2A/2G/2A/2|\"D\"FDD|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"A\"|\"E\"|\"E\"|\"A\"|\"E\"\"A\"|\"A\"|\"F#m\"|\"Bm\"\"E\"|\"Bm\"\"E\"|\"A\"\"Bm\"|\"A\"\"E\"|\"A\"\"A\"|]\n",
      "e|\"A\"a3/2g/2a/2e/2c/2A/2|\"E\"BGE3/2E/2|\"/2F/2A/2AB/2c/2|\"Bm\"dc\"E\"e3/2d/2|\"A\"c3/2B/2A\"E\"B/2^G/2E/2B/2d/2c/2B/2|\"A\"A\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2e/2|\"G\"g/2d/2B/2|GB/2A/2|\"G\"G/4A/4B/4c/4d/2g/2|d/2B/2B/2g/2|\"F\"=f/2A/2A/2B/2|cA\"G\"G/4A/4B/4c/4d/2B/2|\"C\"e/2d/4c/4\"G\"d/2B/2|\"G\"G/4A/4B/4c/4d/2B/2|dB|\"G\"G/4A/4B/4c/4d/2B/2|\"C\"e/2d/4c/4d/2e/2|\"F\"=f/2A/2A/2B/2|cA\"G\"g/2d/2B/4c/4d/4B/4|g/2d/2B/4c/4d/4B/4|\"G\"g/2d/2B/4c/4d/4B/4|gd|\"G\"g/2d/2B/4c/4d/4B/4|g/2d/2B/4c/4d/4B/4|\"D\"a/4d/4A/2A/2B/2|\"D7\"cA|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:F\n",
      "|\"D\"|\"C\"|\"D\"|\"D\"|\"G\"\"A\"|\"D\"|\"G\"|\"D\"|\"E\"|\"A\"|\"G\"|\"D\"|\"G\"\"A\"|\"D\"|]\n",
      "a/2g/2|\"D\"fdfd|f/2af/2ag/2f/2|\"C\"e=cec|e/2ge/2ga/2g/2|\"D\"fdfd|\"D\"f/2af/\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d2|\"G\"B3/2g/2d3/4e/4d/2B/2|\"G\"g/2d/2B/2G/2A/2|B3/4B/4B/2A/2|\"G\"G3/2|\"C\"E/2G/2D/2E/2G/2A/2|\"D\"B3/4B/4B/2A/2G/2|\"G\"G3/2B/2A/2G/2|\"C\"E/2G/2D/2E/2G/2A/2|\"D\"B3/2B/4B/4A/2G/2|\"G\"G2|]\n",
      "\n",
      "M:3/4\n",
      "L:1/4\n",
      "K:Gb\n",
      "|\"D\"|\"D\"|\"G\"|\"D\"|\"D\"|\"Em\"\"A\"|\"D\"|\"D\"|\"A\"|\"Bm\"|\"A7\"|\"D\"|\"A\"|\"E7\"|\"A\"|\"G\"|\"D\"|\"A\"|\"D\"|\"D\"|\"Em\"|\"A7\"|\"D\"|]\n",
      "|A|\"D\"f3/2e/2d|\"D\"AFA|\"G\"BGB|\"D\"AFA|\"D\"f3/2e/2d|\"D\"AFA|\"Em\"Be\"A\"c|\"D\"d2|A|\"D\"f2a|\"A\"e2a|\"Bm\"d3/2e/2d|\"A7\"cBA|\"D\"f2a|\"A\"e2a|\"E7\"^gfg|\"A\"a2a|\"G\"b2b|\"D\"a2a|\"A\"ggg|\"D\"fed|\"D\"f3/2e/2d|\"Em\"Bgf|\"A7\"edc|\"D\"d2\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"D\"f/2e/2f/2g/2a/2b/2|\"D\"c'/2a/2f/2dd|\"G\"g/2f/2g/2a/2b/2g/2e/2d/2|\"C\"c/2g/2f/2g/2a/2g/2e/2d/2c/2|\"G\"B/2g/2f/2g/2d/2g/2d/2B/2|\"D\"cAA|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"G\"|\"G\"\"D7\"|\"G\"\"D7\"|\"G\"|\"D\"|\"G\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    " !python3 sample.py --out_dir=older_ckpt/m_voices --path_meta=older_ckpt/m_voices --start='M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat older_ckpt/m_voices/ckpt.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l older_ckpt/m_voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l out-abc-char/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
