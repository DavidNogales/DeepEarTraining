{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def load_dataframe(relative_path,dataframe_name):\n",
    "    df = pd.read_pickle(f'{relative_path}/{dataframe_name}.pkl')    \n",
    "    return df\n",
    "\n",
    "def read_file(relative_path,file_name):\n",
    "    text= \"\"\n",
    "    with open(f'{relative_path}/{file_name}.abc','r') as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unit_note_length', 'tuneBook', 'title', 'reference_number',\n",
       "       'original_header', 'original_body', 'meter', 'key', 'clean_song',\n",
       "       'clean_header', 'clean_body', 'chord_progression', '\"fm\"', '\"ff'\"',\n",
       "       '\"f7\"', '\"em\"', '\"ee'\"', '\"e7\"', '\"e\"', '\"dm\"', '\"dd'\"', '\"d7\"', '\"d\"',\n",
       "       '\"cm\"', '\"cc'\"', '\"c7\"', '\"c#m\"', '\"c#7\"', '\"c\"', '\"Gm\"', '\"Gg\"',\n",
       "       '\"Gd'\"', '\"G7\"', '\"G#m\"', '\"G#7\"', '\"G\"', '\"Fm\"', '\"Ff\"', '\"Fc'\"',\n",
       "       '\"F7\"', '\"F#m\"', '\"F#7\"', '\"F\"', '\"Em\"', '\"Eb\"', '\"E7\"', '\"E#m\"',\n",
       "       '\"E#7\"', '\"E\"', '\"Dm\"', '\"Da\"', '\"D7\"', '\"D#m\"', '\"D#7\"', '\"D\"', '\"Cm\"',\n",
       "       '\"Cg\"', '\"C7\"', '\"C#m\"', '\"C#7\"', '\"C\"', '\"Bm\"', '\"Bf\"', '\"Bb\"', '\"B7\"',\n",
       "       '\"B#m\"', '\"B#7\"', '\"B\"', '\"Am\"', '\"Ae'\"', '\"Aa\"', '\"A7\"', '\"A#m\"',\n",
       "       '\"A#7\"', '\"A\"'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_path =\"notebooks/data/final_dataset\"\n",
    "filename_name = 'clean_augmented_data'\n",
    "#filename_name = 'clean_original_training_data'\n",
    "#relative_path =\"notebooks/data/original_dataset\"\n",
    "training_data_df = load_dataframe(relative_path,filename_name)\n",
    "training_data_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_note_length</th>\n",
       "      <th>tuneBook</th>\n",
       "      <th>title</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>original_header</th>\n",
       "      <th>original_body</th>\n",
       "      <th>meter</th>\n",
       "      <th>key</th>\n",
       "      <th>clean_song</th>\n",
       "      <th>clean_header</th>\n",
       "      <th>...</th>\n",
       "      <th>\"B#m\"</th>\n",
       "      <th>\"B#7\"</th>\n",
       "      <th>\"B\"</th>\n",
       "      <th>\"Am\"</th>\n",
       "      <th>\"Ae'\"</th>\n",
       "      <th>\"Aa\"</th>\n",
       "      <th>\"A7\"</th>\n",
       "      <th>\"A#m\"</th>\n",
       "      <th>\"A#7\"</th>\n",
       "      <th>\"A\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9491</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Grandpa's</td>\n",
       "      <td>78</td>\n",
       "      <td>X:78\\nT:Grandpa's\\nM:4/4\\nL:1/4\\nK:Amajor</td>\n",
       "      <td>E/2D/2|\"A,\"CE\"E7\"FG|\"A,\"A/2G/2A/2B/2ce|\"B,m\"dc...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9492</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>The Girl With The Green Hat On</td>\n",
       "      <td>79</td>\n",
       "      <td>X:79\\nT:The Girl With The Green Hat On\\nM:4/4\\...</td>\n",
       "      <td>(3E/2F/2G/2|\"A,\"AE\"E7\"E/2F/2E/2D/2|\"A,\"C/2D/2E...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9493</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Green Meadow</td>\n",
       "      <td>80</td>\n",
       "      <td>X:80\\nT:Green Meadow\\nM:4/4\\nL:1/4\\nK:Dmajor</td>\n",
       "      <td>(3A,/2B,/2C/2|\"D\"DD/2E/2F/2D/2F/2A/2|\"G,\"B/2c/...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>D</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9494</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>The Old Grey Cat</td>\n",
       "      <td>82</td>\n",
       "      <td>X:82\\nT:The Old Grey Cat\\nM:4/4\\nL:1/4\\nK:Bminor</td>\n",
       "      <td>F|\"B,m\"BBB,B,/2C/2|\"B,m\"D/2C/2D/2E/2F/2E/2F/2^...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>Bm</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9495</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Gyre And Gimble</td>\n",
       "      <td>84</td>\n",
       "      <td>X:84\\nT:Gyre And Gimble\\nM:4/4\\nL:1/4\\nK:Amajor</td>\n",
       "      <td>E|\"A,\"AECE|\"B,m\"FD\"E7\"B,D|\"A,\"CEA3/2B/2|\"E7\"c/...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unit_note_length          tuneBook                           title  \\\n",
       "9491              1/4  dataset_min5.abc                       Grandpa's   \n",
       "9492              1/4  dataset_min5.abc  The Girl With The Green Hat On   \n",
       "9493              1/4  dataset_min5.abc                    Green Meadow   \n",
       "9494              1/4  dataset_min5.abc                The Old Grey Cat   \n",
       "9495              1/4  dataset_min5.abc                 Gyre And Gimble   \n",
       "\n",
       "     reference_number                                    original_header  \\\n",
       "9491               78          X:78\\nT:Grandpa's\\nM:4/4\\nL:1/4\\nK:Amajor   \n",
       "9492               79  X:79\\nT:The Girl With The Green Hat On\\nM:4/4\\...   \n",
       "9493               80       X:80\\nT:Green Meadow\\nM:4/4\\nL:1/4\\nK:Dmajor   \n",
       "9494               82   X:82\\nT:The Old Grey Cat\\nM:4/4\\nL:1/4\\nK:Bminor   \n",
       "9495               84    X:84\\nT:Gyre And Gimble\\nM:4/4\\nL:1/4\\nK:Amajor   \n",
       "\n",
       "                                          original_body meter key  \\\n",
       "9491  E/2D/2|\"A,\"CE\"E7\"FG|\"A,\"A/2G/2A/2B/2ce|\"B,m\"dc...   4/4   A   \n",
       "9492  (3E/2F/2G/2|\"A,\"AE\"E7\"E/2F/2E/2D/2|\"A,\"C/2D/2E...   4/4   A   \n",
       "9493  (3A,/2B,/2C/2|\"D\"DD/2E/2F/2D/2F/2A/2|\"G,\"B/2c/...   4/4   D   \n",
       "9494  F|\"B,m\"BBB,B,/2C/2|\"B,m\"D/2C/2D/2E/2F/2E/2F/2^...   4/4  Bm   \n",
       "9495  E|\"A,\"AECE|\"B,m\"FD\"E7\"B,D|\"A,\"CEA3/2B/2|\"E7\"c/...   4/4   A   \n",
       "\n",
       "                                             clean_song  \\\n",
       "9491  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...   \n",
       "9492  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...   \n",
       "9493  M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...   \n",
       "9494  M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...   \n",
       "9495  M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...   \n",
       "\n",
       "                                           clean_header  ... \"B#m\" \"B#7\"  \"B\"  \\\n",
       "9491  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...  ...     0     0    0   \n",
       "9492  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...  ...     0     0    0   \n",
       "9493  M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...  ...     0     0    0   \n",
       "9494  M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...  ...     0     0    0   \n",
       "9495  M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...  ...     0     0    0   \n",
       "\n",
       "      \"Am\"  \"Ae'\"  \"Aa\"  \"A7\"  \"A#m\"  \"A#7\"  \"A\"  \n",
       "9491     0      0     0     0      0      0    9  \n",
       "9492     0      0     0     0      0      0    9  \n",
       "9493     0      0     0     7      0      0    0  \n",
       "9494     0      0     0     0      0      0    5  \n",
       "9495     0      0     0     0      0      0   12  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df[\"clean_header\"].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1257"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df[\"clean_body\"].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab:  \n",
      "\"#'(),-/1234567=ABCDEFG[]^_abcdefgmz|~\n",
      "vocab_size 39\n",
      "silences  516\n"
     ]
    }
   ],
   "source": [
    "bodies = \"\"\n",
    "silences = 0\n",
    "for body in training_data_df[\"clean_body\"]:\n",
    "    if 'z' in body:\n",
    "        silences +=1 \n",
    "    bodies += body+\"\\n\"\n",
    "chars = sorted(list(set(bodies)))\n",
    "vocab_size = len(chars)\n",
    "print('vocab: ',''.join(chars))\n",
    "print('vocab_size',vocab_size)\n",
    "print(\"silences \",silences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chars: 4062773\n"
     ]
    }
   ],
   "source": [
    "training_data_text = read_file(relative_path,filename_name)\n",
    "\n",
    "print(\"number of chars:\",len(training_data_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chars \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(training_data_text)))\n\u001b[1;32m      2\u001b[0m vocab_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(chars)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(chars))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_data_text' is not defined"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(training_data_text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.28.0.dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14.2\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import tiktoken\n",
    "\n",
    "print(wandb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile  docker-compose.yaml  overrides.json\n",
      "README.md   notebooks\t\t requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "nano_path = 'notebooks/nanoGPT'\n",
    "os.chdir(nano_path)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE      assets\t      data\t  out-abc-char\twandb\n",
      "README.md    config\t      model.py\t  sample.py\n",
      "__pycache__  configurator.py  older_ckpt  train.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with multiple voices present\n",
    "#length of dataset in characters: 4,149,703\n",
    "#all the unique characters: \n",
    "#\"#'()+,-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
    "#vocab size: 46\n",
    "#train has 3,734,732 tokens\n",
    "#val has 414,971 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 4,062,773\n",
      "all the unique characters: \n",
      "\"#'(),-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
      "vocab size: 45\n",
      "train has 3,656,495 tokens\n",
      "val has 406,278 tokens\n"
     ]
    }
   ],
   "source": [
    "!python3 data/abc_char/prepare.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding config with config/train_abc_char.py:\n",
      "# train a miniature character-level shakespeare model\n",
      "# good for debugging and playing on macbooks and such\n",
      "\n",
      "out_dir = 'out-abc-char'\n",
      "eval_interval = 10 # keep frequent because we'll overfit\n",
      "eval_iters = 500\n",
      "log_interval = 5 # don't print too too often\n",
      "\n",
      "# we expect to overfit on this small dataset, so only save when val improves\n",
      "always_save_checkpoint = False\n",
      "\n",
      "wandb_log = True # override via command line if you like\n",
      "wandb_project = 'abc-char'\n",
      "wandb_run_name = 'mini-char-gpt-bt-84'\n",
      "\n",
      "dataset = 'abc_char'\n",
      "batch_size = 84\n",
      "block_size = 512 # context of up to 512 previous characters\n",
      "\n",
      "# baby GPT model :)\n",
      "n_layer = 12\n",
      "n_head = 8\n",
      "n_embd = 384\n",
      "dropout = 0.2\n",
      "\n",
      "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
      "max_iters = 5000\n",
      "lr_decay_iters = 5000 # make equal to max_iters usually\n",
      "min_lr = 1e-4 # learning_rate / 10 usually\n",
      "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
      "\n",
      "warmup_iters = 5 # not super necessary potentially\n",
      "\n",
      "# on macbook also add\n",
      "# device = 'cpu'  # run on cpu only\n",
      "# compile = False # do not torch compile the model\n",
      "\n",
      "found vocab_size = 45 (inside data/abc_char/meta.pkl)\n",
      "Initializing a new model from scratch\n",
      "number of parameters: 21.26M\n",
      "using fused AdamW: True\n",
      "compiling the model... (takes a ~minute)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavidnogales\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/pt-env/notebooks/nanoGPT/wandb/run-20230412_043941-m66g4lw2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmini-char-gpt-bt-84\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char/runs/m66g4lw2\u001b[0m\n",
      "step 0: train loss 3.9198, val loss 3.9141\n",
      "[2023-04-12 04:42:14,924] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-12 04:42:15,326] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-12 04:42:15,969] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-12 04:42:16,151] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-12 04:42:16,410] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-12 04:42:16,587] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-12 04:42:16,840] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-12 04:42:17,015] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-12 04:42:17,268] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-12 04:42:17,449] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-12 04:42:17,708] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-12 04:42:17,902] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-12 04:42:18,161] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-12 04:42:18,446] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-12 04:42:18,705] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-12 04:42:18,886] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-12 04:42:19,156] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-12 04:42:19,338] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-12 04:42:19,605] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-12 04:42:19,787] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-12 04:42:20,059] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-12 04:42:20,240] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-12 04:42:20,511] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-12 04:42:20,699] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "iter 0: loss 3.9181, time 181088.50ms, mfu -100.00%\n",
      "iter 5: loss 3.1572, time 19781.22ms, mfu 4.34%\n",
      "step 10: train loss 2.6467, val loss 2.6515\n",
      "saving checkpoint to out-abc-char\n",
      "iter 10: loss 2.6986, time 162343.73ms, mfu 3.96%\n",
      "iter 15: loss 2.4025, time 19969.65ms, mfu 4.00%\n",
      "step 20: train loss 2.2461, val loss 2.3071\n",
      "saving checkpoint to out-abc-char\n",
      "iter 20: loss 2.2586, time 162414.63ms, mfu 3.65%\n",
      "iter 25: loss 2.1677, time 19649.76ms, mfu 3.72%\n",
      "step 30: train loss 2.1062, val loss 2.1446\n",
      "saving checkpoint to out-abc-char\n",
      "iter 30: loss 2.1300, time 167701.14ms, mfu 3.40%\n",
      "iter 35: loss 2.0644, time 23224.01ms, mfu 3.43%\n",
      "step 40: train loss 2.0053, val loss 2.0319\n",
      "saving checkpoint to out-abc-char\n",
      "iter 40: loss 1.9859, time 173810.48ms, mfu 3.14%\n",
      "iter 45: loss 1.9678, time 23339.08ms, mfu 3.19%\n",
      "step 50: train loss 1.9001, val loss 1.9281\n",
      "saving checkpoint to out-abc-char\n",
      "iter 50: loss 1.9458, time 177437.18ms, mfu 2.92%\n",
      "iter 55: loss 1.8393, time 23125.13ms, mfu 3.00%\n",
      "step 60: train loss 1.8320, val loss 1.8459\n",
      "saving checkpoint to out-abc-char\n",
      "iter 60: loss 1.8589, time 171330.54ms, mfu 2.75%\n",
      "iter 65: loss 1.8030, time 23176.30ms, mfu 2.85%\n",
      "step 70: train loss 1.7488, val loss 1.7586\n",
      "saving checkpoint to out-abc-char\n",
      "iter 70: loss 1.7856, time 166686.25ms, mfu 2.61%\n",
      "iter 75: loss 1.7439, time 22571.30ms, mfu 2.73%\n",
      "step 80: train loss 1.7324, val loss 1.7531\n",
      "saving checkpoint to out-abc-char\n",
      "iter 80: loss 1.7395, time 166431.82ms, mfu 2.51%\n",
      "iter 85: loss 1.6496, time 22562.17ms, mfu 2.64%\n",
      "step 90: train loss 1.6657, val loss 1.6949\n",
      "saving checkpoint to out-abc-char\n",
      "iter 90: loss 1.6615, time 166954.18ms, mfu 2.43%\n",
      "iter 95: loss 1.6706, time 22554.42ms, mfu 2.57%\n",
      "step 100: train loss 1.6325, val loss 1.6602\n",
      "saving checkpoint to out-abc-char\n",
      "iter 100: loss 1.6288, time 168056.39ms, mfu 2.36%\n",
      "iter 105: loss 1.6500, time 23152.83ms, mfu 2.50%\n",
      "step 110: train loss 1.6124, val loss 1.6554\n",
      "saving checkpoint to out-abc-char\n",
      "iter 110: loss 1.6713, time 167188.69ms, mfu 2.30%\n",
      "iter 115: loss 1.6430, time 22568.31ms, mfu 2.45%\n",
      "step 120: train loss 1.5818, val loss 1.6127\n",
      "saving checkpoint to out-abc-char\n",
      "iter 120: loss 1.6318, time 166371.56ms, mfu 2.26%\n",
      "iter 125: loss 1.5598, time 22578.01ms, mfu 2.41%\n",
      "step 130: train loss 1.5585, val loss 1.5875\n",
      "saving checkpoint to out-abc-char\n",
      "iter 130: loss 1.5672, time 166475.37ms, mfu 2.22%\n",
      "iter 135: loss 1.5572, time 22585.70ms, mfu 2.38%\n",
      "step 140: train loss 1.5430, val loss 1.5694\n",
      "saving checkpoint to out-abc-char\n",
      "iter 140: loss 1.5229, time 166277.77ms, mfu 2.19%\n",
      "iter 145: loss 1.5292, time 22555.70ms, mfu 2.36%\n",
      "step 150: train loss 1.5199, val loss 1.5459\n",
      "saving checkpoint to out-abc-char\n",
      "iter 150: loss 1.5089, time 166503.56ms, mfu 2.17%\n",
      "iter 155: loss 1.5711, time 22567.59ms, mfu 2.34%\n",
      "step 160: train loss 1.5125, val loss 1.5320\n",
      "saving checkpoint to out-abc-char\n",
      "iter 160: loss 1.5007, time 166299.06ms, mfu 2.15%\n",
      "iter 165: loss 1.5038, time 22583.67ms, mfu 2.32%\n",
      "step 170: train loss 1.4813, val loss 1.5011\n",
      "saving checkpoint to out-abc-char\n",
      "iter 170: loss 1.5181, time 166624.84ms, mfu 2.14%\n",
      "iter 175: loss 1.4778, time 22591.74ms, mfu 2.30%\n",
      "step 180: train loss 1.4786, val loss 1.4952\n",
      "saving checkpoint to out-abc-char\n",
      "iter 180: loss 1.4935, time 166759.87ms, mfu 2.13%\n",
      "iter 185: loss 1.4661, time 23208.30ms, mfu 2.28%\n",
      "step 190: train loss 1.4554, val loss 1.4718\n",
      "saving checkpoint to out-abc-char\n",
      "iter 190: loss 1.4249, time 169023.10ms, mfu 2.11%\n",
      "iter 195: loss 1.4555, time 22563.20ms, mfu 2.28%\n",
      "step 200: train loss 1.4492, val loss 1.4691\n",
      "saving checkpoint to out-abc-char\n",
      "iter 200: loss 1.4594, time 166722.10ms, mfu 2.10%\n",
      "iter 205: loss 1.4776, time 22566.36ms, mfu 2.27%\n",
      "step 210: train loss 1.4288, val loss 1.4512\n",
      "saving checkpoint to out-abc-char\n",
      "iter 210: loss 1.4558, time 166593.14ms, mfu 2.10%\n",
      "iter 215: loss 1.4291, time 22561.76ms, mfu 2.27%\n",
      "step 220: train loss 1.4174, val loss 1.4301\n",
      "saving checkpoint to out-abc-char\n",
      "iter 220: loss 1.4417, time 166750.38ms, mfu 2.09%\n",
      "iter 225: loss 1.4938, time 22575.64ms, mfu 2.26%\n",
      "step 230: train loss 1.4060, val loss 1.4203\n",
      "saving checkpoint to out-abc-char\n",
      "iter 230: loss 1.4209, time 166633.82ms, mfu 2.09%\n",
      "iter 235: loss 1.4232, time 22579.38ms, mfu 2.26%\n",
      "step 240: train loss 1.3875, val loss 1.4066\n",
      "saving checkpoint to out-abc-char\n",
      "iter 240: loss 1.4282, time 166596.03ms, mfu 2.09%\n",
      "iter 245: loss 1.4263, time 22559.00ms, mfu 2.26%\n",
      "step 250: train loss 1.3557, val loss 1.3631\n",
      "saving checkpoint to out-abc-char\n",
      "iter 250: loss 1.4007, time 166400.21ms, mfu 2.08%\n",
      "iter 255: loss 1.3474, time 22555.80ms, mfu 2.26%\n",
      "step 260: train loss 1.3270, val loss 1.3413\n",
      "saving checkpoint to out-abc-char\n",
      "iter 260: loss 1.3473, time 166820.97ms, mfu 2.08%\n",
      "iter 265: loss 1.3802, time 23321.27ms, mfu 2.24%\n",
      "step 270: train loss 1.3056, val loss 1.3281\n",
      "saving checkpoint to out-abc-char\n",
      "iter 270: loss 1.3395, time 170127.97ms, mfu 2.07%\n",
      "iter 275: loss 1.3012, time 22568.86ms, mfu 2.24%\n",
      "step 280: train loss 1.2778, val loss 1.3020\n",
      "saving checkpoint to out-abc-char\n",
      "iter 280: loss 1.3112, time 166673.95ms, mfu 2.07%\n",
      "iter 285: loss 1.2874, time 22560.84ms, mfu 2.24%\n",
      "step 290: train loss 1.2678, val loss 1.2909\n",
      "saving checkpoint to out-abc-char\n",
      "iter 290: loss 1.2844, time 166612.65ms, mfu 2.07%\n",
      "iter 295: loss 1.2620, time 22573.27ms, mfu 2.24%\n",
      "step 300: train loss 1.2551, val loss 1.2848\n",
      "saving checkpoint to out-abc-char\n",
      "iter 300: loss 1.2358, time 166517.52ms, mfu 2.07%\n",
      "iter 305: loss 1.2271, time 22560.09ms, mfu 2.25%\n",
      "step 310: train loss 1.2300, val loss 1.2684\n",
      "saving checkpoint to out-abc-char\n",
      "iter 310: loss 1.2632, time 166510.60ms, mfu 2.07%\n",
      "iter 315: loss 1.2481, time 22576.35ms, mfu 2.25%\n",
      "step 320: train loss 1.1986, val loss 1.2322\n",
      "saving checkpoint to out-abc-char\n",
      "iter 320: loss 1.2043, time 166619.89ms, mfu 2.07%\n",
      "iter 325: loss 1.1892, time 22533.98ms, mfu 2.25%\n",
      "step 330: train loss 1.1691, val loss 1.2046\n",
      "saving checkpoint to out-abc-char\n",
      "iter 330: loss 1.2340, time 166525.42ms, mfu 2.07%\n",
      "iter 335: loss 1.1986, time 22555.19ms, mfu 2.25%\n",
      "step 340: train loss 1.1569, val loss 1.1904\n",
      "saving checkpoint to out-abc-char\n",
      "iter 340: loss 1.1955, time 166339.85ms, mfu 2.07%\n",
      "iter 345: loss 1.1367, time 22568.43ms, mfu 2.25%\n",
      "step 350: train loss 1.1251, val loss 1.1505\n",
      "saving checkpoint to out-abc-char\n",
      "iter 350: loss 1.1645, time 166293.30ms, mfu 2.07%\n",
      "iter 355: loss 1.1909, time 22538.54ms, mfu 2.25%\n",
      "step 360: train loss 1.1094, val loss 1.1453\n",
      "saving checkpoint to out-abc-char\n",
      "iter 360: loss 1.1800, time 166244.55ms, mfu 2.08%\n",
      "iter 365: loss 1.0837, time 22557.19ms, mfu 2.25%\n",
      "step 370: train loss 1.0867, val loss 1.1232\n",
      "saving checkpoint to out-abc-char\n",
      "iter 370: loss 1.1201, time 166451.63ms, mfu 2.08%\n",
      "iter 375: loss 1.1023, time 22551.36ms, mfu 2.25%\n",
      "step 380: train loss 1.0715, val loss 1.1039\n",
      "saving checkpoint to out-abc-char\n",
      "iter 380: loss 1.1045, time 166230.20ms, mfu 2.08%\n",
      "iter 385: loss 1.1354, time 22564.56ms, mfu 2.25%\n",
      "step 390: train loss 1.0422, val loss 1.0725\n",
      "saving checkpoint to out-abc-char\n",
      "iter 390: loss 1.0758, time 166336.92ms, mfu 2.08%\n",
      "iter 395: loss 1.0700, time 22562.47ms, mfu 2.25%\n",
      "step 400: train loss 1.0262, val loss 1.0703\n",
      "saving checkpoint to out-abc-char\n",
      "iter 400: loss 1.0968, time 166258.97ms, mfu 2.08%\n",
      "iter 405: loss 1.0390, time 22559.00ms, mfu 2.25%\n",
      "step 410: train loss 0.9919, val loss 1.0281\n",
      "saving checkpoint to out-abc-char\n",
      "iter 410: loss 1.0216, time 166463.91ms, mfu 2.08%\n",
      "iter 415: loss 0.9605, time 22545.13ms, mfu 2.25%\n",
      "step 420: train loss 0.9689, val loss 0.9964\n",
      "saving checkpoint to out-abc-char\n",
      "iter 420: loss 0.9807, time 166396.36ms, mfu 2.08%\n",
      "iter 425: loss 0.9848, time 22557.02ms, mfu 2.25%\n",
      "step 430: train loss 0.9434, val loss 0.9866\n",
      "saving checkpoint to out-abc-char\n",
      "iter 430: loss 0.9696, time 175836.49ms, mfu 2.07%\n",
      "iter 435: loss 0.9541, time 23297.92ms, mfu 2.24%\n",
      "step 440: train loss 0.9176, val loss 0.9562\n",
      "saving checkpoint to out-abc-char\n",
      "iter 440: loss 0.9355, time 166462.47ms, mfu 2.06%\n",
      "iter 445: loss 0.9247, time 22572.50ms, mfu 2.24%\n",
      "step 450: train loss 0.9019, val loss 0.9376\n",
      "saving checkpoint to out-abc-char\n",
      "iter 450: loss 0.9351, time 166282.10ms, mfu 2.07%\n",
      "iter 455: loss 0.9216, time 22566.84ms, mfu 2.24%\n",
      "step 460: train loss 0.8838, val loss 0.9196\n",
      "saving checkpoint to out-abc-char\n",
      "iter 460: loss 0.9060, time 166381.39ms, mfu 2.07%\n",
      "iter 465: loss 0.9307, time 22574.63ms, mfu 2.24%\n",
      "step 470: train loss 0.8581, val loss 0.9040\n",
      "saving checkpoint to out-abc-char\n",
      "iter 470: loss 0.8789, time 166329.78ms, mfu 2.07%\n",
      "iter 475: loss 0.8670, time 22581.94ms, mfu 2.24%\n",
      "step 480: train loss 0.8508, val loss 0.8936\n",
      "saving checkpoint to out-abc-char\n",
      "iter 480: loss 0.8404, time 166496.95ms, mfu 2.07%\n",
      "iter 485: loss 0.8714, time 23874.39ms, mfu 2.22%\n",
      "step 490: train loss 0.8253, val loss 0.8696\n",
      "saving checkpoint to out-abc-char\n",
      "iter 490: loss 0.8914, time 175537.57ms, mfu 2.05%\n",
      "iter 495: loss 0.8287, time 23204.13ms, mfu 2.22%\n",
      "step 500: train loss 0.8143, val loss 0.8708\n",
      "iter 500: loss 0.8291, time 173459.99ms, mfu 2.04%\n",
      "iter 505: loss 0.8426, time 24303.66ms, mfu 2.19%\n",
      "step 510: train loss 0.7939, val loss 0.8426\n",
      "saving checkpoint to out-abc-char\n",
      "iter 510: loss 0.7828, time 176051.77ms, mfu 2.02%\n",
      "iter 515: loss 0.8044, time 25954.48ms, mfu 2.15%\n",
      "step 520: train loss 0.7695, val loss 0.8194\n",
      "saving checkpoint to out-abc-char\n",
      "iter 520: loss 0.7907, time 177600.00ms, mfu 1.98%\n",
      "iter 525: loss 0.7754, time 24431.50ms, mfu 2.14%\n",
      "step 530: train loss 0.7455, val loss 0.7923\n",
      "saving checkpoint to out-abc-char\n",
      "iter 530: loss 0.7924, time 176675.96ms, mfu 1.97%\n",
      "iter 535: loss 0.7643, time 24102.60ms, mfu 2.13%\n",
      "step 540: train loss 0.7232, val loss 0.7751\n",
      "saving checkpoint to out-abc-char\n",
      "iter 540: loss 0.7687, time 179060.00ms, mfu 1.97%\n",
      "iter 545: loss 0.7428, time 24314.19ms, mfu 2.12%\n",
      "step 550: train loss 0.7033, val loss 0.7597\n",
      "saving checkpoint to out-abc-char\n",
      "iter 550: loss 0.7535, time 167147.35ms, mfu 1.96%\n",
      "iter 555: loss 0.7180, time 28257.23ms, mfu 2.07%\n",
      "step 560: train loss 0.6935, val loss 0.7469\n",
      "saving checkpoint to out-abc-char\n",
      "iter 560: loss 0.7472, time 180520.76ms, mfu 1.91%\n",
      "iter 565: loss 0.6859, time 19386.84ms, mfu 2.16%\n",
      "step 570: train loss 0.6688, val loss 0.7302\n",
      "saving checkpoint to out-abc-char\n",
      "iter 570: loss 0.6684, time 174731.53ms, mfu 2.00%\n",
      "iter 575: loss 0.6971, time 19409.28ms, mfu 2.24%\n",
      "step 580: train loss 0.6487, val loss 0.7089\n",
      "saving checkpoint to out-abc-char\n",
      "iter 580: loss 0.6740, time 160659.15ms, mfu 2.07%\n",
      "iter 585: loss 0.6686, time 19393.90ms, mfu 2.31%\n",
      "step 590: train loss 0.6320, val loss 0.6896\n",
      "saving checkpoint to out-abc-char\n",
      "iter 590: loss 0.6638, time 160294.43ms, mfu 2.13%\n",
      "iter 595: loss 0.6593, time 19497.83ms, mfu 2.36%\n",
      "step 600: train loss 0.6176, val loss 0.6803\n",
      "saving checkpoint to out-abc-char\n",
      "iter 600: loss 0.6351, time 160776.42ms, mfu 2.17%\n",
      "iter 605: loss 0.6313, time 19425.32ms, mfu 2.40%\n",
      "step 610: train loss 0.6035, val loss 0.6663\n",
      "saving checkpoint to out-abc-char\n",
      "iter 610: loss 0.6552, time 160598.62ms, mfu 2.21%\n",
      "iter 615: loss 0.6071, time 19460.97ms, mfu 2.43%\n",
      "step 620: train loss 0.5903, val loss 0.6597\n",
      "saving checkpoint to out-abc-char\n",
      "iter 620: loss 0.6168, time 162713.42ms, mfu 2.24%\n",
      "iter 625: loss 0.6321, time 19319.89ms, mfu 2.46%\n",
      "step 630: train loss 0.5744, val loss 0.6448\n",
      "saving checkpoint to out-abc-char\n",
      "iter 630: loss 0.5982, time 160256.36ms, mfu 2.27%\n",
      "iter 635: loss 0.6001, time 19386.01ms, mfu 2.49%\n",
      "step 640: train loss 0.5647, val loss 0.6307\n",
      "saving checkpoint to out-abc-char\n",
      "iter 640: loss 0.6067, time 160654.49ms, mfu 2.29%\n",
      "iter 645: loss 0.6068, time 19401.93ms, mfu 2.51%\n",
      "step 650: train loss 0.5569, val loss 0.6287\n",
      "saving checkpoint to out-abc-char\n",
      "iter 650: loss 0.5673, time 161563.31ms, mfu 2.31%\n",
      "iter 655: loss 0.5906, time 24213.83ms, mfu 2.43%\n",
      "step 660: train loss 0.5368, val loss 0.6169\n",
      "saving checkpoint to out-abc-char\n",
      "iter 660: loss 0.5937, time 171100.88ms, mfu 2.24%\n",
      "iter 665: loss 0.5790, time 22823.39ms, mfu 2.39%\n",
      "step 670: train loss 0.5250, val loss 0.6055\n",
      "saving checkpoint to out-abc-char\n",
      "iter 670: loss 0.5572, time 167260.10ms, mfu 2.20%\n",
      "iter 675: loss 0.5525, time 22584.08ms, mfu 2.36%\n",
      "step 680: train loss 0.5111, val loss 0.5976\n",
      "saving checkpoint to out-abc-char\n",
      "iter 680: loss 0.5647, time 167757.74ms, mfu 2.18%\n",
      "iter 685: loss 0.5477, time 22627.99ms, mfu 2.34%\n",
      "step 690: train loss 0.5019, val loss 0.5898\n",
      "saving checkpoint to out-abc-char\n",
      "iter 690: loss 0.5345, time 167519.84ms, mfu 2.16%\n",
      "iter 695: loss 0.5376, time 22580.59ms, mfu 2.32%\n",
      "step 700: train loss 0.4904, val loss 0.5826\n",
      "saving checkpoint to out-abc-char\n",
      "iter 700: loss 0.5265, time 169011.32ms, mfu 2.14%\n",
      "iter 705: loss 0.5122, time 23323.20ms, mfu 2.30%\n",
      "step 710: train loss 0.4788, val loss 0.5778\n",
      "saving checkpoint to out-abc-char\n",
      "iter 710: loss 0.5080, time 166181.11ms, mfu 2.12%\n",
      "iter 715: loss 0.4968, time 22631.74ms, mfu 2.29%\n",
      "step 720: train loss 0.4685, val loss 0.5723\n",
      "saving checkpoint to out-abc-char\n",
      "iter 720: loss 0.5016, time 167550.25ms, mfu 2.11%\n",
      "iter 725: loss 0.4787, time 23444.24ms, mfu 2.26%\n",
      "step 730: train loss 0.4574, val loss 0.5664\n",
      "saving checkpoint to out-abc-char\n",
      "iter 730: loss 0.5001, time 167665.40ms, mfu 2.09%\n",
      "iter 735: loss 0.4923, time 23126.02ms, mfu 2.25%\n",
      "step 740: train loss 0.4504, val loss 0.5656\n",
      "saving checkpoint to out-abc-char\n",
      "iter 740: loss 0.4926, time 166381.99ms, mfu 2.08%\n",
      "iter 745: loss 0.4772, time 23071.92ms, mfu 2.24%\n",
      "step 750: train loss 0.4441, val loss 0.5626\n",
      "saving checkpoint to out-abc-char\n",
      "iter 750: loss 0.4645, time 174121.61ms, mfu 2.07%\n",
      "iter 755: loss 0.4858, time 23615.95ms, mfu 2.23%\n",
      "step 760: train loss 0.4275, val loss 0.5526\n",
      "saving checkpoint to out-abc-char\n",
      "iter 760: loss 0.4435, time 169178.34ms, mfu 2.05%\n",
      "iter 765: loss 0.4637, time 23059.62ms, mfu 2.22%\n",
      "step 770: train loss 0.4175, val loss 0.5548\n",
      "iter 770: loss 0.4547, time 165503.17ms, mfu 2.05%\n",
      "iter 775: loss 0.4373, time 23100.90ms, mfu 2.22%\n",
      "^C\n",
      "Process ForkProcess-12:\n",
      "Process ForkProcess-13:\n",
      "Process ForkProcess-18:\n",
      "Process ForkProcess-4:\n",
      "Process ForkProcess-16:\n",
      "Process ForkProcess-15:\n",
      "Process ForkProcess-14:\n",
      "Process ForkProcess-8:\n",
      "Process ForkProcess-20:\n",
      "Process ForkProcess-6:\n",
      "Process ForkProcess-11:\n",
      "Process ForkProcess-9:\n",
      "Process ForkProcess-19:\n",
      "Process ForkProcess-3:\n",
      "Process ForkProcess-10:\n",
      "Process ForkProcess-5:\n",
      "Process ForkProcess-17:\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-1:\n",
      "Process ForkProcess-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 97, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 253, in <module>\n",
      "    losses = estimate_loss()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"train.py\", line 214, in estimate_loss\n",
      "    losses[k] = loss.item()\n",
      "KeyboardInterrupt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 255).\u001b[0m Press Control-C to abort syncing.\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py config/train_abc_char.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test key with most occurrences: G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-abc-char\n",
      "Overriding: start = M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "number of parameters: 21.26M\n",
      "abc_char\n",
      "Loading meta from data/abc_char/meta.pkl...\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "B/2c/2|\"G\"dd/2e/2d/2c/2|B/2G/2d/2G/2d/2B/2G/2|\"C\"c3/4B/4A/2G/2E/2|\"D\"dd/2e/2d/2c/2|\"G\"B/2G/2d/2G/2d/2B/2G/2|\"C\"c3/4B/4A/2G/2E/2|\"D\"dd/2e/2f/2e/2d/2c/2|\"G\"B/2G/2d/2G/2d/2B/2G/2|\"C\"c3/2B/2\"D\"A/2B/2A/2c/2|\"G\"B/2G/2d/2G/2d/2G/2B/2|\"C\"c3/4B/4A/2G/2E/2|\"D\"d/2c/2A/2D/2d/2c/2|\"G\"B/2G/2d/2G/2d/2B/2G/2|\"C\"c3/2B/2A/2G/2E/2|\"D\"d/2d/2c/2A/2c/2f/2e/2|\"G\"d/2c/2B/2G/2d/2B/2G/2|\"C\"c3/4B/4A/2G/2E/2|\"D\"d/2c/2A/2c/2f/2e/2|\"G\"d/2c/2B/2G/2d/2B/2G/2|\"C\"c3/4B/4A/2G/2E/2|\"D\"d/2c/2A/2D/2d/2c/2|\"G\"B/2G/2d/2G/2d/2B/2G/2|\"\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "\"G\"gd/2c/2B/2A/2G/2|\"C\"E/2F/2G/2A/2G/2A/2G/2|\"D\"F/2D/2F/2A/2c/2A/2F/2|\"G\"G/2B/2d/2g/2d/2B/2G/2|\"C\"E/2F/2G/2A/2G/2A/2G/2|\"D\"F/2D/2F/2A/2c/2A/2F/2|\"G\"G/2B/2d/2gd/2c/2B/2|\"C\"c/2B/2c/2e/2g/2c/2e/2c/2|\"D\"d/2c/2d/2e/2fd/2e/2|\"G\"f/2e/2d/2c/2B/2A/2G/2|\"C\"A/2G/2A/2c/2e/2g/2e/2c/2|\"D\"d/2c/2d/2e/2fd/2e/2|\"G\"f/2e/2d/2c/2Bc/2d/2|\"C\"e/2d/2e/2f/2g/2e/2c/2|\"D\"d/2c/2B/2c/2A/2F/2D/2F/2|\"G\"G/2B/2d/2gd/2B/2G/2|\"C\"e/2d/2e/2f/2g/2e/2c/2e/2c/2|\"D\"d/2c/2B/2A/2F/2A/2c/2d/2e/2|\"G\"f/2e/2d/2c/2Bc/2d/2|\"C\"e/2d/2e/2f/2g/2e/\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "B/4c/2|\"G\"d/2B/2G/2B/2d/2B/2d/2|\"C\"g/2e/2g/2a/2e/2c/2d/2|\"D\"A/2B/2A/2G/2B/2d/2B/2|\"G\"g/2f/2g/2a/2g/2e/2c/2|\"C\"c/2e/2c/2G/2e/2c/2d/2e/2|\"D\"f/2d/2d/2f/2a/2f/2d/2|\"G\"g/2f/2g/2a/2g/2e/2c/2d/2|\"C\"e/2d/2c/2e/2gA/2c/2|\"D\"f/2d/2d/2f/2a/2f/2d/2f/2|\"G\"g/2f/2g/2a/2g/2d/2g/2e/2c/2|\"C\"c/2e/2c/2G/2e/2c/2d/2c/2|\"D\"A/2F/2A/2d/2A/2F/2d/2F/2|\"G\"g/2f/2g/2a/2g/2e/2c/2d/2|\"C\"c/2e/2c/2G/2e/2c/2d/2e/2|\"D\"f/2d/2d/2f/2a/2f/2d/2f/2|\"C\"e/2c/2e/2c/2g/2f/2g/2e/2|\"D\"f/2d/2d/2f/2a/2f/2d/2f/2|\"G\"g/2f/2e/2c/2\"D\"f/2e/2d/2f/2|\"C\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "\"G\"g/2d/2B/4c/4d/2B/2|g/2G/2B/2d/2|\"C\"c/2c/2c/2c/2d/4e/4|\"D\"f/2d/2A/2A/2d/2B/2|\"D\"f/2d/2A/2A/2d/2e/2|f/2d/4c/4B/4A/4G/4|\"D\"g/2d/2d/2G/2A/2|\"G\"g/2d/2B/4g/4d/2B/2|\"C\"c/2c/2c/2c/2d/2|\"D\"f/2d/4c/4B/4A/4G/4F/2|\"G\"g/2d/2B/2B/2|\"C\"c/2c/2c/2c/4e/4|\"D\"d/2A/2A/2d/2e/2|\"G\"g/2d/2G/2B/4g/4d/4B/4|\"C\"c/2c/2c/2c/4e/4|\"D\"a/2f/2f/4g/4a/4|\"G\"b/2g/2B/2B/2|\"C\"c/2c/2c/2c/2|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:D\n",
      "|\"D\"|\"A\"|\"A\"|\"A\"|\"A\"\"G\"|\"D\"|\"Em\"\"A\"|\"D\"|\"A\"\"D\"|\"A\"|\"Em\"|\"A\"|\"A\"\"G\"|\"D\"\"A\"|\"E\"\"A\"|\"E\"|\"A\"|\"A\"|\"A\"\"G\"|\"D\"\"A\"|]\n",
      "A/2|\"D\"d/2f/2f/2f\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "\"G\"GBB/2B/2|d/2B/2G/2B/2|d/2B/2G/2B/2|\"C\"c/2ec/2e|\"D\"d/2A/2A/2A/2B/2|d/2e/2B/2A/2B/2|\"D\"A/2A/2A/2G/2A/2|\"G\"G/2B/2d/2B/2G/2B/2|\"C\"c/2e/2e/2ec/2e/2|\"D\"d/2A/2A/2G/2A/2A/2B/2|\"G\"d/2B/2E/2G/2B/2d/2B/2|d/2B/2G/2B/2d/2B/2|\"C\"c/2e/2ec/2e/2g/2|\"D\"f/2d/2A/2A/2B/2A/2B/2|\"G\"d/2B/2G/2B/2d/2B/2|g/2B/2g/2B/2g/2B/2|\"C\"c/2ec/2ef/2|\"D\"d/2A/2A/2A/2=B/2|\"G\"g/2B/2g/2B/2g/2B/2f/2|\"D\"d/2A/2A/2B/2d/2B/2|\"G\"g/2B/2g/2B/2g/2B/2|\"C\"c/2e/2ec/2e/2|\"D\"d/2A/2A/2=B/2A/2B/2|d/2e/2B/2A/2B/2A/2B/2|\"G\"g/2B/2g/2B/2g/2B/2|\"C\"c/2ec/2\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "g/4g/2|\"G\"d/2B/4d/4g/4g/4|d/2B/2d/2|\"C\"e/2c/2e/2g/2|\"D\"g3//2g/4a/4|\"D\"f/2d/2A/2f/2|\"G\"g/2d/2B/4d/4g/4|\"C\"e/2c/2e/2g/2|\"D\"f/2d/2c/2B/2|\"D\"A/2c/2c/2B/2c/4d/4|\"G\"g/4d/4B/2B/2B/2|\"C\"e/4d/4e/4g/4e/4g/4|\"D\"f/2d/2A/2f/4d/4|\"G\"g/2G/2G/2G/2|\"C\"e/2c/2e/2g/2|\"D\"f/2d/2A/2f/2d/4|\"G\"g/2B/2B/2B/2|d/2B/4B/4B/4B/2B/2|\"C\"e/2c/2e/2g/2|\"D\"f/2d/4c/4d/4f/4d/4|\"G\"g/2B/2B/4B/4d/4g/4|\"C\"e/2c/2e/2g/2|\"D\"f/2d/2A/4f/4d/4|\"G\"g/2B/2B/2B/2|\"C\"e/2c/2e/2g/2|\"D\"f/2d/2A/4f/4d/4|\"G\"g/2B/2B/4B/4|\"D\"A/2c/2B/4c/4d/4|\"G\"g/2B/2B/2B/2|\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "B/2c/2|\"G\"d3/4B/4GA/2B/2|d3/2B/2GA/2B/2|\"C\"c3/4d/4c/2B/2A/2|\"D\"F3/4G/2A/2B/2c/2|\"D\"A3/2c/2B/2A/2|\"G\"G3/4A/2GB/2c/2|\"C\"c/2c/2c/2B/2A/2|\"D\"d3/4d/4d/2A/2B/2|\"G\"G3/4A/2G/2F/2|G3/4A/2G/2F/2|\"C\"G3/4A/2G/2F/2|G3/4A/4G/4F/2E/2|\"D\"D3/4F/2G/2A/2|\"G\"G3/4A/4G/4F/2E/2|G3/4A/4G/2F/2E/2|\"C\"G3/4A/2G/2F/2E/2|\"D\"D3/4F/4G/2A/2c/2|\"G\"B3/4c/4d/2B/2|\"C\"c3/4d/4c/2B/2A/2|G3/4A/4G/4F/2E/2|\"D\"D3/4F/4G/4A/2c/2|\"G\"B3/2G/2|E/2D/2F/2E/2|\"C\"G3/4A/4G/4F/2E/2|\"C\"G3/4A/4G/2F/2E/2|\"G\"G3/4A/4G/2F/2E/2|D3/4F/2E/2|\"C\"G3/4A/4G/4F/2E\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d/2|\"G\"g3/4g/4g3/4g/4|g3/4g/4g3/4g/4|\"C\"fee3/4e/4|\"D\"d3/4e/4d3/4e/4|\"G\"g3/2d/2B3/4d/4|\"C\"g3/4e/4e/2e3/4e/4|\"D\"d3/4c/4d3/4e/4|\"D\"f3/4d/4A3/4g/4f3/4|\"G\"ecd|\"C\"g3/4e/4c3/4e/4|\"D\"d3/4c/4d3/4e/4|\"G\"f3/4e/4d3/4B/4d3/4B/4|\"C\"g3/4e/4e3/4B/4|\"D\"a3/4g/4f3/4e/4|\"G\"d3/4c/4B3/4d/4|\"C\"g3/4e/4c3/4e/4|\"D\"d3/4c/4d3/4e/4|\"G\"f3/4e/4d3/4c/4B3/4|\"C\"a3/4e/4c3/4e/4|\"G\"d3/4d/4B3/4d/4|\"C\"g3/4e/4c3/4e/4|\"D\"d3/4c/4d3/4e/4|\"G\"f3/4e/4d3/4B/4|\"C\"g3/4e/4c3/4e/4|\"G\"d3/4c/4B3/4d/4|\"C\"g3/4e/4c3/4e/4|\"D\"d3/4c/4d3/4e/4|\"G\"f3/4e/4\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d/2e/2|\"G\"d/2B/2G/2d/2d/2B/2G/2B/2|G/2G/2d/2G/2gd/2e/2|\"C\"g/2e/2c/2e/2g/2c/2e/2|\"D\"fd/2d/2f/2d/2f/2d/2|\"D\"f/2a/2a/2a/2f/2d/2f/2d/2f/2|\"Em\"g/2e/2c/2B/2\"A7\"A/2c/2e/2c/2|\"D\"ddd|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"G\"\"C\"|\"G\"|\"D\"|\"G\"\"C\"|\"G\"\"C\"|\"G\"|\"G\"\"D7\"|\"G\"\"D7\"|\"G\"|\"C\"\"G\"|\"G\"\"C\"|\"G\"\"D7\"|\"G\"|]\n",
      "\"G\"BB/2G/2B/2G/2B/2G/2B/2|\"G\"Bd\"C\"e/2d/2c/2B/2|\"G\"BB/2G/2\"D\"A/2F/2A/2|\"G\"G/2B/2G/2B/2\"C\"e/2d/2c/2B/2|\"G\"dd/2B/2\"C\"e/2d/2c/2B/2|\"G\"BB/2G/2\"C\"e/2d/2c/2B/2|\"G\"BB/2G/2\"D7\"A/2F/2A/2|\"G\"G/2B/2G/2B/2\"D7\"A/2F/2A/2|\"G\"G\"G/2B/2G/2\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "\"G\"D/4G/4G/2D/2|D/4G/4G/4G/2z/4e/4|d/2G/4G/2G/4G/4|\"C\"A/4G/4F/4E/4E/4F/4|G/4G/2G/4G/2|\"D\"D/4G/4G/4A/4B/2A/4B/4|\"G\"G/4F/4E/4F/4E/4F/4G/4|\"C\"A/4B/4c/4d/4e/4f/4g/4e/4|\"D\"dA|d/4e/4f/4g/4f/4e/4d/4e/4|d/2f/2d/4e/4f/4e/4|\"G\"d/4e/4f/4g/4e/4d/4B/4G/4|\"C\"A/4B/4c/4d/4e/4f/4g/4e/4|\"D\"d/4c/4B/4A/4F/4E/4F/4A/4|\"G\"G/4B/4c/4d/4e/4f/4g/4f/4e/4|\"C\"g/4f/4e/4d/4e/4c/4d/4e/4|\"D\"d/4c/4B/4A/4F/4A/4B/4|\"G\"G/4B/4c/4d/4e/4f/4g/4e/4|\"C\"g/4f/4e/4d/4e/4f/4g/4e/4|\"D\"d/4c/4B/4A/4F/4E/4F/4A/4|\"G\"G/4B/4B/4c/4d/4e/4f/4g/4e/4|\"D\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start='M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test major key with low samples: C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-abc-char\n",
      "Overriding: start = M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "number of parameters: 21.26M\n",
      "abc_char\n",
      "Loading meta from data/abc_char/meta.pkl...\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "A/2|\"C\"G/4G/4G/2G/4G/2|G/2G/2G/2z/2|\"F\"a/2f/4d/4c/2A/2|\"G\"G/4G/4G/2G/2z/2|\"G\"G/2G/2G/2z/2|\"C\"G/4G/4G/4G/4G/2G/2|g/2G/2G/4e/4G/4|\"F\"f/4d/4f/4d/4c/4A/4|\"G\"G/4G/4G/4G/4G/4G/4g/4f/2|\"C\"g/4e/4c/4e/4g/4e/4c/4|\"F\"f/4d/4c/4A/4c/4A/2|\"G\"G/4G/4G/4G/2G/2g/4f/4|\"C\"g/4e/4c/4e/4c/4c/4B/4c/4|\"F\"f/4d/4c/4A/4c/4f/4|\"G\"G/4G/4G/4G/4G/4g/4f/4|\"G\"g/4d/4B/4d/4g/4f/4e/4|\"C\"c/4e/4c/4e/4g/4e/4c/4|\"F\"f/4d/4c/4A/4c/4f/4|\"G\"g/4d/4B/4G/4g/4f/4|\"G\"g/2d/2d/2|\"C\"c/4B/4c/4e/4c/4e/4c/4|\"F\"f/4d/4c/4A/4c/4f/4|\"G\"g/4d/4B/4G/4B/4d/\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "c/2d/2|\"C\"e/2g/2e/2de/2f/2|e/2d/2c/2B/2A/2G/2|\"F\"A/2c/2A/2dc/2d/2|\"G\"e/2d/2c/2B/2A/2G/2c/2|\"G\"B/2G/2D/2E/2D/2E/2G/2|\"G\"B/2G/2D/2E/2D/2G/2B/2|\"C\"A/2c/2c/2c/2B/2A/2G/2|\"F\"A/2c/2A/2dc/2d/2|\"G\"e/2d/2c/2B/2A/2G/2B/2G/2|\"C\"E/2C/2C/2E/2G/2E/2G/2|\"F\"A/2c/2A/2d/2c/2d/2|\"G\"e/2d/2c/2B/2A/2G/2B/2G/2|\"C\"c/2c/2c/2cg/2e/2|\"F\"f/2e/2d/2c/2f/2a/2f/2|\"C\"g/2e/2c/2e/2g/2g/2e/2|\"G\"f/2d/2c/2B/2A/2G/2B/2G/2|\"C\"c/2c/2c/2c/2cg/2e/2|\"F\"f/2a/2f/2a/2\"C\"g/2e/2c/2e/2|\"G\"f/2d/2c/2B/2A/2G/2B/2G/2|\"C\"c/2c/2c/2c/2c/2c|]\n",
      "\n",
      "M:4/4\n",
      "L\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "e/4d/2|\"C\"c/2c/2c/2e/2g/2e/2d/2|\"F\"A/2^G/2A/2d/2d/2g/2d/2|\"G\"G/2^F/2G/2A/2B/2c/2|d/2^c/2d/2e/2f/2g/2f/2|\"G\"g/2=f/2g/2d/2B/2d/2f/2|\"G\"g/2^f/2g/2d/2B/2e/2d/2c/2|\"G\"B/2^A/2B/2c/2d/2e/2f/2g/2f/2|\"C\"e/2c/2e/2g/2e/2d/2e/2d/2c/2|\"F\"A/2^G/2A/2d/2d/2d/2g/2d/2d/2|\"G\"d/2^c/2d/2e/2c/2d/2g/2d/2B/2|\"C\"ccc|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:F\n",
      "|\"F\"|\"F\"|\"C\"|\"Dm\"\"C7\"|\"F\"\"C7\"|\"F\"|\"C\"|\"Dm\"\"C7\"|\"F\"\"C7\"|\"F\"|\"F\"|\"C\"|\"Dm\"\"C7\"|\"F\"\"C7\"|\"F\"|\"B\"\"F\"|\"Gm\"\"C7\"|\"F\"\"C7\"|\"F\"|\"C\"\"C7\"|\"F\"|]\n",
      "c/2B/2|\"F\"AFFG/2A/2|\"F\"cfcA|\"C\"GEFG|\"Dm\"c/2A/2F/2A/2\"C7\"G\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "\"C\"ge/2e/2|\"F\"f/4e/4d/2c/2|\"G\"d3/4e/4d/2B/2|\"C\"c/4d/4e/2c/2|\"F\"f/2f/2f/2e/2|\"G\"d3/4e/4d/2B/2|\"C\"c/4d/4e/2e/2|\"F\"f/2f/2f/2|\"G\"g/2d/2B/2B/2|\"C\"c/4B/4c/4d/2|\"F\"c/2c/2F/2|\"G\"G/2B/2B/2B/2|\"C\"c/4B/4c/4d/2e/2|\"F\"f/2f/2f/2|\"G\"g/2d/2B/2B/2|\"C\"c/2B/4c/4d/4e/2|\"F\"f/4e/4d/2c/2|\"G\"d/4d/4B/4G/2B/2|\"C\"c/4B/4c/4d/4e/4|\"F\"f/2f/2f/4e/4f/2|\"G\"g/2d/2B/2|\"C\"c/2B/4c/4d/4e/4|\"F\"f/2f/2f/2|\"G\"g/2d/2B/4B/4|\"C\"c/2B/2c/4d/4e/4|\"F\"f/2f/2f/2|\"G\"g/2d/2B/2|\"C\"c/2B/4c/4d/4|\"F\"f/4e/4d/4c/4|\"G\"d/2B/2B/2|\"C\"c/2c/2|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "e/2d/2|\"C\"c/2G/2A/2G/2E/2G/2|B/2G/2e/2G/2e/2G/2e/2G/2|\"F\"a/2g/2f/2e/2f/2e/2g/2|\"G\"B/2G/2A/2B/2G/2e/2G/2|\"G\"B/2G/2A/2B/2G/2B/2d/2B/2|\"C\"c/2G/2A/2G/2e/2G/2e/2G/2|\"F\"a/2g/2f/2e/2f/2e/2f/2|\"G\"b/2g/2d/2B/2d/2B/2G/2B/2d/2|\"C\"c/2e/2c/2e/2g/2e/2c/2e/2|\"F\"a/2g/2f/2e/2f/2e/2a/2e/2|\"G\"g/2f/2g/2e/2f/2e/2d/2B/2|\"C\"cec|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:C\n",
      "|\"C\"|\"Dm\"|\"G\"|\"G\"|\"G\"|\"G\"|\"G\"|\"G\"|\"G7\"|\"C\"|\"C\"\"G\"|\"C\"|\"G\"|\"C\"\"G\"|\"C\"\"G\"|\"C\"\"G\"|\"C\"\"G\"|\"C\"\"G\"|\"C\"\"G\"|]\n",
      "|c/2d/2|\"C\"eedc|\"Dm\"dd/2c/2B/2A/2G/2F/2|\"G\"GGG/2F/2G/2F/2|\"G\"GBdB/2G/2d\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "g/4|\"C\"g/2c/2c/4g/4|\"F\"a/2^g/4a/4f/2|\"G\"g/2d/2c/2|\"G\"d/2d/2B/4c/4d/4e/2|\"C\"g/4c/4c/2c/2z/4c/4|\"F\"a/2^g/4a/4f/4d/4c/4d/4|\"G\"g/2g/2g/2g/4a/4|\"G\"=b/4a/2g/4a/4b/4g/4a/4|\"C\"g/2c/2c/2|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:F#\n",
      "|\"F\"\"B\"|\"F\"\"C\"|\"F\"\"C\"|\"F\"\"B\"|\"F\"\"C\"|\"F\"\"B\"|\"F\"\"C\"|\"F\"\"C\"|\"F\"\"C\"|\"F\"|\"C\"\"G\"|\"C\"\"C\"|\"F\"\"B\"|\"F\"\"C\"|\"C\"\"G\"|\"F\"\"C\"|\"F\"\"B\"|]\n",
      "|\"F\"A/2F/4c/4A/4\"B\"d/2B/2|\"F\"A/2F/4A/4\"C\"G/2F/4G/4|\"F\"A/2c/4A/4\"B\"d|\"F\"A/2F/4A/2\"C\"G/2F/2G/2|\"F\"A/2F/2\"B\"d/2B/2B/2B/2|\"F\"A/4F/4A/4\"C\"G/2A/4B/4|\"F\"A/2c/2\"C\"B/2c/2|\"F\"f/2f/4e/4f/4\"C\"g/\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "c/2d/2|\"C\"e3/4B/4c/2E/2|\"F\"F/2A/2G/2F/2|\"G\"d/2d/2d/2B/2G/2|\"C\"e/2c/2e/2f/2|\"C\"g3/2c/4B/2|\"F\"A/2G/2A/2B/2|\"G\"G/2d/2d/2B/2G/2|\"C\"e/2c/2e/2f/2|\"F\"f/2c/2A/2B/2|\"G\"G/2d/2d/2d/2B/2G/2|\"C\"e/2c/2e/2f/2|\"F\"f/2c/2A/2B/2|\"G\"G/2d/4d/4d/2B/2G/2|\"C\"e/2c/2e/2f/2|\"F\"f/2c/2A/2B/2|\"G\"G/2d/2d/2d/2B/2G/2|\"C\"e/2c/2e/2f/2|\"F\"f/2c/2A/2B/2|\"G\"G/2d/2d/2d/2B/2G/2|\"C\"e/2c/2e/2f/2|\"F\"f/2c/2A/2B/2|\"G\"G/2d/2d/2d/2B/2G/2|\"C\"e/2c/2e/2f/2|\"F\"f/2c/2A/2B/2|\"G\"g/2d/2d/2d/2B/2G/2|\"C\"e/2c/2e/2f/2|\"F\"f/2c/2A/2B/2|\"G\"G/2d/2d/2d/2B/2G\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "e/2f/2|\"C\"g/2e/2d/2ce/2f/2|\"F\"g/2f/2d/2cf/2f/2|\"G\"g/2g/2g/2g/2d/2d/2c/2|\"G\"B/2G/2G/2G/2B/2d/2G/2|\"C\"c/2B/2A/2G/2A/2c/2e/2f/2|\"F\"g/2f/2d/2c/2ff/2f/2|\"G\"g/2f/2g/2d/2g/2d/2c/2|\"C\"c/2B/2A/2G/2c/2e/2c/2|\"G\"d/2B/2G/2B/2d/2G/2B/2d/2|\"C\"c/2B/2A/2G/2\"F\"cA/2A/2|\"G\"G/2A/2B/2G/2B/2d/2G/2B/2|\"C\"c/2B/2A/2G/2c/2e/2f/2|\"F\"g/2f/2d/2c/2f/2c/2f/2c/2|\"G\"g/2f/2g/2d/2g/2d/2f/2|\"C\"e/2c/2e/2g/2f/2e/2f/2|\"F\"g/2f/2d/2c/2f/2c/2f/2c/2|\"G\"g/2f/2g/2d/2g/2d/2f/2|\"C\"e/2c/2e/2g/2f/2e/2f/2|\"F\"g/2f/2d/2c/2f/2c/2f/2|\"G\"g/2f/2g/2d\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "\"C\"e2|\"F\"d/2c/2A/2|c/2A/4F/2A/2|\"G\"G/2G/2G/2G/2|d2|\"G\"d/2d/2d/2d/2|\"C\"g2f/2|\"F\"d/2c/2A/2|\"G\"G/2G/2G|\"G\"d2|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"\"D7\"|\"G\"\"D7\"|\"G\"\"D7\"|\"G\"\"D7\"|\"G\"\"G\"|\"C\"\"D7\"\"G\"|\"Em\"\"D\"|\"G\"\"D7\"|\"G\"\"D7\"|\"G\"\"G\"|\"C\"\"D7\"|\"Em\"\"G\"|\"Em\"\"D\"|\"G\"\"D7\"|\"G\"\"D7\"|\"G\"\"G7\"|\"C\"\"D7\"|\"G\"\"D7\"|\"G\"|\"G\"\"D7\"|\"G\"\"G7\"|\"C\"\"D\"|\"Em\"\"D\"|\"G\"\"D\"|\"G\"\"G7\"|\"C\"\"D7\"|\"G\"\"D7\"|\"G\"\"D7\"|\"G\"\"G7\"|\"C\"\"D\"|\"G\"|\"C\"\"D7\"|\"Em\"\"D7\"|\"G\"\"D7\"|\"G\"\"D7\"|\"G\"\"G7\"|\"C\"\"D7\"|\"G\"\"G\"|\"G\"\"D7\"|\"G\"\"D7\"|\"G\"\"D7\"|\"G\"\"G7\"|\"C\"\"D7\"|\"G\"\"D\"|\"G\"\"D7\"|\"G\"\"C\"|\"Em\"\"D\"\"Bm\"|\"G\"\"D\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "e/2f/2|\"C\"g/2e/2c/2G/2c/2e/2|\"F\"f/2e/2d/2c/2d/2e/2|\"G\"f/2d/2B/2G/2B/2d/2|\"C\"e/2c/2G/2e/2g/2e/2|\"F\"f/2e/2d/2c/2d/2e/2|\"G\"f/2d/2B/2G/2B/2d/2|\"C\"e/2c/2G/2e/2g/2e/2|\"F\"f/2e/2d/2c/2d/2e/2|\"G\"f/2d/2B/2G/2B/2d/2|\"G\"g/2d/2B/2G/2B/2d/2|\"C\"e/2c/2G/2e/2g/2e/2|\"F\"f/2e/2d/2c/2d/2e/2|\"G\"f/2d/2B/2G/2B/2d/2|\"C\"e/2c/2G/2e/2g/2e/2|\"F\"f/2e/2d/2c/2d/2e/2|\"G\"f/2d/2B/2G/2B/2d/2|\"C\"e/2c/2G/2e/2c/2e/2|\"F\"f/2e/2d/2c/2d/2e/2|\"G\"f/2d/2B/2G/2B/2d/2|\"C\"e/2c/2G/2e/2g/2e/2|\"F\"f/2e/2d/2c/2d/2e/2|\"G\"f/2d/2B/2G/2B/2d/2d/2|\"C\"e/\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start='M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test minor key with low samples: Am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-abc-char\n",
      "Overriding: start = M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "number of parameters: 21.26M\n",
      "abc_char\n",
      "Loading meta from data/abc_char/meta.pkl...\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "A/2-B/2|\"Am\"eee/2f/2|e/2e/2e/2d/2c/2A/2B/2|\"Dm\"F/2A/2D/2^F/2A/2B/2|d/2^c/2B/2A/2G/2E/2|\"E\"E/2^D/2E/2F/2G/2E/2E/2|\"Am\"A/2^G/2E/2D/2E/2A/2^B/2|\"Dm\"d/2^^c/2d/2e/2f/2e/2d/2c/2|\"E\"B/2^A/2^G/2B/2E/2B/2e/2^f/2|\"E\"g/2^^g^^f/2g/2a/2g/2e/2|\"Am\"A/2^G/2A/2B/2c/2d/2e/2|\"Dm\"f/2^f/2^f/2^e/2f/2e/2d/2c/2|\"E\"B/2^A/2^G/2F/2E/2c/2E/2|^G/2^G/2^^F/2G/2E/2e/2^d/2c/2|\"E\"B/2^A/2^G/2B/2e/2^d/2c/2B/2|^G/2^^F/2G/2B/2e/2^d/2c/2B/2|^D/2^^F/2A/2D/2F/2A/2B/2|\"Am\"c/2^B/2c/2d/2e/2f/2e/2d/2|\"Dm\"f/2^f/2^e/2^f/2e/2f/2g/2|\"E\"e/2^d/\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "\"Am\"A3/4B/4^c/2B/2|\"Am\"A3/4B/2A/2|\"Dm\"A3/4B/2A/2|\"E\"B/2B/2B/2e/2|E/2E/2E/2d/2|\"Am\"A3/4B/4A/2G/2|\"Dm\"D3/4E/4D/2|\"E\"F/2G/2E/2D/2|\"Am\"A3/4B/2A/2|\"Dm\"A3/4B/2A/2|\"E\"B/2G/2E/2d/2|\"Am\"A3/4B/4A/2G/2|\"Dm\"D3/4E/4D/2|\"E\"F/2G/2E/2D/2|\"Am\"A3/4B/2A/2|E/4F/4E/2D/2|\"E\"E/2E/2D/2|\"Am\"A/2A/2A|]\n",
      "\n",
      "M:3/4\n",
      "L:1/4\n",
      "K:Bb\n",
      "|\"B\"|\"B\"|\"B\"|\"E\"|\"Cm\"|\"F7\"|\"B\"\"F7\"|\"B\"|\"B\"\"F7\"|\"B\"|\"D7\"|\"Gm\"|\"Cm\"|\"B\"|\"Cm\"|\"F7\"|\"B\"\"F7\"|\"B\"\"B7\"|\"E\"|\"B\"|\"E\"|\"Cm\"|\"F7\"|\"B\"|\"E\"|\"Cm\"\"F7\"|\"B\"\"F7\"|\"B\"\"F7\"|\"B\"|\"B\"|\"E\"|\"B\"|\"Cm\"|\"F7\"|\"B\"|\"B\"\"F7\"|\"B\"\"F7\"|\"B\"|\"B\"\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "c/2d/2|\"Am\"e/2A/2A/2A/2c/2A/2e|\"Dm\"d/2^c/2d/2e/2d/2c/2d/2|\"E\"e/2^d/2e/2f/2g/2f/2e/2d/2|\"E\"e/2^d/2e/2f/2g/2a/2b/2g/2|\"E\"e/2=d/2e/2^f/2g/2f/2e/2d/2|\"E\"e/2^d/2e/2f/2g/2a/2b/2g/2|\"Am\"a/2^g/2a/2g/2f/2e/2d/2c/2A/2|\"Dm\"d/2^c/2d/2e/2d/2c/2d/2e/2|\"E\"e/2^d/2e/2f/2g/2d/2f/2g/2|\"Am\"a/2^g/2a/2^g/2f/2e/2d/2c/2A/2|\"Dm\"d/2^c/2d/2e/2d/2c/2d/2e/2|\"E\"e/2^d/2e/2f/2g/2a/2b/2g/2|\"E\"e/2^d/2e/2f/2g/2f/2e/2d/2|\"Am\"e/2^d/2e/2f/2g/2a/2b/2g/2|\"Dm\"f/2d/2f/2d/2\"E\"B/2^G/2B/2^G/2|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"D7\"|\"G\"|\"D7\"|\"G\"|\"D7\"\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "\"Am\"e3/4^d/4^c/4B/2A/2|\"Dm\"A3/4B/4A/2G/2E/2|\"E\"E3/4D/2E/2G/2|\"E\"E3/4D/4E/2F/2G/2|\"Am\"A3/4B/4c/2B/2A/2|\"Dm\"A3/4B/4A/2G/2|\"E\"E3/4F/2D/2E/2|\"E\"E3/4F/2G/2E/2|\"Am\"e3/4d/2c/2B/2A/2|\"Dm\"A3/4B/4A/4G/2E/2|\"E\"E3/4F/4G/2E/2|\"Am\"A3/4B/4c/2B/2A/2|\"Dm\"f/4e/4d/2c/2B/2A/2|\"E\"E/4^G/4B/4c/4e/4B/4G/4B/2|\"Am\"e/2A/2A/2G/2|\"Dm\"f/4e/4d/4c/4B/4A/4G/4F/2|\"E\"E3/2B/2|\"Am\"A/2A/2A/4B/4c/4B/2A/2|\"Dm\"f/4e/4d/4c/4B/4A/4G/4F/4|\"E\"E3/4F/4G/2E/2|\"Am\"E3/4F/4G/2E/2|\"Dm\"d/2c/2\"C\"B/2A/2|\"E\"E3/4F/4G/4E/4F/2|\"Am\"A/2A/2E/2|]\n",
      "\n",
      "M:3/4\n",
      "L:1\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "e/2d/2|\"Am\"c/2A/2e/2Ag|\"Dm\"f/2e/2d/2e/2d/2c/2d/2|\"E\"e/2d/2e/2B/2g/2e/2d/2|\"Am\"c/2A/2e/2Ag|\"Dm\"f/2e/2d/2e/2f/2e/2d/2c/2|\"E\"B/2A/2G/2A/2B/2G/2G/2E/2|\"Am\"A/2A/2A/2A/2AA/2B/2|\"Dm\"c/2d/2e/2f/2g/2f/2e/2d/2c/2|\"E\"B/2G/2B/2E/2G/2B/2E/2G/2|\"E\"B/2e/2e/2d/2B/2eg|\"Am\"f/2e/2d/2e/2f/2e/2d/2c/2d/2|\"Am\"c/2A/2e/2A/2f/2e/2A/2c/2d/2|\"Dm\"c/2d/2e/2f/2g/2f/2e/2d/2c/2|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:C\n",
      "|\"C\"|\"C\"\"G7\"|\"C\"|\"C\"\"G7\"|\"C\"|\"C\"\"G7\"|\"C\"|\"C\"\"G7\"|\"C\"|\"C\"|\"Dm\"|\"G\"|\"G\"|\"G\"|\"G\"\"G7\"|\"C\"\"G\"|\"C\"\"G7\"|\"C\"\"G7\"|\"C\"|\"F\"|\"F\"|\"G7\"|\"C\"\"G7\"|\"C\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "\"Am\"A/2G/2A/2B/2A/2|B/2A/2^G/2A/2B/2A/2|B/2A/2G/2A/2B/2A/2|\"Am\"A/2B/2A/2G/2A/2B/2A/2|B/2A/2^G/2A/2B/2A/2G/2|\"Dm\"F/2A/2D/2E/2F/2A/2B/2|\"E\"^G/2E/2B/2E/2B/2E/2^G/2|B/2E/2E/2B/2E/2B/2E/2|\"Am\"A/2^G/2A/2B/2A/2B/2A/2B/2|\"Am\"c/2e/2e/2f/2g/2a/2e/2c/2|\"Dm\"d/2^c/2d/2A/2\"E\"B/2^G/2E/2E/2|\"Am\"A/2^G/2A/2B/2A/2B/2A/2B/2|\"Am\"c/2e/2e/2f/2g/2a/2g/2e/2c/2|\"Dm\"d/2^c/2d/2e/2\"E\"f/2e/2d/2c/2|\"Am\"a/2^g/2a/2f/2g/2e/2c/2|\"Dm\"d/2^c/2d/2A/2\"E\"B/2^G/2E/2D/2|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"Am\"|\"Am\"|\"Am\"|\"Dm\"|\"C\"|\"G\"|\"Am\"|\"Am\"|\"Am\"|\"Am\"\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "c/4d/4|\"Am\"e/2A/2B/2E/2c/2A/2B/2|\"Dm\"dAdc/2d/2|\"E\"e/2d/2B/2EE/2G/2|\"Am\"B/2A/2B/2c/2A/2B/2c/2d/2|\"Dm\"e/2d/2B/2c/2A/2B/2c/2d/2|\"E\"e/2d/2c/2B/2A/2B/2c/2d/2|\"Am\"e/2A/2e/2A/2e/2A/2e/2A/2|\"Dm\"f/2d/2g/2a/2f/2e/2d/2c/2|\"E\"B/2G/2E/2G/2B/2G/2E/2G/2|\"Am\"F/2G/2E/2A/2E/2A/2c/2A/2B/2|\"Dm\"A/2B/2d/2f/2e/2f/2g/2a/2f/2|\"E\"e/2d/2c/2B/2e/2B/2c/2d/2|\"Am\"e/2A/2e/2A/2e/2A/2e/2A/2|\"Dm\"f/2d/2g/2a/2f/2e/2d/2c/2|\"E\"B/2G/2E/2G/2B/2G/2E/2G/2|\"Am\"F/2G/2E/2A/2E/2c/2A/2B/2|\"Dm\"A/2f/2d/2g/2a/2f/2e/2d/2c/2|\"E\"B/2G/2E/2G/2B/2G/2\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "\"Am\"Ae/2^f/2e/2c/2A/2|\"Dm\"dd/2e/2d/2c/2B/2A/2|\"E\"Ge/2B/2G/2E/2B/2|\"E\"G/2B/2E/2G/2B/2E/2B/2|\"Am\"(3c/2c/2c/2c/2A/2A/2\"E\"B/2E/2G/2B/2|\"Am\"(3c/2c/2c/2c/2c/2A/2B/2c/2|\"Dm\"(3d/2c/2d/2c/2d/2e/2d/2c/2|\"E\"B/2E/2G/2B/2E/2B/2|\"Am\"(3c/2c/2c/2c/2c/2a/2c/2a/2c/2|\"Dm\"d/2c/2d/2e/2d/2c/2e/2f/2|\"E\"g/2b/2g/2b/2g/2b/2g/2b/2|\"Am\"a/2b/2a/2g/2a/2b/2a/2g/2|\"Dm\"f/2c/2A/2c/2\"E\"B/2E/2G/2B/2|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:E\n",
      "|\"E\"|\"E\"|\"E\"|\"Fm\"|\"Fm\"\"B7\"|\"E\"|\"E\"|\"E\"|\"Fm\"\"B7\"|\"E\"|\"A\"\"E\"|\"B\"|\"A\"\"E\"|\"E\"|\"Fm\"\"B7\"|\"E\"|]\n",
      "G/2A/2|\"E\"BeeG/2A/2|\"E\"B\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "\"Am\"A3/2G/2F/2E/2|\"Dm\"D/2E/2F/2G/2E/2D/2C/2|\"E\"B,2B,/2B,/2B,/2E/2|\"E\"B3/2c/2B/2G/2F/2E/2|\"Am\"D/2E/2F/2G/2\"Dm\"A/2G/2F/2E/2|\"Gm\"B/2d/2d/2e/2d/2c/2B/2c/2|\"E\"d/2c/2B/2A/2G/2F/2E/2|\"E\"B,/2E/2E/2E/2F/2G/2E/2|\"Am\"B/2A/2G/2F/2G/2E/2C/2D/2|\"Dm\"B/2d/2d/2e/2\"E\"d/2c/2B/2A/2|\"Am\"B/2A/2G/2F/2G/2E/2D/2C/2|\"Dm\"B/2A/2G/2F/2A/2F/2E/2D/2C/2|\"E\"B,/2E/2E/2E/2G/2E/2G/2B/2|\"Am\"B/2A/2G/2F/2G/2E/2C/2D/2E/2|\"Dm\"B/2d/2d/2e/2\"E\"d/2c/2B/2A/2|\"Am\"B/2A/2G/2F/2G/2A/2G/2A/2B/2|\"E\"B/2d/2e/2d/2e/2f/2g/2f/2g/2|\"Am\"a/2f/2e/2f/2g/2\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "A/2B/2|A/2B/2A/2c3/2c/2|\"Am\"B/2c/2B/2A/2f/2e/2c/2|\"Dm\"d/2c/2B/2A/2G/2A/2B/2|\"E\"e/2d/2e/2g/2f/2e/2d/2|\"E\"B/2c/2B/2A/2G/2A/2B/2|\"E\"e/2d/2e/2g/2f/2e/2d/2|\"E\"B/2c/2B/2A/2G/2A/2B/2|\"Am\"c/2B/2A/2G/2\"Dm\"F/2D/2E/2F/2|\"E\"G/2B/2e/2e/2g/2f/2e/2d/2|\"Am\"c/2B/2A/2G/2A/2B/2|\"Dm\"c/2B/2A/2G/2A/2B/2d/2|\"E\"e/2d/2e/2g/2f/2e/2d/2|\"Am\"c/2B/2A/2G/2A/2B/2|\"Am\"c/2B/2A/2G/2A/2B/2d/2|\"Dm\"c/2B/2A/2\"E\"B/2c/2d/2c/2|\"Am\"e/2d/2e/2d/2c/2\"Dm\"B/2A/2F/2|\"E\"GEE|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:D\n",
      "|\"D\"|\"D\"|\"D\"|\"G\"|\"D\"|\"A7\"|\"A7\"|\"A7\"|\"A7\"|\"D\"|\"D\"|\"D\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start='M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test older checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = older_ckpt/m_voices\n",
      "Overriding: path_meta = older_ckpt/m_voices\n",
      "Overriding: start = M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "number of parameters: 14.18M\n",
      "shakespeare_char\n",
      "Loading meta from older_ckpt/m_voices/meta.pkl...\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]G/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]G/2E\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d2|\"G\"B3/2g/2d3/2B/2G3/2B/2d3/2B/2|\"D\"c3/2e/2a3/2g/2f3/2d/2e3/2f/2|\"G\"B3/2g/2d3/2B/2g3/2d/2B3/2d/2|\"D\"c3/2A/2d3/2A/2e3/2A/2f3/2A/2|\"G\"g3/2d/2B3/2d/2g3/2b/2a3/2g/2|\"D\"f3/2d/2A3/2d/2f3/2a/2g3/2f/2|\"C\"e3/2d/2c3/2B/2\"D\"c3/2e/2d3/2c/2|\"G\"B2G2G2d2|\"D\"ADBDcDdc|\"G\"BGcG^cGdG|\"D\"ADBDcDd2|\"G\"edd^cd4|\"D\"ADBDcDdc|\"G\"BGcG^cGd2|\"C\"ecgc\"D\"fcac|\"G\"g2b2g4|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:Eb\n",
      "|\"D\"|\"G\"\"A\"|\"D\"|\"Em\"\"A\"|\"D\"|\"G\"\"A\"|\"G\"\"A\"|\"D\"|\"G\"\"D\"|\"G\"\"D\"|\"G\"\"D\"|\"E\"\"A\"|\"G\"\"D\"|\"G\"\"D\"|\"G\"\"D\"|\"E\"\"A\"|\"A\"\"D\"|]\n",
      "A/2|\"D\"d/2c/2d/2e/2fA|\"G\"Be\"\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2f/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d2|\"G\"G/2B/2d3/4d/4|\"C\"e/2e/2c/2A/2|\"D\"F/2A/2D/2|\"D\"F/2A/2D/2d/2|\"D\"=c/2d/2A/2^G/2A/2|\"G\"B/2G/2d3/2e/4|\"G\"d/2B/2G/2A/2|\"C\"E/2G/2D/2=CD/2|\"D\"F/2A/2d/4d/4f/4e/4|\"G\"g/2G/2G/2|\"C\"c/2G/2c/2e|\"D\"d/4c/4B/4A/2f/4|\"G\"g/2d/2B/2G/2|\"D\"F/2A/2D/2A/4d/4|\"G\"B/2G/2d/4d3/4d/4|\"D\"A/2d/4c/4B/4A/2|\"G\"G/2B/2G/2|\"C\"E/2G/2\"G\"G|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:B\n",
      "|\"A\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"A\"\"Bm\"|\"E\"\"A\"\"A\"|\"D\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"D\"|\"A\"\"Bm\"|\"E\"\"A\"|\"A\"\"Bm\"|\"E\"\"A\"|]\n",
      "z/2|\"A\"z/2A/2-A/2G/2AA|\"Bm\"B/2c/2B/2A/2\"E\"GE|\"A\"z/2A/2-\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d/2|\"G\"B3/2G/2G/2|\"C\"cBc|\"D\"d2d|\"G\"G2B/2c/2|\"G\"d3/2B/2GG|\"C\"cB\"D\"AB/2c/2|\"G\"d2\"C\"e/2c/2|\"G\"d2g3/2B/2|\"D\"cABc|\"G\"d2\"C\"e3/2d/2|\"D\"fzde/2f/2|\"G\"g3/2e/2d3/2e/2|g/2c/2B/2A/2G2|\"D\"A2g3/2f/2|\"G\"g3/2d/2B/2\"C\"cB|\"D\"Ad\"G\"g3/2f/2|\"Em\"g/2e/2\"A\"^c/2\"D\"d2|\"A\"e/2d/2c/2d/2eA/2c/2|\"D\"d2\"G\"B/2A/2G/2A/2|\"D\"FDD|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"A\"|\"E\"|\"E\"|\"A\"|\"E\"\"A\"|\"A\"|\"F#m\"|\"Bm\"\"E\"|\"Bm\"\"E\"|\"A\"\"Bm\"|\"A\"\"E\"|\"A\"\"A\"|]\n",
      "e|\"A\"a3/2g/2a/2e/2c/2A/2|\"E\"BGE3/2E/2|\"/2F/2A/2AB/2c/2|\"Bm\"dc\"E\"e3/2d/2|\"A\"c3/2B/2A\"E\"B/2^G/2E/2B/2d/2c/2B/2|\"A\"A\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2e/2|\"G\"g/2d/2B/2|GB/2A/2|\"G\"G/4A/4B/4c/4d/2g/2|d/2B/2B/2g/2|\"F\"=f/2A/2A/2B/2|cA\"G\"G/4A/4B/4c/4d/2B/2|\"C\"e/2d/4c/4\"G\"d/2B/2|\"G\"G/4A/4B/4c/4d/2B/2|dB|\"G\"G/4A/4B/4c/4d/2B/2|\"C\"e/2d/4c/4d/2e/2|\"F\"=f/2A/2A/2B/2|cA\"G\"g/2d/2B/4c/4d/4B/4|g/2d/2B/4c/4d/4B/4|\"G\"g/2d/2B/4c/4d/4B/4|gd|\"G\"g/2d/2B/4c/4d/4B/4|g/2d/2B/4c/4d/4B/4|\"D\"a/4d/4A/2A/2B/2|\"D7\"cA|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:F\n",
      "|\"D\"|\"C\"|\"D\"|\"D\"|\"G\"\"A\"|\"D\"|\"G\"|\"D\"|\"E\"|\"A\"|\"G\"|\"D\"|\"G\"\"A\"|\"D\"|]\n",
      "a/2g/2|\"D\"fdfd|f/2af/2ag/2f/2|\"C\"e=cec|e/2ge/2ga/2g/2|\"D\"fdfd|\"D\"f/2af/\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d2|\"G\"B3/2g/2d3/4e/4d/2B/2|\"G\"g/2d/2B/2G/2A/2|B3/4B/4B/2A/2|\"G\"G3/2|\"C\"E/2G/2D/2E/2G/2A/2|\"D\"B3/4B/4B/2A/2G/2|\"G\"G3/2B/2A/2G/2|\"C\"E/2G/2D/2E/2G/2A/2|\"D\"B3/2B/4B/4A/2G/2|\"G\"G2|]\n",
      "\n",
      "M:3/4\n",
      "L:1/4\n",
      "K:Gb\n",
      "|\"D\"|\"D\"|\"G\"|\"D\"|\"D\"|\"Em\"\"A\"|\"D\"|\"D\"|\"A\"|\"Bm\"|\"A7\"|\"D\"|\"A\"|\"E7\"|\"A\"|\"G\"|\"D\"|\"A\"|\"D\"|\"D\"|\"Em\"|\"A7\"|\"D\"|]\n",
      "|A|\"D\"f3/2e/2d|\"D\"AFA|\"G\"BGB|\"D\"AFA|\"D\"f3/2e/2d|\"D\"AFA|\"Em\"Be\"A\"c|\"D\"d2|A|\"D\"f2a|\"A\"e2a|\"Bm\"d3/2e/2d|\"A7\"cBA|\"D\"f2a|\"A\"e2a|\"E7\"^gfg|\"A\"a2a|\"G\"b2b|\"D\"a2a|\"A\"ggg|\"D\"fed|\"D\"f3/2e/2d|\"Em\"Bgf|\"A7\"edc|\"D\"d2\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"D\"f/2e/2f/2g/2a/2b/2|\"D\"c'/2a/2f/2dd|\"G\"g/2f/2g/2a/2b/2g/2e/2d/2|\"C\"c/2g/2f/2g/2a/2g/2e/2d/2c/2|\"G\"B/2g/2f/2g/2d/2g/2d/2B/2|\"D\"cAA|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"G\"|\"G\"\"D7\"|\"G\"\"D7\"|\"G\"|\"D\"|\"G\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    " !python3 sample.py --out_dir=older_ckpt/m_voices --path_meta=older_ckpt/m_voices --start='M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat older_ckpt/m_voices/ckpt.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l older_ckpt/m_voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l out-abc-char/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
