{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def load_dataframe(relative_path,dataframe_name):\n",
    "    df = pd.read_pickle(f'{relative_path}/{dataframe_name}.pkl')    \n",
    "    return df\n",
    "\n",
    "def read_file(relative_path,file_name):\n",
    "    text= \"\"\n",
    "    with open(f'{relative_path}/{file_name}.abc','r') as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unit_note_length', 'tuneBook', 'title', 'reference_number',\n",
       "       'original_header', 'original_body', 'meter', 'key', 'clean_song',\n",
       "       'clean_header', 'clean_body', 'chord_progression', '\"fm\"', '\"ff'\"',\n",
       "       '\"f7\"', '\"em\"', '\"ee'\"', '\"e7\"', '\"e\"', '\"dm\"', '\"dd'\"', '\"d7\"', '\"d\"',\n",
       "       '\"cm\"', '\"cc'\"', '\"c7\"', '\"c#m\"', '\"c#7\"', '\"c\"', '\"Gm\"', '\"Gg\"',\n",
       "       '\"Gd'\"', '\"G7\"', '\"G#m\"', '\"G#7\"', '\"G\"', '\"Fm\"', '\"Ff\"', '\"Fc'\"',\n",
       "       '\"F7\"', '\"F#m\"', '\"F#7\"', '\"F\"', '\"Em\"', '\"Eb\"', '\"E7\"', '\"E#m\"',\n",
       "       '\"E#7\"', '\"E\"', '\"Dm\"', '\"Da\"', '\"D7\"', '\"D#m\"', '\"D#7\"', '\"D\"', '\"Cm\"',\n",
       "       '\"Cg\"', '\"C7\"', '\"C#m\"', '\"C#7\"', '\"C\"', '\"Bm\"', '\"Bf\"', '\"Bb\"', '\"B7\"',\n",
       "       '\"B#m\"', '\"B#7\"', '\"B\"', '\"Am\"', '\"Ae'\"', '\"Aa\"', '\"A7\"', '\"A#m\"',\n",
       "       '\"A#7\"', '\"A\"'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_path =\"notebooks/data/final_dataset\"\n",
    "filename_name = 'clean_augmented_data'\n",
    "#filename_name = 'clean_original_training_data'\n",
    "#relative_path =\"notebooks/data/original_dataset\"\n",
    "training_data_df = load_dataframe(relative_path,filename_name)\n",
    "training_data_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_note_length</th>\n",
       "      <th>tuneBook</th>\n",
       "      <th>title</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>original_header</th>\n",
       "      <th>original_body</th>\n",
       "      <th>meter</th>\n",
       "      <th>key</th>\n",
       "      <th>clean_song</th>\n",
       "      <th>clean_header</th>\n",
       "      <th>...</th>\n",
       "      <th>\"B#m\"</th>\n",
       "      <th>\"B#7\"</th>\n",
       "      <th>\"B\"</th>\n",
       "      <th>\"Am\"</th>\n",
       "      <th>\"Ae'\"</th>\n",
       "      <th>\"Aa\"</th>\n",
       "      <th>\"A7\"</th>\n",
       "      <th>\"A#m\"</th>\n",
       "      <th>\"A#7\"</th>\n",
       "      <th>\"A\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9491</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Grandpa's</td>\n",
       "      <td>78</td>\n",
       "      <td>X:78\\nT:Grandpa's\\nM:4/4\\nL:1/4\\nK:Amajor</td>\n",
       "      <td>E/2D/2|\"A,\"CE\"E7\"FG|\"A,\"A/2G/2A/2B/2ce|\"B,m\"dc...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9492</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>The Girl With The Green Hat On</td>\n",
       "      <td>79</td>\n",
       "      <td>X:79\\nT:The Girl With The Green Hat On\\nM:4/4\\...</td>\n",
       "      <td>(3E/2F/2G/2|\"A,\"AE\"E7\"E/2F/2E/2D/2|\"A,\"C/2D/2E...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9493</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Green Meadow</td>\n",
       "      <td>80</td>\n",
       "      <td>X:80\\nT:Green Meadow\\nM:4/4\\nL:1/4\\nK:Dmajor</td>\n",
       "      <td>(3A,/2B,/2C/2|\"D\"DD/2E/2F/2D/2F/2A/2|\"G,\"B/2c/...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>D</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9494</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>The Old Grey Cat</td>\n",
       "      <td>82</td>\n",
       "      <td>X:82\\nT:The Old Grey Cat\\nM:4/4\\nL:1/4\\nK:Bminor</td>\n",
       "      <td>F|\"B,m\"BBB,B,/2C/2|\"B,m\"D/2C/2D/2E/2F/2E/2F/2^...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>Bm</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9495</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Gyre And Gimble</td>\n",
       "      <td>84</td>\n",
       "      <td>X:84\\nT:Gyre And Gimble\\nM:4/4\\nL:1/4\\nK:Amajor</td>\n",
       "      <td>E|\"A,\"AECE|\"B,m\"FD\"E7\"B,D|\"A,\"CEA3/2B/2|\"E7\"c/...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unit_note_length          tuneBook                           title  \\\n",
       "9491              1/4  dataset_min5.abc                       Grandpa's   \n",
       "9492              1/4  dataset_min5.abc  The Girl With The Green Hat On   \n",
       "9493              1/4  dataset_min5.abc                    Green Meadow   \n",
       "9494              1/4  dataset_min5.abc                The Old Grey Cat   \n",
       "9495              1/4  dataset_min5.abc                 Gyre And Gimble   \n",
       "\n",
       "     reference_number                                    original_header  \\\n",
       "9491               78          X:78\\nT:Grandpa's\\nM:4/4\\nL:1/4\\nK:Amajor   \n",
       "9492               79  X:79\\nT:The Girl With The Green Hat On\\nM:4/4\\...   \n",
       "9493               80       X:80\\nT:Green Meadow\\nM:4/4\\nL:1/4\\nK:Dmajor   \n",
       "9494               82   X:82\\nT:The Old Grey Cat\\nM:4/4\\nL:1/4\\nK:Bminor   \n",
       "9495               84    X:84\\nT:Gyre And Gimble\\nM:4/4\\nL:1/4\\nK:Amajor   \n",
       "\n",
       "                                          original_body meter key  \\\n",
       "9491  E/2D/2|\"A,\"CE\"E7\"FG|\"A,\"A/2G/2A/2B/2ce|\"B,m\"dc...   4/4   A   \n",
       "9492  (3E/2F/2G/2|\"A,\"AE\"E7\"E/2F/2E/2D/2|\"A,\"C/2D/2E...   4/4   A   \n",
       "9493  (3A,/2B,/2C/2|\"D\"DD/2E/2F/2D/2F/2A/2|\"G,\"B/2c/...   4/4   D   \n",
       "9494  F|\"B,m\"BBB,B,/2C/2|\"B,m\"D/2C/2D/2E/2F/2E/2F/2^...   4/4  Bm   \n",
       "9495  E|\"A,\"AECE|\"B,m\"FD\"E7\"B,D|\"A,\"CEA3/2B/2|\"E7\"c/...   4/4   A   \n",
       "\n",
       "                                             clean_song  \\\n",
       "9491  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...   \n",
       "9492  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...   \n",
       "9493  M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...   \n",
       "9494  M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...   \n",
       "9495  M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...   \n",
       "\n",
       "                                           clean_header  ... \"B#m\" \"B#7\"  \"B\"  \\\n",
       "9491  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...  ...     0     0    0   \n",
       "9492  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...  ...     0     0    0   \n",
       "9493  M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...  ...     0     0    0   \n",
       "9494  M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...  ...     0     0    0   \n",
       "9495  M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...  ...     0     0    0   \n",
       "\n",
       "      \"Am\"  \"Ae'\"  \"Aa\"  \"A7\"  \"A#m\"  \"A#7\"  \"A\"  \n",
       "9491     0      0     0     0      0      0    9  \n",
       "9492     0      0     0     0      0      0    9  \n",
       "9493     0      0     0     7      0      0    0  \n",
       "9494     0      0     0     0      0      0    5  \n",
       "9495     0      0     0     0      0      0   12  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df[\"clean_header\"].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1257"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df[\"clean_body\"].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab:  \n",
      "\"#'(),-/1234567=ABCDEFG[]^_abcdefgmz|~\n",
      "vocab_size 39\n",
      "silences  516\n"
     ]
    }
   ],
   "source": [
    "bodies = \"\"\n",
    "silences = 0\n",
    "for body in training_data_df[\"clean_body\"]:\n",
    "    if 'z' in body:\n",
    "        silences +=1 \n",
    "    bodies += body+\"\\n\"\n",
    "chars = sorted(list(set(bodies)))\n",
    "vocab_size = len(chars)\n",
    "print('vocab: ',''.join(chars))\n",
    "print('vocab_size',vocab_size)\n",
    "print(\"silences \",silences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chars: 4062773\n"
     ]
    }
   ],
   "source": [
    "training_data_text = read_file(relative_path,filename_name)\n",
    "\n",
    "print(\"number of chars:\",len(training_data_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chars \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(training_data_text)))\n\u001b[1;32m      2\u001b[0m vocab_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(chars)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(chars))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_data_text' is not defined"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(training_data_text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.28.0.dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14.2\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import tiktoken\n",
    "\n",
    "print(wandb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile  docker-compose.yaml  overrides.json\n",
      "README.md   notebooks\t\t requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "nano_path = 'notebooks/nanoGPT'\n",
    "os.chdir(nano_path)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE      assets\t      data\t  out-abc-char\twandb\n",
      "README.md    config\t      model.py\t  sample.py\n",
      "__pycache__  configurator.py  older_ckpt  train.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with multiple voices present\n",
    "#length of dataset in characters: 4,149,703\n",
    "#all the unique characters: \n",
    "#\"#'()+,-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
    "#vocab size: 46\n",
    "#train has 3,734,732 tokens\n",
    "#val has 414,971 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 4,062,773\n",
      "all the unique characters: \n",
      "\"#'(),-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
      "vocab size: 45\n",
      "train has 3,656,495 tokens\n",
      "val has 406,278 tokens\n"
     ]
    }
   ],
   "source": [
    "!python3 data/abc_char/prepare.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding config with config/train_abc_char.py:\n",
      "# train a miniature character-level shakespeare model\n",
      "# good for debugging and playing on macbooks and such\n",
      "\n",
      "out_dir = 'out-abc-char'\n",
      "eval_interval = 10 # keep frequent because we'll overfit\n",
      "eval_iters = 500\n",
      "log_interval = 5 # don't print too too often\n",
      "\n",
      "# we expect to overfit on this small dataset, so only save when val improves\n",
      "always_save_checkpoint = False\n",
      "\n",
      "wandb_log = True # override via command line if you like\n",
      "wandb_project = 'abc-char'\n",
      "wandb_run_name = 'mini-char-gpt-hd-8-ly-12-embd-240'\n",
      "\n",
      "dataset = 'abc_char'\n",
      "batch_size = 32\n",
      "block_size = 512 # context of up to 512 previous characters\n",
      "\n",
      "# baby GPT model :)\n",
      "n_layer = 12\n",
      "n_head = 8\n",
      "n_embd = 240\n",
      "dropout = 0.2\n",
      "\n",
      "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
      "max_iters = 5000\n",
      "lr_decay_iters = 5000 # make equal to max_iters usually\n",
      "min_lr = 1e-4 # learning_rate / 10 usually\n",
      "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
      "\n",
      "warmup_iters = 5 # not super necessary potentially\n",
      "\n",
      "# on macbook also add\n",
      "# device = 'cpu'  # run on cpu only\n",
      "# compile = False # do not torch compile the model\n",
      "\n",
      "found vocab_size = 45 (inside data/abc_char/meta.pkl)\n",
      "Initializing a new model from scratch\n",
      "number of parameters: 8.31M\n",
      "using fused AdamW: True\n",
      "compiling the model... (takes a ~minute)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavidnogales\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/pt-env/notebooks/nanoGPT/wandb/run-20230424_190509-nvg8mwne\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmini-char-gpt-hd-8-ly-12-embd-240\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char/runs/nvg8mwne\u001b[0m\n",
      "[2023-04-24 19:05:14,670] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "step 0: train loss 3.8966, val loss 3.9080\n",
      "[2023-04-24 19:06:30,494] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "iter 0: loss 3.8995, time 98053.65ms, mfu -100.00%\n",
      "iter 5: loss 2.9027, time 6643.48ms, mfu 2.14%\n",
      "step 10: train loss 2.4352, val loss 2.4255\n",
      "saving checkpoint to out-abc-char\n",
      "iter 10: loss 2.4664, time 67248.77ms, mfu 1.94%\n",
      "iter 15: loss 2.2972, time 6690.60ms, mfu 1.96%\n",
      "step 20: train loss 2.1953, val loss 2.2377\n",
      "saving checkpoint to out-abc-char\n",
      "iter 20: loss 2.1810, time 67128.85ms, mfu 1.79%\n",
      "iter 25: loss 2.1372, time 6683.12ms, mfu 1.82%\n",
      "step 30: train loss 2.0151, val loss 2.0630\n",
      "saving checkpoint to out-abc-char\n",
      "iter 30: loss 2.0026, time 66413.69ms, mfu 1.66%\n",
      "iter 35: loss 1.9228, time 6544.83ms, mfu 1.71%\n",
      "step 40: train loss 1.8860, val loss 1.9078\n",
      "saving checkpoint to out-abc-char\n",
      "iter 40: loss 1.8617, time 66199.89ms, mfu 1.56%\n",
      "iter 45: loss 1.8439, time 6554.94ms, mfu 1.62%\n",
      "step 50: train loss 1.8350, val loss 1.8412\n",
      "saving checkpoint to out-abc-char\n",
      "iter 50: loss 1.8264, time 66275.17ms, mfu 1.48%\n",
      "iter 55: loss 1.8189, time 6579.24ms, mfu 1.55%\n",
      "step 60: train loss 1.7560, val loss 1.7855\n",
      "saving checkpoint to out-abc-char\n",
      "iter 60: loss 1.7262, time 66803.81ms, mfu 1.41%\n",
      "iter 65: loss 1.8045, time 6676.69ms, mfu 1.49%\n",
      "step 70: train loss 1.7262, val loss 1.7514\n",
      "saving checkpoint to out-abc-char\n",
      "iter 70: loss 1.7662, time 67957.79ms, mfu 1.36%\n",
      "iter 75: loss 1.7764, time 6747.92ms, mfu 1.43%\n",
      "step 80: train loss 1.6775, val loss 1.7040\n",
      "saving checkpoint to out-abc-char\n",
      "iter 80: loss 1.7511, time 68120.62ms, mfu 1.31%\n",
      "iter 85: loss 1.6964, time 6674.34ms, mfu 1.39%\n",
      "step 90: train loss 1.6260, val loss 1.6637\n",
      "saving checkpoint to out-abc-char\n",
      "iter 90: loss 1.6396, time 68021.14ms, mfu 1.27%\n",
      "iter 95: loss 1.6608, time 6801.97ms, mfu 1.35%\n",
      "step 100: train loss 1.5957, val loss 1.6286\n",
      "saving checkpoint to out-abc-char\n",
      "iter 100: loss 1.5836, time 68160.56ms, mfu 1.24%\n",
      "iter 105: loss 1.6183, time 6773.46ms, mfu 1.33%\n",
      "step 110: train loss 1.5628, val loss 1.5979\n",
      "saving checkpoint to out-abc-char\n",
      "iter 110: loss 1.5687, time 67671.78ms, mfu 1.21%\n",
      "iter 115: loss 1.5923, time 6688.47ms, mfu 1.30%\n",
      "step 120: train loss 1.5368, val loss 1.5652\n",
      "saving checkpoint to out-abc-char\n",
      "iter 120: loss 1.5671, time 67350.34ms, mfu 1.20%\n",
      "iter 125: loss 1.5003, time 6678.86ms, mfu 1.29%\n",
      "step 130: train loss 1.5259, val loss 1.5441\n",
      "saving checkpoint to out-abc-char\n",
      "iter 130: loss 1.5096, time 66456.12ms, mfu 1.18%\n",
      "iter 135: loss 1.4774, time 6394.36ms, mfu 1.28%\n",
      "step 140: train loss 1.5074, val loss 1.5152\n",
      "saving checkpoint to out-abc-char\n",
      "iter 140: loss 1.5559, time 64649.25ms, mfu 1.18%\n",
      "iter 145: loss 1.4917, time 6770.99ms, mfu 1.27%\n",
      "step 150: train loss 1.4771, val loss 1.4919\n",
      "saving checkpoint to out-abc-char\n",
      "iter 150: loss 1.5047, time 68210.84ms, mfu 1.16%\n",
      "iter 155: loss 1.4192, time 6774.24ms, mfu 1.26%\n",
      "step 160: train loss 1.4595, val loss 1.4781\n",
      "saving checkpoint to out-abc-char\n",
      "iter 160: loss 1.4597, time 68146.49ms, mfu 1.15%\n",
      "iter 165: loss 1.4519, time 6727.09ms, mfu 1.25%\n",
      "step 170: train loss 1.4670, val loss 1.4746\n",
      "saving checkpoint to out-abc-char\n",
      "iter 170: loss 1.4931, time 67602.57ms, mfu 1.14%\n",
      "iter 175: loss 1.4842, time 6767.91ms, mfu 1.24%\n",
      "step 180: train loss 1.4517, val loss 1.4667\n",
      "saving checkpoint to out-abc-char\n",
      "iter 180: loss 1.4658, time 67685.70ms, mfu 1.14%\n",
      "iter 185: loss 1.4683, time 6684.20ms, mfu 1.23%\n",
      "step 190: train loss 1.4276, val loss 1.4414\n",
      "saving checkpoint to out-abc-char\n",
      "iter 190: loss 1.4495, time 67473.29ms, mfu 1.13%\n",
      "iter 195: loss 1.4575, time 6671.78ms, mfu 1.23%\n",
      "step 200: train loss 1.4072, val loss 1.4183\n",
      "saving checkpoint to out-abc-char\n",
      "iter 200: loss 1.4307, time 66112.24ms, mfu 1.13%\n",
      "iter 205: loss 1.4575, time 6461.81ms, mfu 1.24%\n",
      "step 210: train loss 1.3891, val loss 1.3967\n",
      "saving checkpoint to out-abc-char\n",
      "iter 210: loss 1.4539, time 65024.06ms, mfu 1.13%\n",
      "iter 215: loss 1.4157, time 6460.96ms, mfu 1.24%\n",
      "step 220: train loss 1.3524, val loss 1.3689\n",
      "saving checkpoint to out-abc-char\n",
      "iter 220: loss 1.3575, time 64882.08ms, mfu 1.14%\n",
      "iter 225: loss 1.3783, time 6540.89ms, mfu 1.24%\n",
      "step 230: train loss 1.3385, val loss 1.3540\n",
      "saving checkpoint to out-abc-char\n",
      "iter 230: loss 1.3739, time 66008.32ms, mfu 1.14%\n",
      "iter 235: loss 1.3062, time 6545.05ms, mfu 1.24%\n",
      "step 240: train loss 1.3092, val loss 1.3347\n",
      "saving checkpoint to out-abc-char\n",
      "iter 240: loss 1.2885, time 66034.81ms, mfu 1.14%\n",
      "iter 245: loss 1.3254, time 6544.23ms, mfu 1.24%\n",
      "step 250: train loss 1.2911, val loss 1.3129\n",
      "saving checkpoint to out-abc-char\n",
      "iter 250: loss 1.3497, time 66003.50ms, mfu 1.14%\n",
      "iter 255: loss 1.3195, time 6530.84ms, mfu 1.24%\n",
      "step 260: train loss 1.2705, val loss 1.2892\n",
      "saving checkpoint to out-abc-char\n",
      "iter 260: loss 1.3409, time 66007.33ms, mfu 1.14%\n",
      "iter 265: loss 1.3007, time 6535.22ms, mfu 1.24%\n",
      "step 270: train loss 1.2457, val loss 1.2767\n",
      "saving checkpoint to out-abc-char\n",
      "iter 270: loss 1.2389, time 65377.17ms, mfu 1.14%\n",
      "iter 275: loss 1.2433, time 6363.57ms, mfu 1.25%\n",
      "step 280: train loss 1.2322, val loss 1.2676\n",
      "saving checkpoint to out-abc-char\n",
      "iter 280: loss 1.3180, time 64429.88ms, mfu 1.15%\n",
      "iter 285: loss 1.2435, time 6361.93ms, mfu 1.26%\n",
      "step 290: train loss 1.2042, val loss 1.2266\n",
      "saving checkpoint to out-abc-char\n",
      "iter 290: loss 1.2416, time 64389.02ms, mfu 1.15%\n",
      "iter 295: loss 1.1678, time 6361.59ms, mfu 1.26%\n",
      "step 300: train loss 1.1940, val loss 1.2162\n",
      "saving checkpoint to out-abc-char\n",
      "iter 300: loss 1.2285, time 64381.30ms, mfu 1.16%\n",
      "iter 305: loss 1.1715, time 6363.52ms, mfu 1.26%\n",
      "step 310: train loss 1.1742, val loss 1.1998\n",
      "saving checkpoint to out-abc-char\n",
      "iter 310: loss 1.1784, time 64395.04ms, mfu 1.16%\n",
      "iter 315: loss 1.2220, time 6361.69ms, mfu 1.27%\n",
      "step 320: train loss 1.1702, val loss 1.2041\n",
      "iter 320: loss 1.2566, time 64275.76ms, mfu 1.16%\n",
      "iter 325: loss 1.2264, time 6361.53ms, mfu 1.27%\n",
      "step 330: train loss 1.1281, val loss 1.1573\n",
      "saving checkpoint to out-abc-char\n",
      "iter 330: loss 1.1557, time 64389.97ms, mfu 1.16%\n",
      "iter 335: loss 1.2025, time 6362.33ms, mfu 1.27%\n",
      "step 340: train loss 1.1259, val loss 1.1449\n",
      "saving checkpoint to out-abc-char\n",
      "iter 340: loss 1.1191, time 64418.49ms, mfu 1.17%\n",
      "iter 345: loss 1.1439, time 6360.43ms, mfu 1.27%\n",
      "step 350: train loss 1.1398, val loss 1.1634\n",
      "iter 350: loss 1.1207, time 64272.49ms, mfu 1.17%\n",
      "iter 355: loss 1.1339, time 6362.59ms, mfu 1.27%\n",
      "step 360: train loss 1.1055, val loss 1.1335\n",
      "saving checkpoint to out-abc-char\n",
      "iter 360: loss 1.1165, time 64382.68ms, mfu 1.17%\n",
      "iter 365: loss 1.1544, time 6364.06ms, mfu 1.27%\n",
      "step 370: train loss 1.0929, val loss 1.1233\n",
      "saving checkpoint to out-abc-char\n",
      "iter 370: loss 1.1164, time 64404.42ms, mfu 1.17%\n",
      "iter 375: loss 1.0814, time 6362.08ms, mfu 1.27%\n",
      "step 380: train loss 1.0640, val loss 1.1024\n",
      "saving checkpoint to out-abc-char\n",
      "iter 380: loss 1.0973, time 64403.15ms, mfu 1.17%\n",
      "iter 385: loss 1.0826, time 6363.92ms, mfu 1.28%\n",
      "step 390: train loss 1.0522, val loss 1.0923\n",
      "saving checkpoint to out-abc-char\n",
      "iter 390: loss 1.1157, time 64382.02ms, mfu 1.17%\n",
      "iter 395: loss 1.0756, time 6363.37ms, mfu 1.28%\n",
      "step 400: train loss 1.0428, val loss 1.0779\n",
      "saving checkpoint to out-abc-char\n",
      "iter 400: loss 1.0823, time 64402.44ms, mfu 1.17%\n",
      "iter 405: loss 1.0467, time 6363.24ms, mfu 1.28%\n",
      "step 410: train loss 1.0286, val loss 1.0683\n",
      "saving checkpoint to out-abc-char\n",
      "iter 410: loss 1.0647, time 64397.00ms, mfu 1.17%\n",
      "iter 415: loss 1.0341, time 6364.04ms, mfu 1.28%\n",
      "step 420: train loss 1.0081, val loss 1.0502\n",
      "saving checkpoint to out-abc-char\n",
      "iter 420: loss 1.0597, time 64388.02ms, mfu 1.17%\n",
      "iter 425: loss 1.0670, time 6362.71ms, mfu 1.28%\n",
      "step 430: train loss 0.9972, val loss 1.0349\n",
      "saving checkpoint to out-abc-char\n",
      "iter 430: loss 0.9925, time 64402.67ms, mfu 1.17%\n",
      "iter 435: loss 0.9757, time 6362.63ms, mfu 1.28%\n",
      "step 440: train loss 0.9862, val loss 1.0277\n",
      "saving checkpoint to out-abc-char\n",
      "iter 440: loss 1.0310, time 64387.70ms, mfu 1.17%\n",
      "iter 445: loss 1.0195, time 6364.77ms, mfu 1.28%\n",
      "step 450: train loss 0.9709, val loss 1.0079\n",
      "saving checkpoint to out-abc-char\n",
      "iter 450: loss 1.0152, time 64370.92ms, mfu 1.17%\n",
      "iter 455: loss 1.0037, time 6364.31ms, mfu 1.28%\n",
      "step 460: train loss 0.9599, val loss 1.0012\n",
      "saving checkpoint to out-abc-char\n",
      "iter 460: loss 0.8968, time 64399.23ms, mfu 1.17%\n",
      "iter 465: loss 0.9657, time 6361.48ms, mfu 1.28%\n",
      "step 470: train loss 0.9683, val loss 1.0053\n",
      "iter 470: loss 0.9738, time 64287.16ms, mfu 1.17%\n",
      "iter 475: loss 0.9767, time 6362.43ms, mfu 1.28%\n",
      "step 480: train loss 0.9299, val loss 0.9661\n",
      "saving checkpoint to out-abc-char\n",
      "iter 480: loss 0.9933, time 64371.63ms, mfu 1.17%\n",
      "iter 485: loss 0.9226, time 6363.96ms, mfu 1.28%\n",
      "step 490: train loss 0.9276, val loss 0.9629\n",
      "saving checkpoint to out-abc-char\n",
      "iter 490: loss 0.9468, time 64377.37ms, mfu 1.17%\n",
      "iter 495: loss 0.9230, time 6362.02ms, mfu 1.28%\n",
      "step 500: train loss 0.9210, val loss 0.9598\n",
      "saving checkpoint to out-abc-char\n",
      "iter 500: loss 0.9461, time 64365.97ms, mfu 1.17%\n",
      "iter 505: loss 0.9129, time 6364.36ms, mfu 1.28%\n",
      "step 510: train loss 0.9001, val loss 0.9406\n",
      "saving checkpoint to out-abc-char\n",
      "iter 510: loss 1.0003, time 64367.90ms, mfu 1.17%\n",
      "iter 515: loss 0.9915, time 6362.16ms, mfu 1.28%\n",
      "step 520: train loss 0.8786, val loss 0.9108\n",
      "saving checkpoint to out-abc-char\n",
      "iter 520: loss 0.8969, time 64374.83ms, mfu 1.17%\n",
      "iter 525: loss 0.9349, time 6362.65ms, mfu 1.28%\n",
      "step 530: train loss 0.8696, val loss 0.9053\n",
      "saving checkpoint to out-abc-char\n",
      "iter 530: loss 0.9018, time 64359.33ms, mfu 1.17%\n",
      "iter 535: loss 0.9479, time 6363.75ms, mfu 1.28%\n",
      "step 540: train loss 0.8659, val loss 0.9060\n",
      "iter 540: loss 0.8939, time 64292.49ms, mfu 1.17%\n",
      "iter 545: loss 0.8912, time 6363.47ms, mfu 1.28%\n",
      "step 550: train loss 0.8382, val loss 0.8746\n",
      "saving checkpoint to out-abc-char\n",
      "iter 550: loss 0.8658, time 64411.16ms, mfu 1.17%\n",
      "iter 555: loss 0.8766, time 6362.43ms, mfu 1.28%\n",
      "step 560: train loss 0.8407, val loss 0.8825\n",
      "iter 560: loss 0.8553, time 64293.60ms, mfu 1.17%\n",
      "iter 565: loss 0.8616, time 6365.48ms, mfu 1.28%\n",
      "step 570: train loss 0.8188, val loss 0.8616\n",
      "saving checkpoint to out-abc-char\n",
      "iter 570: loss 0.8707, time 64381.80ms, mfu 1.17%\n",
      "iter 575: loss 0.8584, time 6365.52ms, mfu 1.28%\n",
      "step 580: train loss 0.8034, val loss 0.8385\n",
      "saving checkpoint to out-abc-char\n",
      "iter 580: loss 0.8458, time 64386.56ms, mfu 1.17%\n",
      "iter 585: loss 0.8562, time 6362.61ms, mfu 1.28%\n",
      "step 590: train loss 0.7969, val loss 0.8290\n",
      "saving checkpoint to out-abc-char\n",
      "iter 590: loss 0.8545, time 64380.64ms, mfu 1.17%\n",
      "iter 595: loss 0.7912, time 6362.22ms, mfu 1.28%\n",
      "step 600: train loss 0.7818, val loss 0.8223\n",
      "saving checkpoint to out-abc-char\n",
      "iter 600: loss 0.8079, time 64367.77ms, mfu 1.17%\n",
      "iter 605: loss 0.8094, time 6363.33ms, mfu 1.28%\n",
      "step 610: train loss 0.7729, val loss 0.8083\n",
      "saving checkpoint to out-abc-char\n",
      "iter 610: loss 0.8218, time 64956.40ms, mfu 1.17%\n",
      "iter 615: loss 0.7943, time 6388.85ms, mfu 1.28%\n",
      "step 620: train loss 0.7649, val loss 0.8035\n",
      "saving checkpoint to out-abc-char\n",
      "iter 620: loss 0.8092, time 65085.56ms, mfu 1.17%\n",
      "iter 625: loss 0.8264, time 6500.15ms, mfu 1.27%\n",
      "step 630: train loss 0.7520, val loss 0.7914\n",
      "saving checkpoint to out-abc-char\n",
      "iter 630: loss 0.7781, time 64818.01ms, mfu 1.17%\n",
      "iter 635: loss 0.8029, time 6563.04ms, mfu 1.27%\n",
      "step 640: train loss 0.7458, val loss 0.7860\n",
      "saving checkpoint to out-abc-char\n",
      "iter 640: loss 0.7941, time 64784.85ms, mfu 1.16%\n",
      "iter 645: loss 0.7930, time 6468.06ms, mfu 1.27%\n",
      "step 650: train loss 0.7364, val loss 0.7859\n",
      "saving checkpoint to out-abc-char\n",
      "iter 650: loss 0.7638, time 64734.97ms, mfu 1.16%\n",
      "iter 655: loss 0.7597, time 6372.03ms, mfu 1.27%\n",
      "step 660: train loss 0.7202, val loss 0.7651\n",
      "saving checkpoint to out-abc-char\n",
      "iter 660: loss 0.7491, time 64537.89ms, mfu 1.16%\n",
      "iter 665: loss 0.7283, time 6383.38ms, mfu 1.27%\n",
      "step 670: train loss 0.7112, val loss 0.7555\n",
      "saving checkpoint to out-abc-char\n",
      "iter 670: loss 0.7223, time 64563.93ms, mfu 1.16%\n",
      "iter 675: loss 0.7597, time 6393.39ms, mfu 1.27%\n",
      "step 680: train loss 0.6999, val loss 0.7427\n",
      "saving checkpoint to out-abc-char\n",
      "iter 680: loss 0.7308, time 64478.31ms, mfu 1.16%\n",
      "iter 685: loss 0.7155, time 6435.99ms, mfu 1.27%\n",
      "step 690: train loss 0.6905, val loss 0.7327\n",
      "saving checkpoint to out-abc-char\n",
      "iter 690: loss 0.7411, time 64515.67ms, mfu 1.16%\n",
      "iter 695: loss 0.7041, time 6409.24ms, mfu 1.27%\n",
      "step 700: train loss 0.6858, val loss 0.7333\n",
      "iter 700: loss 0.7511, time 64907.87ms, mfu 1.16%\n",
      "iter 705: loss 0.7286, time 6441.43ms, mfu 1.27%\n",
      "step 710: train loss 0.6761, val loss 0.7251\n",
      "saving checkpoint to out-abc-char\n",
      "iter 710: loss 0.7353, time 64597.49ms, mfu 1.16%\n",
      "iter 715: loss 0.7231, time 6399.57ms, mfu 1.27%\n",
      "step 720: train loss 0.6732, val loss 0.7215\n",
      "saving checkpoint to out-abc-char\n",
      "iter 720: loss 0.7197, time 64679.04ms, mfu 1.16%\n",
      "iter 725: loss 0.7100, time 6438.21ms, mfu 1.27%\n",
      "step 730: train loss 0.6609, val loss 0.7049\n",
      "saving checkpoint to out-abc-char\n",
      "iter 730: loss 0.7102, time 64627.01ms, mfu 1.16%\n",
      "iter 735: loss 0.6941, time 6389.85ms, mfu 1.27%\n",
      "step 740: train loss 0.6631, val loss 0.7083\n",
      "iter 740: loss 0.6931, time 64466.35ms, mfu 1.16%\n",
      "iter 745: loss 0.7107, time 6385.46ms, mfu 1.27%\n",
      "step 750: train loss 0.6487, val loss 0.6946\n",
      "saving checkpoint to out-abc-char\n",
      "iter 750: loss 0.6827, time 64635.98ms, mfu 1.16%\n",
      "iter 755: loss 0.6843, time 6449.11ms, mfu 1.27%\n",
      "step 760: train loss 0.6384, val loss 0.6895\n",
      "saving checkpoint to out-abc-char\n",
      "iter 760: loss 0.6743, time 64435.76ms, mfu 1.16%\n",
      "iter 765: loss 0.6668, time 6432.83ms, mfu 1.27%\n",
      "step 770: train loss 0.6321, val loss 0.6807\n",
      "saving checkpoint to out-abc-char\n",
      "iter 770: loss 0.6917, time 64516.85ms, mfu 1.16%\n",
      "iter 775: loss 0.6721, time 6404.07ms, mfu 1.27%\n",
      "step 780: train loss 0.6299, val loss 0.6779\n",
      "saving checkpoint to out-abc-char\n",
      "iter 780: loss 0.6626, time 64631.95ms, mfu 1.16%\n",
      "iter 785: loss 0.6461, time 6420.10ms, mfu 1.27%\n",
      "step 790: train loss 0.6214, val loss 0.6700\n",
      "saving checkpoint to out-abc-char\n",
      "iter 790: loss 0.6580, time 64632.92ms, mfu 1.16%\n",
      "iter 795: loss 0.6508, time 6479.26ms, mfu 1.27%\n",
      "step 800: train loss 0.6162, val loss 0.6651\n",
      "saving checkpoint to out-abc-char\n",
      "iter 800: loss 0.6558, time 64484.39ms, mfu 1.16%\n",
      "iter 805: loss 0.6515, time 6375.46ms, mfu 1.27%\n",
      "step 810: train loss 0.6145, val loss 0.6613\n",
      "saving checkpoint to out-abc-char\n",
      "iter 810: loss 0.6455, time 64909.67ms, mfu 1.16%\n",
      "iter 815: loss 0.6376, time 6392.35ms, mfu 1.27%\n",
      "step 820: train loss 0.6009, val loss 0.6513\n",
      "saving checkpoint to out-abc-char\n",
      "iter 820: loss 0.6436, time 64586.73ms, mfu 1.16%\n",
      "iter 825: loss 0.6408, time 6384.60ms, mfu 1.27%\n",
      "step 830: train loss 0.5966, val loss 0.6450\n",
      "saving checkpoint to out-abc-char\n",
      "iter 830: loss 0.6121, time 64785.32ms, mfu 1.16%\n",
      "iter 835: loss 0.6328, time 6369.39ms, mfu 1.27%\n",
      "step 840: train loss 0.5851, val loss 0.6356\n",
      "saving checkpoint to out-abc-char\n",
      "iter 840: loss 0.6183, time 64766.30ms, mfu 1.17%\n",
      "iter 845: loss 0.5970, time 6377.54ms, mfu 1.27%\n",
      "step 850: train loss 0.5796, val loss 0.6256\n",
      "saving checkpoint to out-abc-char\n",
      "iter 850: loss 0.6323, time 64720.63ms, mfu 1.17%\n",
      "iter 855: loss 0.6028, time 6387.13ms, mfu 1.27%\n",
      "step 860: train loss 0.5793, val loss 0.6317\n",
      "iter 860: loss 0.6411, time 64372.58ms, mfu 1.17%\n",
      "iter 865: loss 0.6364, time 6484.23ms, mfu 1.27%\n",
      "step 870: train loss 0.5704, val loss 0.6231\n",
      "saving checkpoint to out-abc-char\n",
      "iter 870: loss 0.5921, time 64941.84ms, mfu 1.16%\n",
      "iter 875: loss 0.5879, time 6500.61ms, mfu 1.27%\n",
      "step 880: train loss 0.5663, val loss 0.6160\n",
      "saving checkpoint to out-abc-char\n",
      "iter 880: loss 0.6312, time 64845.77ms, mfu 1.16%\n",
      "iter 885: loss 0.6169, time 6383.95ms, mfu 1.27%\n",
      "step 890: train loss 0.5621, val loss 0.6147\n",
      "saving checkpoint to out-abc-char\n",
      "iter 890: loss 0.6075, time 64450.19ms, mfu 1.16%\n",
      "iter 895: loss 0.6185, time 6428.78ms, mfu 1.27%\n",
      "step 900: train loss 0.5539, val loss 0.6064\n",
      "saving checkpoint to out-abc-char\n",
      "iter 900: loss 0.5970, time 64953.12ms, mfu 1.16%\n",
      "iter 905: loss 0.6122, time 6394.47ms, mfu 1.27%\n",
      "step 910: train loss 0.5495, val loss 0.6016\n",
      "saving checkpoint to out-abc-char\n",
      "iter 910: loss 0.6203, time 64792.11ms, mfu 1.16%\n",
      "iter 915: loss 0.5667, time 6401.82ms, mfu 1.27%\n",
      "step 920: train loss 0.5438, val loss 0.5970\n",
      "saving checkpoint to out-abc-char\n",
      "iter 920: loss 0.5778, time 64496.53ms, mfu 1.16%\n",
      "iter 925: loss 0.5883, time 6406.71ms, mfu 1.27%\n",
      "step 930: train loss 0.5416, val loss 0.5992\n",
      "iter 930: loss 0.5999, time 64265.03ms, mfu 1.16%\n",
      "iter 935: loss 0.5535, time 6540.60ms, mfu 1.26%\n",
      "step 940: train loss 0.5324, val loss 0.5873\n",
      "saving checkpoint to out-abc-char\n",
      "iter 940: loss 0.5453, time 65095.88ms, mfu 1.16%\n",
      "iter 945: loss 0.5746, time 6394.29ms, mfu 1.27%\n",
      "step 950: train loss 0.5303, val loss 0.5880\n",
      "iter 950: loss 0.5394, time 64689.53ms, mfu 1.16%\n",
      "iter 955: loss 0.5662, time 6434.30ms, mfu 1.27%\n",
      "step 960: train loss 0.5207, val loss 0.5761\n",
      "saving checkpoint to out-abc-char\n",
      "iter 960: loss 0.5818, time 64882.84ms, mfu 1.16%\n",
      "iter 965: loss 0.5154, time 6455.36ms, mfu 1.26%\n",
      "step 970: train loss 0.5242, val loss 0.5794\n",
      "iter 970: loss 0.5675, time 64751.93ms, mfu 1.16%\n",
      "iter 975: loss 0.5701, time 6431.06ms, mfu 1.26%\n",
      "step 980: train loss 0.5110, val loss 0.5676\n",
      "saving checkpoint to out-abc-char\n",
      "iter 980: loss 0.5859, time 64815.98ms, mfu 1.16%\n",
      "iter 985: loss 0.5600, time 6399.16ms, mfu 1.27%\n",
      "step 990: train loss 0.5075, val loss 0.5679\n",
      "iter 990: loss 0.5360, time 64644.46ms, mfu 1.16%\n",
      "iter 995: loss 0.5230, time 6392.38ms, mfu 1.27%\n",
      "step 1000: train loss 0.5069, val loss 0.5642\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1000: loss 0.5290, time 64892.53ms, mfu 1.16%\n",
      "iter 1005: loss 0.5352, time 6412.58ms, mfu 1.27%\n",
      "step 1010: train loss 0.5014, val loss 0.5636\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1010: loss 0.5406, time 65111.19ms, mfu 1.16%\n",
      "iter 1015: loss 0.5349, time 6677.61ms, mfu 1.26%\n",
      "step 1020: train loss 0.5023, val loss 0.5730\n",
      "iter 1020: loss 0.5351, time 67787.71ms, mfu 1.15%\n",
      "iter 1025: loss 0.5346, time 6683.62ms, mfu 1.25%\n",
      "step 1030: train loss 0.4966, val loss 0.5588\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1030: loss 0.5139, time 67320.65ms, mfu 1.15%\n",
      "iter 1035: loss 0.5486, time 6496.46ms, mfu 1.25%\n",
      "step 1040: train loss 0.4898, val loss 0.5549\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1040: loss 0.5218, time 66072.44ms, mfu 1.15%\n",
      "iter 1045: loss 0.5318, time 6516.70ms, mfu 1.25%\n",
      "step 1050: train loss 0.4816, val loss 0.5490\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1050: loss 0.5322, time 65972.39ms, mfu 1.15%\n",
      "iter 1055: loss 0.5008, time 6548.87ms, mfu 1.25%\n",
      "step 1060: train loss 0.4817, val loss 0.5478\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1060: loss 0.5132, time 65972.30ms, mfu 1.15%\n",
      "iter 1065: loss 0.5252, time 6495.27ms, mfu 1.25%\n",
      "step 1070: train loss 0.4801, val loss 0.5493\n",
      "iter 1070: loss 0.5279, time 65710.34ms, mfu 1.15%\n",
      "iter 1075: loss 0.4700, time 6435.49ms, mfu 1.25%\n",
      "step 1080: train loss 0.4756, val loss 0.5425\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1080: loss 0.5061, time 64663.45ms, mfu 1.15%\n",
      "iter 1085: loss 0.4731, time 6668.06ms, mfu 1.25%\n",
      "step 1090: train loss 0.4634, val loss 0.5287\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1090: loss 0.5016, time 64343.76ms, mfu 1.14%\n",
      "iter 1095: loss 0.4943, time 6372.14ms, mfu 1.25%\n",
      "step 1100: train loss 0.4601, val loss 0.5270\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1100: loss 0.4955, time 65530.00ms, mfu 1.15%\n",
      "iter 1105: loss 0.5090, time 6538.87ms, mfu 1.25%\n",
      "step 1110: train loss 0.4597, val loss 0.5276\n",
      "iter 1110: loss 0.5201, time 64323.82ms, mfu 1.15%\n",
      "iter 1115: loss 0.4897, time 6505.38ms, mfu 1.25%\n",
      "step 1120: train loss 0.4557, val loss 0.5287\n",
      "iter 1120: loss 0.4652, time 64981.54ms, mfu 1.15%\n",
      "iter 1125: loss 0.4870, time 6548.18ms, mfu 1.25%\n",
      "step 1130: train loss 0.4492, val loss 0.5210\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1130: loss 0.5013, time 65318.40ms, mfu 1.15%\n",
      "iter 1135: loss 0.4785, time 6496.73ms, mfu 1.25%\n",
      "step 1140: train loss 0.4453, val loss 0.5197\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1140: loss 0.4764, time 65551.39ms, mfu 1.15%\n",
      "iter 1145: loss 0.4730, time 6637.86ms, mfu 1.25%\n",
      "step 1150: train loss 0.4406, val loss 0.5172\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1150: loss 0.4832, time 65134.35ms, mfu 1.14%\n",
      "iter 1155: loss 0.4848, time 6495.01ms, mfu 1.25%\n",
      "step 1160: train loss 0.4391, val loss 0.5171\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1160: loss 0.4888, time 65492.17ms, mfu 1.14%\n",
      "iter 1165: loss 0.4782, time 6626.50ms, mfu 1.24%\n",
      "step 1170: train loss 0.4293, val loss 0.5039\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1170: loss 0.4890, time 66151.78ms, mfu 1.14%\n",
      "iter 1175: loss 0.4484, time 6579.16ms, mfu 1.24%\n",
      "step 1180: train loss 0.4251, val loss 0.5065\n",
      "iter 1180: loss 0.4905, time 66762.08ms, mfu 1.14%\n",
      "iter 1185: loss 0.4719, time 6792.57ms, mfu 1.23%\n",
      "^C\n",
      "Process ForkProcess-9:\n",
      "Process ForkProcess-15:\n",
      "Process ForkProcess-12:\n",
      "Process ForkProcess-14:\n",
      "Process ForkProcess-19:\n",
      "Process ForkProcess-4:\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-10:\n",
      "Process ForkProcess-5:\n",
      "Process ForkProcess-11:\n",
      "Process ForkProcess-1:\n",
      "Process ForkProcess-2:\n",
      "Process ForkProcess-8:\n",
      "Process ForkProcess-17:\n",
      "Process ForkProcess-20:\n",
      "Process ForkProcess-13:\n",
      "Process ForkProcess-18:\n",
      "Process ForkProcess-16:\n",
      "Process ForkProcess-6:\n",
      "Process ForkProcess-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 97, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 253, in <module>\n",
      "    losses = estimate_loss()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"train.py\", line 214, in estimate_loss\n",
      "    losses[k] = loss.item()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 255).\u001b[0m Press Control-C to abort syncing.\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py config/train_abc_char.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test key with most occurrences: G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-abc-char\n",
      "Overriding: start = M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "number of parameters: 8.31M\n",
      "abc_char\n",
      "Loading meta from data/abc_char/meta.pkl...\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "D|\"G\"d/2B/2d/2g/2|\"C\"e/2G/2A/2c/2|\"D\"BA|\"D\"dd/2c/2|\"G\"B/2A/2G/2F/2|\"C\"G/2B/2G/2c/2|\"D\"d/2c/2B/2A/2|\"G\"G3/2A/2|\"C\"G/2E/2G/2c/2|\"D\"B/2A/2B/2A|\"G\"G2|G3/2B/2|\"C\"e/2d/2e/2f/2g/2|\"D\"a/2f/2e/2g/2f/2d/2|\"G\"Bd/2d/2|\"D\"B/2f/2e/2g/2f/2d/2|\"G\"g3/2a/2|\"C\"g/2e/2g/2f/2g/2|\"D\"f/2e/2d/2c/2|\"G\"B/2G/2Ge/2B/2|\"G\"G3|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:C\n",
      "|\"C\"|\"G7\"|\"C\"|\"F\"|\"G7\"|\"C\"|\"C\"|\"F\"|\"G7\"|\"C\"|\"C\"|\"F\"|\"G7\"|\"C\"\"G7\"|\"C\"|\"G\"|\"Am\"\"D7\"|\"G7\"|\"C\"|]\n",
      "c/2B/2|\"C\"cGAG|\"C\"cGAG|\"F\"cAGA|\"G7\"BgBd|\"C\"cGAG|\"C\"cGAG|\"F\"cAGA|\"G7\"BgBd|\"C\"c2\"G7\"c|\"C\"c2c\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "B/2c/2|\"G\"d/2B/2B/2B/2B/2B/2B/2c/2|d/2B/2B/2B/2B/2B/2B/2|\"C\"c/2G/2G/2E/2CB/2A/2|G/2E/2G/2c/2G/2E/2G/2|\"D\"D/2E/2D/2E/2F/2D/2E/2F/2|\"G\"d/2B/2B/2B/2B/2B/2B/2B/2|\"C\"c/2G/2C/2E/2Cc/2G/2|\"D\"D/2E/2D/2E/2D/2E/2F/2|\"G\"G/2B/2B/2B/2B/2B/2B/2B/2|\"C\"c/2G/2C/2E/2Cc/2G/2|E/2G/2CE/2G/2C/2|\"D\"D/2E/2D/2E/2D/2E/2F/2|\"G\"GGGd|\"G\"g/2e/2g/2d/2B/2d/2B/2|\"C\"c/2G/2E/2G/2Cc/2G/2|\"D\"D/2E/2D/2E/2F/2D/2E/2F/2|\"G\"GGG|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:D\n",
      "|\"D\"|\"D\"\"A7\"|\"D\"\"D7\"|\"G\"\"G\"|\"D\"\"A7\"|\"D\"\"A7\"|\"D\"\"A7\"|\"D\"|\"D\"|\"C\"|\"A7\"|\"D\"|]\n",
      "\"D\"DF/2A/2d/2A/\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "D|\"G\"B/2d/2g/2d/2|d/2G|\"C\"c/2ee/2|\"D\"dA3/2A/2|\"G\"B/2d/2g/2d/2|\"C\"c/2ee/2c/2|\"D\"d/2e/2d/2c/2|\"G\"BG3/2|\"G\"gg|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:B\n",
      "|\"B\"|\"F\"|\"C\"|\"F\"|\"B\"|\"B\"|\"C\"|\"F\"|\"B\"|\"F\"|\"B\"|\"C\"|\"B\"|\"C\"|\"F\"|\"B\"|\"C\"|]\n",
      "\"B\"d/4c/4B/2G/4A/4B/2|\"F\"c/2A/4F/2F/2A/2|\"C\"G/2G/2G/2F/2E/2|\"F\"F/2F/2F/2F/2G/2|\"B\"A/4B/4c/2B/2G/4A/4B/4|\"C\"c/2e/2e/2e/2c/2|\"F\"A/2F/2F/2F/2G/2|\"B\"A/4B/4c/2B/2G/2|\"C\"c/2e/2e/2e/2c/2|\"F\"A/4B/4c/2f/2f/2a/2|\"B\"b/2b/2b/2b|\"C\"g/2g/2g/2g/2|\"F\"f/2f/2f/2f/2a/2|\"B\"b/2b/2b/2b/2g/2|\"C\"cc/2c/4c/2c/2|\"F\"A/2F/2F/2F/2\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d/4e/4|\"G\"d/2G/2e/2d/2|e/2G/2g/2|\"C\"g/2ed/2|e/2G/2e/2|\"D\"d/2F/2A/2d/2|\"D\"F/2A/2De/4f/4|\"G\"g/2B/2e/2g/2|\"C\"e/2G/2e/2G/2|\"D\"F/2A/2De/2|\"G\"g/2B/2e/2g/2|\"C\"e/2G/2e/2g/2|\"D\"f/2AG/2A/2|\"G\"G2|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"G\"\"D\"|\"G\"|\"G\"\"D\"|\"G\"|\"G\"|\"G\"\"D\"|\"G\"|\"G\"|\"C\"\"G\"|\"D\"\"G\"|\"B\"|\"B\"\"B\"|\"C\"\"G\"|\"D\"\"G\"|\"Em\"\"D\"|\"G\"\"C\"\"B\"|\"B\"\"B\"|\"B\"|\"C\"\"G\"|\"G\"|]\n",
      "|\"G\"d3/2B/2GB|\"G\"dB\"D\"AF|\"G\"d3/2B/2GB|\"G\"dB\"D\"AF|\"G\"G2G|d|\"G\"de\"D\"fd|\"G\"g3/2b/2gg|\"G\"dBg2|\"C\"eg\"G\"dB|\"D\"de\"G\"fe/2d/2|\"Em\"g3/2b/2\"D\"ab/2|\"Em\"ge\"D\"fd|\"G\"g2/2bg2|\"B\"fd\"B\"e\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "|d/2|\"G\"g/2g/2ge/2g/2|b/2b/2a/2g/2b/2|\"C\"c'a/2g/2a/2|\"D\"d'/2a/2g/2f/2ad|\"D\"d/2e/2f/2\"G\"g/2g/2e/2|\"C\"c'a/2g/2a/2g/2|\"D\"f/2a/2g/2f/2a/2f/2|\"G\"ggg|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:C\n",
      "|\"C\"|\"G\"|\"G7\"|\"G7\"|\"C\"|\"G\"|\"G7\"|\"C\"|\"G\"|\"G\"|\"G7\"|\"C\"|\"G\"|\"C\"|\"Am\"|\"D\"|\"D7\"|\"G\"|\"G\"|\"G\"|\"G\"|\"G\"|\"G\"|\"G7\"|\"C\"|]\n",
      "e/2d/2|\"C\"ce/2c/2G/2c/2e/2|\"G7\"d/2B/2G/2B/2d/2B/2G/2|\"G7\"B/2G/2B/2d/2B/2d/2|\"C\"ce/2c/2G/2c/2e/2|\"G\"d/2B/2G/2B/2d/2B/2G/2|\"G7\"B/2G/2B/2d/2B/2d/2B/2G/2|\"C\"ce/2c/2G/2c/2e/2|\"G\"d/2B/2G/2B/2d/2B/2G/2|\"G7\"B/2G/2B/2d/2B/2d/2B/2G/2|\"C\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d/2|\"G\"g/2d/2g/2d/2e/2d/2|\"C\"e/2e/2e/2d/2\"D\"c/2A/2F/2A/2|\"D\"D/2E/2F/2D/2DG/2A/2|\"G\"B/2d/2g/2d/2e/2d/2B/2d/2|\"C\"e/2e/2e/2d/2e/2d/2c/2B/2|\"D\"A/2A/2F/2Dc/2A/2|\"G\"B/2G/2B/2D/2G/2D/2G/2|\"C\"E/2C/2E/2G/2c/2G/2E/2C/2|\"D\"D/2E/2F/2D/2Dc/2A/2|\"G\"B/2G/2B/2D/2G/2B/2d/2|\"C\"e/2c/2d/2e/2d/2c/2B/2A/2|\"G\"B/2G/2B/2DG/2G/2A/2|\"C\"e/2c/2e/2g/2e/2d/2c/2B/2|\"D\"A/2B/2c/2D|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"G\"|\"G\"|\"G\"|\"G\"|\"G\"|\"G\"\"D7\"|\"G\"|\"G\"|\"G\"|\"G\"|\"D7\"\"G\"|\"G\"|\"G\"|\"G\"|\"D7\"|\"G\"|\"G\"|\"G\"|\"D7\"\"G\"|]\n",
      "d|\"G\"ggb/2a/2g/2e/2|\"G\"dd/2e/2dB|\"\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "B/2c/2|\"G\"d/2B/2GB/2f/2|\"C\"g/2e/2ce/2g/2e/2|\"D\"fdf/2e/2|\"G\"d/2B/2GB/2g/2|\"D\"fa\"G\"ge/2d/2|\"C\"e/2g/2e/2ce/2g/2|\"D\"f/2d/2B/2A/2\"G\"G2|\"G\"b/2g/2g/2db/2g/2|\"C\"e/2g/2e/2ce/2g/2e/2|\"D\"d/2c/2B/2A/2\"G\"G2|]\n",
      "\n",
      "M:6/8\n",
      "L:1/8\n",
      "K:D\n",
      "|\"D\"|\"D\"\"G\"|\"D\"\"A\"|\"D\"\"G\"|\"D\"\"A\"|\"D\"\"G\"|\"D\"\"A\"|\"D\"\"G\"|\"D\"\"A\"|\"D\"\"G\"|\"D\"\"Em\"|\"D\"\"G\"|\"D\"\"A\"|\"D\"\"G\"|\"D\"\"G\"|\"D\"\"G\"|\"D\"\"Bm\"\"Em\"|\"Em\"\"\"A\"|\"D\"\"G\"|\"D\"\"G\"|\"D\"\"A\"|\"D\"\"G\"|]\n",
      "a|\"D\"dfaa2a|\"D\"dfa\"G\"bd'c'|\"D\"baf\"A\"ecA|\"D\"def\"G\"gab|\"D\"dfaa2a|\"G\"bd'b\"A\"abc'|\"D\"\"G\"baf\"A\"ecA|\"D\"d2f\"G\"g2a|\"D\"dfa\"G\"bgb|\"D\"d\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "\"G\"g/2d/2B/2|\"C\"c/2B/2A/2G/2|E/2G/2A/2G/2|\"D\"F/2A/2D/2F/2|\"D\"A/2B/2A/2G/2|\"G\"E/2d/2G/2B/2|\"C\"c/2B/2A/2c/2|\"D\"B/2c/2A/2F/2|\"G\"G2|\"G\"Gd3/2B/2|\"C\"Gc3/2B/2|\"D\"AfA|\"G\"Gd3/2B/2|\"C\"Gce3/2B/2|\"D\"Afd|\"G\"G2|]\n",
      "\n",
      "M:2/2\n",
      "L:1/8\n",
      "K:G\n",
      "|\"G\"|\"G\"|\"G\"|\"Am\"\"D\"|\"G\"|\"G\"\"D\"|\"G\"|\"G\"\"D\"|\"G\"|\"G\"|\"C\"|\"D\"|\"G\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "\"G\"D/2G/2B/2d3/2d/2|\"G\"b/2g/2d/2B/2d3/2g/2|\"Am\"a/2ge/2\"D\"d/2e/2c/2A/2|\"G\"D/2G/2B/2d3/2d/2|\"G\"b/2g/2d/2B/2d3/2g/2|\"Am\"a/2ge\"D\"de/2c/2|\"G\"dBG2|\"G\"gg\"D\"faa|\"G\"b/2g/2d/2B/2d3/2g/2|\"C\"egde/2c/2|\"D\"B/2c/2A/2F\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "G/2|\"G\"d/2B/2g/2a/2|g/2B/2g/2|\"C\"e/2g/2e/2g/2f/2|e/2G(3G/2A/2B/2|\"D\"c/2A/2d/2e/2f/2|\"D\"d/2B/2A/2G/2|\"G\"d/2B/2G/2B/2d/2|\"C\"e/2G/2e/2g/2f/2e/2|\"D\"d/2B/2A/2G/2A/2G/2|\"G\"d/2B/2G/2B/2d/2|\"C\"e/2g/2e/2\"D7\"d/2B/2G/2|\"G\"ggg|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:D\n",
      "|\"D\"\"G\"|\"D\"\"A7\"|\"D\"\"G\"|\"A7\"\"D\"|\"D\"\"A7\"|\"D\"\"G\"|\"D\"\"A7\"|\"D\"\"A7\"|\"D\"|\"D\"\"A7\"|\"D\"\"A7\"|\"D\"\"A7\"|\"D\"\"A7\"|\"D\"\"A7\"|\"D\"\"A7\"|\"D\"\"G\"|\"Bm\"\"A7\"|\"D\"|]\n",
      "F/2G/2|\"D\"A/2F/2D/2F/2\"G\"G/2B/2G/2B/2|\"D\"A/2F/2D/2F/2\"A7\"D/2F/2G/2A/2|\"D\"d/2B/2A/2F/2\"G\"G/2B/2d/2B/2|\"A7\"A/2F/2E/2C/2\"D\"D|\"D\"A/2F\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "\"G\"GG/2A/2B/2c/2|d/2B/2d/2g/2|\"C\"_c/2G/2E/2c/2e/2d/2|\"D\"c/2B/2A/2F/2A/2A/2|d/2B/2A/2F/2A/2d/2|\"G\"GG/2A/2B/2c/2|d/2B/2d/2g/2f/2|\"C\"e/2d/2B/2c/2_c/2e/2d/2|\"C\"c/2G/2_E/2c/2e/2d/2|\"D\"c/2B/2A/2F/2A/2d/2B/2|\"G\"GG/2B/2d/2g/2f/2|\"C\"e/2d/2B/2ce/2d/2|\"D\"c/2B/2A/2F/2A/2d/2B/2|\"G\"GBG|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:D\n",
      "|\"D\"|\"G\"|\"D\"\"A\"|\"D\"|\"D\"|\"Em\"\"A7\"|\"D\"|\"G\"\"A\"|\"D\"\"A\"|\"D\"\"G\"|\"D\"|\"G\"|\"G\"|\"G\"\"C\"|\"G\"\"D\"|\"C\"\"G\"|\"G\"\"C\"|\"G\"\"D\"|\"G\"\"D7\"|\"G\"|]\n",
      "E|\"D\"F/2A/2A/2F/2d3/2c/2|\"G\"B/2d/2g/2e/2d/2B/2d/2B/2G/2|\"D\"F/2A/2A/2F/2D/2\"A\"E/2E/2G/2E/\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start='M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test major key with low samples: C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-abc-char\n",
      "Overriding: start = M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "number of parameters: 8.31M\n",
      "abc_char\n",
      "Loading meta from data/abc_char/meta.pkl...\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "GF|\"C\"E2EE|\"F\"F2A3/2A/2|\"G\"BGGA|\"C\"AGGA|\"C\"cccd/2e/2|\"F\"fAGF|\"G\"GBGA|\"C\"cc3|\"F\"cde|\"G\"dg/2e/2f/2e/2d/2|\"C\"c2c3/2e/2|\"F\"fAGF|\"G\"GBGA|\"C\"ccc|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:C\n",
      "|\"C\"|\"G7\"|\"C\"|\"G7\"|\"C\"|\"G7\"|\"C\"|\"C\"|\"C\"|\"G7\"|\"C\"|\"G7\"|\"C\"|\"C\"|\"C\"|\"F\"|\"G7\"|\"C\"|]\n",
      "e/2f/2|\"C\"gec|\"G7\"Bd/2e/2d/2c/2|\"C\"cec|\"G7\"dBe/2f/2|\"C\"gec|\"G7\"Bd/2e/2d/2c/2|\"C\"c2c|e/2f/2|\"C\"gecf/2g/2|\"C\"gecd/2e/2|\"G7\"gg/2g/2f/2e/2|\"C\"gecd/2e/2|\"G7\"gG/2A/2B/2d/2c/2|\"C\"c2c2|\"C\"gecf/2g/2|\"C\"c'ecc/2g/2|\"F\"c'ecd/2e/2|\"G7\"fdBd|\"C\"c2c|]\n",
      "\n",
      "M:2/2\n",
      "L:1/8\n",
      "K:G\n",
      "|\"G\"|\"G\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "G/2|\"C\"c/2c/2c/4A/4|G/2c/2|\"F\"F/2d/2c/2|c3/4B/4A/2G/2|\"G\"G/2A/2B/2|\"C\"c/2G/2A/2|G3/2|\"F\"F/2A/2c/2|\"G\"B3/4A/4G/2G/2|\"C\"c/2c/4A/2G/2|\"F\"A/2c/2f/2|e/2d/2c/2|\"G\"B/2d/2B/2|\"C\"c/2G/2A/2G/2|\"F\"F/2A/2c/2|\"G\"B/2d/2B/2G/2|\"C\"c/2e/2G/2c/2|\"F\"f/2e/2d/2c/2|\"G\"B3/2A/2G/2|\"C\"G/2c/2e/2g/2|\"F\"f/2e/2d/2c/2|\"G\"B/2d/2B/2G/2|\"F\"A/2c/2\"G\"B/2d/2|\"C\"c2|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:C\n",
      "|\"C\"|\"C\"|\"G\"|\"C\"|\"G\"|\"C\"|\"C\"|\"G\"|\"C\"\"G\"|\"C\"|\"D\"\"G\"|\"C\"|\"G\"\"C\"|\"G\"|\"C\"\"G\"|\"C\"|]\n",
      "E/2F/2|\"C\"GEc3/2e/2|\"C\"gece|\"G\"dBGe/2f/2|\"C\"gece/2f/2|\"G\"gBGBe/2f/2|\"C\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "\"F\"C/2C/2\"G\"D/2E/2F/2|\"G\"G/2A/2GB/2A/2G/2|\"C\"G/2c/2e/2d/2e/2c/2|\"F\"A/2G/2F/2A/2c/2d/2c/2A/2|\"G\"G/2A/2GB/2\"C\"c/2G/2E/2G/2|\"F\"A/2G/2F/2A/2c/2d/2c/2A/2|\"G\"G/2A/2GB/2G/2A/2G/2|\"C\"G/2E/2G/2C|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:F#\n",
      "|\"F\"\"C7\"|\"F\"|\"B\"\"F\"|\"Gm\"\"C7\"|\"F\"\"C7\"|\"F\"|\"Gm\"|\"Gm\"\"C7\"|\"F\"|\"F\"|\"C\"|\"Gm\"\"C7\"|\"F\"|]\n",
      "c|\"F\"c3/2A/2\"C7\"GA/2B/2|\"F\"cc3/2A/2\"C7\"GA/2B/2|\"F\"c3/2A/2\"C7\"GA/2G/2|\"F\"F/2E/2F/2G/2A/2\"C7\"GA/2B/2|\"F\"c3/2A/2\"C7\"GA/2G/2|\"F\"FF|c|\"F\"f3/2e/2\"C7\"de|\"F\"f3/2e/2fc|\"C\"g3/2e/2cc|\"Gm\"BBe/2d/2c/2B/2A/2|\"Gm\"GG\"C7\"EA/2G/2\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "c/4d/4|\"C\"e/2G/2e/2c/2|e/2G/2g/2|\"F\"f/2FA/2c/2|f/2F/2f/2^d/2|\"G\"B/2G/2d/2f|\"G\"e/2G/2B/2e/2|\"C\"G/2e/2c/2e/2|e/2G/2g/2|\"F\"f/2Fe/4f/4|\"G\"g/2fe/2|\"G\"d/2B/2\"C\"c|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"C\"|\"C\"|\"G\"\"B\"|\"Am\"\"D7\"|\"G\"|\"C\"|\"G\"\"C\"|\"G\"\"D7\"|\"G\"|\"G\"|\"G\"\"C\"|\"G\"\"D7\"|\"G\"|]\n",
      "D|\"G\"G3/4A/2G/2|\"C\"E/2G/2c/2e/2|\"G\"d/2B/2\"B\"A/2G/2|\"Am\"A/2G/2\"D7\"F/2A/2|\"G\"G3/2d/2g/2|\"C\"e/2g/2g/2e/2|\"G\"g/2e/2\"C\"G/2e/2g/2|\"G\"d/2B/2\"C\"A/2G/2E/2|\"G\"G2\"D7\"D2|\"G\"B3/2d/2g/2|\"G\"f/2e/2d/2\"C\"e/2d/2g/2|\"G\"d/2B/2\"D7\"A/2G/2E/2|\"G\"G3/2|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "|\"C\"E/2G/2A/2G/2e/2c/2G/2|\"F\"F/2A/2F/2A/2F/2A/2|\"G\"G/2^F/2G/2A/2G/2B/2d/2|\"G\"g/2d/2c/2e/2d/2B/2G/2|\"C\"E/2G/2A/2G/2e/2c/2G/2|\"F\"F/2A/2G/2F/2A/2c/2d/2|\"G\"G/2^F/2G/2A/2B/2d/2|\"C\"e/2g/2a/2g/2e/2g/2e/2g/2|\"F\"f/2a/2g/2f/2a/2f/2a/2|\"G\"g/2^f/2g/2d/2e/2d/2B/2G/2|\"C\"cg/2a/2g/2e/2g/2e/2g/2|\"F\"f/2a/2b/2c'/2\"G\"b/2g/2a/2b/2|\"C\"c'/2b/2c'/2g/2e/2g/2e/2g/2|\"F\"fa/2g/2f/2a/2f/2a/2|\"G\"g/2^f/2g/2d/2e/2d/2B/2G/2|\"C\"E/2G/2A/2G/2E/2G/2e/2c/2|\"F\"F/2A/2G/2F/2A/2c/2d/2|\"G\"G/2^F/2G/2A/2B/2d/2|\"C\"e/2g/2a/2g/2e/2g/2e/2g/2|\"\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "c/2B/2|\"C\"c/2c/2G/2e/2|\"F\"f/2e/2d/2e/2d/2c/2|\"G\"d/2GA/2B/2G/2B/2|\"G\"G/2B/2d/2B/2G/2B/2d/2|\"C\"e/2c/2G/2e/2c/2e/2c/2|\"F\"A/2B/2A/2B/2c/2A/2|\"G\"G/2B/2d/2B/2G/2B/2d/2|\"C\"e/2c/2G/2e/2c/2e/2c/2|\"F\"A/2B/2c/2A/2B/2c/2A/2|\"G\"G/2B/2d/2B/2G/2B/2d/2|\"C\"e/2c/2G/2e/2c/2e/2c/2|\"F\"A/2B/2A/2B/2c/2A/2B/2|\"G\"G/2B/2d/2B/2G/2B/2d/2|\"C\"e/2c/2G/2e/2c/2e/2c/2|\"F\"A/2B/2A/2B/2c/2A/2|\"G\"G/2B/2d/2B/2G/2B/2d/2|\"C\"e/2c/2G/2e/2c/2e/2c/2g/2|\"G\"g/2f/2e/2d/2B/2d/2g/2|\"C\"e/2c/2G/2e/2c/2e/2c/2g/2|\"F\"A/2B/2A/2B/2c/2f/2A/2|\"G\"g/2f/2\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "G/2|\"C\"c/4d/4e/4c/2g/2|e/2G/2c/2e/2|\"F\"f/4d/4c/4d/2c/2|\"G\"B/2G/2d/2|B/2G/2d/2|\"G\"B/2G/2d/2|\"C\"e/2G/2c/2e/2|\"F\"f/4e/4d/4e/4c/2|\"G\"B/2G/2d/2|B/2G/2d/2|\"C\"e/2G/2c/2e/2|\"F\"f/4e/4d/4e/4c/2|\"G\"B/2G/2\"C\"c|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:C\n",
      "|\"C\"\"G7\"|\"C\"\"G7\"|\"C\"\"G7\"|\"C\"|\"F\"\"G7\"|\"C\"\"C\"|\"F\"\"G7\"|\"C\"|\"F\"\"G7\"|\"C\"\"F\"|\"C\"\"G7\"|\"C\"\"F\"|\"C\"\"G7\"|\"C\"\"G7\"|\"C\"\"F\"|\"C\"\"G7\"|\"C\"\"F\"|\"C\"\"F\"|\"C\"\"G7\"|\"C\"\"F\"|]\n",
      "\"C\"C/2E/2G/2E/2G/2\"G7\"G/2A/2B/2G/2|\"C\"C/2E/2G/2E/2G/2\"G7\"G/2A/2B/2G/2|\"C\"C/2E/2G/2E/2G/2\"G7\"G/2A/2B/2G/2|\"C\"C/2E/2G/2E/2G/2E/2G/2G/2|\"\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "ccd|\"C\"e/2ge/2gg/2e/2|g/2g/2e/2d/2c/2d/2e/2|\"F\"f/2f/2d/2f/2a/2f/2|\"G\"e3/2B/2d/2f/2|\"C\"e/2g/2e/2gg/2e/2|g/2e/2g/2e/2d/2e/2d/2|\"D\"A/2f/2d/2a/2f/2d/2e/2|f/2d/2f/2a/2f/2e/2d/2|\"G\"B/2G/2G/2D/2B/2G/2A/2B/2|\"C\"c/2G/2E/2G/2cc/2e/2|\"F\"f/2A/2c/2\"G\"B/2G/2A/2B/2|\"C\"ccc|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:Bb\n",
      "|\"B\"|\"Cm\"|\"F\"|\"B\"|\"Cm\"\"F7\"|\"B\"|\"Cm\"|\"F\"|\"F\"|\"B\"|\"Cm\"\"F7\"|\"B\"|\"Cm\"\"F7\"|\"E\"|\"F\"\"F7\"|\"E\"|\"B\"|\"Cm\"\"F7\"|\"B\"|]\n",
      "\"B\"B/2G/2F/2D/2B,/2D/2F/2|\"Cm\"GCCC/2D/2|\"F\"FF/2A/2cc/2|\"B\"d/2B/2c/2A/2B/2d/2c/2B/2|\"Cm\"AG\"F7\"FF/2G/2|\"B\"B/2G/2F/2D/2\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "GA|\"C\"G3/2A/2|GG|\"F\"A/2G/2F/2E/2G/2D/2|\"G\"G3/2F/2E/2D/2|\"G\"G/2A/2B/2c/2B/2c/2d/2|\"C\"e/2d/2c/2B/2G/2E/2G/2|\"F\"A/2G/2F/2E/2G/2D/2F/2|\"G\"G/2A/2B/2GB/2c/2|\"G\"d/2c/2B/2\"C\"ce/2f/2|\"C\"g/2f/2e/2f/2g/2e/2|\"F\"f/2e/2d/2e/2f/2c/2e/2|\"G\"d/2c/2B/2G/2B/2c/2d/2|\"C\"e/2c/2e/2g/2e/2c/2e/2|\"C\"g/2f/2e/2f/2g/2e/2c/2|\"F\"f/2e/2d/2e/2f/2c/2e/2|\"G\"d/2B/2c/2d/2B/2G/2B/2|\"C\"cece/2f/2|\"C\"g/2f/2e/2f/2g/2e/2d/2|\"F\"f/2e/2d/2e/2f/2c/2e/2|\"G\"d/2B/2c/2d/2\"C\"e/2c/2e/2f/2|\"C\"g/2f/2e/2f/2g/2e/2c/2e/2|\"F\"f/2e/2d/2e/2f/2c/2e/2|\"G\"d/2\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "\"C\"GG/2c/2|\"F\"cA/2c/2c/2|\"G\"B/2GG/2B/2|\"C\"ce/2d/2c/2|\"F\"cA/2c/2c/2|\"G\"B/2GG/2B/2|\"G\"d/2f/2d/2B/2|\"C\"ce/2f/2e/2|\"F\"ff/2e/2d/2|\"G\"B/2GG/2B/2|\"C\"ce/2d/2c/2|\"F\"AA/2c/2c/2|\"G\"B/2G/2GG/2B/2|\"C\"ce/2d/2c/2|\"F\"ff/2e/2d/2|\"G\"B/2G/2GG/2B/2|\"C\"cee/2d/2c/2|\"F\"cA/2c/2c/2|\"G\"B/2G/2B/2\"G\"G/2B/2d/2|\"C\"ce/2f/2e/2d/2c/2|\"F\"A/2c/2A/2c/2d/2c/2|\"G\"B/2G/2GG/2B/2|\"C\"ce/2d/2c/2G/2B/2|\"F\"AA/2c/2c/2c/2|\"G\"B/2G/2G/2B/2\"G\"G/2B/2d/2d/2|\"C\"ce/2f/2e/2d/2c/2|\"F\"A/2c/2f/2e/2d/2|\"G\"B/2G/2G/2B/2\"G\"G/2B/2d/2g/2|\"C\"ce/2d/2c/2G/2B/2\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start='M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test minor key with low samples: Am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-abc-char\n",
      "Overriding: start = M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "number of parameters: 8.31M\n",
      "abc_char\n",
      "Loading meta from data/abc_char/meta.pkl...\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "A|\"Am\"A/2B/2A/2B/2A/2B/2|c/2B/2A/2B/2A/2B/2c/2|\"Dm\"d/2e/2d/2e/2d/2B/2A/2|\"E\"^G/2A/2B/2G/2Ee/2d/2|\"Am\"e/2e/2A/2B/2A/2B/2c/2d/2|\"G\"e/2d/2B/2G/2E/2G/2A/2B/2|\"Am\"c/2B/2A/2\"Dm\"F/2A/2A|\"E\"G/2B/2c/2B/2E/2G/2B/2|\"Am\"c/2A/2B/2G/2A/2B/2c/2B/2|\"Dm\"AF/2A/2\"Dm\"A|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:C\n",
      "|\"C\"|\"C\"|\"Dm\"\"G7\"|\"C\"|\"C\"|\"Dm\"\"G7\"|\"C\"|\"C\"|\"C\"\"G7\"|\"C\"|\"C\"\"G7\"|\"C\"|\"F\"\"G7\"|\"C\"\"G7\"|\"C\"|\"C\"|\"G7\"|\"C\"|\"C\"|\"Dm\"\"G7\"|\"C\"|]\n",
      "D|\"C\"CC/2C/2C/2E/2G/2c/2|\"C\"c/2G/2c/2d/2e/2g/2f/2e/2|\"Dm\"d/2c/2B/2A/2\"G7\"GD/2D/2|\"C\"CCC/2C/2E/2G/2c/2|\"C\"c/2G/2\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "\"Am\"eAA/2B/2|\"Dm\"AA/2B/2A/2B/2|\"E\"G/2F/2E/2D/2E/2F/2|\"Am\"GEEC|\"Dm\"D2E3/2F/2|\"E\"G/2F/2E/2D/2E/2F/2|\"E\"E3/2C/2B,/2A,/2G,/2|\"Am\"A,3/2C/2B,B,/2|\"Dm\"A,3/2F/2F/2E/2D/2|\"E\"^G3/2E/2G/2F/2E/2|\"Am\"A,3/2C/2B,B,|\"Dm\"A,3/2F/2FE/2D/2|\"E\"^G3/2E/2G/2F/2E/2D/2|\"Am\"A,3/2C/2B,B,|\"Dm\"A,3/2F/2F/2E/2D/2|\"E\"^G3/2E/2G/2F/2E/2D/2|\"Am\"C3/2C/2B,B,|\"Am\"A,3/2C/2EB,|\"Am\"A,3/2C/2B,B,|\"E\"=G,3/2C/2B,B,|\"Am\"A,3/2C/2B,B,|\"Am\"A,3/2C/2B,B,|\"Am\"A,3/2C/2B,B,|\"Am\"A,3|]\n",
      "\n",
      "M:2/4\n",
      "L:1/4\n",
      "K:B\n",
      "|\"B\"|\"B\"|\"Cm\"\"F7\"|\"B\"|\"B\"|\"Cm\"\"F7\"|\"B\"|\"B\"|\"B\"|\"\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "A/2B/2|\"Am\"e/2A/2e/2AB/2c/2|d/2c/2B/2A/2B/2c/2d/2|\"E\"e/2G/2E/2G/2B/2E/2G/2|\"E\"E/2G/2B/2G/2EB/2A/2|\"Am\"c/2A/2e/2A/2\"E\"B/2G/2E/2G/2|\"Am\"AAA|e/2f/2|\"Am\"g/2e/2a/2b/2a/2g/2e/2|\"Dm\"f/2de/2f/2a/2f/2d/2|\"E\"e/2^d/2e/2f/2g/2e/2f/2|\"Am\"g/2e/2a/2b/2a/2g/2e/2|\"Dm\"f/2de/2f/2a/2f/2d/2|\"E\"e/2^d/2e/2f/2g/2e/2f/2|\"Am\"g/2e/2a/2b/2a/2g/2e/2|\"Dm\"f/2de/2f/2a/2f/2d/2|\"E\"e/2^d/2e/2f/2g/2e/2f/2|\"Am\"g/2e/2a/2b/2a/2g/2e/2|\"Dm\"f/2de/2f/2g/2e/2f/2d/2|\"E\"e/2^d/2e/2f/2g/2e/2f/2g/2|\"Am\"aage|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:C\n",
      "|\"c\"|\"G7\"|\"c\"|\"c\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "\"Am\"A/2A/2A/2c/2|A/2B/2c|\"Dm\"d/2e/2f/2e/2f/2g/2f/2|\"E\"e/2d/2c/2B/2B/2A/2|\"E\"^G/2E/2G/2Be/2f/2|\"Am\"e/2d/2c/2B/2\"Dm\"A/2F/2D|\"G\"G3|B/2c/2|\"B\"B3/2d/2Bd/2e/2|\"B\"f3/2d/2Bd/2e/2|\"B\"f3/2d/2Bd|\"E\"f3e/2e/2|\"Am\"A3A/2B/2|\"Dm\"A3/2B/2Ad/2e/2|\"E\"^G3/2B/2^Gd/2e/2|\"Am\"f/2e/2d/2c/2\"Dm\"BA/2F/2|\"G\"G3|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:D\n",
      "|\"D\"\"A7\"|\"D\"|\"G\"\"D\"|\"A7\"\"D\"|\"D\"|\"A7\"\"D\"|\"D\"|\"D\"|\"D\"|\"A7\"\"D\"|\"D\"|\"G\"|\"D\"|\"A7\"\"D\"|]\n",
      "A|\"D\"d/2e/2d/2e/2\"A7\"f/2g/2e/2c/2|\"D\"d/2e/2f/2g/2\"A7\"aA/2B/2|\"D\"d/2e/2d/2e/2\"A7\"f/2g/2e/2c/2|\"D\"d/2e/2f/2g/2a/2f/2e/\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "\"Am\"A/2B/2c/2B/2GF/2E/2|\"Dm\"D/2E/2F/2E/2DA,/2B,/2|\"E\"EEE/2F/2G/2F/2E/2|\"E\"D/2EB,/2EE/2F/2G/2|\"Am\"A/2B/2c/2B/2G/2\"Dm\"AD|\"Dm\"AAA/2B/2A/2F/2|\"E\"^G/2E/2E/2G/2B/2G/2B/2G/2|\"Am\"A/2B/2c/2B/2G/2AE/2F/2E/2|\"Dm\"DAA/2B/2A/2F/2|\"E\"^G/2E/2E/2G/2B/2G/2B/2G/2|\"Am\"A/2B/2c/2d/2e/2f/2g/2e/2|\"Dm\"f/2e/2d/2c/2\"Dm\"dD|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"G\"|\"G\"|\"A\"|\"Am\"|\"Am\"|\"D\"|\"G\"|\"G\"|\"G\"|\"Am\"|\"D\"|\"D\"|\"G\"|\"G\"|\"G\"|\"Am\"|\"D\"|\"G\"|]\n",
      "G/2F/2|\"G\"G/2A/2B/2c/2d/2e/2d/2|\"G\"B/2G/2B/2d/2g/2e/2d/2|\"G\"B/2g/2d/2B/2G/2B/2d/2|\"A\"^c/2e/2A/2AB/2c\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "\"Am\"aa/2e/2f/2e/2d/2e/2|f/2e/2c/2B/2A/2c/2e/2|\"Dm\"dd/2d/2e/2f/2e/2d/2|\"E\"e/2^d/2e/2f/2g/2f/2e/2=c/2|\"Am\"A/2A/2A/2B/2c/2e/2|\"Dm\"dd/2d/2e/2f/2e/2d/2|\"E\"e/2^d/2e/2f/2g/2f/2e/2=c/2|\"Am\"AAA/2B/2c/2e/2|\"Dm\"d/2d/2d/2e/2f/2e/2d/2|\"E\"e/2^d/2e/2f/2g/2f/2e/2=c/2|\"Am\"AAA/2B/2c/2e/2|\"Dm\"d/2d/2d/2e/2f/2e/2d/2|\"E\"e/2^d/2e/2f/2g/2f/2e/2|\"Am\"AAA|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:Ab\n",
      "|\"A\"|\"E7\"|\"A\"|\"A\"|\"E7\"|\"E7\"|\"A\"|\"E7\"|\"A\"|\"A\"|\"E7\"|\"E\"\"E7\"|\"A\"|\"A\"|\"E7\"|\"A\"|\"A7\"|\"D\"|\"Bm\"|\"Bm\"|\"E7\"|\"A\"|\"E7\"|\"A\"|\"A\"|\"E7\"|\"A\"|]\n",
      "ed|\"A\"ce3/2c/2|BAcA|\"\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "A/2B/2|\"Am\"cc/2c/2c/2c/2e/2|\"Dm\"d/2d/2d/2dd/2d/2|\"Am\"e/2e/2e/2e/2f/2e/2e/2d/2|\"E\"B/2B/2B/2G/2EA/2B/2|\"Am\"c/2B/2c/2d/2e/2f/2e/2d/2|\"Am\"\"E\"c/2B/2c/2d/2e/2c/2A/2B/2|\"Am\"c/2A/2c/2B/2\"Dm\"A|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"\"D7\"|\"G\"|\"C\"\"D7\"|\"G\"\"D7\"|\"G\"\"D7\"|\"G\"\"C\"|\"G\"|\"G\"\"D7\"|\"G\"|\"C\"|\"G\"|\"G\"\"D7\"|\"G\"\"D7\"|\"G\"|\"C\"|\"G\"\"D7\"|\"G\"\"D7\"|\"G\"\"D7\"|\"G\"|]\n",
      "(3D/2E/2F/2|\"G\"GG/2B/2\"D7\"AA/2G/2|\"G\"EG/2B/2\"D7\"AA/2G/2|\"G\"F/2G/2B/2d/2\"D7\"AA/2G/2|\"G\"B/2c/2B/2d/2\"C\"e/2d/2c/2e/2|\"G\"d/2B/2G/2B/2\"D7\"AA/2G/2|\"G\"EG/2B/2\"C\"c/2d/2e/2c/2|\"G\"B/2c\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "\"Am\"A3/4B/4^c/2d/2e/2f/2|\"E\"e/2g/2e/2B/2B/2g/2|e/2B/2e/2B/2g/2e/2|\"Am\"A/2B/2A/2\"Dm\"A/2f/2e/2|\"E\"e/2g/2f/2e/2B/2G/2|\"Am\"AAA/2B/2|\"Dm\"A/2A/2A/2B/2A/2B/2|\"E\"d/2B/2B/2G/2B/2B/2|\"Am\"AA/2B/2A/2B/2|\"Dm\"A/2A/2A/2B/2A/2B/2|\"E\"G/2A/2G/2E/2G/2B/2|\"Am\"c/2B/2A/2\"Dm\"A|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"G\"|\"Am\"\"D7\"|\"G\"|\"G\"|\"G\"|\"Am\"\"D7\"|\"G\"|\"G\"\"D7\"|\"G\"\"D7\"|\"G\"|\"Am\"\"D7\"|\"G\"\"D7\"|\"G\"|\"G\"|\"Em\"|\"Am\"\"D7\"|\"G\"|\"G\"|\"G\"|\"Em\"|\"Am\"\"D7\"|\"G\"\"D7\"|\"G\"|\"G\"|\"G\"\"D7\"|\"G\"|]\n",
      "G/2A/2|\"G\"BB/2G/2A/2B/2c/2|\"G\"dd/2B/2GG/2A/2|\"Am\"B/2A/2G/2F/2\"D7\"GG\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "|e/2|\"Am\"e/2A/2B/2d/2e3/2|\"Dm\"d/2A/2B/2g/2f/2e/2d/2c/2B/2|\"E\"G/2A/2B/2G/2e/2B/2G/2|\"E\"B/2G/2E/2B/2e3/2B/2|\"Am\"A/2e/2A/2B/2d/2e/2|\"Dm\"ddd/2e/2|\"E\"f/2d/2e/2c/2B/2c/2B/2|\"Am\"A2A|e/2|\"Dm\"f/2d/2a/2d/2b/2a/2f/2d/2|\"E\"e/2^d/2e/2f/2g/2f/2e/2d/2|\"Am\"e/2A/2c/2e3/2f/2|\"Am\"\"E\"e/2^d/2e/2f/2g/2f/2e/2d/2c/2B/2|\"Am\"A2A2e/2f/2|\"Am\"g/2e/2A/2c/2\"G\"B/2c/2d/2B/2|\"E\"G/2E/2G/2B/2ee/2B/2G/2|\"Am\"A2A2|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:E\n",
      "|\"E\"|\"A\"|\"B7\"|\"E\"|\"E\"|\"A\"|\"B7\"|\"E\"|\"A\"\"B7\"|\"E\"|\"A\"|\"B7\"|\"E\"|\"E\"|\"A\"|\"B7\"|\"E\"|]\n",
      "(3B/2c/2d/2|\"E\"e/2g/2e\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "c/2d/2|\"Am\"e/2a/2a/2g/2e/2a/2g/2|\"Dm\"f/2dd/2a/2d/2g/2e/2|\"E\"=f/2e/2f/2g/2e/2a/2g/2e/2|\"E\"^f/2e/2f/2g/2e/2=f/2e/2|\"Am\"c/2e/2a/2g/2e/2a/2g/2|\"Dm\"f/2dd/2a/2d/2g/2e/2|\"E\"^f/2e/2f/2g/2e/2B/2=c/2|\"Am\"\"E\"e/2c/2A/2G/2A|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:B\n",
      "|\"B\"|\"B\"|\"B\"|\"E\"|\"B\"|\"cm\"\"F7\"|\"B\"|\"B\"|\"B\"|\"cm\"\"F7\"|\"B\"|\"B\"|\"cm\"\"F7\"|\"B\"|]\n",
      "d/2e/2|\"B\"f/2d/2d/2d/2f/2d/2|\"B\"B/2d/2d/2d/2f/2d/2d/2|\"E\"e/2d/2e/2f/2g/2a/2b/2d'/2|\"B\"bd/2d/2d/2f/2d/2|\"cm\"e/2d/2c/2B/2\"F7\"c/2e/2f/2g/2|\"B\"a/2g/2f/2d/2f/2d/2f/2d/2|\"B\"Bd/2B/2d/2f/2d/2d/2|\"B\"b/2a/\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start='M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test older checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = older_ckpt/m_voices\n",
      "Overriding: path_meta = older_ckpt/m_voices\n",
      "Overriding: start = M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "number of parameters: 14.18M\n",
      "shakespeare_char\n",
      "Loading meta from older_ckpt/m_voices/meta.pkl...\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]G/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]G/2E\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d2|\"G\"B3/2g/2d3/2B/2G3/2B/2d3/2B/2|\"D\"c3/2e/2a3/2g/2f3/2d/2e3/2f/2|\"G\"B3/2g/2d3/2B/2g3/2d/2B3/2d/2|\"D\"c3/2A/2d3/2A/2e3/2A/2f3/2A/2|\"G\"g3/2d/2B3/2d/2g3/2b/2a3/2g/2|\"D\"f3/2d/2A3/2d/2f3/2a/2g3/2f/2|\"C\"e3/2d/2c3/2B/2\"D\"c3/2e/2d3/2c/2|\"G\"B2G2G2d2|\"D\"ADBDcDdc|\"G\"BGcG^cGdG|\"D\"ADBDcDd2|\"G\"edd^cd4|\"D\"ADBDcDdc|\"G\"BGcG^cGd2|\"C\"ecgc\"D\"fcac|\"G\"g2b2g4|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:Eb\n",
      "|\"D\"|\"G\"\"A\"|\"D\"|\"Em\"\"A\"|\"D\"|\"G\"\"A\"|\"G\"\"A\"|\"D\"|\"G\"\"D\"|\"G\"\"D\"|\"G\"\"D\"|\"E\"\"A\"|\"G\"\"D\"|\"G\"\"D\"|\"G\"\"D\"|\"E\"\"A\"|\"A\"\"D\"|]\n",
      "A/2|\"D\"d/2c/2d/2e/2fA|\"G\"Be\"\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2f/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d2|\"G\"G/2B/2d3/4d/4|\"C\"e/2e/2c/2A/2|\"D\"F/2A/2D/2|\"D\"F/2A/2D/2d/2|\"D\"=c/2d/2A/2^G/2A/2|\"G\"B/2G/2d3/2e/4|\"G\"d/2B/2G/2A/2|\"C\"E/2G/2D/2=CD/2|\"D\"F/2A/2d/4d/4f/4e/4|\"G\"g/2G/2G/2|\"C\"c/2G/2c/2e|\"D\"d/4c/4B/4A/2f/4|\"G\"g/2d/2B/2G/2|\"D\"F/2A/2D/2A/4d/4|\"G\"B/2G/2d/4d3/4d/4|\"D\"A/2d/4c/4B/4A/2|\"G\"G/2B/2G/2|\"C\"E/2G/2\"G\"G|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:B\n",
      "|\"A\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"A\"\"Bm\"|\"E\"\"A\"\"A\"|\"D\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"D\"|\"A\"\"Bm\"|\"E\"\"A\"|\"A\"\"Bm\"|\"E\"\"A\"|]\n",
      "z/2|\"A\"z/2A/2-A/2G/2AA|\"Bm\"B/2c/2B/2A/2\"E\"GE|\"A\"z/2A/2-\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d/2|\"G\"B3/2G/2G/2|\"C\"cBc|\"D\"d2d|\"G\"G2B/2c/2|\"G\"d3/2B/2GG|\"C\"cB\"D\"AB/2c/2|\"G\"d2\"C\"e/2c/2|\"G\"d2g3/2B/2|\"D\"cABc|\"G\"d2\"C\"e3/2d/2|\"D\"fzde/2f/2|\"G\"g3/2e/2d3/2e/2|g/2c/2B/2A/2G2|\"D\"A2g3/2f/2|\"G\"g3/2d/2B/2\"C\"cB|\"D\"Ad\"G\"g3/2f/2|\"Em\"g/2e/2\"A\"^c/2\"D\"d2|\"A\"e/2d/2c/2d/2eA/2c/2|\"D\"d2\"G\"B/2A/2G/2A/2|\"D\"FDD|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"A\"|\"E\"|\"E\"|\"A\"|\"E\"\"A\"|\"A\"|\"F#m\"|\"Bm\"\"E\"|\"Bm\"\"E\"|\"A\"\"Bm\"|\"A\"\"E\"|\"A\"\"A\"|]\n",
      "e|\"A\"a3/2g/2a/2e/2c/2A/2|\"E\"BGE3/2E/2|\"/2F/2A/2AB/2c/2|\"Bm\"dc\"E\"e3/2d/2|\"A\"c3/2B/2A\"E\"B/2^G/2E/2B/2d/2c/2B/2|\"A\"A\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2e/2|\"G\"g/2d/2B/2|GB/2A/2|\"G\"G/4A/4B/4c/4d/2g/2|d/2B/2B/2g/2|\"F\"=f/2A/2A/2B/2|cA\"G\"G/4A/4B/4c/4d/2B/2|\"C\"e/2d/4c/4\"G\"d/2B/2|\"G\"G/4A/4B/4c/4d/2B/2|dB|\"G\"G/4A/4B/4c/4d/2B/2|\"C\"e/2d/4c/4d/2e/2|\"F\"=f/2A/2A/2B/2|cA\"G\"g/2d/2B/4c/4d/4B/4|g/2d/2B/4c/4d/4B/4|\"G\"g/2d/2B/4c/4d/4B/4|gd|\"G\"g/2d/2B/4c/4d/4B/4|g/2d/2B/4c/4d/4B/4|\"D\"a/4d/4A/2A/2B/2|\"D7\"cA|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:F\n",
      "|\"D\"|\"C\"|\"D\"|\"D\"|\"G\"\"A\"|\"D\"|\"G\"|\"D\"|\"E\"|\"A\"|\"G\"|\"D\"|\"G\"\"A\"|\"D\"|]\n",
      "a/2g/2|\"D\"fdfd|f/2af/2ag/2f/2|\"C\"e=cec|e/2ge/2ga/2g/2|\"D\"fdfd|\"D\"f/2af/\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d2|\"G\"B3/2g/2d3/4e/4d/2B/2|\"G\"g/2d/2B/2G/2A/2|B3/4B/4B/2A/2|\"G\"G3/2|\"C\"E/2G/2D/2E/2G/2A/2|\"D\"B3/4B/4B/2A/2G/2|\"G\"G3/2B/2A/2G/2|\"C\"E/2G/2D/2E/2G/2A/2|\"D\"B3/2B/4B/4A/2G/2|\"G\"G2|]\n",
      "\n",
      "M:3/4\n",
      "L:1/4\n",
      "K:Gb\n",
      "|\"D\"|\"D\"|\"G\"|\"D\"|\"D\"|\"Em\"\"A\"|\"D\"|\"D\"|\"A\"|\"Bm\"|\"A7\"|\"D\"|\"A\"|\"E7\"|\"A\"|\"G\"|\"D\"|\"A\"|\"D\"|\"D\"|\"Em\"|\"A7\"|\"D\"|]\n",
      "|A|\"D\"f3/2e/2d|\"D\"AFA|\"G\"BGB|\"D\"AFA|\"D\"f3/2e/2d|\"D\"AFA|\"Em\"Be\"A\"c|\"D\"d2|A|\"D\"f2a|\"A\"e2a|\"Bm\"d3/2e/2d|\"A7\"cBA|\"D\"f2a|\"A\"e2a|\"E7\"^gfg|\"A\"a2a|\"G\"b2b|\"D\"a2a|\"A\"ggg|\"D\"fed|\"D\"f3/2e/2d|\"Em\"Bgf|\"A7\"edc|\"D\"d2\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"D\"f/2e/2f/2g/2a/2b/2|\"D\"c'/2a/2f/2dd|\"G\"g/2f/2g/2a/2b/2g/2e/2d/2|\"C\"c/2g/2f/2g/2a/2g/2e/2d/2c/2|\"G\"B/2g/2f/2g/2d/2g/2d/2B/2|\"D\"cAA|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"G\"|\"G\"\"D7\"|\"G\"\"D7\"|\"G\"|\"D\"|\"G\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    " !python3 sample.py --out_dir=older_ckpt/m_voices --path_meta=older_ckpt/m_voices --start='M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat older_ckpt/m_voices/ckpt.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l older_ckpt/m_voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l out-abc-char/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
