{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_dataframe(relative_path,dataframe_name):\n",
    "    df = pd.read_pickle(f'{relative_path}/{dataframe_name}.pkl')    \n",
    "    return df\n",
    "\n",
    "def read_file(relative_path,file_name):\n",
    "    text= \"\"\n",
    "    with open(f'{relative_path}/{file_name}.abc','r') as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unit_note_length', 'tuneBook', 'title', 'reference_number',\n",
       "       'original_header', 'original_body', 'meter', 'key', 'clean_song',\n",
       "       'clean_header', 'clean_body', 'chord_progression', '\"Gm\"', '\"G7\"',\n",
       "       '\"G\"', '\"F7\"', '\"F#m\"', '\"F#7\"', '\"F\"', '\"Em\"', '\"Eb\"', '\"E7\"', '\"E\"',\n",
       "       '\"Dm\"', '\"D7\"', '\"D\"', '\"Cm\"', '\"C7\"', '\"C\"', '\"Bm\"', '\"Bb\"', '\"B7\"',\n",
       "       '\"B\"', '\"Am\"', '\"A7\"', '\"A\"'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_path =\"notebooks/data/final_dataset\"\n",
    "filename_name = 'clean_augmented_data'\n",
    "#filename_name = 'clean_original_training_data'\n",
    "#relative_path =\"notebooks/data/original_dataset\"\n",
    "training_data_df = load_dataframe(relative_path,filename_name)\n",
    "training_data_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \"Gm\"g4\"D7\"^f2=ef\"Gm\"g4|\"Cm\"d2cB\"D7\"ABc2\"Gm\"B2G...\n",
       "1    |D|\"G\"GBBA/2B/2|\"D7\"cAAd|\"G\"BGGB|\"Am\"A/2G/2F/2...\n",
       "2    \"G\"DEDG2A|\"G\"BcBA2G|\"G7\"dB2A2G|\"C\"E3-E3|\"G\"DED...\n",
       "3    a|\"Dm\"afga|\"Dm\"fe/2f/2da|\"Dm\"afga|\"Dm\"f2fa|\"F\"...\n",
       "4    A|\"D\"d2efdf|\"G\"g3\"A7\"fga|\"D\"fgf\"Em\"e2d|\"E7\"e3\"...\n",
       "Name: clean_body, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df.head()[\"clean_body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_note_length</th>\n",
       "      <th>tuneBook</th>\n",
       "      <th>title</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>original_header</th>\n",
       "      <th>original_body</th>\n",
       "      <th>meter</th>\n",
       "      <th>key</th>\n",
       "      <th>clean_song</th>\n",
       "      <th>clean_header</th>\n",
       "      <th>...</th>\n",
       "      <th>\"Cm\"</th>\n",
       "      <th>\"C7\"</th>\n",
       "      <th>\"C\"</th>\n",
       "      <th>\"Bm\"</th>\n",
       "      <th>\"Bb\"</th>\n",
       "      <th>\"B7\"</th>\n",
       "      <th>\"B\"</th>\n",
       "      <th>\"Am\"</th>\n",
       "      <th>\"A7\"</th>\n",
       "      <th>\"A\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9720</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Grandpa's</td>\n",
       "      <td>78</td>\n",
       "      <td>X:78\\nT:Grandpa's\\nM:4/4\\nL:1/4\\nK:A</td>\n",
       "      <td>A/2G/2|\"D\"FA\"A7\"Bc|\"D\"d/2c/2d/2e/2fa|\"Em\"gf\"E7...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"|\"Em\"\"E7\"|\"A7\"|...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"|\"Em\"\"E7\"|\"A7\"|...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9721</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>The Girl With The Green Hat On</td>\n",
       "      <td>79</td>\n",
       "      <td>X:79\\nT:The Girl With The Green Hat On\\nM:4/4\\...</td>\n",
       "      <td>(3A/2B/2c/2|\"D\"dA\"A7\"A/2B/2A/2G/2|\"D\"F/2G/2A/2...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"\"A7\"|\"D\"|\"A7\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"\"A7\"|\"D\"|\"A7\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9722</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Green Meadow</td>\n",
       "      <td>80</td>\n",
       "      <td>X:80\\nT:Green Meadow\\nM:4/4\\nL:1/4\\nK:D</td>\n",
       "      <td>(3D/2E/2F/2|\"G\"GG/2A/2B/2G/2B/2d/2|\"C\"e/2f/2g/...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>D</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:D\\n|\"G\"|\"C\"\"G\"|\"Am\"|\"Am\"\"D7\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:D\\n|\"G\"|\"C\"\"G\"|\"Am\"|\"Am\"\"D7\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9723</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>The Old Grey Cat</td>\n",
       "      <td>82</td>\n",
       "      <td>X:82\\nT:The Old Grey Cat\\nM:4/4\\nL:1/4\\nK:Bm</td>\n",
       "      <td>B|\"Em\"eeEE/2F/2|\"Em\"G/2F/2G/2A/2B/2A/2B/2^c/2|...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>Bm</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:Bm\\n|\"Em\"|\"Em\"|\"D\"|\"D\"|\"Em\"|\"E...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:Bm\\n|\"Em\"|\"Em\"|\"D\"|\"D\"|\"Em\"|\"E...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9724</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Gyre And Gimble</td>\n",
       "      <td>84</td>\n",
       "      <td>X:84\\nT:Gyre And Gimble\\nM:4/4\\nL:1/4\\nK:A</td>\n",
       "      <td>A|\"D\"dAFA|\"Em\"BG\"A7\"EG|\"D\"FAd3/2e/2|\"A7\"f/2g/2...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"D\"|\"Em\"\"A7\"|\"D\"|\"A7\"\"D\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"D\"|\"Em\"\"A7\"|\"D\"|\"A7\"\"D\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unit_note_length          tuneBook                           title  \\\n",
       "9720              1/4  dataset_min5.abc                       Grandpa's   \n",
       "9721              1/4  dataset_min5.abc  The Girl With The Green Hat On   \n",
       "9722              1/4  dataset_min5.abc                    Green Meadow   \n",
       "9723              1/4  dataset_min5.abc                The Old Grey Cat   \n",
       "9724              1/4  dataset_min5.abc                 Gyre And Gimble   \n",
       "\n",
       "     reference_number                                    original_header  \\\n",
       "9720               78               X:78\\nT:Grandpa's\\nM:4/4\\nL:1/4\\nK:A   \n",
       "9721               79  X:79\\nT:The Girl With The Green Hat On\\nM:4/4\\...   \n",
       "9722               80            X:80\\nT:Green Meadow\\nM:4/4\\nL:1/4\\nK:D   \n",
       "9723               82       X:82\\nT:The Old Grey Cat\\nM:4/4\\nL:1/4\\nK:Bm   \n",
       "9724               84         X:84\\nT:Gyre And Gimble\\nM:4/4\\nL:1/4\\nK:A   \n",
       "\n",
       "                                          original_body meter key  \\\n",
       "9720  A/2G/2|\"D\"FA\"A7\"Bc|\"D\"d/2c/2d/2e/2fa|\"Em\"gf\"E7...   4/4   A   \n",
       "9721  (3A/2B/2c/2|\"D\"dA\"A7\"A/2B/2A/2G/2|\"D\"F/2G/2A/2...   4/4   A   \n",
       "9722  (3D/2E/2F/2|\"G\"GG/2A/2B/2G/2B/2d/2|\"C\"e/2f/2g/...   4/4   D   \n",
       "9723  B|\"Em\"eeEE/2F/2|\"Em\"G/2F/2G/2A/2B/2A/2B/2^c/2|...   4/4  Bm   \n",
       "9724  A|\"D\"dAFA|\"Em\"BG\"A7\"EG|\"D\"FAd3/2e/2|\"A7\"f/2g/2...   4/4   A   \n",
       "\n",
       "                                             clean_song  \\\n",
       "9720  M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"|\"Em\"\"E7\"|\"A7\"|...   \n",
       "9721  M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"\"A7\"|\"D\"|\"A7\"|\"...   \n",
       "9722  M:4/4\\nL:1/4\\nK:D\\n|\"G\"|\"C\"\"G\"|\"Am\"|\"Am\"\"D7\"|\"...   \n",
       "9723  M:4/4\\nL:1/4\\nK:Bm\\n|\"Em\"|\"Em\"|\"D\"|\"D\"|\"Em\"|\"E...   \n",
       "9724  M:4/4\\nL:1/4\\nK:A\\n|\"D\"|\"Em\"\"A7\"|\"D\"|\"A7\"\"D\"|\"...   \n",
       "\n",
       "                                           clean_header  ... \"Cm\" \"C7\"  \"C\"  \\\n",
       "9720  M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"|\"Em\"\"E7\"|\"A7\"|...  ...    0    0    0   \n",
       "9721  M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"\"A7\"|\"D\"|\"A7\"|\"...  ...    0    0    0   \n",
       "9722  M:4/4\\nL:1/4\\nK:D\\n|\"G\"|\"C\"\"G\"|\"Am\"|\"Am\"\"D7\"|\"...  ...    0    0    6   \n",
       "9723  M:4/4\\nL:1/4\\nK:Bm\\n|\"Em\"|\"Em\"|\"D\"|\"D\"|\"Em\"|\"E...  ...    0    0    0   \n",
       "9724  M:4/4\\nL:1/4\\nK:A\\n|\"D\"|\"Em\"\"A7\"|\"D\"|\"A7\"\"D\"|\"...  ...    0    0    0   \n",
       "\n",
       "      \"Bm\"  \"Bb\"  \"B7\"  \"B\"  \"Am\"  \"A7\"  \"A\"  \n",
       "9720     0     0     0    0     0     7    2  \n",
       "9721     0     0     0    0     0     6    2  \n",
       "9722     0     0     0    0     4     0    0  \n",
       "9723     0     0     3    0     1     0    0  \n",
       "9724     0     0     0    0     0     7    1  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df[\"clean_header\"].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab:  \n",
      "\"#'()+,-/1234567=ABCDEFG[]^_abcdefgmz|~\n",
      "vocab_size 40\n",
      "silences  612\n"
     ]
    }
   ],
   "source": [
    "bodies = \"\"\n",
    "silences = 0\n",
    "for body in training_data_df[\"clean_body\"]:\n",
    "    if 'z' in body:\n",
    "        silences +=1 \n",
    "    bodies += body+\"\\n\"\n",
    "chars = sorted(list(set(bodies)))\n",
    "vocab_size = len(chars)\n",
    "print('vocab: ',''.join(chars))\n",
    "print('vocab_size',vocab_size)\n",
    "print(\"silences \",silences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chars: 4149705\n"
     ]
    }
   ],
   "source": [
    "training_data_text = read_file(relative_path,filename_name)\n",
    "\n",
    "print(\"number of chars:\",len(training_data_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"#'()+,-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(training_data_text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.28.0.dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14.2\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import tiktoken\n",
    "\n",
    "print(wandb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==1.4.0\n",
      "aiohttp==3.8.4\n",
      "aiosignal==1.3.1\n",
      "alembic==1.10.2\n",
      "antlr4-python3-runtime==4.9.3\n",
      "anyio==3.6.2\n",
      "appdirs==1.4.4\n",
      "APScheduler==3.10.1\n",
      "argon2-cffi==21.3.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "arrow==1.2.3\n",
      "asttokens==2.2.1\n",
      "async-timeout==4.0.2\n",
      "attrs==22.2.0\n",
      "audioread==3.0.0\n",
      "av==9.2.0\n",
      "Babel==2.12.1\n",
      "backcall==0.2.0\n",
      "backoff==1.11.1\n",
      "backports.zoneinfo==0.2.1\n",
      "beautifulsoup4==4.11.2\n",
      "binaryornot==0.4.4\n",
      "black==23.1.0\n",
      "bleach==6.0.0\n",
      "cachetools==5.3.0\n",
      "certifi==2022.12.7\n",
      "cffi==1.15.1\n",
      "chardet==5.1.0\n",
      "charset-normalizer==3.1.0\n",
      "click==8.1.3\n",
      "clldutils==3.19.0\n",
      "cloudpickle==2.2.1\n",
      "cmaes==0.9.1\n",
      "cmake==3.25.0\n",
      "codecarbon==1.2.0\n",
      "colorama==0.4.6\n",
      "coloredlogs==15.0.1\n",
      "colorlog==6.7.0\n",
      "comm==0.1.3\n",
      "contourpy==1.0.7\n",
      "cookiecutter==1.7.3\n",
      "csvw==3.1.3\n",
      "cycler==0.11.0\n",
      "dash==2.8.1\n",
      "dash-bootstrap-components==1.4.0\n",
      "dash-core-components==2.0.0\n",
      "dash-html-components==2.0.0\n",
      "dash-table==5.0.0\n",
      "datasets==2.10.1\n",
      "debugpy==1.6.7\n",
      "decorator==5.1.1\n",
      "decord==0.6.0\n",
      "defusedxml==0.7.1\n",
      "detectron2 @ git+https://github.com/facebookresearch/detectron2.git@3ed66980529aadf662f469bca744221cab762e83\n",
      "dill==0.3.4\n",
      "distlib==0.3.6\n",
      "dlinfo==1.2.1\n",
      "docker-pycreds==0.4.0\n",
      "evaluate==0.4.0\n",
      "exceptiongroup==1.1.1\n",
      "execnet==1.9.0\n",
      "executing==1.2.0\n",
      "faiss-cpu==1.7.3\n",
      "fastjsonschema==2.16.3\n",
      "filelock==3.9.1\n",
      "fire==0.5.0\n",
      "Flask==2.2.3\n",
      "flatbuffers==23.3.3\n",
      "fonttools==4.39.0\n",
      "fqdn==1.5.1\n",
      "frozenlist==1.3.3\n",
      "fsspec==2023.3.0\n",
      "fugashi==1.2.1\n",
      "fvcore==0.1.5.post20221221\n",
      "gitdb==4.0.10\n",
      "GitPython==3.1.18\n",
      "google-auth==2.16.2\n",
      "google-auth-oauthlib==0.4.6\n",
      "gql==3.4.0\n",
      "graphql-core==3.2.3\n",
      "greenlet==2.0.2\n",
      "grpcio==1.51.3\n",
      "hf-doc-builder==0.4.0\n",
      "huggingface-hub==0.13.2\n",
      "humanfriendly==10.0\n",
      "hydra-core==1.3.2\n",
      "hypothesis==6.68.3\n",
      "idna==3.4\n",
      "importlib-metadata==6.0.0\n",
      "importlib-resources==5.12.0\n",
      "iniconfig==2.0.0\n",
      "iopath==0.1.9\n",
      "ipadic==1.0.0\n",
      "ipykernel==6.22.0\n",
      "ipython==8.12.0\n",
      "ipython-genutils==0.2.0\n",
      "isodate==0.6.1\n",
      "isoduration==20.11.0\n",
      "isort==5.12.0\n",
      "itsdangerous==2.0.1\n",
      "jedi==0.18.2\n",
      "Jinja2==3.1.2\n",
      "jinja2-time==0.2.0\n",
      "joblib==1.2.0\n",
      "json5==0.9.11\n",
      "jsonpointer==2.3\n",
      "jsonschema==4.17.3\n",
      "jupyter-events==0.6.3\n",
      "jupyter_client==8.1.0\n",
      "jupyter_core==5.2.0\n",
      "jupyter_server==2.5.0\n",
      "jupyter_server_terminals==0.4.4\n",
      "jupyterlab==3.5.1\n",
      "jupyterlab-pygments==0.2.2\n",
      "jupyterlab_server==2.22.0\n",
      "kenlm==0.1\n",
      "kiwisolver==1.4.4\n",
      "language-tags==1.2.0\n",
      "lazy_loader==0.1\n",
      "librosa==0.10.0\n",
      "lit==15.0.7\n",
      "llvmlite==0.39.1\n",
      "lxml==4.9.2\n",
      "Mako==1.2.4\n",
      "Markdown==3.4.1\n",
      "MarkupSafe==2.1.2\n",
      "matplotlib==3.6.2\n",
      "matplotlib-inline==0.1.6\n",
      "mistune==2.0.5\n",
      "mpmath==1.3.0\n",
      "msgpack==1.0.5\n",
      "multidict==6.0.4\n",
      "multiprocess==0.70.12.2\n",
      "mypy-extensions==1.0.0\n",
      "nbclassic==0.5.5\n",
      "nbclient==0.7.3\n",
      "nbconvert==7.3.0\n",
      "nbformat==5.7.3\n",
      "nest-asyncio==1.5.6\n",
      "networkx==3.0\n",
      "nltk==3.8.1\n",
      "notebook==6.5.4\n",
      "notebook_shim==0.2.2\n",
      "numba==0.56.4\n",
      "numpy==1.23.4\n",
      "nvidia-cublas-cu11==11.10.3.66\n",
      "nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "nvidia-cuda-runtime-cu11==11.7.99\n",
      "nvidia-cudnn-cu11==8.5.0.96\n",
      "oauthlib==3.2.2\n",
      "omegaconf==2.3.0\n",
      "onnx==1.13.1\n",
      "onnxruntime==1.14.1\n",
      "onnxruntime-tools==1.7.0\n",
      "optuna==3.1.0\n",
      "packaging==23.0\n",
      "pandas==1.5.2\n",
      "pandocfilters==1.5.0\n",
      "parameterized==0.8.1\n",
      "parso==0.8.3\n",
      "pathspec==0.11.1\n",
      "pathtools==0.1.2\n",
      "pexpect==4.8.0\n",
      "phonemizer==3.2.1\n",
      "pickleshare==0.7.5\n",
      "Pillow==9.4.0\n",
      "pkgutil_resolve_name==1.3.10\n",
      "plac==1.3.5\n",
      "platformdirs==3.1.1\n",
      "plotly==5.13.1\n",
      "pluggy==1.0.0\n",
      "pooch==1.7.0\n",
      "portalocker==2.0.0\n",
      "poyo==0.5.0\n",
      "prometheus-client==0.16.0\n",
      "prompt-toolkit==3.0.38\n",
      "protobuf==3.20.2\n",
      "psutil==5.9.4\n",
      "ptyprocess==0.7.0\n",
      "pure-eval==0.2.2\n",
      "py-cpuinfo==9.0.0\n",
      "py3nvml==0.2.7\n",
      "pyarrow==11.0.0\n",
      "pyasn1==0.4.8\n",
      "pyasn1-modules==0.2.8\n",
      "pycocotools==2.0.6\n",
      "pycparser==2.21\n",
      "pyctcdecode==0.5.0\n",
      "Pygments==2.14.0\n",
      "pygtrie==2.5.0\n",
      "pylatexenc==2.10\n",
      "pynvml==11.5.0\n",
      "pyparsing==3.0.9\n",
      "pypng==0.20220715.0\n",
      "pyrsistent==0.19.3\n",
      "pytesseract==0.3.10\n",
      "pytest==7.2.2\n",
      "pytest-timeout==2.1.0\n",
      "pytest-xdist==3.2.1\n",
      "python-dateutil==2.8.2\n",
      "python-json-logger==2.0.7\n",
      "python-slugify==8.0.1\n",
      "pytz==2022.7.1\n",
      "pytz-deprecation-shim==0.1.0.post0\n",
      "PyYAML==5.4.1\n",
      "pyzmq==25.0.2\n",
      "ray==2.3.0\n",
      "rdflib==6.2.0\n",
      "regex==2022.10.31\n",
      "requests==2.28.2\n",
      "requests-oauthlib==1.3.1\n",
      "requests-toolbelt==0.10.1\n",
      "responses==0.18.0\n",
      "rfc3339-validator==0.1.4\n",
      "rfc3986==1.5.0\n",
      "rfc3986-validator==0.1.1\n",
      "rhoknp==1.2.1\n",
      "rjieba==0.1.11\n",
      "rouge-score==0.1.2\n",
      "rsa==4.9\n",
      "ruff==0.0.256\n",
      "sacrebleu==1.5.1\n",
      "sacremoses==0.0.53\n",
      "safetensors==0.3.0\n",
      "scikit-learn==1.2.2\n",
      "scipy==1.10.1\n",
      "seaborn==0.12.1\n",
      "segments==2.2.1\n",
      "Send2Trash==1.8.0\n",
      "sentencepiece==0.1.97\n",
      "sentry-sdk==1.19.1\n",
      "setproctitle==1.3.2\n",
      "sigopt==8.7.0\n",
      "six==1.16.0\n",
      "smmap==5.0.0\n",
      "sniffio==1.3.0\n",
      "sortedcontainers==2.4.0\n",
      "soundfile==0.12.1\n",
      "soupsieve==2.4\n",
      "soxr==0.3.4\n",
      "SQLAlchemy==2.0.6\n",
      "stack-data==0.6.2\n",
      "SudachiDict-core==20230110\n",
      "SudachiPy==0.6.7\n",
      "sympy==1.11.1\n",
      "tabulate==0.9.0\n",
      "tenacity==8.2.2\n",
      "tensorboard==2.12.0\n",
      "tensorboard-data-server==0.7.0\n",
      "tensorboard-plugin-wit==1.8.1\n",
      "tensorboardX==2.6\n",
      "termcolor==2.2.0\n",
      "terminado==0.17.1\n",
      "text-unidecode==1.3\n",
      "threadpoolctl==3.1.0\n",
      "tiktoken==0.3.3\n",
      "timeout-decorator==0.5.0\n",
      "timm==0.6.12\n",
      "tinycss2==1.2.1\n",
      "tokenizers==0.13.2\n",
      "tomli==2.0.1\n",
      "torch==2.0.0+cu117\n",
      "torchaudio==2.0.0+cu117\n",
      "torchvision==0.15.0+cu117\n",
      "tornado==6.2\n",
      "tqdm==4.65.0\n",
      "traitlets==5.9.0\n",
      "-e git+https://github.com/huggingface/transformers@f7329751fe5c43365751951502c00df5a4654359#egg=transformers\n",
      "triton==2.0.0\n",
      "typing_extensions==4.5.0\n",
      "tzdata==2022.7\n",
      "tzlocal==4.2\n",
      "unidic==1.1.0\n",
      "unidic-lite==1.0.8\n",
      "uri-template==1.2.0\n",
      "uritemplate==4.1.1\n",
      "urllib3==1.26.15\n",
      "virtualenv==20.21.0\n",
      "wandb==0.14.2\n",
      "wasabi==0.10.1\n",
      "wcwidth==0.2.6\n",
      "webcolors==1.13\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.5.1\n",
      "Werkzeug==2.2.3\n",
      "xmltodict==0.13.0\n",
      "xxhash==3.2.0\n",
      "yacs==0.1.8\n",
      "yarl==1.8.2\n",
      "zipp==3.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile  docker-compose.yaml  overrides.json\n",
      "README.md   notebooks\t\t requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE      bench.py\t      model.py\t\t    train.py\n",
      "README.md    config\t      out-shakespeare-char  transformer_sizing.ipynb\n",
      "__pycache__  configurator.py  sample.py\n",
      "assets\t     data\t      scaling_laws.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "nano_path = 'notebooks/nanoGPT'\n",
    "os.chdir(nano_path)\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 4,149,703\n",
      "all the unique characters: \n",
      "\"#'()+,-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
      "vocab size: 46\n",
      "train has 3,734,732 tokens\n",
      "val has 414,971 tokens\n"
     ]
    }
   ],
   "source": [
    "!python3 data/shakespeare_char/prepare.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding config with config/train_shakespeare_char.py:\n",
      "# train a miniature character-level shakespeare model\n",
      "# good for debugging and playing on macbooks and such\n",
      "\n",
      "out_dir = 'out-abc-char'\n",
      "eval_interval = 50 # keep frequent because we'll overfit\n",
      "eval_iters = 500\n",
      "log_interval = 20 # don't print too too often\n",
      "\n",
      "# we expect to overfit on this small dataset, so only save when val improves\n",
      "always_save_checkpoint = False\n",
      "\n",
      "wandb_log = True # override via command line if you like\n",
      "wandb_project = 'abc-char'\n",
      "wandb_run_name = 'mini-char-gpt'\n",
      "\n",
      "dataset = 'shakespeare_char'\n",
      "batch_size = 128\n",
      "block_size = 512 # context of up to 512 previous characters\n",
      "\n",
      "# baby GPT model :)\n",
      "n_layer = 6\n",
      "n_head = 6\n",
      "n_embd = 768\n",
      "dropout = 0.2\n",
      "\n",
      "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
      "max_iters = 5000\n",
      "lr_decay_iters = 500 # make equal to max_iters usually\n",
      "min_lr = 1e-4 # learning_rate / 10 usually\n",
      "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
      "\n",
      "warmup_iters = 5 # not super necessary potentially\n",
      "\n",
      "# on macbook also add\n",
      "# device = 'cpu'  # run on cpu only\n",
      "# compile = False # do not torch compile the model\n",
      "\n",
      "found vocab_size = 46 (inside data/shakespeare_char/meta.pkl)\n",
      "Initializing a new model from scratch\n",
      "number of parameters: 42.51M\n",
      "using fused AdamW: True\n",
      "compiling the model... (takes a ~minute)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavidnogales\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/pt-env/notebooks/nanoGPT/wandb/run-20230408_214908-w1nwog0h\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmini-char-gpt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char/runs/w1nwog0h\u001b[0m\n",
      "step 0: train loss 4.0351, val loss 4.0287\n",
      "[2023-04-08 21:54:21,920] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 21:54:22,310] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 21:54:22,960] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 21:54:23,136] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 21:54:23,407] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 21:54:23,592] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 21:54:23,874] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 21:54:24,060] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 21:54:29,403] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 21:54:29,583] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 289, in <module>\n",
      "    logits, loss = model(X, Y)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_dynamo/eval_frame.py\", line 82, in forward\n",
      "    return self.dynamo_ctx(self._orig_mod.forward)(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_dynamo/eval_frame.py\", line 209, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/pt-env/notebooks/nanoGPT/model.py\", line 188, in forward\n",
      "    x = block(x)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/pt-env/notebooks/nanoGPT/model.py\", line 111, in forward\n",
      "    x = x + self.attn(self.ln_1(x))\n",
      "  File \"/pt-env/notebooks/nanoGPT/model.py\", line 111, in <graph break in forward>\n",
      "    x = x + self.attn(self.ln_1(x))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_dynamo/eval_frame.py\", line 209, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 2819, in forward\n",
      "    return compiled_fn(full_args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 1222, in g\n",
      "    return f(*args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 2386, in debug_compiled_function\n",
      "    return compiled_function(*args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 1898, in runtime_wrapper\n",
      "    all_outs = call_func_with_args(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 1247, in call_func_with_args\n",
      "    out = normalize_as_list(f(args))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 1222, in g\n",
      "    return f(*args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/function.py\", line 506, in apply\n",
      "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 2151, in forward\n",
      "    fw_outs = call_func_with_args(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 1247, in call_func_with_args\n",
      "    out = normalize_as_list(f(args))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_inductor/compile_fx.py\", line 248, in run\n",
      "    return model(new_inputs)\n",
      "  File \"/tmp/torchinductor_root/xj/cxjrok7nolh7yun5wzpgtjakjtjdjfbxcqqg7jbb7rg5rzhr2c5g.py\", line 214, in call\n",
      "    buf8 = empty_strided((128, 512, 3072), (1572864, 3072, 1), device='cuda', dtype=torch.float32)\n",
      "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 768.00 MiB (GPU 0; 12.00 GiB total capacity; 11.27 GiB already allocated; 0 bytes free; 11.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 1).\u001b[0m Press Control-C to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       iter ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         lr ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        mfu ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/loss ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val/loss ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       iter 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         lr 0.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        mfu -100.0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/loss 4.03507\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val/loss 4.0287\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmini-char-gpt\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char/runs/w1nwog0h\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230408_214908-w1nwog0h/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py config/train_shakespeare_char.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-shakespeare-char\n",
      "Overriding: start = M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "number of parameters: 10.64M\n",
      "Loading meta from data/shakespeare_char/meta.pkl...\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "B/2c/2|\"G\"d/2G/2B/2d/2G/2|d/2B/2e/2B/2d/2B/2A/2G/2|\"G\"d/2G/2B/2d/2B/2G/2B/2|\"Am\"A/2D/2c/2B/2Ac/2A/2|\"D\"A/2B/2c/2d/2B/2e/2f/2|\"G\"g/2e/2d/2B/2G/2B/2|\"G\"d/2B/2G/2B/2dc/2B/2|\"Am\"A/2B/2c/2d/2c/2B/2A/2G/2|\"D\"AB/2c/2d/2e/2|\"D\"f/2e/2d/2c/2B/2A/2|\"G\"GBG|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:C\n",
      "|\"D\"\"A7\"|\"D\"|\"G\"\"D\"|\"Em\"\"E7\"|\"A7\"|\"D\"\"A7\"|\"D\"|\"G\"\"D\"|\"A7\"\"D\"|\"B\"|\"D\"|\"E7\"\"A7\"|\"D\"|\"A7\"|\"D\"|\"G\"\"D\"|\"A7\"\"D\"|]\n",
      "F/2G/2|\"D\"AA/2B/2AA/2B/2|\"G\"GB/2G/2\"D\"F/2A/2|\"Em\"G/2F/2E/2D/2\"E7\"EF/2G/2|\"A7\"E/2D/2E/2F/2\"D\"D2|\"A7\"E/2D/2E/2F/2\"D\"D2|\"A7\"AA/2B/\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "\"G\"e2d|B3/2A/2G|\"G\"def|\"C\"g3/2g/2f/2e/2|\"D\"ddc|\"D\"A3/2B/2A|\"G\"G3/2B/2d/2|\"C\"g3/2g/2fe|\"G\"dBG|\"A\"A2g|\"D\"fdfe|\"D\"d3/2e/2dd|\"G\"G3-|\"G\"G2B/2c/2dd|\"C\"egge|\"D\"faA\"A7\"ge|\"D\"d2\"A7\"dc|\"D\"d2-|\"D\"dddz|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:Db\n",
      "|\"A\"|\"A\"\"D\"|\"A\"|\"E\"|\"A\"|\"A\"\"D\"|\"E\"|\"A\"\"D\"|\"E\"A\"|\"E\"\"A\"|\"E\"|\"A\"\"E\"|\"E\"|\"A\"|\"A\"\"D\"|\"A\"|\"E\"|\"A\"|\"A\"\"D\"|\"E\"|\"A\"\"D\"|\"E\"\"A\"|\"E\"|\"A\"\"E\"|\"E\"|\"A\"|\"A\"\"D\"|\"E\"\"A\"|]\n",
      "|\"A\"|\"A\"\"D\"|\"A\"|\"E\"|\"A\"|\"A\"\"D\"|\"E\"|\"A\"\"D\"|\"E\"\"A\"|\"E\"\"A\"|\"E\"|\"A\"\"E\"|\"E\"\"D\"|\"A\"|\"A\"\"D\"|\"A\"|\"E\"|\"A\"\"D\"|\"A\"|\"A\"|\"A\"\"D\"|\"E\"|\"A\"\"D\"|\"E\"|]e|\"A\"\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "\"G\"G/2B/2d/2g/2|\"C\"g/2c/2e/2g/2c/2|\"G\"B/2d/2G/2A/2B/2G/2|\"C\"c/2d/2c/2B/2\"Am\"AA|\"D\"d/2^c/2d/2e/2f/2|\"G\"g/2d/2e/2d/2B/2G/2B/2|\"C\"c/2e/2g/2f/2g/2e/2|\"D\"d/2^c/2d/2e/2^f/2d/2e/2f/2|\"G\"g2ef|\"F\"f/2e/2d/2c/2\"G\"B/2G/2A/2B/2|\"C\"c3e/2f/2|\"C\"g2-g/2a/2g|e2-e/2g/2e/2d/2|\"D\"d/2^c/2d/2e/2f/2d/2e/2f/2|\"G\"g2e/2f/2d/2c/2d/2|\"D7\"c2^A/2B/2c/2A/2B/2|\"G\"G/2A/2B/2c/2d/2e/2d/2B/2|\"G\"g2ef|\"C\"g2-g/2a/2g|e2-e/2g/2e/2d/2|\"Am\"d/2^c/2d/2c/2B/2|\"Am\"c/2B/2A/2G/2\"D7\"G/2F/2E/2D/2|\"G\"G2G|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:Db\n",
      "|\"G\"|\"Am\"|\"C\"|\"G\"|\"G\"|\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d|\"G\"G/2B/2d/2G/2|\"C\"c/2e/2g/2f/2e/2|\"D\"d/2c/2A/2B/2c/2A/2|\"G\"G/2B/2dd|\"C\"e/2d/2c/2B/2\"A\"A-|\"D\"d/2c/2B/2A/2F/2E/2|\"G\"G/2B/2D/2G/2B/2dd|\"C\"e/2f/2g/2e/2\"G\"d/2B/2G/2B/2|\"D\"A/2d/2c/2B/2A/2\"G\"G|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:B\n",
      "|\"D\"\"A7\"|\"D\"|\"Em\"\"C\"|\"D\"\"A7\"|\"D\"|\"Em\"\"A7\"|\"D\"|\"D\"|\"G\"\"A7\"|\"D\"|\"D\"|\"Em\"\"C\"|\"A7\"|\"D\"\"A7\"|\"D\"|\"Em\"\"A7\"|\"D\"|\"D\"|\"G\"\"A7\"|\"D\"|]\n",
      "A|\"D\"d2\"A7\"A3/2G/2|\"D\"FDDE/2F/2|\"Em\"GE\"C\"G3/2A/2|\"D\"FD\"A7\"EA|\"D\"ddAF|\"Em\"GE\"A7\"DC|\"D\"D2D3/2|E/2|\"D\"D2D|\"D\"feg|\"G\"dcB\"A7\"A3/2B/2|\"D\"Addc/2d/2|\"D\"fedA/2B/2|\"Em\"ce\"A7\"e2|\"D\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "f/2^e/2|\"G\"gg/2a/2gd/2c/2|gd/2e/2g/2b/2g/2|\"C\"c3/2g/2f/2e/2d/2c/2|\"G\"B/2G/2B/2dd/2e/2|\"F\"=f/2e/2d/2c/2A/2F/2A/2|\"D\"d/2e/2d/2c/2B/2A/2|\"G\"G/2B/2d/2\"C\"c3/2d/2|\"G\"g3/2a/2gd|\"G\"B/2g/2B/2d/2g/2d/2|\"C\"e/2g/2f/2e/2d/2c/2B/2|\"D\"cAAd/2c/2|\"G\"BGG|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:Bb\n",
      "|\"G\"|\"G\"|\"G\"\"Em\"|\"Am\"\"D7\"|\"G\"|\"G\"\"Em\"|\"D7\"\"G\"|\"G\"|\"G7\"|\"C\"|\"C\"\"D7\"|\"G\"|\"G\"\"D7\"|\"G\"|]\n",
      "d|\"G\"BddB|\"G\"BddB|\"G\"Bd-\"Em\"ef|\"Am\"e/2-\"D7\"A2|\"G\"Bd\"D7\"dB|\"G\"G2GA/2B/2|\"G\"Bd\"Em\"dB|\"D7\"A3/2B/2AG|\"G\"Bd\"Em\"g2|\"G\"gfed|\"G\"Bd\"D7\"dB/2A/2|\"G\"G2G2|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "D|\"G\"G/2A/2Bd|\"C\"c3/2d/2e|\"D\"cAF|\"G\"G/2A/2B/2c/2dB|\"C\"c/2d/2e/2f/2g|\"D\"a/2g/2e/2d/2e/2c/2|\"G\"B/2c/2d/2B/2G2|\"C\"c3/2d/2e|\"D\"cBA|\"G\"G2B/2A/2G/2|\"C\"E/2G/2c/2G/2E/2|\"D\"F/2A/2D/2F/2A/2d/2c/2B/2A/2|\"G\"G2GB|\"C\"c/2d/2e/2f/2g/2e/2|\"D\"d/2^c/2dB_B/2|\"D\"cAAd/2c/2|\"G\"BGGe/2d/2|\"C\"c/2d/2e/2f/2g|\"D\"a/2g/2f/2e/2\"G\"d/2B/2G/2B/2|\"C\"c3|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:F\n",
      "|\"Bb\"|\"Eb\"\"F7\"|\"Bb\"|\"Bb\"|\"Eb\"\"F7\"|\"Bb\"|\"Bb\"|\"Dm\"\"Gm\"|\"Eb\"\"Bb\"|\"Eb\"\"F7\"|\"Bb\"\"A7\"|\"Dm\"\"Gm\"|\"Eb\"\"Bb\"|\"Gm\"\"C7\"|\"F7\"|\"Bb\"|\"Eb\"\"F7\"|\"Bb\"|\"Bb\"|\"Bb\"|\"Dm\"\"Gm\"|\"Eb\"\"Bb\"|\"E\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2f/2|\"G\"g/2d/2g/2B/2g/2|\"G\"d/2g/2g/2e/2d/2|g/2g/2f/2g/2a/2bb|\"C\"e3/2e/2|\"D\"d/2^c/2d/2e/2^f/2d/2e/2f/2|\"G\"g/2d/2g/2d/2e/2d/2c/2|\"G\"B/2G/2A/2B/2c/2|\"G\"d/2B/2G/2A/2B/2c/2B/2A/2G/2|\"C\"A/2G/2F/2E/2F/2G/2|\"D\"A/2^G/2A/2F/2D/2E/2F/2|\"G\"G/2F/2G/2A/2G/2A/2B/2c/2|\"G\"d/2B/2c/2A/2B/2G/2B/2|\"C\"A/2G/2F/2E/2D/2E/2G/2A/2|\"D\"F/2G/2F/2E/2D/2C/2B,/2A,|\"D\"A,/2B,/2D/2E/2F/2D/2B,/2|\"G\"G,/2B,/2D/2G/2B/2A/2G/2|\"G\"B/2A/2G/2B/2\"D\"A/2A/2G/2A/2|\"G\"B/2A/2B/2c/2d/2B/2G/2A/2|\"G\"B/2G/2B/2\"D7\"A/2c/2B/2A/2|\"G\"G/2F/2G/2A/2B/2c/\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d|\"G\"G/2B/2d/2G/2B/2d/2|\"C\"c/2e/2g/2f/2e/2|\"D\"d/2c/2B/2A/2\"G\"G/2B/2|\"C\"c/2d/2(3e/2d/2c/2B/2\"A\"AG|\"D\"F/2G/2A/2B/2cD/2E/2F/2|\"G\"GBG|\"G\"B/2d/2g/2d/2B/2G/2|\"C\"c/2e/2g/2f/2e/2d/2e/2|\"D\"d/2c/2B/2A/2e/22d/2c/2|\"G\"B/2G/2B/2d/2g/2d/2B/2G/2|\"C\"c/2e/2g/2f/2e/2d/2c/2|\"D\"B/2G/2A/2F/2A/2c/2d/2|\"G\"BGG2|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:Eb\n",
      "|\"D\"\"A7\"|\"D\"|\"Em\"|\"A7\"|\"D\"\"A7\"|\"D\"|\"Em\"\"A7\"|\"D\"|\"D\"|\"D\"|\"G\"|\"A7\"|\"D\"|\"G\"\"A7\"|\"D\"|\"D\"|\"Em\"|\"A7\"|\"D\"\"A7\"|\"D\"|\"Em\"\"A7\"|\"D\"|\"D\"|\"G\"|\"A7\"|\"D\"|\"G\"\"A7\"|\"D\"|\"D\"|\"Em\"|\"A7\"|\"D\"\"A7\"|\"D\"|\"Em\"\"A7\"|\"D\"|\"D\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d/2e/2|\"G\"g/2G/2B/2d3/4e/4|d/2B/2G/2A/2|B/2B/2A/2G/2|\"D\"A3/2G/2A/2|\"D\"d/4d/4e/4d3/4e/4|\"D\"f/2g/2a/2g/2f/2|\"Em\"e/2d/2\"B\"B/2c/2|\"Em\"d/2e/2f/2\"A7\"e|\"D\"d/2d/2d/2c/2|\"D\"dd/2de/2|\"D\"f/2f/2f/2f/2f/2e/2|\"G\"g/2B/2B/2B/2gf/2e/2|\"D\"f/2a/2g/2e/2\"A\"c/2A/2B/2c/2|\"D\"dfd2|\"A\"c3/2e/2e/2|\"E\"B/2B/2^c/2|\"A\"e/2f/2e/2d/2\"A\"c/2A/2B/2c/2|\"D\"dfd2|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:Db\n",
      "|\"D\"\"A7\"|\"D\"|\"D\"\"A7\"|\"D\"\"G\"|\"A7\"\"G\"|\"A7\"\"G\"|\"A7\"\"D\"|\"D\"\"A7\"|\"D\"\"A7\"|\"D\"\"G\"|\"A7\"\"A7\"|\"D\"|\"D\"\"A\"|\"Em\"\"A7\"|\"D\"\"A7\"|\"A7\"\"D\"|]\n",
      "|\"D\"\"A7\"|\"D\"\"G\"|\"A7\"\"G\"|\"A7\"\"A7\"|\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2f/2|\"G\"gg/2a/2g/2e/2d/2|gg/2a/2bb/2e/2|\"G\"g/2e/2d/2e/2d/2c/2|\"C\"e/2g/2f/2g/2a/2g/2e/2|\"D\"d/2^c/2d/2e/2^f/2d/2e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2e/2d/2c/2d/2c/2B/2|\"D7\"A/2B/2c/2A/2\"G\"GB/2c/2|\"G\"d/2B/2c/2de/2f/2|\"C\"gg/2e/2d/2e/2f/2|\"D\"ff/2g/2aa/2f/2|\"G\"gg/2g/2d/2g/2|\"C\"g/2f/2e/2g/2e/2g/2e/2d/2|\"D\"cd/2c/2B/2A/2G/2|\"G\"GGd/2c/2|\"G\"B/2E/2E/2D/2E/2G/2A/2|\"G\"BB/2D/2\"Em\"B/2G/2B/2|\"Am\"A/2G/2A/2B/2\"D7\"A/2G/2A/2|\"G\"G/2F/2G/2A/2B/2c/2B/2A/2G/2|\"G\"BB/2c/2Bd|\"C\"e/2f/2e/2d/2B/2d/2e/2f/2|\"Em\"g/2e/2d/2B/2\"D7\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    " !python3 sample.py --out_dir=out-shakespeare-char --start='M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
