{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_dataframe(relative_path,dataframe_name):\n",
    "    df = pd.read_pickle(f'{relative_path}/{dataframe_name}.pkl')    \n",
    "    return df\n",
    "\n",
    "def read_file(relative_path,file_name):\n",
    "    text= \"\"\n",
    "    with open(f'{relative_path}/{file_name}.abc','r') as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'notebooks/data/augmented_dataset/clean_augmented_data.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m filename_name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mclean_augmented_data\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39m#filename_name = 'clean_original_training_data'\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m#relative_path =\"notebooks/data/original_dataset\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m training_data_df \u001b[39m=\u001b[39m load_dataframe(relative_path,filename_name)\n\u001b[1;32m      6\u001b[0m training_data_df\u001b[39m.\u001b[39mcolumns\n",
      "Cell \u001b[0;32mIn[21], line 5\u001b[0m, in \u001b[0;36mload_dataframe\u001b[0;34m(relative_path, dataframe_name)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_dataframe\u001b[39m(relative_path,dataframe_name):\n\u001b[0;32m----> 5\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_pickle(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m{\u001b[39;49;00mrelative_path\u001b[39m}\u001b[39;49;00m\u001b[39m/\u001b[39;49m\u001b[39m{\u001b[39;49;00mdataframe_name\u001b[39m}\u001b[39;49;00m\u001b[39m.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m)    \n\u001b[1;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/pickle.py:190\u001b[0m, in \u001b[0;36mread_pickle\u001b[0;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[39mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39m4    4    9\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    189\u001b[0m excs_to_catch \u001b[39m=\u001b[39m (\u001b[39mAttributeError\u001b[39;00m, \u001b[39mImportError\u001b[39;00m, \u001b[39mModuleNotFoundError\u001b[39;00m, \u001b[39mTypeError\u001b[39;00m)\n\u001b[0;32m--> 190\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m    191\u001b[0m     filepath_or_buffer,\n\u001b[1;32m    192\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    193\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m    194\u001b[0m     is_text\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    195\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m    196\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    197\u001b[0m \n\u001b[1;32m    198\u001b[0m     \u001b[39m# 1) try standard library Pickle\u001b[39;00m\n\u001b[1;32m    199\u001b[0m     \u001b[39m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[39m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    203\u001b[0m         \u001b[39m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[1;32m    204\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py:865\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(handle, ioargs\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    866\u001b[0m     handles\u001b[39m.\u001b[39mappend(handle)\n\u001b[1;32m    868\u001b[0m \u001b[39m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'notebooks/data/augmented_dataset/clean_augmented_data.pkl'"
     ]
    }
   ],
   "source": [
    "relative_path =\"notebooks/data/augmented_dataset\"\n",
    "filename_name = 'clean_augmented_data'\n",
    "#filename_name = 'clean_original_training_data'\n",
    "#relative_path =\"notebooks/data/original_dataset\"\n",
    "training_data_df = load_dataframe(relative_path,filename_name)\n",
    "training_data_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    M:3/2\\nL:1/8\\nK:C#m\\n|\"Gm\"\"D7\"\"Gm\"|\"Cm\"\"D7\"\"Gm...\n",
       "1    M:4/4\\nL:1/4\\nK:Db\\n|\"G\"|\"D7\"|\"G\"|\"Am\"\"D7\"|\"G\"...\n",
       "2    M:6/8\\nL:1/8\\nK:Db\\n|\"G\"|\"G\"|\"G7\"|\"C\"|\"G\"|\"G\"|...\n",
       "3    M:4/4\\nL:1/4\\nK:G#m\\n|\"Dm\"|\"Dm\"|\"Dm\"|\"Dm\"|\"F\"|...\n",
       "4    M:6/8\\nL:1/8\\nK:Ab\\n|\"D\"|\"G\"\"A7\"|\"D\"\"Em\"|\"E7\"\"...\n",
       "Name: clean_header, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df.head()[\"clean_header\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \"Gm\"g4\"D7\"^f2=ef\"Gm\"g4|\"Cm\"d2cB\"D7\"ABc2\"Gm\"B2G...\n",
       "1    |D|\"G\"GBBA/2B/2|\"D7\"cAAd|\"G\"BGGB|\"Am\"A/2G/2F/2...\n",
       "2    \"G\"DEDG2A|\"G\"BcBA2G|\"G7\"dB2A2G|\"C\"E3-E3|\"G\"DED...\n",
       "3    a|\"Dm\"afga|\"Dm\"fe/2f/2da|\"Dm\"afga|\"Dm\"f2fa|\"F\"...\n",
       "4    A|\"D\"d2efdf|\"G\"g3\"A7\"fga|\"D\"fgf\"Em\"e2d|\"E7\"e3\"...\n",
       "Name: clean_body, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df.head()[\"clean_body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_note_length</th>\n",
       "      <th>tuneBook</th>\n",
       "      <th>title</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>original_header</th>\n",
       "      <th>original_body</th>\n",
       "      <th>meter</th>\n",
       "      <th>key</th>\n",
       "      <th>clean_song</th>\n",
       "      <th>clean_header</th>\n",
       "      <th>...</th>\n",
       "      <th>\"Cm\"</th>\n",
       "      <th>\"C7\"</th>\n",
       "      <th>\"C\"</th>\n",
       "      <th>\"Bm\"</th>\n",
       "      <th>\"Bb\"</th>\n",
       "      <th>\"B7\"</th>\n",
       "      <th>\"B\"</th>\n",
       "      <th>\"Am\"</th>\n",
       "      <th>\"A7\"</th>\n",
       "      <th>\"A\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19445</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Grandpa's</td>\n",
       "      <td>78</td>\n",
       "      <td>X:78\\nT:Grandpa's\\nM:4/4\\nL:1/4\\nK:A</td>\n",
       "      <td>A/2G/2|\"D\"FA\"A7\"Bc|\"D\"d/2c/2d/2e/2fa|\"Em\"gf\"E7...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"|\"Em\"\"E7\"|\"A7\"|...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"|\"Em\"\"E7\"|\"A7\"|...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19446</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>The Girl With The Green Hat On</td>\n",
       "      <td>79</td>\n",
       "      <td>X:79\\nT:The Girl With The Green Hat On\\nM:4/4\\...</td>\n",
       "      <td>(3A/2B/2c/2|\"D\"dA\"A7\"A/2B/2A/2G/2|\"D\"F/2G/2A/2...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"\"A7\"|\"D\"|\"A7\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"\"A7\"|\"D\"|\"A7\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19447</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Green Meadow</td>\n",
       "      <td>80</td>\n",
       "      <td>X:80\\nT:Green Meadow\\nM:4/4\\nL:1/4\\nK:D</td>\n",
       "      <td>(3D/2E/2F/2|\"G\"GG/2A/2B/2G/2B/2d/2|\"C\"e/2f/2g/...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>D</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:D\\n|\"G\"|\"C\"\"G\"|\"Am\"|\"Am\"\"D7\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:D\\n|\"G\"|\"C\"\"G\"|\"Am\"|\"Am\"\"D7\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19448</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>The Old Grey Cat</td>\n",
       "      <td>82</td>\n",
       "      <td>X:82\\nT:The Old Grey Cat\\nM:4/4\\nL:1/4\\nK:Bm</td>\n",
       "      <td>B|\"Em\"eeEE/2F/2|\"Em\"G/2F/2G/2A/2B/2A/2B/2^c/2|...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>Bm</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:Bm\\n|\"Em\"|\"Em\"|\"D\"|\"D\"|\"Em\"|\"E...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:Bm\\n|\"Em\"|\"Em\"|\"D\"|\"D\"|\"Em\"|\"E...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19449</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Gyre And Gimble</td>\n",
       "      <td>84</td>\n",
       "      <td>X:84\\nT:Gyre And Gimble\\nM:4/4\\nL:1/4\\nK:A</td>\n",
       "      <td>A|\"D\"dAFA|\"Em\"BG\"A7\"EG|\"D\"FAd3/2e/2|\"A7\"f/2g/2...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"D\"|\"Em\"\"A7\"|\"D\"|\"A7\"\"D\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"D\"|\"Em\"\"A7\"|\"D\"|\"A7\"\"D\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      unit_note_length          tuneBook                           title  \\\n",
       "19445              1/4  dataset_min5.abc                       Grandpa's   \n",
       "19446              1/4  dataset_min5.abc  The Girl With The Green Hat On   \n",
       "19447              1/4  dataset_min5.abc                    Green Meadow   \n",
       "19448              1/4  dataset_min5.abc                The Old Grey Cat   \n",
       "19449              1/4  dataset_min5.abc                 Gyre And Gimble   \n",
       "\n",
       "      reference_number                                    original_header  \\\n",
       "19445               78               X:78\\nT:Grandpa's\\nM:4/4\\nL:1/4\\nK:A   \n",
       "19446               79  X:79\\nT:The Girl With The Green Hat On\\nM:4/4\\...   \n",
       "19447               80            X:80\\nT:Green Meadow\\nM:4/4\\nL:1/4\\nK:D   \n",
       "19448               82       X:82\\nT:The Old Grey Cat\\nM:4/4\\nL:1/4\\nK:Bm   \n",
       "19449               84         X:84\\nT:Gyre And Gimble\\nM:4/4\\nL:1/4\\nK:A   \n",
       "\n",
       "                                           original_body meter key  \\\n",
       "19445  A/2G/2|\"D\"FA\"A7\"Bc|\"D\"d/2c/2d/2e/2fa|\"Em\"gf\"E7...   4/4   A   \n",
       "19446  (3A/2B/2c/2|\"D\"dA\"A7\"A/2B/2A/2G/2|\"D\"F/2G/2A/2...   4/4   A   \n",
       "19447  (3D/2E/2F/2|\"G\"GG/2A/2B/2G/2B/2d/2|\"C\"e/2f/2g/...   4/4   D   \n",
       "19448  B|\"Em\"eeEE/2F/2|\"Em\"G/2F/2G/2A/2B/2A/2B/2^c/2|...   4/4  Bm   \n",
       "19449  A|\"D\"dAFA|\"Em\"BG\"A7\"EG|\"D\"FAd3/2e/2|\"A7\"f/2g/2...   4/4   A   \n",
       "\n",
       "                                              clean_song  \\\n",
       "19445  M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"|\"Em\"\"E7\"|\"A7\"|...   \n",
       "19446  M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"\"A7\"|\"D\"|\"A7\"|\"...   \n",
       "19447  M:4/4\\nL:1/4\\nK:D\\n|\"G\"|\"C\"\"G\"|\"Am\"|\"Am\"\"D7\"|\"...   \n",
       "19448  M:4/4\\nL:1/4\\nK:Bm\\n|\"Em\"|\"Em\"|\"D\"|\"D\"|\"Em\"|\"E...   \n",
       "19449  M:4/4\\nL:1/4\\nK:A\\n|\"D\"|\"Em\"\"A7\"|\"D\"|\"A7\"\"D\"|\"...   \n",
       "\n",
       "                                            clean_header  ... \"Cm\" \"C7\"  \"C\"  \\\n",
       "19445  M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"|\"Em\"\"E7\"|\"A7\"|...  ...    0    0    0   \n",
       "19446  M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"\"A7\"|\"D\"|\"A7\"|\"...  ...    0    0    0   \n",
       "19447  M:4/4\\nL:1/4\\nK:D\\n|\"G\"|\"C\"\"G\"|\"Am\"|\"Am\"\"D7\"|\"...  ...    0    0    6   \n",
       "19448  M:4/4\\nL:1/4\\nK:Bm\\n|\"Em\"|\"Em\"|\"D\"|\"D\"|\"Em\"|\"E...  ...    0    0    0   \n",
       "19449  M:4/4\\nL:1/4\\nK:A\\n|\"D\"|\"Em\"\"A7\"|\"D\"|\"A7\"\"D\"|\"...  ...    0    0    0   \n",
       "\n",
       "       \"Bm\"  \"Bb\"  \"B7\"  \"B\"  \"Am\"  \"A7\"  \"A\"  \n",
       "19445     0     0     0    0     0     7    2  \n",
       "19446     0     0     0    0     0     6    2  \n",
       "19447     0     0     0    0     4     0    0  \n",
       "19448     0     0     3    0     1     0    0  \n",
       "19449     0     0     0    0     0     7    1  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "644"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df[\"clean_header\"].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab:  \n",
      "\"#'()+,-/1234567=ABCDEFG[]^_abcdefgmz|~\n",
      "vocab_size 40\n",
      "silences  1224\n"
     ]
    }
   ],
   "source": [
    "bodies = \"\"\n",
    "silences = 0\n",
    "for body in training_data_df[\"clean_body\"]:\n",
    "    if 'z' in body:\n",
    "        silences +=1 \n",
    "    bodies += body+\"\\n\"\n",
    "chars = sorted(list(set(bodies)))\n",
    "vocab_size = len(chars)\n",
    "print('vocab: ',''.join(chars))\n",
    "print('vocab_size',vocab_size)\n",
    "print(\"silences \",silences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chars: 10352974\n"
     ]
    }
   ],
   "source": [
    "training_data_text = read_file(relative_path,filename_name)\n",
    "\n",
    "print(\"number of chars:\",len(training_data_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"#'()+,-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(training_data_text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.28.0.dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14.2\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import tiktoken\n",
    "\n",
    "print(wandb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==1.4.0\n",
      "aiohttp==3.8.4\n",
      "aiosignal==1.3.1\n",
      "alembic==1.10.2\n",
      "antlr4-python3-runtime==4.9.3\n",
      "anyio==3.6.2\n",
      "appdirs==1.4.4\n",
      "APScheduler==3.10.1\n",
      "argon2-cffi==21.3.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "arrow==1.2.3\n",
      "asttokens==2.2.1\n",
      "async-timeout==4.0.2\n",
      "attrs==22.2.0\n",
      "audioread==3.0.0\n",
      "av==9.2.0\n",
      "Babel==2.12.1\n",
      "backcall==0.2.0\n",
      "backoff==1.11.1\n",
      "backports.zoneinfo==0.2.1\n",
      "beautifulsoup4==4.11.2\n",
      "binaryornot==0.4.4\n",
      "black==23.1.0\n",
      "bleach==6.0.0\n",
      "cachetools==5.3.0\n",
      "certifi==2022.12.7\n",
      "cffi==1.15.1\n",
      "chardet==5.1.0\n",
      "charset-normalizer==3.1.0\n",
      "click==8.1.3\n",
      "clldutils==3.19.0\n",
      "cloudpickle==2.2.1\n",
      "cmaes==0.9.1\n",
      "cmake==3.25.0\n",
      "codecarbon==1.2.0\n",
      "colorama==0.4.6\n",
      "coloredlogs==15.0.1\n",
      "colorlog==6.7.0\n",
      "comm==0.1.3\n",
      "contourpy==1.0.7\n",
      "cookiecutter==1.7.3\n",
      "csvw==3.1.3\n",
      "cycler==0.11.0\n",
      "dash==2.8.1\n",
      "dash-bootstrap-components==1.4.0\n",
      "dash-core-components==2.0.0\n",
      "dash-html-components==2.0.0\n",
      "dash-table==5.0.0\n",
      "datasets==2.10.1\n",
      "debugpy==1.6.7\n",
      "decorator==5.1.1\n",
      "decord==0.6.0\n",
      "defusedxml==0.7.1\n",
      "detectron2 @ git+https://github.com/facebookresearch/detectron2.git@3ed66980529aadf662f469bca744221cab762e83\n",
      "dill==0.3.4\n",
      "distlib==0.3.6\n",
      "dlinfo==1.2.1\n",
      "docker-pycreds==0.4.0\n",
      "evaluate==0.4.0\n",
      "exceptiongroup==1.1.1\n",
      "execnet==1.9.0\n",
      "executing==1.2.0\n",
      "faiss-cpu==1.7.3\n",
      "fastjsonschema==2.16.3\n",
      "filelock==3.9.1\n",
      "fire==0.5.0\n",
      "Flask==2.2.3\n",
      "flatbuffers==23.3.3\n",
      "fonttools==4.39.0\n",
      "fqdn==1.5.1\n",
      "frozenlist==1.3.3\n",
      "fsspec==2023.3.0\n",
      "fugashi==1.2.1\n",
      "fvcore==0.1.5.post20221221\n",
      "gitdb==4.0.10\n",
      "GitPython==3.1.18\n",
      "google-auth==2.16.2\n",
      "google-auth-oauthlib==0.4.6\n",
      "gql==3.4.0\n",
      "graphql-core==3.2.3\n",
      "greenlet==2.0.2\n",
      "grpcio==1.51.3\n",
      "hf-doc-builder==0.4.0\n",
      "huggingface-hub==0.13.2\n",
      "humanfriendly==10.0\n",
      "hydra-core==1.3.2\n",
      "hypothesis==6.68.3\n",
      "idna==3.4\n",
      "importlib-metadata==6.0.0\n",
      "importlib-resources==5.12.0\n",
      "iniconfig==2.0.0\n",
      "iopath==0.1.9\n",
      "ipadic==1.0.0\n",
      "ipykernel==6.22.0\n",
      "ipython==8.12.0\n",
      "ipython-genutils==0.2.0\n",
      "isodate==0.6.1\n",
      "isoduration==20.11.0\n",
      "isort==5.12.0\n",
      "itsdangerous==2.0.1\n",
      "jedi==0.18.2\n",
      "Jinja2==3.1.2\n",
      "jinja2-time==0.2.0\n",
      "joblib==1.2.0\n",
      "json5==0.9.11\n",
      "jsonpointer==2.3\n",
      "jsonschema==4.17.3\n",
      "jupyter-events==0.6.3\n",
      "jupyter_client==8.1.0\n",
      "jupyter_core==5.2.0\n",
      "jupyter_server==2.5.0\n",
      "jupyter_server_terminals==0.4.4\n",
      "jupyterlab==3.5.1\n",
      "jupyterlab-pygments==0.2.2\n",
      "jupyterlab_server==2.22.0\n",
      "kenlm==0.1\n",
      "kiwisolver==1.4.4\n",
      "language-tags==1.2.0\n",
      "lazy_loader==0.1\n",
      "librosa==0.10.0\n",
      "lit==15.0.7\n",
      "llvmlite==0.39.1\n",
      "lxml==4.9.2\n",
      "Mako==1.2.4\n",
      "Markdown==3.4.1\n",
      "MarkupSafe==2.1.2\n",
      "matplotlib==3.6.2\n",
      "matplotlib-inline==0.1.6\n",
      "mistune==2.0.5\n",
      "mpmath==1.3.0\n",
      "msgpack==1.0.5\n",
      "multidict==6.0.4\n",
      "multiprocess==0.70.12.2\n",
      "mypy-extensions==1.0.0\n",
      "nbclassic==0.5.5\n",
      "nbclient==0.7.3\n",
      "nbconvert==7.3.0\n",
      "nbformat==5.7.3\n",
      "nest-asyncio==1.5.6\n",
      "networkx==3.0\n",
      "nltk==3.8.1\n",
      "notebook==6.5.4\n",
      "notebook_shim==0.2.2\n",
      "numba==0.56.4\n",
      "numpy==1.23.4\n",
      "nvidia-cublas-cu11==11.10.3.66\n",
      "nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "nvidia-cuda-runtime-cu11==11.7.99\n",
      "nvidia-cudnn-cu11==8.5.0.96\n",
      "oauthlib==3.2.2\n",
      "omegaconf==2.3.0\n",
      "onnx==1.13.1\n",
      "onnxruntime==1.14.1\n",
      "onnxruntime-tools==1.7.0\n",
      "optuna==3.1.0\n",
      "packaging==23.0\n",
      "pandas==1.5.2\n",
      "pandocfilters==1.5.0\n",
      "parameterized==0.8.1\n",
      "parso==0.8.3\n",
      "pathspec==0.11.1\n",
      "pathtools==0.1.2\n",
      "pexpect==4.8.0\n",
      "phonemizer==3.2.1\n",
      "pickleshare==0.7.5\n",
      "Pillow==9.4.0\n",
      "pkgutil_resolve_name==1.3.10\n",
      "plac==1.3.5\n",
      "platformdirs==3.1.1\n",
      "plotly==5.13.1\n",
      "pluggy==1.0.0\n",
      "pooch==1.7.0\n",
      "portalocker==2.0.0\n",
      "poyo==0.5.0\n",
      "prometheus-client==0.16.0\n",
      "prompt-toolkit==3.0.38\n",
      "protobuf==3.20.2\n",
      "psutil==5.9.4\n",
      "ptyprocess==0.7.0\n",
      "pure-eval==0.2.2\n",
      "py-cpuinfo==9.0.0\n",
      "py3nvml==0.2.7\n",
      "pyarrow==11.0.0\n",
      "pyasn1==0.4.8\n",
      "pyasn1-modules==0.2.8\n",
      "pycocotools==2.0.6\n",
      "pycparser==2.21\n",
      "pyctcdecode==0.5.0\n",
      "Pygments==2.14.0\n",
      "pygtrie==2.5.0\n",
      "pylatexenc==2.10\n",
      "pynvml==11.5.0\n",
      "pyparsing==3.0.9\n",
      "pypng==0.20220715.0\n",
      "pyrsistent==0.19.3\n",
      "pytesseract==0.3.10\n",
      "pytest==7.2.2\n",
      "pytest-timeout==2.1.0\n",
      "pytest-xdist==3.2.1\n",
      "python-dateutil==2.8.2\n",
      "python-json-logger==2.0.7\n",
      "python-slugify==8.0.1\n",
      "pytz==2022.7.1\n",
      "pytz-deprecation-shim==0.1.0.post0\n",
      "PyYAML==5.4.1\n",
      "pyzmq==25.0.2\n",
      "ray==2.3.0\n",
      "rdflib==6.2.0\n",
      "regex==2022.10.31\n",
      "requests==2.28.2\n",
      "requests-oauthlib==1.3.1\n",
      "requests-toolbelt==0.10.1\n",
      "responses==0.18.0\n",
      "rfc3339-validator==0.1.4\n",
      "rfc3986==1.5.0\n",
      "rfc3986-validator==0.1.1\n",
      "rhoknp==1.2.1\n",
      "rjieba==0.1.11\n",
      "rouge-score==0.1.2\n",
      "rsa==4.9\n",
      "ruff==0.0.256\n",
      "sacrebleu==1.5.1\n",
      "sacremoses==0.0.53\n",
      "safetensors==0.3.0\n",
      "scikit-learn==1.2.2\n",
      "scipy==1.10.1\n",
      "seaborn==0.12.1\n",
      "segments==2.2.1\n",
      "Send2Trash==1.8.0\n",
      "sentencepiece==0.1.97\n",
      "sentry-sdk==1.19.1\n",
      "setproctitle==1.3.2\n",
      "sigopt==8.7.0\n",
      "six==1.16.0\n",
      "smmap==5.0.0\n",
      "sniffio==1.3.0\n",
      "sortedcontainers==2.4.0\n",
      "soundfile==0.12.1\n",
      "soupsieve==2.4\n",
      "soxr==0.3.4\n",
      "SQLAlchemy==2.0.6\n",
      "stack-data==0.6.2\n",
      "SudachiDict-core==20230110\n",
      "SudachiPy==0.6.7\n",
      "sympy==1.11.1\n",
      "tabulate==0.9.0\n",
      "tenacity==8.2.2\n",
      "tensorboard==2.12.0\n",
      "tensorboard-data-server==0.7.0\n",
      "tensorboard-plugin-wit==1.8.1\n",
      "tensorboardX==2.6\n",
      "termcolor==2.2.0\n",
      "terminado==0.17.1\n",
      "text-unidecode==1.3\n",
      "threadpoolctl==3.1.0\n",
      "tiktoken==0.3.3\n",
      "timeout-decorator==0.5.0\n",
      "timm==0.6.12\n",
      "tinycss2==1.2.1\n",
      "tokenizers==0.13.2\n",
      "tomli==2.0.1\n",
      "torch==2.0.0+cu117\n",
      "torchaudio==2.0.0+cu117\n",
      "torchvision==0.15.0+cu117\n",
      "tornado==6.2\n",
      "tqdm==4.65.0\n",
      "traitlets==5.9.0\n",
      "-e git+https://github.com/huggingface/transformers@f7329751fe5c43365751951502c00df5a4654359#egg=transformers\n",
      "triton==2.0.0\n",
      "typing_extensions==4.5.0\n",
      "tzdata==2022.7\n",
      "tzlocal==4.2\n",
      "unidic==1.1.0\n",
      "unidic-lite==1.0.8\n",
      "uri-template==1.2.0\n",
      "uritemplate==4.1.1\n",
      "urllib3==1.26.15\n",
      "virtualenv==20.21.0\n",
      "wandb==0.14.2\n",
      "wasabi==0.10.1\n",
      "wcwidth==0.2.6\n",
      "webcolors==1.13\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.5.1\n",
      "Werkzeug==2.2.3\n",
      "xmltodict==0.13.0\n",
      "xxhash==3.2.0\n",
      "yacs==0.1.8\n",
      "yarl==1.8.2\n",
      "zipp==3.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile  docker-compose.yaml  overrides.json\n",
      "README.md   notebooks\t\t requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'notebooks/nanoGPT'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m      3\u001b[0m nano_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnotebooks/nanoGPT\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 4\u001b[0m os\u001b[39m.\u001b[39;49mchdir(nano_path)\n\u001b[1;32m      5\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mls\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'notebooks/nanoGPT'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "nano_path = 'notebooks/nanoGPT'\n",
    "os.chdir(nano_path)\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 10,352,974\n",
      "all the unique characters: \n",
      "\"#'()+,-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
      "vocab size: 46\n",
      "train has 9,317,676 tokens\n",
      "val has 1,035,298 tokens\n"
     ]
    }
   ],
   "source": [
    "!python3 data/shakespeare_char/prepare.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding config with config/train_shakespeare_char.py:\n",
      "# train a miniature character-level shakespeare model\n",
      "# good for debugging and playing on macbooks and such\n",
      "\n",
      "out_dir = 'out-shakespeare-char'\n",
      "eval_interval = 100 # keep frequent because we'll overfit\n",
      "eval_iters = 500\n",
      "log_interval = 50 # don't print too too often\n",
      "\n",
      "# we expect to overfit on this small dataset, so only save when val improves\n",
      "always_save_checkpoint = True\n",
      "\n",
      "wandb_log = False # override via command line if you like\n",
      "wandb_project = 'abc-char'\n",
      "wandb_run_name = 'mini-char-gpt'\n",
      "\n",
      "dataset = 'shakespeare_char'\n",
      "batch_size = 64\n",
      "block_size = 512 # context of up to 512 previous characters\n",
      "\n",
      "# baby GPT model :)\n",
      "n_layer = 6\n",
      "n_head = 6\n",
      "n_embd = 384\n",
      "dropout = 0.2\n",
      "\n",
      "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
      "max_iters = 5000\n",
      "lr_decay_iters = 500 # make equal to max_iters usually\n",
      "min_lr = 1e-4 # learning_rate / 10 usually\n",
      "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
      "\n",
      "warmup_iters = 5 # not super necessary potentially\n",
      "\n",
      "# on macbook also add\n",
      "# device = 'cpu'  # run on cpu only\n",
      "# compile = False # do not torch compile the model\n",
      "\n",
      "found vocab_size = 46 (inside data/shakespeare_char/meta.pkl)\n",
      "Initializing a new model from scratch\n",
      "number of parameters: 10.64M\n",
      "using fused AdamW: True\n",
      "compiling the model... (takes a ~minute)\n",
      "step 0: train loss 3.8202, val loss 3.8613\n",
      "[2023-04-08 10:02:38,663] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 10:02:38,883] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 10:02:39,195] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 10:02:39,376] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 10:02:39,628] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 10:02:39,874] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 10:02:40,122] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 10:02:40,301] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 10:02:40,546] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 10:02:40,724] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 10:02:40,975] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 10:02:41,155] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "iter 0: loss 3.8384, time 69098.62ms, mfu -100.00%\n",
      "iter 50: loss 1.6275, time 7349.36ms, mfu 4.46%\n",
      "step 100: train loss 1.4094, val loss 1.5241\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 100: loss 1.4248, time 61010.90ms, mfu 4.07%\n",
      "iter 150: loss 1.3171, time 7345.83ms, mfu 4.11%\n",
      "step 200: train loss 1.2303, val loss 1.3553\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 200: loss 1.2556, time 60145.01ms, mfu 3.75%\n",
      "iter 250: loss 1.1338, time 7147.72ms, mfu 3.83%\n",
      "step 300: train loss 1.0237, val loss 1.1514\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 300: loss 1.0996, time 59433.14ms, mfu 3.50%\n",
      "iter 350: loss 0.9763, time 7153.19ms, mfu 3.61%\n",
      "step 400: train loss 0.8982, val loss 1.0139\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 400: loss 0.9295, time 59409.57ms, mfu 3.31%\n",
      "iter 450: loss 0.9342, time 7327.51ms, mfu 3.42%\n",
      "step 500: train loss 0.8233, val loss 0.9279\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 500: loss 0.8425, time 59323.91ms, mfu 3.14%\n",
      "iter 550: loss 0.8518, time 7152.31ms, mfu 3.28%\n",
      "step 600: train loss 0.7570, val loss 0.8544\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 600: loss 0.8011, time 59301.58ms, mfu 3.01%\n",
      "iter 650: loss 0.7815, time 7148.49ms, mfu 3.17%\n",
      "step 700: train loss 0.7093, val loss 0.7992\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 700: loss 0.7505, time 59287.21ms, mfu 2.90%\n",
      "iter 750: loss 0.7332, time 7150.95ms, mfu 3.07%\n",
      "step 800: train loss 0.6677, val loss 0.7510\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 800: loss 0.7048, time 59259.37ms, mfu 2.82%\n",
      "iter 850: loss 0.7021, time 7333.57ms, mfu 2.98%\n",
      "step 900: train loss 0.6291, val loss 0.7066\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 900: loss 0.6705, time 59621.85ms, mfu 2.74%\n",
      "iter 950: loss 0.6713, time 7150.59ms, mfu 2.93%\n",
      "step 1000: train loss 0.5897, val loss 0.6601\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 1000: loss 0.6636, time 60777.36ms, mfu 2.69%\n",
      "iter 1050: loss 0.6316, time 7150.94ms, mfu 2.88%\n",
      "step 1100: train loss 0.5495, val loss 0.6168\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 1100: loss 0.5899, time 59257.01ms, mfu 2.64%\n",
      "iter 1150: loss 0.5928, time 7344.30ms, mfu 2.83%\n",
      "step 1200: train loss 0.5084, val loss 0.5718\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 1200: loss 0.5901, time 59226.86ms, mfu 2.60%\n",
      "iter 1250: loss 0.5716, time 7151.61ms, mfu 2.80%\n",
      "step 1300: train loss 0.4697, val loss 0.5299\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 1300: loss 0.5421, time 60811.61ms, mfu 2.57%\n",
      "iter 1350: loss 0.5354, time 7150.00ms, mfu 2.77%\n",
      "step 1400: train loss 0.4342, val loss 0.4893\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 1400: loss 0.5207, time 61022.24ms, mfu 2.55%\n",
      "iter 1450: loss 0.4995, time 7828.25ms, mfu 2.71%\n",
      "step 1500: train loss 0.3975, val loss 0.4482\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 1500: loss 0.4603, time 62099.69ms, mfu 2.49%\n",
      "iter 1550: loss 0.4620, time 7482.95ms, mfu 2.68%\n",
      "step 1600: train loss 0.3656, val loss 0.4102\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 1600: loss 0.4413, time 61541.75ms, mfu 2.47%\n",
      "iter 1650: loss 0.4164, time 7442.78ms, mfu 2.66%\n",
      "step 1700: train loss 0.3334, val loss 0.3745\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 1700: loss 0.4351, time 61790.17ms, mfu 2.45%\n",
      "iter 1750: loss 0.4102, time 7342.64ms, mfu 2.65%\n",
      "step 1800: train loss 0.3060, val loss 0.3422\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 1800: loss 0.3937, time 61265.10ms, mfu 2.44%\n",
      "iter 1850: loss 0.3606, time 7148.43ms, mfu 2.65%\n",
      "step 1900: train loss 0.2789, val loss 0.3102\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 1900: loss 0.3648, time 58898.63ms, mfu 2.44%\n",
      "iter 1950: loss 0.3504, time 7110.74ms, mfu 2.66%\n",
      "step 2000: train loss 0.2557, val loss 0.2826\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 2000: loss 0.3446, time 59296.49ms, mfu 2.45%\n",
      "iter 2050: loss 0.3379, time 7108.30ms, mfu 2.66%\n",
      "step 2100: train loss 0.2346, val loss 0.2579\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 2100: loss 0.3065, time 58875.93ms, mfu 2.45%\n",
      "iter 2150: loss 0.3149, time 7422.18ms, mfu 2.65%\n",
      "step 2200: train loss 0.2160, val loss 0.2365\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 2200: loss 0.3073, time 59248.78ms, mfu 2.44%\n",
      "iter 2250: loss 0.2855, time 7144.98ms, mfu 2.65%\n",
      "step 2300: train loss 0.1990, val loss 0.2156\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 2300: loss 0.2755, time 60434.86ms, mfu 2.44%\n",
      "iter 2350: loss 0.2721, time 8426.69ms, mfu 2.59%\n",
      "step 2400: train loss 0.1822, val loss 0.1964\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 2400: loss 0.2495, time 69833.72ms, mfu 2.38%\n",
      "iter 2450: loss 0.2573, time 8426.73ms, mfu 2.53%\n",
      "step 2500: train loss 0.1675, val loss 0.1792\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 2500: loss 0.2463, time 69963.13ms, mfu 2.32%\n",
      "iter 2550: loss 0.2278, time 8393.12ms, mfu 2.48%\n",
      "step 2600: train loss 0.1554, val loss 0.1652\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 2600: loss 0.2281, time 69862.61ms, mfu 2.28%\n",
      "iter 2650: loss 0.2265, time 8330.34ms, mfu 2.44%\n",
      "step 2700: train loss 0.1434, val loss 0.1516\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 2700: loss 0.2190, time 61004.32ms, mfu 2.25%\n",
      "iter 2750: loss 0.2019, time 7339.19ms, mfu 2.47%\n",
      "step 2800: train loss 0.1328, val loss 0.1391\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 2800: loss 0.2071, time 59579.14ms, mfu 2.28%\n",
      "iter 2850: loss 0.1874, time 7161.96ms, mfu 2.51%\n",
      "step 2900: train loss 0.1239, val loss 0.1276\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 2900: loss 0.1980, time 60449.12ms, mfu 2.31%\n",
      "iter 2950: loss 0.1860, time 7212.03ms, mfu 2.54%\n",
      "step 3000: train loss 0.1160, val loss 0.1205\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 3000: loss 0.1840, time 60894.69ms, mfu 2.34%\n",
      "iter 3050: loss 0.1761, time 7450.31ms, mfu 2.54%\n",
      "step 3100: train loss 0.1063, val loss 0.1095\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 3100: loss 0.1733, time 62077.60ms, mfu 2.34%\n",
      "iter 3150: loss 0.1701, time 7442.38ms, mfu 2.55%\n",
      "step 3200: train loss 0.0997, val loss 0.1009\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 3200: loss 0.1584, time 60552.93ms, mfu 2.35%\n",
      "iter 3250: loss 0.1581, time 7328.46ms, mfu 2.56%\n",
      "step 3300: train loss 0.0926, val loss 0.0939\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 3300: loss 0.1489, time 60825.03ms, mfu 2.36%\n",
      "iter 3350: loss 0.1555, time 7388.42ms, mfu 2.57%\n",
      "step 3400: train loss 0.0875, val loss 0.0877\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 3400: loss 0.1554, time 62003.64ms, mfu 2.36%\n",
      "iter 3450: loss 0.1419, time 7420.44ms, mfu 2.57%\n",
      "step 3500: train loss 0.0818, val loss 0.0818\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 3500: loss 0.1330, time 61791.47ms, mfu 2.36%\n",
      "iter 3550: loss 0.1371, time 7491.88ms, mfu 2.56%\n",
      "step 3600: train loss 0.0785, val loss 0.0784\n",
      "saving checkpoint to out-shakespeare-char\n",
      "iter 3600: loss 0.1332, time 61167.05ms, mfu 2.36%\n",
      "^C\n",
      "Process ForkProcess-4:\n",
      "Process ForkProcess-17:\n",
      "Process ForkProcess-8:\n",
      "Process ForkProcess-10:\n",
      "Process ForkProcess-20:\n",
      "Process ForkProcess-3:\n",
      "Process ForkProcess-2:\n",
      "Process ForkProcess-19:\n",
      "Process ForkProcess-14:\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-6:\n",
      "Process ForkProcess-15:\n",
      "Process ForkProcess-16:\n",
      "Process ForkProcess-13:\n",
      "Process ForkProcess-1:\n",
      "Process ForkProcess-5:\n",
      "Process ForkProcess-12:\n",
      "Process ForkProcess-18:\n",
      "Process ForkProcess-11:\n",
      "Process ForkProcess-9:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 97, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 293, in <module>\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\", line 487, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\", line 200, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py config/train_shakespeare_char.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-shakespeare-char\n",
      "Overriding: start = M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "number of parameters: 10.64M\n",
      "Loading meta from data/shakespeare_char/meta.pkl...\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "|\"C\"\"F\"|\"G\"|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|\"C\"\"F\"|\"G\"|]\n",
      "[ac]|\"C\"[g3/2B3/2][f/2B/2][eB][dB][cB]|[c3/2][c/2A/2][gB][cA]|\"F\"[c3/2A3/2][c/2A/2][gA][cA]|\"G\"[B3/2][c/2B/2][dB][eB]|\"C\"[d3/2B3/2][dB]|\"F\"[c3/2A3/2][c/2A/2][fA][ac]|\"G\"[f2A2][fA][ac]|\"C\"[g3/2B3/2][f/2B/2][eB]|\"F\"[c3/2A3/2][c/2A/2][fA][ac]|\"G\"g3/2a/2g/2][f/2B/2][eB]|\"C\"[e3/2B3/2][dB][eB]|\"F\"[f2A2][fA]c|\"G\"B2G2][fA]|\"C\"[g3/2B3/2][dB][eB]|\"F\"[f2A2][fA][ac]|\"G\"[f2B2][fA]|\"C\"[e3/2][eB]|\"F\"[f2A2][fA]|\"G\"[B2d2][ce][df]|\"G\"[B2d2][ce]\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "|\"C\"|\"C\"|\"D\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|\"C\"|\"F\"|\"G\"|\"C\"|\"C\"|]\"C\"[ac][gB]|[c3e3]|\"F\"f2A2][gA]c|\"G\"G/2B/2][A/2F/2][GB][Fc]|\"G\"[G/2B/2][GB][A/2][GB]|\"C\"[c3E3]|\"F\"[F2A2][GB]|[A/2c/2][Ac][Bd]|\"G\"[B3d3]|\"C\"[c2e2][df]|[e3g3]|\"C\"[e2g2][df]|[e2g2][df]|\"F\"[c2e2][cf]|[B3g3]|\"G\"[B2d2][ce]|\"C\"[c2e2][df]|\"F\"[c2e2][Bd]|[A2c2][Bd]|\"G\"[B2d2][ce]|\"C\"[c2e2][df]|\"F\"[c2e2][Bd]|[A2c2][Bd]|\"G\"[F2A2][GB]|[C3E3]|[C3E3]|\"C\"[C3E3]|\"E\"[^G2e2][Af]|[^G2e2][Fd]|[E\"[F2d2][Ec]|[D2c2][DB]|[C2A2][CE]|[D2B2][CA]|[C2A2][Ec]|[B,2G2][D\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "\"C\"[C2E2][DF]|[E3G3]|\"F\"[F2A2][GB]|[A3c3]|\"G\"[B2d2][ce]|[d3f3]|\"C\"[c2e2][df]|[e3g3]|\"C\"[e2g2][fa]|[e2g2][df]|\"F\"[c2e2][Bd]|[A2c2][GB]|\"G\"[F2A2][EG]|[D2F2][CE]|\"C\"[C3E3]|[C3E3]|\"E\"[^G2e2][Af]|[^G2e2][Fd]|[E2c2][Fd]|[E2c2][DB]|[E2c2][DB]|[E2c2][DB]|\"Am\"[C3A3]|[C3G3A3]|\"Dm\"[F2d2][Ge]|[F2d2][Ec]|[D2B2][CA]|[B,2G2][CA]|[B,2G2][A,F]|[G,2E2][G,D]|\"G\"[G,3D3]|]\n",
      "\n",
      "M:6/8\n",
      "L:1/8\n",
      "K:E\n",
      "|\"G\"\"D\"|\"G\"|\"G\"\"D\"|\"G\"\"D\"|\"G\"\"D\"|\"G\"\"Em\"|\"Am\"\"D\"|\"G\"|\"D\"\"A\"|\"D\"|\"A\"\"E\"|\"A\"|\"D\"\"A\"|\"D\"|\"G\"\"D\"|\"G\"|\"G\"\"D\"|\"G\"\"D\"|\"G\"\"Em\"|\"Am\"\"D\"|\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "c|\"C\"[a/2g/2c/2][fd]|[c3e3]|\"F\"[f2A2][ac]|[a3c3]|\"G\"b3/2b/2bb|\"G\"ag\"C\"e3/2g/2|\"F\"fdfe|\"G\"g/2a/2g/2e/2g/2bb|\"C\"c'ac'\"C\"e/2g3/2c'/2|\"C\"e/2g3/2a/2g/2f/2|\"F\"a/2b/2a/2g/2f/2a/2g/2f/2|\"G\"gd\"C\"e/2g3/2e/2|\"C\"g/2e/2\"D\"d2|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:B\n",
      "|\"D\"|\"Em\"|\"Em\"\"A7\"|\"D\"|\"Em\"\"A7\"|\"D\"|\"D\"|\"G\"\"A7\"|\"D\"\"A7\"|\"D\"|\"D\"|\"Em\"|\"Em\"\"A7\"|\"D\"|\"Em\"\"A7\"|\"D\"|\"D\"|\"G\"\"A7\"|\"D\"\"A7\"|\"D\"|\"D\"|\"Em\"|\"Em\"\"A7\"|\"D\"|\"D\"|\"G\"\"A7\"|\"D\"\"A7\"|\"D\"|\"D\"|\"Em\"|\"Em\"\"A7\"|\"D\"|\"D\"|\"G\"\"A7\"|\"D\"\"A7\"|\"D\"|]\n",
      "|\"D\"|\"Em\"|\"Em\"\"A7\"|\"D\"|\"Em\"\"A7\"|\"D\"|\"Em\"\"A7\"|\"D\"|\"D\"|\"G\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "|\"F\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|\"C\"|\"F\"|\"G\"|\"C\"|\"D7\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|\"C\"|\"F\"|\"G\"|\"C\"|\"D7\"|\"G\"|]\n",
      "|\"C\"|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|\"D7\"|\"G\"|]\"C\"c2c|\"C\"G/2c3/2E|\"F\"F/2G/2A3/2c/2|\"G\"d2G|\"C\"EGc|\"F\"A3/2G/2F|\"E7\"EGc|\"F\"dfe|\"G\"dAB|\"C\"c2c|\"F\"A3/2c/2A|\"G\"G2G|\"C\"z2c|\"C\"e2c|\"D7\"dcA|\"G\"G2A|\"G\"G2/2|\"C\"zF2|\"F\"A2c|\"G\"G2A|\"C\"G2c|\"C\"G2c|\"D7\"zF|\"G\"G2A|\"G\"G2A|\"C\"c2c|\"F\"A2c|\"G\"d2d|\"C\"e2\"D7\"d2|\"G\"G2A|\"G\"G2A|\"C\"B2c|\"F\"dcA|\"E7\"e3d|\"Am\"c2B|\"D7\"d2A|\"G\"G2A|\"C\"c3/2c/2c|\"C\"edc|\"F\"dcA|\"G\"G2G|\"C\"\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "|\"C\"|\"F\"|\"G\"|\"C\"|\"C\"|\"D\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|\"F\"|\"G\"|]\n",
      "|\"C\"|\"C\"|\"F\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|\"F\"|\"G\"|][C3|\"C\"[C3/2][f/2B/2][eB][dB]|\"F\"[c3/2A3/2][c/2A/2][gA][cA]|\"G\"[B3/2][c/2B/2][cB][cB]|\"C\"[c3/2B3/2][dB]|\"F\"[c3/2A3/2][c/2A/2][gA][cA]|\"G\"[B3/2][c/2B/2][dB][eB]|\"C\"[e3/2][dB]|\"F\"[c3/2A3/2][c/2A/2][gA][cA]|\"G\"[B3/2][c/2B/2][dB]|\"C\"[c2E2][df]|[e3/2][df][eB]|\"F\"[c3/2A3/2][c/2A/2][gA][cA]|\"G\"[B3/2][c/2B/2][dB][eB]|\"C\"[c2e2][dB]|\"F\"[c3/2][c/22A2][B/2c/2d/2|[c3A3]|\"G\"[B3\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "e|\"C\"g2a|\"C\"g2a|\"F\"fa2|\"G\"gg/2a/2g/2e/2d/2|\"G\"g/2f/2e/2de/2d/2|\"Am\"c/2d/2c/2A/2B/2c/2A/2|\"C\"G/2A/2G/2E/2G/2A/2E/2D/2|\"C\"G/2A/2G/2F/2E/2D/2E/2G/2A/2|\"F\"c/2A/2c/2d/2c/2A/2F/2|\"G\"G/2A/2B/2G/2F/2G/2|\"C\"G/2A/2G/2E/2G/2A/2c/2d/2|\"C\"e/2^d/2e/2f/2g/2a/2g/2e/2|\"Dm\"c/2d/2c/2\"G\"B/2G/2A/2B/2|\"C\"c3e/2f/2|\"C\"g2-g/2a/2g|e2-e/2g/2e/2d/2|\"F\"c/2d/2c/2B/2c/2B/2A/2|\"G\"G/2A/2B/2\"C\"c|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:B\n",
      "|\"A\"|\"A\"|\"D\"\"E7\"|\"A\"|\"A\"|\"D\"\"E7\"|\"F#m\"|\"B7\"|\"E7\"|\"A\"|\"A\"|\"D\"\"E7\"|\"A\"|\"A\"|\"D\"\"E7\"|\"F#m\"|\"B7\"|\"E7\"|\"A\"|\"A\"|\"D\"\"E7\"|\"F\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "\"C\"[C3E3|\"F\"[F2A2][GB]|[A3c3]|\"G\"[B2d2][ce]|[d3f3]|\"C\"[c2e2][df]|[e3g3]|\"C\"[e2g2][fa]|[e2g2][df]|\"F\"[c2e2][Bd]|\"G\"[F2A2][EG]|[C3E3]|\"C\"[C3E3]|\"E\"[^G2e2][Af]|[^G2e2][Fd]|[E2c2][DB]|[E2c2][DB]|[E2c2][DB]|\"Am\"[C3A3]|[C3G3A3]|\"D\"[F2d2][Ge]|[F2d2][Ec]|[D2B2][CA]|[B,2G2][CA]|[B,2G2][A,F]|[G,2E2][G,D]|\"G\"[G,3D3]|]\n",
      "\n",
      "M:6/8\n",
      "L:1/8\n",
      "K:Db\n",
      "|\"G\"\"D\"|\"G\"|\"G\"\"D\"|\"G\"\"D\"|\"G\"\"Em\"|\"Am\"\"D\"|\"G\"|\"D\"\"A\"|\"D\"|\"A\"\"E\"|\"A\"|\"D\"\"A\"|\"D\"|\"Em\"\"A\"|\"D\"|\"G\"\"D\"|\"G\"|\"G\"\"D\"|\"G\"\"D\"|\"G\"\"Em\"|\"Am\"\"D\"|\"G\"|\"D\"\"A\"|\"D\"|\"A\"\"E\"|\"A\"|\"D\"\"A\"|\"D\"|\"A\"\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "|\"C\"|\"F\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|\"C\"|\"F\"|\"G\"|\"C\"|\"D7\"|\"G\"|]\"C\"[C2E2][DF]|[E3G3]|\"F\"[F2A2][GB]|[A3c3]|\"G\"[B2d2][ce]|[d3f3]|\"C\"[c2e2][df]|[e2g2][df]|[e2g2][df]|\"F\"[c2e2][Bd]|[A2c2][GB]|[A2c2][FA][GB]|[C2A2][FA]|\"G\"[G,2E2][DB]|[C3E3]|\"C\"[C3E3]|[C3E3]|\"E\"[^G2e2][Af]|[^G2e2][Af]|[^G2e2][Fd]|[E2c2][DB]|[E2c2][CE]|\"Am\"[C3G3A3]|[C3A3]|\"Dm\"[F2d2][Ge]|[F2d2][Ec]|[D2B2][Ec]|[D2B2][CA]|[B,2G2][CA]|[B,2G2][A,F]|[G,2E2][G,D]|\"G\"[G,3D3]|]\n",
      "\n",
      "M:6/8\n",
      "L:1/8\n",
      "K:A\n",
      "|\"G\"\"D\"|\"G\"|\"G\"\"D\"|\"G\"\"D\"|\"G\"\"D\"|\"G\"\"Em\"|\"Am\"\"\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "\"C\"[ac]|[g3/2B3/2][f/2B/2][eB][dB]|\"F\"[c3/2A3/2][c/2A/2][gA][cA]|\"G\"[B3/2][c/2B/2][gB]|[B3/2][cB][dB]|\"C\"[c2E2][df]|\"F\"[c3/2A3/2][c/2A/2][fA][ac]|\"G\"[b3/2B3/2][f/2B/2][eB]|\"C\"[e3/2][eB][dB]|\"F\"[c3/2A3/2][c/2A/2][gA]|[c3/2][c/2B/2][dB][eB]|\"F\"[c3/2A3/2][fA][ac]|\"C\"[g3/2B3/2][f/2B/2][eB][dB]|\"F\"[c3/2A3/2][c/2A/2][gA][cA]|\"C\"[c3/2B3/2][c/2B/2][dB][eB]|\"F\"[f2A2][fA][fA]c|\"F\"A/2d/2c/2A/2d/2c/2A-|A/2c/2f/2c/2a/2c/2f/2A/2|\"F\"A/2d/2c/2A/2d/2c/2A-|A/2c/2f/2c/2a/2c/2f/2A/2|\"F\"A/2d/2c/2A|\"C\"=B/2c/2e/2c/2g\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    " !python3 sample.py --out_dir=out-shakespeare-char --start='M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
