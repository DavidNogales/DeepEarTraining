{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def load_dataframe(relative_path,dataframe_name):\n",
    "    df = pd.read_pickle(f'{relative_path}/{dataframe_name}.pkl')    \n",
    "    return df\n",
    "\n",
    "def read_file(relative_path,file_name):\n",
    "    text= \"\"\n",
    "    with open(f'{relative_path}/{file_name}.abc','r') as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unit_note_length', 'tuneBook', 'title', 'reference_number',\n",
       "       'original_header', 'original_body', 'meter', 'key', 'clean_song',\n",
       "       'clean_header', 'clean_body', 'chord_progression', '\"fm\"', '\"ff'\"',\n",
       "       '\"f7\"', '\"em\"', '\"ee'\"', '\"e7\"', '\"e\"', '\"dm\"', '\"dd'\"', '\"d7\"', '\"d\"',\n",
       "       '\"cm\"', '\"cc'\"', '\"c7\"', '\"c#m\"', '\"c#7\"', '\"c\"', '\"Gm\"', '\"Gg\"',\n",
       "       '\"Gd'\"', '\"G7\"', '\"G#m\"', '\"G#7\"', '\"G\"', '\"Fm\"', '\"Ff\"', '\"Fc'\"',\n",
       "       '\"F7\"', '\"F#m\"', '\"F#7\"', '\"F\"', '\"Em\"', '\"Eb\"', '\"E7\"', '\"E#m\"',\n",
       "       '\"E#7\"', '\"E\"', '\"Dm\"', '\"Da\"', '\"D7\"', '\"D#m\"', '\"D#7\"', '\"D\"', '\"Cm\"',\n",
       "       '\"Cg\"', '\"C7\"', '\"C#m\"', '\"C#7\"', '\"C\"', '\"Bm\"', '\"Bf\"', '\"Bb\"', '\"B7\"',\n",
       "       '\"B#m\"', '\"B#7\"', '\"B\"', '\"Am\"', '\"Ae'\"', '\"Aa\"', '\"A7\"', '\"A#m\"',\n",
       "       '\"A#7\"', '\"A\"'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_path =\"notebooks/data/final_dataset\"\n",
    "filename_name = 'clean_augmented_data'\n",
    "#filename_name = 'clean_original_training_data'\n",
    "#relative_path =\"notebooks/data/original_dataset\"\n",
    "training_data_df = load_dataframe(relative_path,filename_name)\n",
    "training_data_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_note_length</th>\n",
       "      <th>tuneBook</th>\n",
       "      <th>title</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>original_header</th>\n",
       "      <th>original_body</th>\n",
       "      <th>meter</th>\n",
       "      <th>key</th>\n",
       "      <th>clean_song</th>\n",
       "      <th>clean_header</th>\n",
       "      <th>...</th>\n",
       "      <th>\"B#m\"</th>\n",
       "      <th>\"B#7\"</th>\n",
       "      <th>\"B\"</th>\n",
       "      <th>\"Am\"</th>\n",
       "      <th>\"Ae'\"</th>\n",
       "      <th>\"Aa\"</th>\n",
       "      <th>\"A7\"</th>\n",
       "      <th>\"A#m\"</th>\n",
       "      <th>\"A#7\"</th>\n",
       "      <th>\"A\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9491</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Grandpa's</td>\n",
       "      <td>78</td>\n",
       "      <td>X:78\\nT:Grandpa's\\nM:4/4\\nL:1/4\\nK:Amajor</td>\n",
       "      <td>E/2D/2|\"A,\"CE\"E7\"FG|\"A,\"A/2G/2A/2B/2ce|\"B,m\"dc...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9492</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>The Girl With The Green Hat On</td>\n",
       "      <td>79</td>\n",
       "      <td>X:79\\nT:The Girl With The Green Hat On\\nM:4/4\\...</td>\n",
       "      <td>(3E/2F/2G/2|\"A,\"AE\"E7\"E/2F/2E/2D/2|\"A,\"C/2D/2E...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9493</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Green Meadow</td>\n",
       "      <td>80</td>\n",
       "      <td>X:80\\nT:Green Meadow\\nM:4/4\\nL:1/4\\nK:Dmajor</td>\n",
       "      <td>(3A,/2B,/2C/2|\"D\"DD/2E/2F/2D/2F/2A/2|\"G,\"B/2c/...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>D</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9494</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>The Old Grey Cat</td>\n",
       "      <td>82</td>\n",
       "      <td>X:82\\nT:The Old Grey Cat\\nM:4/4\\nL:1/4\\nK:Bminor</td>\n",
       "      <td>F|\"B,m\"BBB,B,/2C/2|\"B,m\"D/2C/2D/2E/2F/2E/2F/2^...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>Bm</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9495</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Gyre And Gimble</td>\n",
       "      <td>84</td>\n",
       "      <td>X:84\\nT:Gyre And Gimble\\nM:4/4\\nL:1/4\\nK:Amajor</td>\n",
       "      <td>E|\"A,\"AECE|\"B,m\"FD\"E7\"B,D|\"A,\"CEA3/2B/2|\"E7\"c/...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unit_note_length          tuneBook                           title  \\\n",
       "9491              1/4  dataset_min5.abc                       Grandpa's   \n",
       "9492              1/4  dataset_min5.abc  The Girl With The Green Hat On   \n",
       "9493              1/4  dataset_min5.abc                    Green Meadow   \n",
       "9494              1/4  dataset_min5.abc                The Old Grey Cat   \n",
       "9495              1/4  dataset_min5.abc                 Gyre And Gimble   \n",
       "\n",
       "     reference_number                                    original_header  \\\n",
       "9491               78          X:78\\nT:Grandpa's\\nM:4/4\\nL:1/4\\nK:Amajor   \n",
       "9492               79  X:79\\nT:The Girl With The Green Hat On\\nM:4/4\\...   \n",
       "9493               80       X:80\\nT:Green Meadow\\nM:4/4\\nL:1/4\\nK:Dmajor   \n",
       "9494               82   X:82\\nT:The Old Grey Cat\\nM:4/4\\nL:1/4\\nK:Bminor   \n",
       "9495               84    X:84\\nT:Gyre And Gimble\\nM:4/4\\nL:1/4\\nK:Amajor   \n",
       "\n",
       "                                          original_body meter key  \\\n",
       "9491  E/2D/2|\"A,\"CE\"E7\"FG|\"A,\"A/2G/2A/2B/2ce|\"B,m\"dc...   4/4   A   \n",
       "9492  (3E/2F/2G/2|\"A,\"AE\"E7\"E/2F/2E/2D/2|\"A,\"C/2D/2E...   4/4   A   \n",
       "9493  (3A,/2B,/2C/2|\"D\"DD/2E/2F/2D/2F/2A/2|\"G,\"B/2c/...   4/4   D   \n",
       "9494  F|\"B,m\"BBB,B,/2C/2|\"B,m\"D/2C/2D/2E/2F/2E/2F/2^...   4/4  Bm   \n",
       "9495  E|\"A,\"AECE|\"B,m\"FD\"E7\"B,D|\"A,\"CEA3/2B/2|\"E7\"c/...   4/4   A   \n",
       "\n",
       "                                             clean_song  \\\n",
       "9491  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...   \n",
       "9492  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...   \n",
       "9493  M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...   \n",
       "9494  M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...   \n",
       "9495  M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...   \n",
       "\n",
       "                                           clean_header  ... \"B#m\" \"B#7\"  \"B\"  \\\n",
       "9491  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"|\"Bm\"\"B7\"|\"E7\"|...  ...     0     0    0   \n",
       "9492  M:4/4\\nL:1/4\\nK:A\\n|\"A\"\"E7\"|\"A\"\"E7\"|\"A\"|\"E7\"|\"...  ...     0     0    0   \n",
       "9493  M:4/4\\nL:1/4\\nK:D\\n|\"D\"|\"G\"\"D\"|\"Em\"|\"Em\"\"A7\"|\"...  ...     0     0    0   \n",
       "9494  M:4/4\\nL:1/4\\nK:Bm\\n|\"Bm\"|\"Bm\"|\"A\"|\"A\"|\"Bm\"|\"B...  ...     0     0    0   \n",
       "9495  M:4/4\\nL:1/4\\nK:A\\n|\"A\"|\"Bm\"\"E7\"|\"A\"|\"E7\"\"A\"|\"...  ...     0     0    0   \n",
       "\n",
       "      \"Am\"  \"Ae'\"  \"Aa\"  \"A7\"  \"A#m\"  \"A#7\"  \"A\"  \n",
       "9491     0      0     0     0      0      0    9  \n",
       "9492     0      0     0     0      0      0    9  \n",
       "9493     0      0     0     7      0      0    0  \n",
       "9494     0      0     0     0      0      0    5  \n",
       "9495     0      0     0     0      0      0   12  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "373"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df[\"clean_header\"].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1257"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df[\"clean_body\"].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab:  \n",
      "\"#'(),-/1234567=ABCDEFG[]^_abcdefgmz|~\n",
      "vocab_size 39\n",
      "silences  516\n"
     ]
    }
   ],
   "source": [
    "bodies = \"\"\n",
    "silences = 0\n",
    "for body in training_data_df[\"clean_body\"]:\n",
    "    if 'z' in body:\n",
    "        silences +=1 \n",
    "    bodies += body+\"\\n\"\n",
    "chars = sorted(list(set(bodies)))\n",
    "vocab_size = len(chars)\n",
    "print('vocab: ',''.join(chars))\n",
    "print('vocab_size',vocab_size)\n",
    "print(\"silences \",silences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chars: 4062773\n"
     ]
    }
   ],
   "source": [
    "training_data_text = read_file(relative_path,filename_name)\n",
    "\n",
    "print(\"number of chars:\",len(training_data_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'training_data_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chars \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\u001b[39mlist\u001b[39m(\u001b[39mset\u001b[39m(training_data_text)))\n\u001b[1;32m      2\u001b[0m vocab_size \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(chars)\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(chars))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'training_data_text' is not defined"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(training_data_text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.28.0.dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14.2\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import tiktoken\n",
    "\n",
    "print(wandb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile  docker-compose.yaml  overrides.json\n",
      "README.md   notebooks\t\t requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "nano_path = 'notebooks/nanoGPT'\n",
    "os.chdir(nano_path)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE      assets\t      data\t  out-abc-char\twandb\n",
      "README.md    config\t      model.py\t  sample.py\n",
      "__pycache__  configurator.py  older_ckpt  train.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with multiple voices present\n",
    "#length of dataset in characters: 4,149,703\n",
    "#all the unique characters: \n",
    "#\"#'()+,-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
    "#vocab size: 46\n",
    "#train has 3,734,732 tokens\n",
    "#val has 414,971 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 4,062,773\n",
      "all the unique characters: \n",
      "\"#'(),-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
      "vocab size: 45\n",
      "train has 3,656,495 tokens\n",
      "val has 406,278 tokens\n"
     ]
    }
   ],
   "source": [
    "!python3 data/abc_char/prepare.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding config with config/train_abc_char.py:\n",
      "# train a miniature character-level shakespeare model\n",
      "# good for debugging and playing on macbooks and such\n",
      "\n",
      "out_dir = 'out-abc-char'\n",
      "eval_interval = 10 # keep frequent because we'll overfit\n",
      "eval_iters = 500\n",
      "log_interval = 5 # don't print too too often\n",
      "\n",
      "# we expect to overfit on this small dataset, so only save when val improves\n",
      "always_save_checkpoint = False\n",
      "\n",
      "wandb_log = True # override via command line if you like\n",
      "wandb_project = 'abc-char'\n",
      "wandb_run_name = 'mini-char-gpt-hd-8-ly-12-embd-280'\n",
      "\n",
      "dataset = 'abc_char'\n",
      "batch_size = 32\n",
      "block_size = 512 # context of up to 512 previous characters\n",
      "\n",
      "# baby GPT model :)\n",
      "n_layer = 12\n",
      "n_head = 8\n",
      "n_embd = 280\n",
      "dropout = 0.2\n",
      "\n",
      "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
      "max_iters = 5000\n",
      "lr_decay_iters = 5000 # make equal to max_iters usually\n",
      "min_lr = 1e-4 # learning_rate / 10 usually\n",
      "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
      "\n",
      "warmup_iters = 5 # not super necessary potentially\n",
      "\n",
      "# on macbook also add\n",
      "# device = 'cpu'  # run on cpu only\n",
      "# compile = False # do not torch compile the model\n",
      "\n",
      "found vocab_size = 45 (inside data/abc_char/meta.pkl)\n",
      "Initializing a new model from scratch\n",
      "number of parameters: 11.31M\n",
      "using fused AdamW: True\n",
      "compiling the model... (takes a ~minute)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavidnogales\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/pt-env/notebooks/nanoGPT/wandb/run-20230423_190055-w6zul33s\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmini-char-gpt-hd-8-ly-12-embd-280\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char/runs/w6zul33s\u001b[0m\n",
      "[2023-04-23 19:01:00,598] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "step 0: train loss 3.9818, val loss 3.9797\n",
      "[2023-04-23 19:02:20,736] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "iter 0: loss 3.9368, time 103783.88ms, mfu -100.00%\n",
      "iter 5: loss 2.8019, time 7863.43ms, mfu 2.36%\n",
      "step 10: train loss 2.4481, val loss 2.4541\n",
      "saving checkpoint to out-abc-char\n",
      "iter 10: loss 2.3775, time 76371.11ms, mfu 2.15%\n",
      "iter 15: loss 2.1118, time 7870.29ms, mfu 2.17%\n",
      "step 20: train loss 2.1483, val loss 2.1848\n",
      "saving checkpoint to out-abc-char\n",
      "iter 20: loss 2.1792, time 76322.24ms, mfu 1.98%\n",
      "iter 25: loss 2.1195, time 7887.97ms, mfu 2.02%\n",
      "step 30: train loss 2.0044, val loss 2.0383\n",
      "saving checkpoint to out-abc-char\n",
      "iter 30: loss 2.0498, time 76549.96ms, mfu 1.84%\n",
      "iter 35: loss 1.9125, time 7867.36ms, mfu 1.89%\n",
      "step 40: train loss 1.8927, val loss 1.9202\n",
      "saving checkpoint to out-abc-char\n",
      "iter 40: loss 1.9133, time 76231.35ms, mfu 1.73%\n",
      "iter 45: loss 1.8336, time 7863.88ms, mfu 1.79%\n",
      "step 50: train loss 1.8178, val loss 1.8503\n",
      "saving checkpoint to out-abc-char\n",
      "iter 50: loss 1.7794, time 76392.28ms, mfu 1.64%\n",
      "iter 55: loss 1.8536, time 7872.34ms, mfu 1.71%\n",
      "step 60: train loss 1.7929, val loss 1.8136\n",
      "saving checkpoint to out-abc-char\n",
      "iter 60: loss 1.8213, time 76206.41ms, mfu 1.56%\n",
      "iter 65: loss 1.7979, time 7885.91ms, mfu 1.64%\n",
      "step 70: train loss 1.7289, val loss 1.7641\n",
      "saving checkpoint to out-abc-char\n",
      "iter 70: loss 1.7463, time 76762.02ms, mfu 1.50%\n",
      "iter 75: loss 1.7048, time 7889.13ms, mfu 1.59%\n",
      "step 80: train loss 1.6621, val loss 1.6906\n",
      "saving checkpoint to out-abc-char\n",
      "iter 80: loss 1.6520, time 76412.84ms, mfu 1.45%\n",
      "iter 85: loss 1.7048, time 7881.53ms, mfu 1.54%\n",
      "step 90: train loss 1.6268, val loss 1.6611\n",
      "saving checkpoint to out-abc-char\n",
      "iter 90: loss 1.5976, time 76527.97ms, mfu 1.41%\n",
      "iter 95: loss 1.6220, time 7902.20ms, mfu 1.51%\n",
      "step 100: train loss 1.5887, val loss 1.6069\n",
      "saving checkpoint to out-abc-char\n",
      "iter 100: loss 1.5986, time 75032.23ms, mfu 1.38%\n",
      "iter 105: loss 1.5928, time 7843.08ms, mfu 1.48%\n",
      "step 110: train loss 1.5555, val loss 1.5717\n",
      "saving checkpoint to out-abc-char\n",
      "iter 110: loss 1.4684, time 75045.84ms, mfu 1.36%\n",
      "iter 115: loss 1.5822, time 7713.19ms, mfu 1.46%\n",
      "step 120: train loss 1.5159, val loss 1.5334\n",
      "saving checkpoint to out-abc-char\n",
      "iter 120: loss 1.6140, time 74514.32ms, mfu 1.34%\n",
      "iter 125: loss 1.5423, time 7752.24ms, mfu 1.45%\n",
      "step 130: train loss 1.5025, val loss 1.5178\n",
      "saving checkpoint to out-abc-char\n",
      "iter 130: loss 1.4078, time 74501.22ms, mfu 1.33%\n",
      "iter 135: loss 1.4236, time 7672.81ms, mfu 1.44%\n",
      "step 140: train loss 1.4837, val loss 1.4973\n",
      "saving checkpoint to out-abc-char\n",
      "iter 140: loss 1.4583, time 74874.86ms, mfu 1.32%\n",
      "iter 145: loss 1.5411, time 7778.73ms, mfu 1.42%\n",
      "step 150: train loss 1.4731, val loss 1.4928\n",
      "saving checkpoint to out-abc-char\n",
      "iter 150: loss 1.5136, time 75387.58ms, mfu 1.31%\n",
      "iter 155: loss 1.5070, time 7707.41ms, mfu 1.42%\n",
      "step 160: train loss 1.4538, val loss 1.4662\n",
      "saving checkpoint to out-abc-char\n",
      "iter 160: loss 1.4673, time 74712.03ms, mfu 1.30%\n",
      "iter 165: loss 1.4611, time 7736.43ms, mfu 1.41%\n",
      "step 170: train loss 1.4275, val loss 1.4480\n",
      "saving checkpoint to out-abc-char\n",
      "iter 170: loss 1.4479, time 74717.89ms, mfu 1.29%\n",
      "iter 175: loss 1.4435, time 7931.37ms, mfu 1.40%\n",
      "step 180: train loss 1.4424, val loss 1.4496\n",
      "iter 180: loss 1.3635, time 76532.42ms, mfu 1.28%\n",
      "iter 185: loss 1.4030, time 7936.62ms, mfu 1.39%\n",
      "step 190: train loss 1.4027, val loss 1.4196\n",
      "saving checkpoint to out-abc-char\n",
      "iter 190: loss 1.4041, time 77007.74ms, mfu 1.27%\n",
      "iter 195: loss 1.4277, time 8003.29ms, mfu 1.38%\n",
      "step 200: train loss 1.3816, val loss 1.3920\n",
      "saving checkpoint to out-abc-char\n",
      "iter 200: loss 1.2938, time 76798.89ms, mfu 1.27%\n",
      "iter 205: loss 1.3844, time 7861.07ms, mfu 1.38%\n",
      "step 210: train loss 1.3542, val loss 1.3681\n",
      "saving checkpoint to out-abc-char\n",
      "iter 210: loss 1.3830, time 78086.76ms, mfu 1.26%\n",
      "iter 215: loss 1.3751, time 7954.33ms, mfu 1.37%\n",
      "step 220: train loss 1.3123, val loss 1.3324\n",
      "saving checkpoint to out-abc-char\n",
      "iter 220: loss 1.2517, time 77403.17ms, mfu 1.26%\n",
      "iter 225: loss 1.3796, time 8057.51ms, mfu 1.36%\n",
      "step 230: train loss 1.2983, val loss 1.3116\n",
      "saving checkpoint to out-abc-char\n",
      "iter 230: loss 1.3428, time 77300.65ms, mfu 1.25%\n",
      "iter 235: loss 1.3810, time 7899.77ms, mfu 1.36%\n",
      "step 240: train loss 1.2736, val loss 1.2954\n",
      "saving checkpoint to out-abc-char\n",
      "iter 240: loss 1.2906, time 76923.45ms, mfu 1.25%\n",
      "iter 245: loss 1.2355, time 7940.84ms, mfu 1.36%\n",
      "step 250: train loss 1.2451, val loss 1.2752\n",
      "saving checkpoint to out-abc-char\n",
      "iter 250: loss 1.3005, time 77070.56ms, mfu 1.25%\n",
      "iter 255: loss 1.2682, time 7871.69ms, mfu 1.36%\n",
      "step 260: train loss 1.2312, val loss 1.2502\n",
      "saving checkpoint to out-abc-char\n",
      "iter 260: loss 1.2565, time 76334.76ms, mfu 1.25%\n",
      "iter 265: loss 1.2793, time 7873.76ms, mfu 1.36%\n",
      "step 270: train loss 1.2041, val loss 1.2423\n",
      "saving checkpoint to out-abc-char\n",
      "iter 270: loss 1.2601, time 76195.41ms, mfu 1.25%\n",
      "iter 275: loss 1.1992, time 7998.72ms, mfu 1.35%\n",
      "step 280: train loss 1.1845, val loss 1.2174\n",
      "saving checkpoint to out-abc-char\n",
      "iter 280: loss 1.2430, time 77044.36ms, mfu 1.24%\n",
      "iter 285: loss 1.2063, time 8017.17ms, mfu 1.35%\n",
      "step 290: train loss 1.1615, val loss 1.1857\n",
      "saving checkpoint to out-abc-char\n",
      "iter 290: loss 1.1638, time 76742.88ms, mfu 1.24%\n",
      "iter 295: loss 1.2141, time 7676.12ms, mfu 1.36%\n",
      "step 300: train loss 1.1543, val loss 1.1842\n",
      "saving checkpoint to out-abc-char\n",
      "iter 300: loss 1.1760, time 74704.89ms, mfu 1.25%\n",
      "iter 305: loss 1.1463, time 7768.59ms, mfu 1.36%\n",
      "step 310: train loss 1.1321, val loss 1.1711\n",
      "saving checkpoint to out-abc-char\n",
      "iter 310: loss 1.1065, time 74799.20ms, mfu 1.25%\n",
      "iter 315: loss 1.1381, time 7661.34ms, mfu 1.37%\n",
      "step 320: train loss 1.1106, val loss 1.1414\n",
      "saving checkpoint to out-abc-char\n",
      "iter 320: loss 1.1099, time 74392.44ms, mfu 1.26%\n",
      "iter 325: loss 1.1103, time 7683.90ms, mfu 1.37%\n",
      "step 330: train loss 1.0858, val loss 1.1169\n",
      "saving checkpoint to out-abc-char\n",
      "iter 330: loss 1.1181, time 74525.82ms, mfu 1.26%\n",
      "iter 335: loss 1.0598, time 7726.92ms, mfu 1.37%\n",
      "step 340: train loss 1.0773, val loss 1.1107\n",
      "saving checkpoint to out-abc-char\n",
      "iter 340: loss 1.1060, time 74906.48ms, mfu 1.26%\n",
      "iter 345: loss 1.0842, time 7820.87ms, mfu 1.37%\n",
      "step 350: train loss 1.0520, val loss 1.0933\n",
      "saving checkpoint to out-abc-char\n",
      "iter 350: loss 1.0708, time 76657.81ms, mfu 1.26%\n",
      "iter 355: loss 1.0408, time 7775.31ms, mfu 1.37%\n",
      "step 360: train loss 1.0564, val loss 1.0839\n",
      "saving checkpoint to out-abc-char\n",
      "iter 360: loss 1.1184, time 75773.90ms, mfu 1.26%\n",
      "iter 365: loss 1.1032, time 7777.81ms, mfu 1.37%\n",
      "step 370: train loss 1.0305, val loss 1.0697\n",
      "saving checkpoint to out-abc-char\n",
      "iter 370: loss 1.0355, time 75583.04ms, mfu 1.26%\n",
      "iter 375: loss 1.0617, time 7936.85ms, mfu 1.37%\n",
      "step 380: train loss 1.0035, val loss 1.0521\n",
      "saving checkpoint to out-abc-char\n",
      "iter 380: loss 1.0737, time 75581.60ms, mfu 1.26%\n",
      "iter 385: loss 0.9942, time 7788.01ms, mfu 1.37%\n",
      "step 390: train loss 0.9863, val loss 1.0260\n",
      "saving checkpoint to out-abc-char\n",
      "iter 390: loss 1.0535, time 74740.22ms, mfu 1.26%\n",
      "iter 395: loss 1.0340, time 7692.97ms, mfu 1.37%\n",
      "step 400: train loss 0.9781, val loss 1.0228\n",
      "saving checkpoint to out-abc-char\n",
      "iter 400: loss 0.9767, time 74601.53ms, mfu 1.26%\n",
      "iter 405: loss 0.9486, time 7689.43ms, mfu 1.38%\n",
      "step 410: train loss 0.9634, val loss 1.0019\n",
      "saving checkpoint to out-abc-char\n",
      "iter 410: loss 1.0416, time 74464.85ms, mfu 1.26%\n",
      "iter 415: loss 1.0134, time 7699.97ms, mfu 1.38%\n",
      "step 420: train loss 0.9523, val loss 0.9850\n",
      "saving checkpoint to out-abc-char\n",
      "iter 420: loss 0.9894, time 74465.59ms, mfu 1.27%\n",
      "iter 425: loss 0.9691, time 7676.58ms, mfu 1.38%\n",
      "step 430: train loss 0.9345, val loss 0.9771\n",
      "saving checkpoint to out-abc-char\n",
      "iter 430: loss 0.9583, time 74467.41ms, mfu 1.27%\n",
      "iter 435: loss 0.9442, time 7697.62ms, mfu 1.38%\n",
      "step 440: train loss 0.9208, val loss 0.9624\n",
      "saving checkpoint to out-abc-char\n",
      "iter 440: loss 0.9407, time 74823.18ms, mfu 1.27%\n",
      "iter 445: loss 0.9402, time 7789.13ms, mfu 1.38%\n",
      "step 450: train loss 0.9103, val loss 0.9582\n",
      "saving checkpoint to out-abc-char\n",
      "iter 450: loss 0.9304, time 74763.80ms, mfu 1.27%\n",
      "iter 455: loss 0.9154, time 7699.64ms, mfu 1.38%\n",
      "step 460: train loss 0.8955, val loss 0.9290\n",
      "saving checkpoint to out-abc-char\n",
      "iter 460: loss 0.9248, time 74859.90ms, mfu 1.27%\n",
      "iter 465: loss 0.8919, time 7727.91ms, mfu 1.38%\n",
      "step 470: train loss 0.8848, val loss 0.9188\n",
      "saving checkpoint to out-abc-char\n",
      "iter 470: loss 0.9195, time 75018.97ms, mfu 1.27%\n",
      "iter 475: loss 0.8950, time 7691.79ms, mfu 1.38%\n",
      "step 480: train loss 0.8624, val loss 0.8981\n",
      "saving checkpoint to out-abc-char\n",
      "iter 480: loss 0.8847, time 74749.55ms, mfu 1.27%\n",
      "iter 485: loss 0.9083, time 7779.00ms, mfu 1.38%\n",
      "step 490: train loss 0.8480, val loss 0.8860\n",
      "saving checkpoint to out-abc-char\n",
      "iter 490: loss 0.8580, time 74790.63ms, mfu 1.27%\n",
      "iter 495: loss 0.8673, time 7697.71ms, mfu 1.38%\n",
      "step 500: train loss 0.8542, val loss 0.8827\n",
      "saving checkpoint to out-abc-char\n",
      "iter 500: loss 0.8275, time 74679.85ms, mfu 1.27%\n",
      "iter 505: loss 0.8787, time 7759.78ms, mfu 1.38%\n",
      "step 510: train loss 0.8361, val loss 0.8711\n",
      "saving checkpoint to out-abc-char\n",
      "iter 510: loss 0.8688, time 74708.55ms, mfu 1.27%\n",
      "iter 515: loss 0.8491, time 7675.39ms, mfu 1.38%\n",
      "step 520: train loss 0.8220, val loss 0.8588\n",
      "saving checkpoint to out-abc-char\n",
      "iter 520: loss 0.8245, time 74607.58ms, mfu 1.27%\n",
      "iter 525: loss 0.8473, time 7660.56ms, mfu 1.39%\n",
      "step 530: train loss 0.8009, val loss 0.8413\n",
      "saving checkpoint to out-abc-char\n",
      "iter 530: loss 0.8208, time 74661.17ms, mfu 1.27%\n",
      "iter 535: loss 0.8461, time 7676.69ms, mfu 1.39%\n",
      "step 540: train loss 0.7862, val loss 0.8259\n",
      "saving checkpoint to out-abc-char\n",
      "iter 540: loss 0.8009, time 74595.94ms, mfu 1.27%\n",
      "iter 545: loss 0.8366, time 7684.43ms, mfu 1.39%\n",
      "step 550: train loss 0.7740, val loss 0.8106\n",
      "saving checkpoint to out-abc-char\n",
      "iter 550: loss 0.7718, time 77475.50ms, mfu 1.27%\n",
      "iter 555: loss 0.8059, time 7660.24ms, mfu 1.39%\n",
      "step 560: train loss 0.7597, val loss 0.7974\n",
      "saving checkpoint to out-abc-char\n",
      "iter 560: loss 0.7688, time 74490.98ms, mfu 1.27%\n",
      "iter 565: loss 0.7792, time 7987.36ms, mfu 1.38%\n",
      "step 570: train loss 0.7439, val loss 0.7782\n",
      "saving checkpoint to out-abc-char\n",
      "iter 570: loss 0.7808, time 75804.07ms, mfu 1.27%\n",
      "iter 575: loss 0.7704, time 7652.25ms, mfu 1.38%\n",
      "step 580: train loss 0.7284, val loss 0.7651\n",
      "saving checkpoint to out-abc-char\n",
      "iter 580: loss 0.7375, time 75089.08ms, mfu 1.27%\n",
      "iter 585: loss 0.7434, time 7848.99ms, mfu 1.38%\n",
      "step 590: train loss 0.7275, val loss 0.7667\n",
      "iter 590: loss 0.7719, time 74226.05ms, mfu 1.27%\n",
      "iter 595: loss 0.7511, time 7705.74ms, mfu 1.38%\n",
      "step 600: train loss 0.7095, val loss 0.7534\n",
      "saving checkpoint to out-abc-char\n",
      "iter 600: loss 0.7332, time 75758.45ms, mfu 1.27%\n",
      "iter 605: loss 0.6999, time 8088.95ms, mfu 1.37%\n",
      "step 610: train loss 0.6981, val loss 0.7400\n",
      "saving checkpoint to out-abc-char\n",
      "iter 610: loss 0.7461, time 75803.22ms, mfu 1.26%\n",
      "iter 615: loss 0.6948, time 7807.70ms, mfu 1.37%\n",
      "step 620: train loss 0.6892, val loss 0.7363\n",
      "saving checkpoint to out-abc-char\n",
      "iter 620: loss 0.7800, time 75839.41ms, mfu 1.26%\n",
      "iter 625: loss 0.7383, time 7668.55ms, mfu 1.37%\n",
      "step 630: train loss 0.6710, val loss 0.7121\n",
      "saving checkpoint to out-abc-char\n",
      "iter 630: loss 0.6731, time 76349.26ms, mfu 1.26%\n",
      "iter 635: loss 0.7133, time 7832.72ms, mfu 1.37%\n",
      "step 640: train loss 0.6646, val loss 0.7054\n",
      "saving checkpoint to out-abc-char\n",
      "iter 640: loss 0.7125, time 74820.92ms, mfu 1.26%\n",
      "iter 645: loss 0.7000, time 7659.25ms, mfu 1.38%\n",
      "step 650: train loss 0.6555, val loss 0.7019\n",
      "saving checkpoint to out-abc-char\n",
      "iter 650: loss 0.7006, time 75154.31ms, mfu 1.26%\n",
      "iter 655: loss 0.6964, time 7811.13ms, mfu 1.38%\n",
      "step 660: train loss 0.6419, val loss 0.6878\n",
      "saving checkpoint to out-abc-char\n",
      "iter 660: loss 0.6447, time 74845.19ms, mfu 1.26%\n",
      "iter 665: loss 0.6440, time 7810.50ms, mfu 1.37%\n",
      "step 670: train loss 0.6410, val loss 0.6879\n",
      "iter 670: loss 0.6581, time 75008.22ms, mfu 1.26%\n",
      "iter 675: loss 0.6375, time 7844.69ms, mfu 1.37%\n",
      "step 680: train loss 0.6269, val loss 0.6722\n",
      "saving checkpoint to out-abc-char\n",
      "iter 680: loss 0.6854, time 75099.17ms, mfu 1.26%\n",
      "iter 685: loss 0.6765, time 7767.45ms, mfu 1.37%\n",
      "step 690: train loss 0.6251, val loss 0.6680\n",
      "saving checkpoint to out-abc-char\n",
      "iter 690: loss 0.6524, time 75571.98ms, mfu 1.26%\n",
      "iter 695: loss 0.6487, time 7729.26ms, mfu 1.38%\n",
      "step 700: train loss 0.6179, val loss 0.6638\n",
      "saving checkpoint to out-abc-char\n",
      "iter 700: loss 0.6695, time 75523.24ms, mfu 1.26%\n",
      "iter 705: loss 0.6506, time 7834.44ms, mfu 1.37%\n",
      "step 710: train loss 0.6105, val loss 0.6604\n",
      "saving checkpoint to out-abc-char\n",
      "iter 710: loss 0.6007, time 76168.59ms, mfu 1.26%\n",
      "iter 715: loss 0.6220, time 7867.83ms, mfu 1.37%\n",
      "step 720: train loss 0.5969, val loss 0.6476\n",
      "saving checkpoint to out-abc-char\n",
      "iter 720: loss 0.6221, time 76092.35ms, mfu 1.26%\n",
      "iter 725: loss 0.6057, time 7853.56ms, mfu 1.37%\n",
      "step 730: train loss 0.5947, val loss 0.6470\n",
      "saving checkpoint to out-abc-char\n",
      "iter 730: loss 0.6623, time 74638.36ms, mfu 1.26%\n",
      "iter 735: loss 0.6219, time 7660.64ms, mfu 1.37%\n",
      "step 740: train loss 0.5812, val loss 0.6314\n",
      "saving checkpoint to out-abc-char\n",
      "iter 740: loss 0.6260, time 74230.61ms, mfu 1.26%\n",
      "iter 745: loss 0.5927, time 7710.40ms, mfu 1.38%\n",
      "step 750: train loss 0.5793, val loss 0.6320\n",
      "iter 750: loss 0.5924, time 74808.66ms, mfu 1.26%\n",
      "iter 755: loss 0.6192, time 7665.74ms, mfu 1.38%\n",
      "step 760: train loss 0.5669, val loss 0.6228\n",
      "saving checkpoint to out-abc-char\n",
      "iter 760: loss 0.5787, time 74424.58ms, mfu 1.27%\n",
      "iter 765: loss 0.5776, time 7662.13ms, mfu 1.38%\n",
      "step 770: train loss 0.5606, val loss 0.6177\n",
      "saving checkpoint to out-abc-char\n",
      "iter 770: loss 0.6063, time 74351.27ms, mfu 1.27%\n",
      "iter 775: loss 0.6039, time 7658.17ms, mfu 1.39%\n",
      "step 780: train loss 0.5556, val loss 0.6100\n",
      "saving checkpoint to out-abc-char\n",
      "iter 780: loss 0.5580, time 73759.44ms, mfu 1.27%\n",
      "iter 785: loss 0.5956, time 7601.08ms, mfu 1.39%\n",
      "step 790: train loss 0.5477, val loss 0.6084\n",
      "saving checkpoint to out-abc-char\n",
      "iter 790: loss 0.5517, time 73727.14ms, mfu 1.28%\n",
      "iter 795: loss 0.6041, time 7599.48ms, mfu 1.39%\n",
      "step 800: train loss 0.5508, val loss 0.6068\n",
      "saving checkpoint to out-abc-char\n",
      "iter 800: loss 0.5899, time 73707.31ms, mfu 1.28%\n",
      "iter 805: loss 0.5674, time 7603.25ms, mfu 1.40%\n",
      "step 810: train loss 0.5388, val loss 0.5986\n",
      "saving checkpoint to out-abc-char\n",
      "iter 810: loss 0.5704, time 73771.23ms, mfu 1.28%\n",
      "iter 815: loss 0.6140, time 7600.35ms, mfu 1.40%\n",
      "step 820: train loss 0.5288, val loss 0.5876\n",
      "saving checkpoint to out-abc-char\n",
      "iter 820: loss 0.5719, time 73729.18ms, mfu 1.28%\n",
      "iter 825: loss 0.5771, time 7600.52ms, mfu 1.40%\n",
      "step 830: train loss 0.5211, val loss 0.5807\n",
      "saving checkpoint to out-abc-char\n",
      "iter 830: loss 0.5421, time 73760.76ms, mfu 1.28%\n",
      "iter 835: loss 0.5196, time 7599.91ms, mfu 1.40%\n",
      "step 840: train loss 0.5186, val loss 0.5793\n",
      "saving checkpoint to out-abc-char\n",
      "iter 840: loss 0.5414, time 73735.55ms, mfu 1.29%\n",
      "iter 845: loss 0.5525, time 7602.48ms, mfu 1.40%\n",
      "step 850: train loss 0.5125, val loss 0.5757\n",
      "saving checkpoint to out-abc-char\n",
      "iter 850: loss 0.5351, time 73750.89ms, mfu 1.29%\n",
      "iter 855: loss 0.5408, time 7602.86ms, mfu 1.40%\n",
      "step 860: train loss 0.5103, val loss 0.5740\n",
      "saving checkpoint to out-abc-char\n",
      "iter 860: loss 0.5589, time 73729.93ms, mfu 1.29%\n",
      "iter 865: loss 0.5362, time 7603.41ms, mfu 1.40%\n",
      "step 870: train loss 0.5051, val loss 0.5707\n",
      "saving checkpoint to out-abc-char\n",
      "iter 870: loss 0.5313, time 73757.51ms, mfu 1.29%\n",
      "iter 875: loss 0.5342, time 7602.11ms, mfu 1.40%\n",
      "step 880: train loss 0.4975, val loss 0.5666\n",
      "saving checkpoint to out-abc-char\n",
      "iter 880: loss 0.5467, time 73740.17ms, mfu 1.29%\n",
      "iter 885: loss 0.5853, time 7600.83ms, mfu 1.40%\n",
      "step 890: train loss 0.4914, val loss 0.5609\n",
      "saving checkpoint to out-abc-char\n",
      "iter 890: loss 0.5528, time 73787.96ms, mfu 1.29%\n",
      "iter 895: loss 0.5001, time 7606.06ms, mfu 1.40%\n",
      "step 900: train loss 0.4861, val loss 0.5596\n",
      "saving checkpoint to out-abc-char\n",
      "iter 900: loss 0.5140, time 73782.51ms, mfu 1.29%\n",
      "iter 905: loss 0.5268, time 7604.48ms, mfu 1.40%\n",
      "step 910: train loss 0.4787, val loss 0.5511\n",
      "saving checkpoint to out-abc-char\n",
      "iter 910: loss 0.5178, time 73814.22ms, mfu 1.29%\n",
      "iter 915: loss 0.5204, time 7602.84ms, mfu 1.41%\n",
      "step 920: train loss 0.4745, val loss 0.5487\n",
      "saving checkpoint to out-abc-char\n",
      "iter 920: loss 0.4929, time 73998.96ms, mfu 1.29%\n",
      "iter 925: loss 0.5090, time 7624.82ms, mfu 1.40%\n",
      "step 930: train loss 0.4760, val loss 0.5507\n",
      "iter 930: loss 0.4985, time 73852.03ms, mfu 1.29%\n",
      "iter 935: loss 0.4949, time 7629.42ms, mfu 1.40%\n",
      "step 940: train loss 0.4632, val loss 0.5409\n",
      "saving checkpoint to out-abc-char\n",
      "iter 940: loss 0.5167, time 73996.87ms, mfu 1.29%\n",
      "iter 945: loss 0.5207, time 7626.85ms, mfu 1.40%\n",
      "step 950: train loss 0.4637, val loss 0.5424\n",
      "iter 950: loss 0.5113, time 73866.41ms, mfu 1.29%\n",
      "iter 955: loss 0.4795, time 7624.94ms, mfu 1.40%\n",
      "step 960: train loss 0.4543, val loss 0.5381\n",
      "saving checkpoint to out-abc-char\n",
      "iter 960: loss 0.5294, time 74002.43ms, mfu 1.29%\n",
      "iter 965: loss 0.4621, time 7623.12ms, mfu 1.40%\n",
      "step 970: train loss 0.4461, val loss 0.5281\n",
      "saving checkpoint to out-abc-char\n",
      "iter 970: loss 0.4788, time 73981.29ms, mfu 1.29%\n",
      "iter 975: loss 0.5068, time 7626.40ms, mfu 1.40%\n",
      "step 980: train loss 0.4407, val loss 0.5259\n",
      "saving checkpoint to out-abc-char\n",
      "iter 980: loss 0.4834, time 71953.95ms, mfu 1.29%\n",
      "iter 985: loss 0.4648, time 7624.01ms, mfu 1.40%\n",
      "step 990: train loss 0.4420, val loss 0.5320\n",
      "iter 990: loss 0.4668, time 73853.70ms, mfu 1.29%\n",
      "iter 995: loss 0.4647, time 7624.12ms, mfu 1.40%\n",
      "step 1000: train loss 0.4335, val loss 0.5200\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1000: loss 0.4988, time 74007.91ms, mfu 1.29%\n",
      "iter 1005: loss 0.4889, time 7625.63ms, mfu 1.40%\n",
      "step 1010: train loss 0.4279, val loss 0.5201\n",
      "iter 1010: loss 0.4746, time 73853.00ms, mfu 1.29%\n",
      "iter 1015: loss 0.4590, time 7625.49ms, mfu 1.40%\n",
      "step 1020: train loss 0.4212, val loss 0.5110\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1020: loss 0.4713, time 73994.17ms, mfu 1.29%\n",
      "iter 1025: loss 0.4511, time 7623.61ms, mfu 1.40%\n",
      "step 1030: train loss 0.4194, val loss 0.5157\n",
      "iter 1030: loss 0.5019, time 73835.86ms, mfu 1.29%\n",
      "iter 1035: loss 0.4704, time 7627.48ms, mfu 1.40%\n",
      "step 1040: train loss 0.4113, val loss 0.5049\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1040: loss 0.4601, time 73996.40ms, mfu 1.29%\n",
      "iter 1045: loss 0.4382, time 7624.96ms, mfu 1.40%\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 253, in <module>\n",
      "    losses = estimate_loss()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"train.py\", line 214, in estimate_loss\n",
      "    losses[k] = loss.item()\n",
      "KeyboardInterrupt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 255).\u001b[0m Press Control-C to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: / 0.028 MB of 0.028 MB uploaded (0.000 MB deduped)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       iter ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         lr ▁██████████████████████████████████▇▇▇▇▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        mfu ▁███████████████████████████████████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/loss █▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val/loss █▄▄▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       iter 1040\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         lr 0.00091\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        mfu 1.40263\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/loss 0.41133\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val/loss 0.50491\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run \u001b[33mmini-char-gpt-hd-8-ly-12-embd-280\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char/runs/w6zul33s\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230423_190055-w6zul33s/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py config/train_abc_char.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test key with most occurrences: G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-abc-char\n",
      "Overriding: start = M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "number of parameters: 11.31M\n",
      "abc_char\n",
      "Loading meta from data/abc_char/meta.pkl...\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d|\"G\"d2d3/2d/2|\"C\"e2d3/2B/2|\"D\"Bd2|\"D\"A2-A2|\"G\"d2d3/2d/2|\"G\"d2d3/2d/2|\"C\"e2d3/2B/2|\"D\"A2G2|\"D\"A2B2|\"G\"G3|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:C\n",
      "|\"C\"|\"F\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|\"F\"\"C\"|\"Dm\"|]\n",
      "G|\"C\"cB/2c/2d/2e/2d/2|\"F\"cA3/2c/2f/2c/2|\"G\"BG3/2d/2|\"C\"e/2d/2c/2B/2G/2B/2c/2|\"F\"AFA/2B/2c/2|\"G\"d/2c/2B/2A/2G/2F/2G/2|\"C\"E/2C/2D/2E/2F/2G/2A/2|\"F\"cB/2c/2d/2e/2d/2c/2|\"G\"B/2GA/2B/2c/2d/2|\"C\"e/2d/2c/2e/2c/2G/2c/2|\"F\"A/2F/2A/2c/2f/2c/2A/2c/2|\"G\"B/2G/2A/2B/2c/2d/2e/2f/2|\"C\"g2cd/2e/2|\"F\"fA\"C\"cA|\"Dm\"f/2e/2d/2c/2B/2A/2B/2c/2|\"\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "B/2c/2|\"G\"d/2^c/2d/2g/2f/2g/2f/2e/2|d/2^c/2BB/2c/2|\"C\"AG3/2F/2G/2E/2|C/2E/2C/2A/2cA/2G/2|\"D\"F/2^E/2D/2E/2DD|\"D\"D/2^C/2D/2E/2A/2c/2A/2d/2|\"G\"cBB|\"C\"c/2d/2e/2d/2c/2B/2A/2G/2|\"D\"F/2^E/2D/2E/2F/2D/2E/2F/2|\"G\"G2G|\"C\"cc/2B/2c/2c/2c/2d/2e/2|c/2e/2c/2e/2g/2f/2e/2|\"D\"B/2d/2A/2F/2AB/2c/2|\"D\"d/2^c/2d/2e/2f/2e/2d/2c/2|\"G\"BGG|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"D7\"|\"G\"|\"G\"|\"Am\"\"D7\"|\"G\"|\"D7\"|\"G\"|\"G\"|\"Am\"\"D7\"|\"G\"|\"G\"|\"D7\"|\"G\"|\"G\"\"D7\"|\"G\"|\"G\"|\"C\"\"D7\"|\"G\"|]\n",
      "\"G\"GDB,D|B,/2C/2|\"D7\"DB,A2|\"G\"GDB,D|\"G\"B,/2C/2DB,D|\"Am\"CA,\"D7\"A,2\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "D3/2G/2|\"G\"E2E2|G3/2E/2G3/2A/2|\"C\"E2E3/2G/2|c3/2c/2e3/2d/2c3/2A/2|\"D\"F3/2A/2D3/2A/2c3/2A/2|\"G\"G3/2B/2G3/2A/2G3/2A/2|B3/2G/2A3/2G/2F3/2G/2|\"C\"E2E3/2G/2|C3/2G/2c3/2A/2G3/2A/2|\"D\"F3/2A/2D3/2c/2B3/2A/2G6/2|\"G\"B3/2G/2D3/2G/2A3/2G/2|\"C\"c3/2G/2c3/2G/2E3/2G/2|\"D\"F3/2A/2D3/2c/2B3/2A/2|\"G\"G2G2G2|\"C\"ccBc3/2G/2|\"D\"A3/2F/2D3/2A/2d3/2A/2F3/2|\"G\"B3/2G/2D3/2G/2A3/2G/2|\"C\"ccBc3/2G/2c3/2e/2|\"D\"d3/2A/2F3/2A/2d3/2A/2f3/2e/2|\"G\"d2G2G2|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:C\n",
      "|\"C\"|\"C\"|\"C\"\"F\"|\"Dm\"|\"G7\"\"C\"|\"C\"|\"C\"|\"F\"|\"F\"\"D7\"|\"G7\"|\"G7\"|\"C\"\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d|\"G\"g3/2e/2|\"C\"e/2d/2c/2|\"D\"g3/2e/2|\"D\"d3/2e/2|\"G\"d/2c/2B/2A/2|\"C\"G/2A/2B/2A/2|\"D\"G/2B/2A/2G/2F/2|\"G\"G3/2A/2G/2|\"C\"G/2A/2G/2E/2|\"D\"A/2G/2F/2E/2D/2|\"G\"GG/2A/2|\"C\"G/2A/2G/2E/2|\"D\"D/2C/2D/2E/2D/2|\"G\"GG/2A/2|\"C\"G/2A/2G/2E/2|\"D\"D/2C/2D/2E/2D/2|\"G\"GG/2A/2|\"C\"G/2A/2G/2E/2|\"D\"D/2C/2D/2E/2D/2|\"G\"GG/2A/2|\"C\"G/2A/2G/2E/2|\"D\"D/2C/2D/2E/2D/2|\"G\"GG/2A/2|\"C\"G/2A/2G/2E/2|\"D\"D/2C/2D/2E/2D/2|\"G\"GG/2A/2|\"C\"G/2A/2G/2E/2|\"D\"D/2C/2D/2E/2D/2|\"G\"GG/2A/2|\"C\"G/2A/2G/2E/2|\"D\"D/2C/2D/2E/2D/2|\"G\"GGG/2A/2|\"C\"G/2A/2G/2E/2|\"\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "|d|\"G\"gage|ge/2e/2d/2|\"C\"cee|\"D\"f/2e/2d/2c/2A/2|\"D\"aag/2f/2|\"G\"g/2e/2d/2BB/2d/2|\"C\"cee|\"D\"f/2e/2d/2c/2A/2D/2E/2|\"G\"Dgfg/2a/2|\"C\"ge/2g/2-g/2e/2g/2|ge/2d/2e/2d/2|\"C\"cee/2d/2c/2d/2|\"D\"a/2e/2d/2c/2A/2d/2e/2|\"G\"d/2B/2G/2A/2G|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:D\n",
      "|\"D\"|\"A\"|\"A\"|\"D\"|\"D\"|\"A\"\"D\"|\"D\"|\"A\"|\"A\"\"G\"|\"D\"\"E\"|\"A\"|\"A\"\"D\"|\"G\"|\"A\"\"G\"|\"G\"|\"D\"|\"A\"\"G\"|\"D\"\"E\"|]\n",
      "D/2E/2|\"D\"FD/2F/2A/2F/2D/2F/2|\"A\"EAA/2B/2A/2G/2|\"A\"F/2G/2A/2c/2e/2d/2c/2B/2|\"A\"AA/2B/2c/2A/2G/2|\"D\"FD/2F/2A/2F/2D/2F/2|\"D\"A/2d/2e/2d/2c/2d/2e/2f/2|\"A\"g/2e/2c/2e/2\"D\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d|\"G\"ggg/2a/2|gg/2g/2|\"C\"a/2g/2e/2|e/2d/2g/2e/2|\"D\"dA|\"D\"gg/2a/2|\"G\"g/2g/2g/2a/2|\"C\"g/2a/2g/2e/2|\"D\"d/2c/2B/2c/2A/2|\"G\"GGB/2A/2|\"C\"GG/2A/2B/2c/2|\"D\"d/2c/2B/2A/2B/2A/2B/2c/2|\"D\"d/2c/2B/2A/2B/2A/2B/2c/2|\"G\"d/2c/2B/2A/2G|B/2A/2G/2E/2G/2A/2B/2|\"C\"c/2B/2c/2A/2G|\"D\"d3/2c/2B/2A/2B/2c/2|\"G\"d/2c/2B/2A/2G/2B/2A/2G/2|\"C\"e/2d/2c/2B/2c/2A/2B/2c/2|\"D\"d/2c/2B/2A/2B/2c/2d/2e/2|\"G\"fdcB/2c/2|\"C\"A/2B/2c/2A/2GG|\"D\"d3/2c/2BA|\"G\"B/2A/2G/2E/2GD|\"C\"c/2B/2c/2A/2GE|\"D\"d3/2c/2BA|\"G\"B/2A/2G/2E/2F/2GB/2A/2G/2|\"C\"c/2B/2c/2A\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "B/2c/2|\"G\"d3/2d/2c/2B/2A/2|GDEF/2G/2|\"C\"E3/2G/2A/2B/2c/2d/2|e/2d/2c/2B/2A/2G/2A/2|\"D\"DEFA/2G/2|\"D\"FDc/2G/2F/2A/2|\"G\"GDEF/2G/2|\"C\"EGc/2B/2c/2d/2|e/2d/2c/2B/2A/2G/2A/2|\"D\"DEFA/2G/2|\"D\"FDEF/2G/2|\"G\"FDc/2B/2A/2G/2A/2|\"C\"EGcd/2c/2|\"D\"FDc/2A/2G/2F/2A/2|\"G\"GDEF/2G/2|\"C\"EGc/2B/2c/2d/2|e/2d/2c/2B/2A/2G|\"D\"FDc/2B/2A/2G/2|\"G\"FDc/2B/2A/2G/2|\"C\"EGc/2B/2c/2d/2|e/2d/2c/2B/2AG|\"D\"FDc/2B/2A/2G/2|\"D\"FDc/2B/2A/2G/2|\"G\"FDc/2B/2A/2G/2|\"C\"EGc/2B/2c/2d/2|ed/2c/2B/2AG|\"D\"FDc/2B/2A/2G/2|\"G\"FDc/2B/2A/2G/2|\"C\"EGc/2B/2c/2\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d|\"G\"Bd/2e/2d/2B/2G/2B/2|d/2B/2A/2G/2A/2B/2A/2G/2|\"C\"c/2B/2A/2G/2F/2E/2D/2C/2E/2|\"D\"D/2F/2A/2D/2c/2d/2c/2A/2|\"G\"B/2A/2G/2B/2d/2d/2c/2B/2A/2G/2|\"C\"c/2B/2A/2G/2F/2E/2D/2C/2E/2|\"D\"D/2F/2A/2D/2c/2D/2c/2A/2|\"G\"B/2A/2G/2B/2d/2d/2c/2B/2A/2G/2|\"C\"cecAB/2c/2|\"D\"d/2c/2B/2A/2c/2d/2c/2d/2c/2|\"G\"BGG|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"C\"|\"G\"|\"D7\"|\"G\"|\"C\"\"F\"|\"G7\"|\"C\"|\"G\"|\"C\"\"F\"|\"G7\"|\"C\"\"G7\"|\"C\"|\"G\"|\"G\"|\"C\"\"F\"|\"G7\"|\"C\"|]\n",
      "e/2d/2|\"G\"g/2d/2B/2d/2g/2d/2B/2G/2|\"C\"c/2e/2G/2c/2e/2G/2c/2E/2|\"G\"G/2B/2d/2G/2g/2d/2G/2B/2G/2D/2|\"D7\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "GA|\"G\"G3/2A/2|GBA|GBA|\"C\"E4|E2D|\"D\"D3/2E/2F|AcF|\"D\"A2F|ED2A|\"G\"G3/2A/2|GBA|\"C\"E4|E2EF|\"D\"D3/2E/2F|AcA|\"G\"G3/2A/2BA|GBA|\"C\"Bcde|\"D\"f3/2e/2dc|\"G\"B4|\"C\"Bcde|\"D\"f3/2e/2dc|\"G\"B4|\"C\"Bcde|\"D\"f3/2e/2dc|\"G\"B4|\"C\"ccde|\"D\"f3/2e/2dc|c2B2G|\"D\"AcA|\"G\"G3/2A/2BA|GBA|\"C\"Bcde|\"D\"f3/2e/2dc|\"G\"B4|\"C\"cdef|\"D\"f3/2e/2dc|\"G\"B4|\"C\"cBde|\"D\"f3/2e/2dc|\"G\"B4|\"C\"ccde|\"D\"f3/2e/2dc|\"G\"B4|\"C\"cdef|\"D\"f3/2e/2dc|\"G\"B4|\"C\"Bcde|\"D\"f3/2e/2dc|\"G\"B4|\"C\"ccdef|\"D\"f3/2e/2dc|\"G\"B4|\"C\"ccBde|\"D\"f3/2e/2dc|\"G\"B4|\"C\"cBcde|\"D\"f3/2e/2dc|\"G\"B4|\"C\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "\"G\"DG/2A/2|\"G\"BG3/2A/2|\"C\"BG3/2A/2|\"D\"BA3/2G/2|\"D\"AFD|\"G\"DG/2A/2|\"G\"BG3/2A/2|\"C\"BG3/2A/2|\"D\"BA3/2G/2|\"D\"AFD|\"G\"DGG/2A/2|\"C\"BG\"G\"D3/2G/2|\"D\"ED2|\"G\"DGG/2A/2|\"C\"BG3/2A/2|\"D\"BA3/2G/2A|\"G\"BGG2|\"C\"cece|\"D\"fed3/2e/2|\"G\"dGA/2B/2|\"C\"cee|\"D\"fede/2g/2|\"G\"dGG|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"C\"\"D7\"|\"G\"\"D7\"|\"G\"|\"C\"\"D7\"|\"G\"|\"C\"\"D7\"|\"G\"|\"Em\"\"D7\"|\"G\"|\"G\"\"C\"|\"Am\"\"D7\"|\"G\"|\"Am\"\"D7\"|\"G\"|]\n",
      "D|\"G\"GGG/2A/2B/2c/2|\"C\"B/2c/2A/2G/2\"D7\"DD/2E/2|\"G\"GGG/2A/2B/2c/2|\"C\"B/2c/2A/2G/2\"D7\"DD/2E/2|\"G\"GGG/2A/2B/2c/2|\"C\"B/2c/2A/2G/2\"D7\"DD/2E/\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start='M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test major key with low samples: C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-abc-char\n",
      "Overriding: start = M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "number of parameters: 11.31M\n",
      "abc_char\n",
      "Loading meta from data/abc_char/meta.pkl...\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "G|\"C\"c/2d/2e/2d/2|c/2G|\"F\"A3/2G/2|\"G\"GA/2B/2|\"C\"c/2d/2e/2d/2|\"F\"cAG|\"G\"GA/2B/2c/2d/2|\"C\"e/2d/2c/2AG|\"F\"A3/2G/2E/2|\"G\"GAG/2A/2|\"C\"c/2d/2e/2d/2c/2B/2c/2|\"F\"A3/2G/2E/2|\"G\"GA/2B/2c/2d/2|\"C\"e/2d/2c/2AG|\"F\"A3/2G/2EE/2|\"G\"GA/2B/2c/2d/2|\"C\"e/2d/2c/2AG|\"F\"A3/2G/2ED/2C/2|\"G\"GAG/2A/2|\"C\"c3/2B/2cG|\"F\"A3/2G/2ED|\"G\"GA/2B/2c/2d/2e/2|\"C\"c3|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:F\n",
      "|\"F\"\"C7\"|\"F\"|\"Dm\"|\"C7\"|\"F\"\"C7\"|\"F\"|\"B\"|\"F\"|\"F\"\"G7\"|\"C7\"|\"F\"\"C7\"|\"F\"|\"B\"\"F\"|\"Gm\"|\"C7\"|\"F\"\"C7\"|\"F7\"|\"B\"|\"F\"|\"C7\"|\"F\"|]\n",
      "\"F\"FA/2G/2\"C7\"F/2E/2G/2B/2|\"F\"AFFA/2G\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "G|\"C\"g\"cec/2d/2e/2|\"F\"f/2e/2d/2c/2A/2c/2A/2|\"G\"B/2G/2A/2B/2G/2A/2B/2|\"C\"cec/2d/2e/2|\"F\"f/2e/2d/2c/2A/2c/2A/2|\"G\"G/2A/2B/2c/2d/2e/2f/2d/2|\"C\"cec/2d/2e/2c/2|\"F\"f/2e/2d/2c/2A/2c/2A/2c/2|\"G\"B/2G/2A/2B/2c/2d/2e/2f/2|\"C\"gec|e/2f/2|\"C\"gecce/2f/2|\"C\"gecc|\"F\"A/2c/2A/2B/2c/2A/2c/2A/2|\"G\"B/2G/2dGe/2f/2|\"C\"g/2e/2c/2d/2e/2cc/2e/2|\"F\"f/2e/2d/2c/2A/2c/2A/2c/2A/2c/2|\"G\"B/2G/2A/2B/2d/2e/2f/2d/2|\"C\"cec|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"G\"|\"G\"|\"G\"\"D7\"|\"G\"|\"G\"|\"G\"|\"G\"\"D7\"|\"G\"|\"G\"|\"G\"|\"G\"|\"G\"|\"G\"|\"D7\"|\"G\"|\"G\"|\"G\"|\"G\"|\"G\"|\"G\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "c3/2|\"C\"c3/2d/2|e/2e/2d/2|\"F\"c3/2d/2|e/2f/2e/2d/2c/2|A3/2B/2c/2d/2|\"G\"B3/2A/2G/2F/2|\"C\"E3/2D/2C/2|\"F\"C3/2D/2F/2G/2|A3/2G/2F/2A/2G/2|\"G\"F3/2E/2D/2C/2|\"C\"C3/2D/2F/2G/2|\"F\"A3/2G/2F/2A/2G/2|\"G\"F3/2E/2D/2C/2B,/2|\"C\"A,/2C/2D/2E/2F/2G/2|\"F\"A3/2G/2F/2A/2G/2|F/2E/2F/2G/2A/2G/2|\"G\"F/2E/2D/2C/2D/2G,/2|\"C\"C3/2D/2F/2G/2|\"F\"A/2c/2d/2e/2d/2c/2|\"G\"BGF|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:C\n",
      "|\"C\"|\"C\"|\"Dm\"|\"G7\"|\"C\"|\"C\"|\"Dm\"\"G7\"|\"C\"|\"C\"|\"F\"|\"C\"|\"Dm\"|\"G7\"|\"C\"|\"C\"|\"F\"|\"F\"|\"F\"|\"G7\"|\"C\"|\"C\"|\"F\"|\"B\"|\"G7\"|\"C\"|]\n",
      "c/2d/2|\"C\"eccc/2d/2|ecc/2d/2\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "c/2d/2|\"C\"e/2G/2cA/2B/2|G2c|\"F\"A/2cA/2B/2|c/2A/2G/2FG/2A/2|\"G\"B/2c/2B/2A/2G/2A/2|\"G\"BG3/2F/2|\"C\"E/2GGA/2B/2|c/2A/2GG|\"F\"A/2cA/2B/2|\"G\"B/2c/2B/2A/2G/2A/2|\"C\"G/2F/2E/2D/2C/2D/2E/2|\"F\"F/2E/2F/2G/2A/2B/2|\"G\"c/2B/2A/2G/2\"C\"EC|\"C\"ccc|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:C\n",
      "|\"G7\"|\"C\"|\"C\"|\"G7\"|\"C\"|\"C\"|\"G7\"|\"G7\"|\"C\"|\"C\"|\"G7\"|\"C\"|\"G\"|\"C\"|\"Dm\"|\"Dm\"|\"G7\"|\"C\"|]\n",
      "\"G7\"G|\"C\"cc/2B/2c/2B/2c/2|d/2c/2B/2AG2|\"C\"G/2F/2E/2G/2BA/2G/2|\"G7\"G/2A/2G/2F/2E/2D2|\"C\"C2E2|\"C\"CE/2F/2G/2c/2B/2c/2|d/2c/2B/2AG|\"C\"cGE2|\"G7\"G/2A/2G/2F/2E/2D/2E/2F/2|\"G7\"F\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "|(3GF/2G/2|\"C\"cE/2G/2cG/2c/2|\"F\"A/2c/2A/2c/2A/2c/2A/2|\"G\"BGDG/2F/2|\"G\"E/2D/2G/2B/2A/2G/2F/2E/2|\"C\"CCEG/2c/2G/2|\"F\"A/2c/2A/2c/2A/2c/2A/2|\"G\"BGAB|\"C\"ccc|B/2c/2|\"F\"A/2c/2f/2c/2A/2c/2A/2c/2|\"G\"B/2G/2d/2G/2B/2G/2B/2G/2|\"C\"c/2e/2G/2B/2e/2G/2B/2G/2|\"F\"A/2c/2f/2c/2A/2c/2A/2c/2|\"G\"B/2G/2d/2G/2B/2G/2B/2G/2|\"C\"ccc|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"C\"|\"G\"|\"D7\"|\"G\"|\"C\"|\"G\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|\"D7\"|\"G\"|\"G\"\"C\"|\"G\"|\"D\"|\"G\"|\"A7\"|\"D7\"|\"G\"|]\n",
      "\"G\"G/2A/2B/2c/2d2|\"C\"e/2d/2c/2B/2AB|\"G\"G/2A/2B/2c/2d2|\"D7\"A/2B/2c/2d/2ef|\"G\"g2d2|\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "c/2B/2|\"C\"c/2c/2G/2c/2|\"F\"aag/2a/2|\"G\"b/2g/2a/2g/2f/2e/2|\"G\"gGA/2B/2|\"C\"c/2c/2G/2c/2e/2c/2|\"F\"a/2g/2f/2e/2d/2c/2|\"G\"B/2GGB|\"C\"c/2c/2G/2E/2C/2E/2|\"F\"A/2c/2c/2A/2c/2A/2c/2|\"G\"B/2GG/2B/2d/2G/2B/2|\"C\"cec|e/2f/2|\"C\"g/2e/2c/2e/2gg|\"F\"a/2f/2d/2f/2aa/2g/2|\"G\"f/2e/2d/2c/2B/2d/2G/2B/2|\"C\"cec|\"C\"e/2c/2G/2E/2G/2c/2e/2|\"F\"a/2g/2f/2e/2d/2c/2A/2c/2|\"G\"B/2GGG/2A/2B/2|\"C\"cec|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"C\"|\"G\"|\"Am\"\"D7\"|\"G\"|\"C\"\"D7\"|\"G\"|\"G\"|\"G\"\"D7\"|\"G\"|\"G\"|\"C\"|\"D7\"|\"G\"\"D7\"|\"G\"|\"G\"\"D7\"|\"G\"|\"C\"\"D7\"|\"G\"|]\n",
      "d/2c/2|\"G\"BGBA\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "G|\"C\"g2e3/2d/2|g2c3/2d/2|c2G3/2A/2|\"F\"FGA3/2F/2|\"G\"g2e3/2d/2|\"G\"c2G3/2A/2|\"C\"G2d3/2A/2|G2c3/2d/2|\"F\"c2f3/2e/2|\"G\"d2d3/2e/2|\"G\"c2G3/2A/2|\"C\"G2d3/2c/2|G2c3/2d/2|\"F\"c2f3/2e/2|\"G\"d2d3/2e/2|\"C\"g2c3/2d/2|\"F\"c2f3/2e/2|\"G\"d2G3/2A/2|\"C\"G2d3/2c/2|G2c3/2d/2|\"F\"c2f3/2e/2|\"G\"c2G3/2A/2|\"C\"G2d3/2c/2|\"F\"A2f3/2e/2|\"G\"d2G3/2A/2|\"C\"G2d3/2c/2|G2c3/2d/2|\"F\"c2f3/2e/2|\"G\"d2G3/2A/2|\"G\"c2d3/2c/2|\"C\"G2d3/2c/2|G2c3/2d/2|\"F\"c2f3/2e/2|\"G\"d2G3/2A/2|\"C\"G2d3/2c/2|\"F\"cAAG/2A/2|G2c3/2d/2|\"F\"c2f3/2e/2|\"G\"d2G3/2A/2|\"C\"G2d3/2c/2|d\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "cd|\"C\"e/2e/2e/2d/2|c/2A/2G/2A/2|\"F\"A3/2G/2|A/2G/2A/2|\"G\"B/2A/2G/2A/2|\"G\"GB/2A/2|\"C\"G3/2c/4d/4|e/2c/2A/2G/2|\"F\"A3/2G/2|A/2G/2F/2A/2|\"G\"G3/2F/4G/2A/2|\"C\"E/2F/2\"F\"F/2A/2c/2A/2|c/2B/2A/2G/2E/2|\"G\"D2|\"C\"E2C|\"F\"A/2G/2A/2G/2F/2E/2|F/2A/2G/2F/2A/2|\"G\"B/2G/2A/2G/2A/2|\"C\"E3/2c/2d/4|c/2A/2G/2A/2G/2|\"F\"A/2G/2F/2A/2c/2A/2|c/2B/2A/2G/2|\"G\"B/2G/2A/2G/2A/2|\"C\"C2|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:C\n",
      "|\"G7\"|\"G7\"|\"C\"|\"C\"|\"Dm\"|\"G7\"|\"G7\"|\"C\"|\"C\"|\"C\"|\"C\"\"D7\"|\"G7\"|\"G7\"|\"C\"|\"C\"|\"F\"|\"C\"|\"Dm\"|\"G\"|\"G7\"|\"C\"|]\n",
      "G/2F/2|\"G7\"E/2D/2E/2F/2GD/2F/2|\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "G|\"C\"GGA|\"F\"F/2A/2G/2F/2E/2F/2G/2|ADC|\"F\"A/2F/2A/2G/2F/2E/2F/2G/2|\"G\"AGA|\"C\"GCC2|\"F\"FF/2A/2G/2A/2B/2|c/2A/2c/2d/2c/2A/2G/2F/2G/2|\"G\"D/2GGA|\"C\"GGA2|\"F\"A/2G/2A/2G/2F/2E/2F/2G/2|A/2G/2F/2E/2F/2G/2A/2B/2|\"G\"cGC2|\"F\"F3|c/2d/2|c/2|d/2c/2B/2A/2Gd/2e/2d/2c/2|d/2c/2B/2A/2Gd/2c/2|\"G\"B/2G/2d/2G/2B/2d/2e/2d/2c/2B/2|\"C\"c/2d/2c/2B/2A/2Gd/2e/2d/2c/2|dcBGA|\"F\"F/2A/2G/2A/2G/2F/2E/2F/2G/2|A/2F/2A/2G/2F/2E/2F/2G/2|A/2F/2A/2G/2F/2E/2F/2A/2G/2|\"G\"AGGA|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"G\"\"C\"|\"G\"|\"D\"|\"D\"|\"D\"|\"G\"|\"G\"|\"G\"\"C\"|\"G\n",
      "---------------\n",
      "M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]\n",
      "\"C\"GG|\"C\"CCE/2G/2|\"F\"A/2G/2A/2c/2A/2G/2A/2|\"G\"B/2G/2A/2G/2A/2G/2A/2|\"G\"B/2G/2A/2G/2F/2D/2E/2D/2|\"C\"CCE/2G/2|\"F\"A/2G/2A/2c/2A/2G/2A/2|\"G\"B/2G/2A/2G/2F/2D/2E/2G/2|\"C\"CCE/2G/2|\"F\"A/2G/2A/2c/2A/2G/2A/2|\"G\"B/2G/2A/2G/2F/2D/2E/2G/2|\"C\"CCE/2G/2c/2|\"F\"A/2c/2f/2e/2d/2e/2f/2|\"G\"dBG^G/2A/2|\"C\"G/2ee/2g/2e/2g/2e/2|\"F\"A/2c/2f/2e/2d/2e/2f/2|\"G\"d/2g/2f/2e/2de/2f/2|\"C\"ecc|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:F\n",
      "|\"F\"|\"F\"|\"C\"|\"F\"|\"F\"|\"C\"|\"Dm\"|\"F\"|\"F\"|\"F\"|\"C\"|\"F\"|\"F\"|\"F\"|\"F\"|\"C\"|\"F\"|\"C\"|\"F\"|]\n",
      "A/2B/2|\"F\"c/2A/2A/2A/2AA/2B/2|c/2A/2A/2A/2\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start='M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test minor key with low samples: Am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-abc-char\n",
      "Overriding: start = M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "number of parameters: 11.31M\n",
      "abc_char\n",
      "Loading meta from data/abc_char/meta.pkl...\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "EF|\"Am\"EABA/2G/2|\"Am\"A3/2B/2c/2B/2A/2|\"Dm\"A2DE|\"E\"EAAB|\"Am\"EABA/2G/2|\"Am\"A3/2B/2c/2B/2A/2|\"Dm\"A2FE|\"E\"EAAG|\"Am\"AGG^F|\"Dm\"GAFG|\"G\"B2cd|\"Am\"c/2d/2c/2B/2A/2G/2F/2E/2|\"Dm\"D2DE|\"E\"EAAA|\"Am\"EAAG^F|\"E\"EAAG^F|\"Am\"EAAG^F|\"Dm\"GAFG|\"G\"B4|\"Am\"A2AG|\"Am\"AGG^F|\"E\"EAAG^F|\"Am\"EAAG^F|\"E\"EAAG^F|\"Am\"EAAG^F|\"Dm\"GAFG|\"G\"B2cd|\"Am\"c/2d/2c/2B/2A/2G/2F/2E/2|\"Dm\"D2DE|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"C\"\"D7\"|\"G\"|\"G\"|\"Am\"\"D7\"|\"G\"\"D7\"|\"G\"|\"C\"\"D7\"|\"G\"|\"G\"|\"G\"|\"Am\"|\"Am\"\"D7\"|\"G\"|\"G\"|\"Am\"\"D7\"|\"G\"|\"G\"|\"C\"\"D7\"|\"G\"|]\n",
      "d/2c/2|\"G\"B/2A/2G/2F/2\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "\"Am\"eA/2B/2|c/2B/2A/2|\"Am\"A3/2B/2|\"Dm\"A/2B/2A/2|\"E\"^G/2A/2B/2|\"Am\"eAA/2B/2|c/2B/2A|\"Am\"e2e/2f/2|\"Dm\"e/2d/2c/2B/2A|\"E\"^GEe3/2f/2|\"Am\"e/2^d/2e/2f/2e/2f/2|\"Dm\"edd/2e/2f/2|\"E\"fee/2f/2|\"Am\"e2e/2f/2|\"Dm\"edd/2e/2|\"E\"^cee3/2f/2|\"Am\"eAAB|\"Am\"c/2A/2\"D\"e3/2f/2|\"E\"e2e|\"Am\"e2e/2f/2|\"Dm\"edd/2e/2f/2|\"E\"e2e|\"Am\"e2e/2f/2|\"G\"e2e|\"Am\"e2e/2f/2|\"G\"e2e/2^d/2|\"Am\"e2e/2f/2|\"Dm\"edd/2e/2|\"E\"^cee3/2f/2|\"Am\"e2AB|\"E\"e2e|\"Am\"e2e/2f/2|\"E\"e2e/2^d/2f/2|\"Am\"e2A|\"Am\"e2e/2f/2|\"Dm\"eddd/2e/2|\"G\"^cee|\"Am\"A2AB|\"E\"e2e/2f/2|\"Am\"e2e/2f/\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "\"Am\"agf/2e/2|c/2c/2A/2B/2A/2B/2|c/2A/2EE|\"Am\"agf/2e/2|\"Dm\"c/2A/2A/2B/2A/2B/2|c/2A/2EE|\"G\"G/2A/2B/2A/2B/2c/2d/2|\"E\"e/2d/2c/2B/2A/2B/2|\"Am\"c/2A/2EE|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:D\n",
      "|\"D\"|\"D\"\"A\"|\"D\"|\"G\"\"A\"|\"D\"|\"D\"\"A\"|\"D\"|\"D\"|\"D\"|\"A\"|\"D\"|\"D\"|\"D\"\"Bm\"|\"E\"\"A\"|\"D\"|]\n",
      "d/2e/2|\"D\"fd/2A/2FA|\"D\"FA\"A\"Ge/2f/2g/2|\"D\"fd/2A/2FA|\"G\"BG/2A/2\"A\"G/2F/2E/2G/2|\"D\"FAFA|\"D\"F/2G/2A/2F/2A|\"D\"FA/2d/2\"A\"e/2f/2g/2e/2|\"D\"fdd|f/2g/2|\"D\"afdf/2g/2|\"D\"afdf/2g/2|\"D\"af\"A\"ge|\"D\"fddf/2g/2|\"D\"afdf/2g/2|\"D\"afdf/2g/2|\"D\"af\"Bm\"ge/2f/2|\"E\"ge/2d/2\"A\"c/2e/2\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "|G|\"Am\"A2B|cBcd|\"Am\"e2B|cBAB|\"Dm\"c2B2|\"E\"A2GA|BcBcd|\"Am\"e2BBc|\"Dm\"cBAA2|\"E\"A2GA|Bcdef|\"Am\"e2Bcd|e2Bcd|\"Dm\"edcBA|\"E\"A2GA2|Bc|\"Am\"A2GA|BcdBc|\"Dm\"deddcB|\"E\"A2GA2|Bc|\"Am\"A2GA2B|cdBc2B|\"Am\"A3/2G/2A|Bcdefg|\"Dm\"a2efed|\"E\"A2GA2|BcdBcB|\"Am\"AecA2B|cdBc2B|\"Am\"A/2B/2A/2G/2A2|BcdBc|\"Dm\"deddcB|\"E\"A2GA2|Bcdef|\"E\"e2BcdcB|\"Am\"A2GA2|]\n",
      "\n",
      "M:6/8\n",
      "L:1/8\n",
      "K:F#\n",
      "|\"F\"|\"F\"|\"Gm\"\"C7\"|\"F\"|\"F\"|\"Gm\"\"C7\"|\"F\"|\"F\"|\"B\"|\"F\"|\"Gm\"\"C7\"|\"F\"|\"F\"|\"B\"|\"F\"|\"Gm\"\"C7\"|\"F\"|\"F\"|\"B\"|\"F\"\"F7\"|\"B\"\"C7\"|\"F\"|\"F\"|\"Gm\"\"C7\"|\"F\"|\"D#m\"|\"B\"\"C7\"|\"F\"|]\n",
      "D/2E/2|\"\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "\"Am\"A3/2B/2|c/2B/2A/2|B/2E|\"Am\"A3/2B/2|c3/2B/2G/2|\"Dm\"A3/2B/2|c3/2B/2A/2|\"E\"B3/2c/2B/2|c3/2B/2G/2|\"Am\"A3/2B/2c3/2|\"Dm\"B2A/2G/2|\"E\"E3/2F/2G/2F/2|E2E|\"Am\"A3/2B/2c3/2B/2|\"Dm\"A3/2B/2c3/2B/2|A3/2B/2c3/2B/2|\"E\"c3/2B/2B/2G/2|\"Am\"A3/2B/2c3/2B/2|\"Dm\"A3/2B/2c3/2|\"E\"E2E|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:Bb\n",
      "|\"B\"|\"E\"|\"E\"|\"F\"\"F7\"|\"B\"|\"E\"|\"B\"|\"G#m\"\"E\"|\"B\"|\"E\"\"B\"|\"C#m\"\"F7\"|\"B\"|\"E\"|\"B\"|\"E\"|\"F7\"|\"B\"|\"E\"\"B\"|\"C#m\"\"F7\"|\"B\"|]\n",
      "B/2c/2|\"B\"d/2c/2d/2c/2BD|\"E\"E/2F/2G/2A/2BG|\"E\"E/2F/2G/2A/2BG|\"F\"F3\"F7\"F2|\"B\"d/2c/2d/2c/2BD|\"E\"E/2F/2G/2A/2BG\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "\"Am\"aa3/4g/4f/2e/2|\"Dm\"d/2c/2d/2c/2|\"E\"B/2EF/2G/2|\"Am\"A3/4B/4c/2A/2|\"Dm\"d/2c/2A/2c/2|\"E\"B/2E/2EF/2G/2|\"Am\"A3/2B/4c/2A/2|\"Dm\"d/2c/2d/2c/2|\"E\"B/2E/2EG/2A/2|\"Am\"A3/2|B/2|\"Am\"A3/2B/2c/2B/2|A/2G/2F/2E/2F/2G/2|\"Dm\"A3/2B/2c/2A/2|\"E\"B/2E/2G/2A/2B/2c/2|\"Am\"A2A|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:Am\n",
      "|\"E7\"|\"Am\"\"G\"|\"Am\"\"E7\"|\"Am\"\"E7\"|\"Am\"|\"Am\"|\"E7\"|\"Am\"|\"G\"|\"G\"\"C\"|\"G\"\"Em\"|\"Am\"|\"Em\"\"C\"|\"Em\"|]\n",
      "|E|\"E7\"EBBB2|\"Am\"AA\"G\"GG|\"Am\"AA\"E7\"E^G|\"Am\"ABA\"E7\"G2|\"Am\"AA\"E7\"E^G|\"Am\"ABAA\"E7\"EF^G|\"Am\"ABAA3|\"G\"G2GGFG|\"G\"G2G\"C\"cde|\"G\"d2G\"Em\"E2G|\"Am\"A\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "E/2F/2|\"Am\"E/2F/2E/2F/2G/2|\"Am\"A3/2B/2c/2d/2|e/2d/2c/2B/2A/2G/2A/2|\"Dm\"F/2E/2F/2G/2A/2G/2E/2F/2|\"E\"E/2F/2G/2A/2B/2A/2G/2A/2|\"E\"^G/2E/2F/2G/2E/2F/2G/2|\"Am\"AAA|E/2E/2|\"Am\"A/2A/2A/2^G/2AA|\"Dm\"d/2^c/2d/2e/2d/2c/2B/2A/2|\"E\"^G/2B/2E/2D/2E/2F/2G/2|\"Am\"A/2A/2A/2^G/2AA|\"Dm\"d/2^c/2d/2e/2d/2c/2B/2A/2|\"E\"^G/2E/2F/2G/2E/2F/2G/2|\"Am\"AA|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:D\n",
      "|\"D\"|\"D\"|\"D\"|\"G\"\"A\"|\"D\"|\"D\"|\"D\"|\"D\"|\"G\"\"A\"|\"D\"|\"G\"\"A\"|\"D\"|\"A\"\"A\"|\"D\"|\"E\"\"A\"|\"D\"|\"G\"\"A\"|\"D\"|]\n",
      "d/2e/2|\"D\"f/2d/2A/2B/2AA|\"D\"d/2e/2d/2c/2df|\"D\"A/2B/2A/2B/2AA|\"G\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "c/2d/2|\"Am\"e/2c/2e/2d/2c/2B/2c/2|\"Am\"e/2c/2e/2d/2c/2d/2|e/2c/2e/2d/2c/2B/2A/2|\"Dm\"d/2e/2d/2c/2B/2A/2G/2|\"E\"EEG/2A/2|\"Am\"e/2c/2e/2d/2e/2c/2d/2|\"Dm\"e/2d/2e/2f/2g/2f/2e/2d/2|\"E\"e/2=d/2e/2d/2c/2B/2A/2G/2|\"Am\"EAA/2G/2A/2|\"Dm\"d/2e/2d/2c/2B/2A/2G/2|\"E\"EEG/2A/2|\"Am\"e/2a/2a/2b/2a/2g/2f/2e/2|\"Dm\"d/2e/2d/2c/2B/2A/2G/2|\"E\"EEG/2A/2|\"Am\"e/2a/2a/2b/2a/2g/2f/2e/2d/2|\"Dm\"A/2a/2a/2g/2a3/2g/2|\"E\"e/2=d/2e/2d/2c/2B/2A/2G/2|\"Am\"EAA/2G/2A/2|E/2E/2|\"Dm\"D/2a/2a/2g/2f/2e/2f/2e/2d/2|\"Em\"EEEG/2A/2|\"Am\"e/2a/2b/2a/2b/2a/2g/\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "|E/2F/2|\"Am\"EAAB/2^c/2|e/2A/2B/2A/2^G/2A/2B/2|e/2A/2B/2A/2^G/2A/2B/2|\"Dm\"AAAB/2^c/2|\"E\"e/2^d/2e/2f/2e/2d/2c/2d/2|e/2A/2B/2A/2^GE|\"Am\"EAAB/2^c/2|e/2A/2B/2A/2^GA/2B/2|e/2A/2B/2A/2^GA/2B/2|e/2A/2B/2A/2GE|\"Dm\"A/2^G/2A/2B/2A(3G/2A/2G/2A/2B/2|e/2A/2B/2A/2^GA/2B/2|\"Am\"e/2A/2B/2A/2G/2A/2B/2^c/2|e/2A/2B/2A/2^GA/2B/2|e/2A/2B/2A/2\"E\"B/2A/2F/2G/2|\"Am\"AcA|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:A\n",
      "|\"A\"|\"A\"|\"E7\"|\"A\"|\"A\"|\"D\"\"E7\"|\"A\"|\"B7\"|\"E\"|\"E\"|\"E\"|\"E\"|\"E\"|\"E\"|\"B7\"|\"E\"|\"B7\"|\"B7\"|\"E\"|\"E\"|\"E\"|\"E\"|\"B7\"|\"E\"|\"E\"|\"Fm\"|\"F7\"|\"B7\"|\"B7\"|\"E\"|\n",
      "---------------\n",
      "M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]\n",
      "c/2d/2|\"Am\"e/2=d/2e/2=fg/2a/2|\"Am\"e/2^d/2e/2^f/2g/2a/2|\"Dm\"e/2f/2e/2d/2c/2d/2e/2=f/2|\"E\"e/2^d/2e/2^f/2g/2a/2g/2f/2e/2|\"E\"d/2c/2B/2G/2A/2G/2=F/2E/2|\"Am\"A/2^G/2A/2B/2c/2A/2G/2A/2|\"Dm\"d/2^c/2d/2e/2\"E\"^g/2f/2g/2e/2|\"Am\"a2A|\"Dm\"afde/2f/2|\"E\"e/2^d/2e/2^f/2g/2a/2g/2f/2e/2|\"Am\"a/2^g/2a/2b/2a/2g/2a|\"Dm\"g/2e/2d/2e/2e/2^f/2g/2a/2g/2|\"E\"e/2^d/2e/2^f/2g/2a/2g/2f/2e/2|\"Am\"a2AG|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:A\n",
      "|\"A\"|\"A\"|\"E\"|\"E\"\"E7\"|\"A\"|\"A\"|\"A\"|\"E\"|\"E\"|\"E\"|\"E\"|\"E\"|\"E\"|\"A\"|\"A\"|\"A\"|\"E\"|\"E\"|\"E\"|\"E\"|\"E\"|\"E\"|\"E\"\"E7\"|\"A\"|]\n",
      "A/2B/2|\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start='M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test older checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = older_ckpt/m_voices\n",
      "Overriding: path_meta = older_ckpt/m_voices\n",
      "Overriding: start = M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "number of parameters: 14.18M\n",
      "shakespeare_char\n",
      "Loading meta from older_ckpt/m_voices/meta.pkl...\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]G/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]G/2E\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d2|\"G\"B3/2g/2d3/2B/2G3/2B/2d3/2B/2|\"D\"c3/2e/2a3/2g/2f3/2d/2e3/2f/2|\"G\"B3/2g/2d3/2B/2g3/2d/2B3/2d/2|\"D\"c3/2A/2d3/2A/2e3/2A/2f3/2A/2|\"G\"g3/2d/2B3/2d/2g3/2b/2a3/2g/2|\"D\"f3/2d/2A3/2d/2f3/2a/2g3/2f/2|\"C\"e3/2d/2c3/2B/2\"D\"c3/2e/2d3/2c/2|\"G\"B2G2G2d2|\"D\"ADBDcDdc|\"G\"BGcG^cGdG|\"D\"ADBDcDd2|\"G\"edd^cd4|\"D\"ADBDcDdc|\"G\"BGcG^cGd2|\"C\"ecgc\"D\"fcac|\"G\"g2b2g4|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:Eb\n",
      "|\"D\"|\"G\"\"A\"|\"D\"|\"Em\"\"A\"|\"D\"|\"G\"\"A\"|\"G\"\"A\"|\"D\"|\"G\"\"D\"|\"G\"\"D\"|\"G\"\"D\"|\"E\"\"A\"|\"G\"\"D\"|\"G\"\"D\"|\"G\"\"D\"|\"E\"\"A\"|\"A\"\"D\"|]\n",
      "A/2|\"D\"d/2c/2d/2e/2fA|\"G\"Be\"\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2f/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d2|\"G\"G/2B/2d3/4d/4|\"C\"e/2e/2c/2A/2|\"D\"F/2A/2D/2|\"D\"F/2A/2D/2d/2|\"D\"=c/2d/2A/2^G/2A/2|\"G\"B/2G/2d3/2e/4|\"G\"d/2B/2G/2A/2|\"C\"E/2G/2D/2=CD/2|\"D\"F/2A/2d/4d/4f/4e/4|\"G\"g/2G/2G/2|\"C\"c/2G/2c/2e|\"D\"d/4c/4B/4A/2f/4|\"G\"g/2d/2B/2G/2|\"D\"F/2A/2D/2A/4d/4|\"G\"B/2G/2d/4d3/4d/4|\"D\"A/2d/4c/4B/4A/2|\"G\"G/2B/2G/2|\"C\"E/2G/2\"G\"G|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:B\n",
      "|\"A\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"A\"\"Bm\"|\"E\"\"A\"\"A\"|\"D\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"D\"|\"A\"\"Bm\"|\"E\"\"A\"|\"A\"\"Bm\"|\"E\"\"A\"|]\n",
      "z/2|\"A\"z/2A/2-A/2G/2AA|\"Bm\"B/2c/2B/2A/2\"E\"GE|\"A\"z/2A/2-\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d/2|\"G\"B3/2G/2G/2|\"C\"cBc|\"D\"d2d|\"G\"G2B/2c/2|\"G\"d3/2B/2GG|\"C\"cB\"D\"AB/2c/2|\"G\"d2\"C\"e/2c/2|\"G\"d2g3/2B/2|\"D\"cABc|\"G\"d2\"C\"e3/2d/2|\"D\"fzde/2f/2|\"G\"g3/2e/2d3/2e/2|g/2c/2B/2A/2G2|\"D\"A2g3/2f/2|\"G\"g3/2d/2B/2\"C\"cB|\"D\"Ad\"G\"g3/2f/2|\"Em\"g/2e/2\"A\"^c/2\"D\"d2|\"A\"e/2d/2c/2d/2eA/2c/2|\"D\"d2\"G\"B/2A/2G/2A/2|\"D\"FDD|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"A\"|\"E\"|\"E\"|\"A\"|\"E\"\"A\"|\"A\"|\"F#m\"|\"Bm\"\"E\"|\"Bm\"\"E\"|\"A\"\"Bm\"|\"A\"\"E\"|\"A\"\"A\"|]\n",
      "e|\"A\"a3/2g/2a/2e/2c/2A/2|\"E\"BGE3/2E/2|\"/2F/2A/2AB/2c/2|\"Bm\"dc\"E\"e3/2d/2|\"A\"c3/2B/2A\"E\"B/2^G/2E/2B/2d/2c/2B/2|\"A\"A\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2e/2|\"G\"g/2d/2B/2|GB/2A/2|\"G\"G/4A/4B/4c/4d/2g/2|d/2B/2B/2g/2|\"F\"=f/2A/2A/2B/2|cA\"G\"G/4A/4B/4c/4d/2B/2|\"C\"e/2d/4c/4\"G\"d/2B/2|\"G\"G/4A/4B/4c/4d/2B/2|dB|\"G\"G/4A/4B/4c/4d/2B/2|\"C\"e/2d/4c/4d/2e/2|\"F\"=f/2A/2A/2B/2|cA\"G\"g/2d/2B/4c/4d/4B/4|g/2d/2B/4c/4d/4B/4|\"G\"g/2d/2B/4c/4d/4B/4|gd|\"G\"g/2d/2B/4c/4d/4B/4|g/2d/2B/4c/4d/4B/4|\"D\"a/4d/4A/2A/2B/2|\"D7\"cA|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:F\n",
      "|\"D\"|\"C\"|\"D\"|\"D\"|\"G\"\"A\"|\"D\"|\"G\"|\"D\"|\"E\"|\"A\"|\"G\"|\"D\"|\"G\"\"A\"|\"D\"|]\n",
      "a/2g/2|\"D\"fdfd|f/2af/2ag/2f/2|\"C\"e=cec|e/2ge/2ga/2g/2|\"D\"fdfd|\"D\"f/2af/\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d2|\"G\"B3/2g/2d3/4e/4d/2B/2|\"G\"g/2d/2B/2G/2A/2|B3/4B/4B/2A/2|\"G\"G3/2|\"C\"E/2G/2D/2E/2G/2A/2|\"D\"B3/4B/4B/2A/2G/2|\"G\"G3/2B/2A/2G/2|\"C\"E/2G/2D/2E/2G/2A/2|\"D\"B3/2B/4B/4A/2G/2|\"G\"G2|]\n",
      "\n",
      "M:3/4\n",
      "L:1/4\n",
      "K:Gb\n",
      "|\"D\"|\"D\"|\"G\"|\"D\"|\"D\"|\"Em\"\"A\"|\"D\"|\"D\"|\"A\"|\"Bm\"|\"A7\"|\"D\"|\"A\"|\"E7\"|\"A\"|\"G\"|\"D\"|\"A\"|\"D\"|\"D\"|\"Em\"|\"A7\"|\"D\"|]\n",
      "|A|\"D\"f3/2e/2d|\"D\"AFA|\"G\"BGB|\"D\"AFA|\"D\"f3/2e/2d|\"D\"AFA|\"Em\"Be\"A\"c|\"D\"d2|A|\"D\"f2a|\"A\"e2a|\"Bm\"d3/2e/2d|\"A7\"cBA|\"D\"f2a|\"A\"e2a|\"E7\"^gfg|\"A\"a2a|\"G\"b2b|\"D\"a2a|\"A\"ggg|\"D\"fed|\"D\"f3/2e/2d|\"Em\"Bgf|\"A7\"edc|\"D\"d2\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"D\"f/2e/2f/2g/2a/2b/2|\"D\"c'/2a/2f/2dd|\"G\"g/2f/2g/2a/2b/2g/2e/2d/2|\"C\"c/2g/2f/2g/2a/2g/2e/2d/2c/2|\"G\"B/2g/2f/2g/2d/2g/2d/2B/2|\"D\"cAA|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"G\"|\"G\"\"D7\"|\"G\"\"D7\"|\"G\"|\"D\"|\"G\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    " !python3 sample.py --out_dir=older_ckpt/m_voices --path_meta=older_ckpt/m_voices --start='M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat older_ckpt/m_voices/ckpt.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l older_ckpt/m_voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l out-abc-char/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
