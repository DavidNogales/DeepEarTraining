{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_dataframe(relative_path,dataframe_name):\n",
    "    df = pd.read_pickle(f'{relative_path}/{dataframe_name}.pkl')    \n",
    "    return df\n",
    "\n",
    "def read_file(relative_path,file_name):\n",
    "    text= \"\"\n",
    "    with open(f'{relative_path}/{file_name}.abc','r') as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['unit_note_length', 'tuneBook', 'title', 'reference_number',\n",
       "       'original_header', 'original_body', 'meter', 'key', 'clean_song',\n",
       "       'clean_header', 'clean_body', 'chord_progression', '\"Gm\"', '\"G7\"',\n",
       "       '\"G\"', '\"F7\"', '\"F#m\"', '\"F#7\"', '\"F\"', '\"Em\"', '\"Eb\"', '\"E7\"', '\"E\"',\n",
       "       '\"Dm\"', '\"D7\"', '\"D\"', '\"Cm\"', '\"C7\"', '\"C\"', '\"Bm\"', '\"Bb\"', '\"B7\"',\n",
       "       '\"B\"', '\"Am\"', '\"A7\"', '\"A\"'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_path =\"notebooks/data/final_dataset\"\n",
    "filename_name = 'clean_augmented_data'\n",
    "#filename_name = 'clean_original_training_data'\n",
    "#relative_path =\"notebooks/data/original_dataset\"\n",
    "training_data_df = load_dataframe(relative_path,filename_name)\n",
    "training_data_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    \"Gm\"g4\"D7\"^f2=ef\"Gm\"g4|\"Cm\"d2cB\"D7\"ABc2\"Gm\"B2G...\n",
       "1    |D|\"G\"GBBA/2B/2|\"D7\"cAAd|\"G\"BGGB|\"Am\"A/2G/2F/2...\n",
       "2    \"G\"DEDG2A|\"G\"BcBA2G|\"G7\"dB2A2G|\"C\"E3-E3|\"G\"DED...\n",
       "3    a|\"Dm\"afga|\"Dm\"fe/2f/2da|\"Dm\"afga|\"Dm\"f2fa|\"F\"...\n",
       "4    A|\"D\"d2efdf|\"G\"g3\"A7\"fga|\"D\"fgf\"Em\"e2d|\"E7\"e3\"...\n",
       "Name: clean_body, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df.head()[\"clean_body\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_note_length</th>\n",
       "      <th>tuneBook</th>\n",
       "      <th>title</th>\n",
       "      <th>reference_number</th>\n",
       "      <th>original_header</th>\n",
       "      <th>original_body</th>\n",
       "      <th>meter</th>\n",
       "      <th>key</th>\n",
       "      <th>clean_song</th>\n",
       "      <th>clean_header</th>\n",
       "      <th>...</th>\n",
       "      <th>\"Cm\"</th>\n",
       "      <th>\"C7\"</th>\n",
       "      <th>\"C\"</th>\n",
       "      <th>\"Bm\"</th>\n",
       "      <th>\"Bb\"</th>\n",
       "      <th>\"B7\"</th>\n",
       "      <th>\"B\"</th>\n",
       "      <th>\"Am\"</th>\n",
       "      <th>\"A7\"</th>\n",
       "      <th>\"A\"</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9720</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Grandpa's</td>\n",
       "      <td>78</td>\n",
       "      <td>X:78\\nT:Grandpa's\\nM:4/4\\nL:1/4\\nK:A</td>\n",
       "      <td>A/2G/2|\"D\"FA\"A7\"Bc|\"D\"d/2c/2d/2e/2fa|\"Em\"gf\"E7...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"|\"Em\"\"E7\"|\"A7\"|...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"|\"Em\"\"E7\"|\"A7\"|...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9721</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>The Girl With The Green Hat On</td>\n",
       "      <td>79</td>\n",
       "      <td>X:79\\nT:The Girl With The Green Hat On\\nM:4/4\\...</td>\n",
       "      <td>(3A/2B/2c/2|\"D\"dA\"A7\"A/2B/2A/2G/2|\"D\"F/2G/2A/2...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"\"A7\"|\"D\"|\"A7\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"\"A7\"|\"D\"|\"A7\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9722</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Green Meadow</td>\n",
       "      <td>80</td>\n",
       "      <td>X:80\\nT:Green Meadow\\nM:4/4\\nL:1/4\\nK:D</td>\n",
       "      <td>(3D/2E/2F/2|\"G\"GG/2A/2B/2G/2B/2d/2|\"C\"e/2f/2g/...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>D</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:D\\n|\"G\"|\"C\"\"G\"|\"Am\"|\"Am\"\"D7\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:D\\n|\"G\"|\"C\"\"G\"|\"Am\"|\"Am\"\"D7\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9723</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>The Old Grey Cat</td>\n",
       "      <td>82</td>\n",
       "      <td>X:82\\nT:The Old Grey Cat\\nM:4/4\\nL:1/4\\nK:Bm</td>\n",
       "      <td>B|\"Em\"eeEE/2F/2|\"Em\"G/2F/2G/2A/2B/2A/2B/2^c/2|...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>Bm</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:Bm\\n|\"Em\"|\"Em\"|\"D\"|\"D\"|\"Em\"|\"E...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:Bm\\n|\"Em\"|\"Em\"|\"D\"|\"D\"|\"Em\"|\"E...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9724</th>\n",
       "      <td>1/4</td>\n",
       "      <td>dataset_min5.abc</td>\n",
       "      <td>Gyre And Gimble</td>\n",
       "      <td>84</td>\n",
       "      <td>X:84\\nT:Gyre And Gimble\\nM:4/4\\nL:1/4\\nK:A</td>\n",
       "      <td>A|\"D\"dAFA|\"Em\"BG\"A7\"EG|\"D\"FAd3/2e/2|\"A7\"f/2g/2...</td>\n",
       "      <td>4/4</td>\n",
       "      <td>A</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"D\"|\"Em\"\"A7\"|\"D\"|\"A7\"\"D\"|\"...</td>\n",
       "      <td>M:4/4\\nL:1/4\\nK:A\\n|\"D\"|\"Em\"\"A7\"|\"D\"|\"A7\"\"D\"|\"...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     unit_note_length          tuneBook                           title  \\\n",
       "9720              1/4  dataset_min5.abc                       Grandpa's   \n",
       "9721              1/4  dataset_min5.abc  The Girl With The Green Hat On   \n",
       "9722              1/4  dataset_min5.abc                    Green Meadow   \n",
       "9723              1/4  dataset_min5.abc                The Old Grey Cat   \n",
       "9724              1/4  dataset_min5.abc                 Gyre And Gimble   \n",
       "\n",
       "     reference_number                                    original_header  \\\n",
       "9720               78               X:78\\nT:Grandpa's\\nM:4/4\\nL:1/4\\nK:A   \n",
       "9721               79  X:79\\nT:The Girl With The Green Hat On\\nM:4/4\\...   \n",
       "9722               80            X:80\\nT:Green Meadow\\nM:4/4\\nL:1/4\\nK:D   \n",
       "9723               82       X:82\\nT:The Old Grey Cat\\nM:4/4\\nL:1/4\\nK:Bm   \n",
       "9724               84         X:84\\nT:Gyre And Gimble\\nM:4/4\\nL:1/4\\nK:A   \n",
       "\n",
       "                                          original_body meter key  \\\n",
       "9720  A/2G/2|\"D\"FA\"A7\"Bc|\"D\"d/2c/2d/2e/2fa|\"Em\"gf\"E7...   4/4   A   \n",
       "9721  (3A/2B/2c/2|\"D\"dA\"A7\"A/2B/2A/2G/2|\"D\"F/2G/2A/2...   4/4   A   \n",
       "9722  (3D/2E/2F/2|\"G\"GG/2A/2B/2G/2B/2d/2|\"C\"e/2f/2g/...   4/4   D   \n",
       "9723  B|\"Em\"eeEE/2F/2|\"Em\"G/2F/2G/2A/2B/2A/2B/2^c/2|...   4/4  Bm   \n",
       "9724  A|\"D\"dAFA|\"Em\"BG\"A7\"EG|\"D\"FAd3/2e/2|\"A7\"f/2g/2...   4/4   A   \n",
       "\n",
       "                                             clean_song  \\\n",
       "9720  M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"|\"Em\"\"E7\"|\"A7\"|...   \n",
       "9721  M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"\"A7\"|\"D\"|\"A7\"|\"...   \n",
       "9722  M:4/4\\nL:1/4\\nK:D\\n|\"G\"|\"C\"\"G\"|\"Am\"|\"Am\"\"D7\"|\"...   \n",
       "9723  M:4/4\\nL:1/4\\nK:Bm\\n|\"Em\"|\"Em\"|\"D\"|\"D\"|\"Em\"|\"E...   \n",
       "9724  M:4/4\\nL:1/4\\nK:A\\n|\"D\"|\"Em\"\"A7\"|\"D\"|\"A7\"\"D\"|\"...   \n",
       "\n",
       "                                           clean_header  ... \"Cm\" \"C7\"  \"C\"  \\\n",
       "9720  M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"|\"Em\"\"E7\"|\"A7\"|...  ...    0    0    0   \n",
       "9721  M:4/4\\nL:1/4\\nK:A\\n|\"D\"\"A7\"|\"D\"\"A7\"|\"D\"|\"A7\"|\"...  ...    0    0    0   \n",
       "9722  M:4/4\\nL:1/4\\nK:D\\n|\"G\"|\"C\"\"G\"|\"Am\"|\"Am\"\"D7\"|\"...  ...    0    0    6   \n",
       "9723  M:4/4\\nL:1/4\\nK:Bm\\n|\"Em\"|\"Em\"|\"D\"|\"D\"|\"Em\"|\"E...  ...    0    0    0   \n",
       "9724  M:4/4\\nL:1/4\\nK:A\\n|\"D\"|\"Em\"\"A7\"|\"D\"|\"A7\"\"D\"|\"...  ...    0    0    0   \n",
       "\n",
       "      \"Bm\"  \"Bb\"  \"B7\"  \"B\"  \"Am\"  \"A7\"  \"A\"  \n",
       "9720     0     0     0    0     0     7    2  \n",
       "9721     0     0     0    0     0     6    2  \n",
       "9722     0     0     0    0     4     0    0  \n",
       "9723     0     0     3    0     1     0    0  \n",
       "9724     0     0     0    0     0     7    1  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_df[\"clean_header\"].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab:  \n",
      "\"#'()+,-/1234567=ABCDEFG[]^_abcdefgmz|~\n",
      "vocab_size 40\n",
      "silences  612\n"
     ]
    }
   ],
   "source": [
    "bodies = \"\"\n",
    "silences = 0\n",
    "for body in training_data_df[\"clean_body\"]:\n",
    "    if 'z' in body:\n",
    "        silences +=1 \n",
    "    bodies += body+\"\\n\"\n",
    "chars = sorted(list(set(bodies)))\n",
    "vocab_size = len(chars)\n",
    "print('vocab: ',''.join(chars))\n",
    "print('vocab_size',vocab_size)\n",
    "print(\"silences \",silences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of chars: 4149705\n"
     ]
    }
   ],
   "source": [
    "training_data_text = read_file(relative_path,filename_name)\n",
    "\n",
    "print(\"number of chars:\",len(training_data_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"#'()+,-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(training_data_text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu117\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.28.0.dev0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14.2\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import tiktoken\n",
    "\n",
    "print(wandb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==1.4.0\n",
      "aiohttp==3.8.4\n",
      "aiosignal==1.3.1\n",
      "alembic==1.10.2\n",
      "antlr4-python3-runtime==4.9.3\n",
      "anyio==3.6.2\n",
      "appdirs==1.4.4\n",
      "APScheduler==3.10.1\n",
      "argon2-cffi==21.3.0\n",
      "argon2-cffi-bindings==21.2.0\n",
      "arrow==1.2.3\n",
      "asttokens==2.2.1\n",
      "async-timeout==4.0.2\n",
      "attrs==22.2.0\n",
      "audioread==3.0.0\n",
      "av==9.2.0\n",
      "Babel==2.12.1\n",
      "backcall==0.2.0\n",
      "backoff==1.11.1\n",
      "backports.zoneinfo==0.2.1\n",
      "beautifulsoup4==4.11.2\n",
      "binaryornot==0.4.4\n",
      "black==23.1.0\n",
      "bleach==6.0.0\n",
      "cachetools==5.3.0\n",
      "certifi==2022.12.7\n",
      "cffi==1.15.1\n",
      "chardet==5.1.0\n",
      "charset-normalizer==3.1.0\n",
      "click==8.1.3\n",
      "clldutils==3.19.0\n",
      "cloudpickle==2.2.1\n",
      "cmaes==0.9.1\n",
      "cmake==3.25.0\n",
      "codecarbon==1.2.0\n",
      "colorama==0.4.6\n",
      "coloredlogs==15.0.1\n",
      "colorlog==6.7.0\n",
      "comm==0.1.3\n",
      "contourpy==1.0.7\n",
      "cookiecutter==1.7.3\n",
      "csvw==3.1.3\n",
      "cycler==0.11.0\n",
      "dash==2.8.1\n",
      "dash-bootstrap-components==1.4.0\n",
      "dash-core-components==2.0.0\n",
      "dash-html-components==2.0.0\n",
      "dash-table==5.0.0\n",
      "datasets==2.10.1\n",
      "debugpy==1.6.7\n",
      "decorator==5.1.1\n",
      "decord==0.6.0\n",
      "defusedxml==0.7.1\n",
      "detectron2 @ git+https://github.com/facebookresearch/detectron2.git@3ed66980529aadf662f469bca744221cab762e83\n",
      "dill==0.3.4\n",
      "distlib==0.3.6\n",
      "dlinfo==1.2.1\n",
      "docker-pycreds==0.4.0\n",
      "evaluate==0.4.0\n",
      "exceptiongroup==1.1.1\n",
      "execnet==1.9.0\n",
      "executing==1.2.0\n",
      "faiss-cpu==1.7.3\n",
      "fastjsonschema==2.16.3\n",
      "filelock==3.9.1\n",
      "fire==0.5.0\n",
      "Flask==2.2.3\n",
      "flatbuffers==23.3.3\n",
      "fonttools==4.39.0\n",
      "fqdn==1.5.1\n",
      "frozenlist==1.3.3\n",
      "fsspec==2023.3.0\n",
      "fugashi==1.2.1\n",
      "fvcore==0.1.5.post20221221\n",
      "gitdb==4.0.10\n",
      "GitPython==3.1.18\n",
      "google-auth==2.16.2\n",
      "google-auth-oauthlib==0.4.6\n",
      "gql==3.4.0\n",
      "graphql-core==3.2.3\n",
      "greenlet==2.0.2\n",
      "grpcio==1.51.3\n",
      "hf-doc-builder==0.4.0\n",
      "huggingface-hub==0.13.2\n",
      "humanfriendly==10.0\n",
      "hydra-core==1.3.2\n",
      "hypothesis==6.68.3\n",
      "idna==3.4\n",
      "importlib-metadata==6.0.0\n",
      "importlib-resources==5.12.0\n",
      "iniconfig==2.0.0\n",
      "iopath==0.1.9\n",
      "ipadic==1.0.0\n",
      "ipykernel==6.22.0\n",
      "ipython==8.12.0\n",
      "ipython-genutils==0.2.0\n",
      "isodate==0.6.1\n",
      "isoduration==20.11.0\n",
      "isort==5.12.0\n",
      "itsdangerous==2.0.1\n",
      "jedi==0.18.2\n",
      "Jinja2==3.1.2\n",
      "jinja2-time==0.2.0\n",
      "joblib==1.2.0\n",
      "json5==0.9.11\n",
      "jsonpointer==2.3\n",
      "jsonschema==4.17.3\n",
      "jupyter-events==0.6.3\n",
      "jupyter_client==8.1.0\n",
      "jupyter_core==5.2.0\n",
      "jupyter_server==2.5.0\n",
      "jupyter_server_terminals==0.4.4\n",
      "jupyterlab==3.5.1\n",
      "jupyterlab-pygments==0.2.2\n",
      "jupyterlab_server==2.22.0\n",
      "kenlm==0.1\n",
      "kiwisolver==1.4.4\n",
      "language-tags==1.2.0\n",
      "lazy_loader==0.1\n",
      "librosa==0.10.0\n",
      "lit==15.0.7\n",
      "llvmlite==0.39.1\n",
      "lxml==4.9.2\n",
      "Mako==1.2.4\n",
      "Markdown==3.4.1\n",
      "MarkupSafe==2.1.2\n",
      "matplotlib==3.6.2\n",
      "matplotlib-inline==0.1.6\n",
      "mistune==2.0.5\n",
      "mpmath==1.3.0\n",
      "msgpack==1.0.5\n",
      "multidict==6.0.4\n",
      "multiprocess==0.70.12.2\n",
      "mypy-extensions==1.0.0\n",
      "nbclassic==0.5.5\n",
      "nbclient==0.7.3\n",
      "nbconvert==7.3.0\n",
      "nbformat==5.7.3\n",
      "nest-asyncio==1.5.6\n",
      "networkx==3.0\n",
      "nltk==3.8.1\n",
      "notebook==6.5.4\n",
      "notebook_shim==0.2.2\n",
      "numba==0.56.4\n",
      "numpy==1.23.4\n",
      "nvidia-cublas-cu11==11.10.3.66\n",
      "nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "nvidia-cuda-runtime-cu11==11.7.99\n",
      "nvidia-cudnn-cu11==8.5.0.96\n",
      "oauthlib==3.2.2\n",
      "omegaconf==2.3.0\n",
      "onnx==1.13.1\n",
      "onnxruntime==1.14.1\n",
      "onnxruntime-tools==1.7.0\n",
      "optuna==3.1.0\n",
      "packaging==23.0\n",
      "pandas==1.5.2\n",
      "pandocfilters==1.5.0\n",
      "parameterized==0.8.1\n",
      "parso==0.8.3\n",
      "pathspec==0.11.1\n",
      "pathtools==0.1.2\n",
      "pexpect==4.8.0\n",
      "phonemizer==3.2.1\n",
      "pickleshare==0.7.5\n",
      "Pillow==9.4.0\n",
      "pkgutil_resolve_name==1.3.10\n",
      "plac==1.3.5\n",
      "platformdirs==3.1.1\n",
      "plotly==5.13.1\n",
      "pluggy==1.0.0\n",
      "pooch==1.7.0\n",
      "portalocker==2.0.0\n",
      "poyo==0.5.0\n",
      "prometheus-client==0.16.0\n",
      "prompt-toolkit==3.0.38\n",
      "protobuf==3.20.2\n",
      "psutil==5.9.4\n",
      "ptyprocess==0.7.0\n",
      "pure-eval==0.2.2\n",
      "py-cpuinfo==9.0.0\n",
      "py3nvml==0.2.7\n",
      "pyarrow==11.0.0\n",
      "pyasn1==0.4.8\n",
      "pyasn1-modules==0.2.8\n",
      "pycocotools==2.0.6\n",
      "pycparser==2.21\n",
      "pyctcdecode==0.5.0\n",
      "Pygments==2.14.0\n",
      "pygtrie==2.5.0\n",
      "pylatexenc==2.10\n",
      "pynvml==11.5.0\n",
      "pyparsing==3.0.9\n",
      "pypng==0.20220715.0\n",
      "pyrsistent==0.19.3\n",
      "pytesseract==0.3.10\n",
      "pytest==7.2.2\n",
      "pytest-timeout==2.1.0\n",
      "pytest-xdist==3.2.1\n",
      "python-dateutil==2.8.2\n",
      "python-json-logger==2.0.7\n",
      "python-slugify==8.0.1\n",
      "pytz==2022.7.1\n",
      "pytz-deprecation-shim==0.1.0.post0\n",
      "PyYAML==5.4.1\n",
      "pyzmq==25.0.2\n",
      "ray==2.3.0\n",
      "rdflib==6.2.0\n",
      "regex==2022.10.31\n",
      "requests==2.28.2\n",
      "requests-oauthlib==1.3.1\n",
      "requests-toolbelt==0.10.1\n",
      "responses==0.18.0\n",
      "rfc3339-validator==0.1.4\n",
      "rfc3986==1.5.0\n",
      "rfc3986-validator==0.1.1\n",
      "rhoknp==1.2.1\n",
      "rjieba==0.1.11\n",
      "rouge-score==0.1.2\n",
      "rsa==4.9\n",
      "ruff==0.0.256\n",
      "sacrebleu==1.5.1\n",
      "sacremoses==0.0.53\n",
      "safetensors==0.3.0\n",
      "scikit-learn==1.2.2\n",
      "scipy==1.10.1\n",
      "seaborn==0.12.1\n",
      "segments==2.2.1\n",
      "Send2Trash==1.8.0\n",
      "sentencepiece==0.1.97\n",
      "sentry-sdk==1.19.1\n",
      "setproctitle==1.3.2\n",
      "sigopt==8.7.0\n",
      "six==1.16.0\n",
      "smmap==5.0.0\n",
      "sniffio==1.3.0\n",
      "sortedcontainers==2.4.0\n",
      "soundfile==0.12.1\n",
      "soupsieve==2.4\n",
      "soxr==0.3.4\n",
      "SQLAlchemy==2.0.6\n",
      "stack-data==0.6.2\n",
      "SudachiDict-core==20230110\n",
      "SudachiPy==0.6.7\n",
      "sympy==1.11.1\n",
      "tabulate==0.9.0\n",
      "tenacity==8.2.2\n",
      "tensorboard==2.12.0\n",
      "tensorboard-data-server==0.7.0\n",
      "tensorboard-plugin-wit==1.8.1\n",
      "tensorboardX==2.6\n",
      "termcolor==2.2.0\n",
      "terminado==0.17.1\n",
      "text-unidecode==1.3\n",
      "threadpoolctl==3.1.0\n",
      "tiktoken==0.3.3\n",
      "timeout-decorator==0.5.0\n",
      "timm==0.6.12\n",
      "tinycss2==1.2.1\n",
      "tokenizers==0.13.2\n",
      "tomli==2.0.1\n",
      "torch==2.0.0+cu117\n",
      "torchaudio==2.0.0+cu117\n",
      "torchvision==0.15.0+cu117\n",
      "tornado==6.2\n",
      "tqdm==4.65.0\n",
      "traitlets==5.9.0\n",
      "-e git+https://github.com/huggingface/transformers@f7329751fe5c43365751951502c00df5a4654359#egg=transformers\n",
      "triton==2.0.0\n",
      "typing_extensions==4.5.0\n",
      "tzdata==2022.7\n",
      "tzlocal==4.2\n",
      "unidic==1.1.0\n",
      "unidic-lite==1.0.8\n",
      "uri-template==1.2.0\n",
      "uritemplate==4.1.1\n",
      "urllib3==1.26.15\n",
      "virtualenv==20.21.0\n",
      "wandb==0.14.2\n",
      "wasabi==0.10.1\n",
      "wcwidth==0.2.6\n",
      "webcolors==1.13\n",
      "webencodings==0.5.1\n",
      "websocket-client==1.5.1\n",
      "Werkzeug==2.2.3\n",
      "xmltodict==0.13.0\n",
      "xxhash==3.2.0\n",
      "yacs==0.1.8\n",
      "yarl==1.8.2\n",
      "zipp==3.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile  docker-compose.yaml  overrides.json\n",
      "README.md   notebooks\t\t requirements.txt\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE      bench.py\t      model.py\t\t    train.py\n",
      "README.md    config\t      out-shakespeare-char  transformer_sizing.ipynb\n",
      "__pycache__  configurator.py  sample.py\n",
      "assets\t     data\t      scaling_laws.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "nano_path = 'notebooks/nanoGPT'\n",
    "os.chdir(nano_path)\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 4,149,703\n",
      "all the unique characters: \n",
      "\"#'()+,-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
      "vocab size: 46\n",
      "train has 3,734,732 tokens\n",
      "val has 414,971 tokens\n"
     ]
    }
   ],
   "source": [
    "!python3 data/shakespeare_char/prepare.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding config with config/train_shakespeare_char.py:\n",
      "# train a miniature character-level shakespeare model\n",
      "# good for debugging and playing on macbooks and such\n",
      "\n",
      "out_dir = 'out-abc-char'\n",
      "eval_interval = 25 # keep frequent because we'll overfit\n",
      "eval_iters = 500\n",
      "log_interval = 20 # don't print too too often\n",
      "\n",
      "# we expect to overfit on this small dataset, so only save when val improves\n",
      "always_save_checkpoint = False\n",
      "\n",
      "wandb_log = True # override via command line if you like\n",
      "wandb_project = 'abc-char'\n",
      "wandb_run_name = 'mini-char-gpt'\n",
      "\n",
      "dataset = 'shakespeare_char'\n",
      "batch_size = 64\n",
      "block_size = 512 # context of up to 512 previous characters\n",
      "\n",
      "# baby GPT model :)\n",
      "n_layer = 8\n",
      "n_head = 6\n",
      "n_embd = 384\n",
      "dropout = 0.2\n",
      "\n",
      "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
      "max_iters = 5000\n",
      "lr_decay_iters = 5000 # make equal to max_iters usually\n",
      "min_lr = 1e-4 # learning_rate / 10 usually\n",
      "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
      "\n",
      "warmup_iters = 5 # not super necessary potentially\n",
      "\n",
      "# on macbook also add\n",
      "# device = 'cpu'  # run on cpu only\n",
      "# compile = False # do not torch compile the model\n",
      "\n",
      "found vocab_size = 46 (inside data/shakespeare_char/meta.pkl)\n",
      "Initializing a new model from scratch\n",
      "number of parameters: 14.18M\n",
      "using fused AdamW: True\n",
      "compiling the model... (takes a ~minute)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavidnogales\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/pt-env/notebooks/nanoGPT/wandb/run-20230408_220842-60dcuq7u\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmini-char-gpt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char/runs/60dcuq7u\u001b[0m\n",
      "step 0: train loss 3.7824, val loss 3.7873\n",
      "[2023-04-08 22:09:59,204] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 22:09:59,431] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 22:09:59,758] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 22:09:59,940] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 22:10:00,201] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 22:10:00,379] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 22:10:00,725] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 22:10:00,906] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 22:10:01,157] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 22:10:01,334] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 22:10:01,592] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 22:10:01,773] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 22:10:02,026] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 22:10:02,204] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 22:10:02,465] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-08 22:10:02,651] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "iter 0: loss 3.8229, time 91022.40ms, mfu -100.00%\n",
      "iter 20: loss 2.4482, time 9671.79ms, mfu 4.52%\n",
      "step 25: train loss 2.0983, val loss 2.0590\n",
      "saving checkpoint to out-abc-char\n",
      "iter 40: loss 2.0231, time 9460.30ms, mfu 4.53%\n",
      "step 50: train loss 1.9096, val loss 1.8770\n",
      "saving checkpoint to out-abc-char\n",
      "iter 60: loss 1.7987, time 9457.40ms, mfu 4.53%\n",
      "step 75: train loss 1.7544, val loss 1.7282\n",
      "saving checkpoint to out-abc-char\n",
      "iter 80: loss 1.6960, time 9457.79ms, mfu 4.54%\n",
      "step 100: train loss 1.6222, val loss 1.5966\n",
      "saving checkpoint to out-abc-char\n",
      "iter 100: loss 1.5704, time 79579.77ms, mfu 4.14%\n",
      "iter 120: loss 1.5769, time 9672.91ms, mfu 4.18%\n",
      "step 125: train loss 1.5647, val loss 1.5373\n",
      "saving checkpoint to out-abc-char\n",
      "iter 140: loss 1.5809, time 9455.78ms, mfu 4.22%\n",
      "step 150: train loss 1.5153, val loss 1.4920\n",
      "saving checkpoint to out-abc-char\n",
      "iter 160: loss 1.4940, time 9453.10ms, mfu 4.26%\n",
      "step 175: train loss 1.4844, val loss 1.4605\n",
      "saving checkpoint to out-abc-char\n",
      "iter 180: loss 1.4261, time 9455.35ms, mfu 4.30%\n",
      "step 200: train loss 1.4533, val loss 1.4248\n",
      "saving checkpoint to out-abc-char\n",
      "iter 200: loss 1.4727, time 78013.17ms, mfu 3.93%\n",
      "iter 220: loss 1.4924, time 9450.11ms, mfu 4.00%\n",
      "step 225: train loss 1.4218, val loss 1.4006\n",
      "saving checkpoint to out-abc-char\n",
      "iter 240: loss 1.3945, time 9453.50ms, mfu 4.06%\n",
      "step 250: train loss 1.3880, val loss 1.3664\n",
      "saving checkpoint to out-abc-char\n",
      "iter 260: loss 1.4142, time 9453.26ms, mfu 4.11%\n",
      "step 275: train loss 1.3732, val loss 1.3513\n",
      "saving checkpoint to out-abc-char\n",
      "iter 280: loss 1.3948, time 9451.35ms, mfu 4.16%\n",
      "step 300: train loss 1.3181, val loss 1.2956\n",
      "saving checkpoint to out-abc-char\n",
      "iter 300: loss 1.3735, time 77842.96ms, mfu 3.80%\n",
      "iter 320: loss 1.3503, time 9453.86ms, mfu 3.89%\n",
      "step 325: train loss 1.2504, val loss 1.2277\n",
      "saving checkpoint to out-abc-char\n",
      "iter 340: loss 1.2459, time 9457.73ms, mfu 3.96%\n",
      "step 350: train loss 1.2180, val loss 1.1958\n",
      "saving checkpoint to out-abc-char\n",
      "iter 360: loss 1.2264, time 9450.59ms, mfu 4.03%\n",
      "step 375: train loss 1.1545, val loss 1.1383\n",
      "saving checkpoint to out-abc-char\n",
      "iter 380: loss 1.1982, time 9455.83ms, mfu 4.08%\n",
      "step 400: train loss 1.1254, val loss 1.1081\n",
      "saving checkpoint to out-abc-char\n",
      "iter 400: loss 1.1703, time 80549.98ms, mfu 3.73%\n",
      "iter 420: loss 1.0816, time 9695.23ms, mfu 3.81%\n",
      "step 425: train loss 1.0541, val loss 1.0393\n",
      "saving checkpoint to out-abc-char\n",
      "iter 440: loss 1.0555, time 9799.29ms, mfu 3.87%\n",
      "step 450: train loss 1.0032, val loss 0.9882\n",
      "saving checkpoint to out-abc-char\n",
      "iter 460: loss 1.0219, time 9711.51ms, mfu 3.93%\n",
      "step 475: train loss 0.9590, val loss 0.9479\n",
      "saving checkpoint to out-abc-char\n",
      "iter 480: loss 0.9917, time 9664.84ms, mfu 3.99%\n",
      "step 500: train loss 0.9261, val loss 0.9168\n",
      "saving checkpoint to out-abc-char\n",
      "iter 500: loss 0.9390, time 79595.93ms, mfu 3.65%\n",
      "iter 520: loss 0.9056, time 9664.14ms, mfu 3.74%\n",
      "step 525: train loss 0.8619, val loss 0.8518\n",
      "saving checkpoint to out-abc-char\n",
      "iter 540: loss 0.8617, time 9449.73ms, mfu 3.82%\n",
      "step 550: train loss 0.8258, val loss 0.8175\n",
      "saving checkpoint to out-abc-char\n",
      "iter 560: loss 0.8177, time 9662.82ms, mfu 3.89%\n",
      "step 575: train loss 0.7769, val loss 0.7684\n",
      "saving checkpoint to out-abc-char\n",
      "iter 580: loss 0.8238, time 9602.94ms, mfu 3.96%\n",
      "step 600: train loss 0.7294, val loss 0.7220\n",
      "saving checkpoint to out-abc-char\n",
      "iter 600: loss 0.7861, time 80814.83ms, mfu 3.62%\n",
      "iter 620: loss 0.7038, time 9829.37ms, mfu 3.70%\n",
      "step 625: train loss 0.6927, val loss 0.6889\n",
      "saving checkpoint to out-abc-char\n",
      "iter 640: loss 0.7033, time 9455.86ms, mfu 3.79%\n",
      "step 650: train loss 0.6359, val loss 0.6328\n",
      "saving checkpoint to out-abc-char\n",
      "iter 660: loss 0.7030, time 9454.29ms, mfu 3.87%\n",
      "step 675: train loss 0.5799, val loss 0.5764\n",
      "saving checkpoint to out-abc-char\n",
      "iter 680: loss 0.6455, time 9454.02ms, mfu 3.95%\n",
      "step 700: train loss 0.5435, val loss 0.5405\n",
      "saving checkpoint to out-abc-char\n",
      "iter 700: loss 0.5936, time 77867.11ms, mfu 3.61%\n",
      "iter 720: loss 0.5561, time 9454.84ms, mfu 3.71%\n",
      "step 725: train loss 0.4837, val loss 0.4817\n",
      "saving checkpoint to out-abc-char\n",
      "iter 740: loss 0.5011, time 9454.04ms, mfu 3.80%\n",
      "step 750: train loss 0.4358, val loss 0.4363\n",
      "saving checkpoint to out-abc-char\n",
      "iter 760: loss 0.4733, time 9453.60ms, mfu 3.88%\n",
      "step 775: train loss 0.3908, val loss 0.3914\n",
      "saving checkpoint to out-abc-char\n",
      "iter 780: loss 0.4338, time 9454.84ms, mfu 3.96%\n",
      "step 800: train loss 0.3536, val loss 0.3523\n",
      "saving checkpoint to out-abc-char\n",
      "iter 800: loss 0.4242, time 77849.21ms, mfu 3.62%\n",
      "iter 820: loss 0.3855, time 9455.66ms, mfu 3.72%\n",
      "step 825: train loss 0.3170, val loss 0.3163\n",
      "saving checkpoint to out-abc-char\n",
      "iter 840: loss 0.3644, time 9455.32ms, mfu 3.81%\n",
      "step 850: train loss 0.2797, val loss 0.2788\n",
      "saving checkpoint to out-abc-char\n",
      "iter 860: loss 0.3374, time 9455.53ms, mfu 3.89%\n",
      "step 875: train loss 0.2458, val loss 0.2464\n",
      "saving checkpoint to out-abc-char\n",
      "iter 880: loss 0.3174, time 9700.13ms, mfu 3.95%\n",
      "step 900: train loss 0.2139, val loss 0.2137\n",
      "saving checkpoint to out-abc-char\n",
      "iter 900: loss 0.2716, time 78791.23ms, mfu 3.61%\n",
      "iter 920: loss 0.2588, time 9795.74ms, mfu 3.70%\n",
      "step 925: train loss 0.1870, val loss 0.1870\n",
      "saving checkpoint to out-abc-char\n",
      "iter 940: loss 0.2399, time 9707.58ms, mfu 3.78%\n",
      "step 950: train loss 0.1775, val loss 0.1770\n",
      "saving checkpoint to out-abc-char\n",
      "iter 960: loss 0.2164, time 9735.27ms, mfu 3.85%\n",
      "step 975: train loss 0.1555, val loss 0.1551\n",
      "saving checkpoint to out-abc-char\n",
      "iter 980: loss 0.2143, time 9698.01ms, mfu 3.91%\n",
      "step 1000: train loss 0.1415, val loss 0.1412\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1000: loss 0.1961, time 79244.14ms, mfu 3.58%\n",
      "iter 1020: loss 0.1911, time 9708.63ms, mfu 3.67%\n",
      "step 1025: train loss 0.1234, val loss 0.1236\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1040: loss 0.1736, time 9457.10ms, mfu 3.76%\n",
      "step 1050: train loss 0.1099, val loss 0.1101\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1060: loss 0.1679, time 9449.50ms, mfu 3.85%\n",
      "step 1075: train loss 0.0993, val loss 0.0992\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1080: loss 0.1468, time 9410.76ms, mfu 3.93%\n",
      "step 1100: train loss 0.0914, val loss 0.0912\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1100: loss 0.1418, time 77425.43ms, mfu 3.59%\n",
      "iter 1120: loss 0.1325, time 9447.07ms, mfu 3.69%\n",
      "step 1125: train loss 0.0807, val loss 0.0809\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1140: loss 0.1180, time 9409.21ms, mfu 3.79%\n",
      "step 1150: train loss 0.0771, val loss 0.0768\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1160: loss 0.1072, time 9408.24ms, mfu 3.87%\n",
      "step 1175: train loss 0.0678, val loss 0.0677\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1180: loss 0.1103, time 9704.28ms, mfu 3.94%\n",
      "step 1200: train loss 0.0654, val loss 0.0656\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1200: loss 0.1086, time 79994.58ms, mfu 3.60%\n",
      "iter 1220: loss 0.0974, time 9454.48ms, mfu 3.70%\n",
      "step 1225: train loss 0.0612, val loss 0.0624\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1240: loss 0.0912, time 9453.78ms, mfu 3.79%\n",
      "step 1250: train loss 0.0582, val loss 0.0583\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1260: loss 0.0907, time 9708.48ms, mfu 3.86%\n",
      "step 1275: train loss 0.0549, val loss 0.0552\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1280: loss 0.0868, time 9695.41ms, mfu 3.93%\n",
      "step 1300: train loss 0.0540, val loss 0.0543\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1300: loss 0.0892, time 79830.96ms, mfu 3.59%\n",
      "iter 1320: loss 0.0791, time 9687.56ms, mfu 3.68%\n",
      "step 1325: train loss 0.0515, val loss 0.0520\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1340: loss 0.0744, time 9812.53ms, mfu 3.76%\n",
      "step 1350: train loss 0.0487, val loss 0.0496\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1360: loss 0.0718, time 9695.72ms, mfu 3.83%\n",
      "step 1375: train loss 0.0477, val loss 0.0479\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1380: loss 0.0718, time 9455.24ms, mfu 3.91%\n",
      "step 1400: train loss 0.0465, val loss 0.0464\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1400: loss 0.0689, time 80606.39ms, mfu 3.57%\n",
      "iter 1420: loss 0.0681, time 9667.43ms, mfu 3.67%\n",
      "step 1425: train loss 0.0451, val loss 0.0460\n",
      "saving checkpoint to out-abc-char\n",
      "^C\n",
      "Process ForkProcess-14:\n",
      "Process ForkProcess-20:\n",
      "Process ForkProcess-13:\n",
      "Process ForkProcess-19:\n",
      "Process ForkProcess-6:\n",
      "Process ForkProcess-8:\n",
      "Process ForkProcess-3:\n",
      "Process ForkProcess-9:\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-18:\n",
      "Process ForkProcess-15:\n",
      "Process ForkProcess-16:\n",
      "Process ForkProcess-4:\n",
      "Process ForkProcess-5:\n",
      "Process ForkProcess-12:\n",
      "Process ForkProcess-10:\n",
      "Process ForkProcess-11:\n",
      "Process ForkProcess-17:\n",
      "Process ForkProcess-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Process ForkProcess-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 97, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 293, in <module>\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\", line 487, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\", line 200, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 255).\u001b[0m Press Control-C to abort syncing.\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py config/train_shakespeare_char.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding: out_dir = out-abc-char\n",
      "Overriding: start = M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "number of parameters: 14.18M\n",
      "Loading meta from data/shakespeare_char/meta.pkl...\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]G/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]G/2E\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d2|\"G\"B3/2g/2d3/2B/2G3/2B/2d3/2B/2|\"D\"c3/2e/2a3/2g/2f3/2d/2e3/2f/2|\"G\"B3/2g/2d3/2B/2g3/2d/2B3/2d/2|\"D\"c3/2A/2d3/2A/2e3/2A/2f3/2A/2|\"G\"g3/2d/2B3/2d/2g3/2b/2a3/2g/2|\"D\"f3/2d/2A3/2d/2f3/2a/2g3/2f/2|\"C\"e3/2d/2c3/2B/2\"D\"c3/2e/2d3/2c/2|\"G\"B2G2G2d2|\"D\"ADBDcDdc|\"G\"BGcG^cGdG|\"D\"ADBDcDd2|\"G\"edd^cd4|\"D\"ADBDcDdc|\"G\"BGcG^cGd2|\"C\"ecgc\"D\"fcac|\"G\"g2b2g4|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:Eb\n",
      "|\"D\"|\"G\"\"A\"|\"D\"|\"Em\"\"A\"|\"D\"|\"G\"\"A\"|\"G\"\"A\"|\"D\"|\"G\"\"D\"|\"G\"\"D\"|\"G\"\"D\"|\"E\"\"A\"|\"G\"\"D\"|\"G\"\"D\"|\"G\"\"D\"|\"E\"\"A\"|\"A\"\"D\"|]\n",
      "A/2|\"D\"d/2c/2d/2e/2fA|\"G\"Be\"\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2f/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d2|\"G\"G/2B/2d3/4d/4|\"C\"e/2e/2c/2A/2|\"D\"F/2A/2D/2|\"D\"F/2A/2D/2d/2|\"D\"=c/2d/2A/2^G/2A/2|\"G\"B/2G/2d3/2e/4|\"G\"d/2B/2G/2A/2|\"C\"E/2G/2D/2=CD/2|\"D\"F/2A/2d/4d/4f/4e/4|\"G\"g/2G/2G/2|\"C\"c/2G/2c/2e|\"D\"d/4c/4B/4A/2f/4|\"G\"g/2d/2B/2G/2|\"D\"F/2A/2D/2A/4d/4|\"G\"B/2G/2d/4d3/4d/4|\"D\"A/2d/4c/4B/4A/2|\"G\"G/2B/2G/2|\"C\"E/2G/2\"G\"G|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:B\n",
      "|\"A\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"A\"\"Bm\"|\"E\"\"A\"\"A\"|\"D\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"Bm\"\"E\"|\"A\"|\"D\"|\"A\"\"Bm\"|\"E\"\"A\"|\"A\"\"Bm\"|\"E\"\"A\"|]\n",
      "z/2|\"A\"z/2A/2-A/2G/2AA|\"Bm\"B/2c/2B/2A/2\"E\"GE|\"A\"z/2A/2-\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d/2|\"G\"B3/2G/2G/2|\"C\"cBc|\"D\"d2d|\"G\"G2B/2c/2|\"G\"d3/2B/2GG|\"C\"cB\"D\"AB/2c/2|\"G\"d2\"C\"e/2c/2|\"G\"d2g3/2B/2|\"D\"cABc|\"G\"d2\"C\"e3/2d/2|\"D\"fzde/2f/2|\"G\"g3/2e/2d3/2e/2|g/2c/2B/2A/2G2|\"D\"A2g3/2f/2|\"G\"g3/2d/2B/2\"C\"cB|\"D\"Ad\"G\"g3/2f/2|\"Em\"g/2e/2\"A\"^c/2\"D\"d2|\"A\"e/2d/2c/2d/2eA/2c/2|\"D\"d2\"G\"B/2A/2G/2A/2|\"D\"FDD|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"A\"|\"E\"|\"E\"|\"A\"|\"E\"\"A\"|\"A\"|\"F#m\"|\"Bm\"\"E\"|\"Bm\"\"E\"|\"A\"\"Bm\"|\"A\"\"E\"|\"A\"\"A\"|]\n",
      "e|\"A\"a3/2g/2a/2e/2c/2A/2|\"E\"BGE3/2E/2|\"/2F/2A/2AB/2c/2|\"Bm\"dc\"E\"e3/2d/2|\"A\"c3/2B/2A\"E\"B/2^G/2E/2B/2d/2c/2B/2|\"A\"A\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2e/2|\"G\"g/2d/2B/2|GB/2A/2|\"G\"G/4A/4B/4c/4d/2g/2|d/2B/2B/2g/2|\"F\"=f/2A/2A/2B/2|cA\"G\"G/4A/4B/4c/4d/2B/2|\"C\"e/2d/4c/4\"G\"d/2B/2|\"G\"G/4A/4B/4c/4d/2B/2|dB|\"G\"G/4A/4B/4c/4d/2B/2|\"C\"e/2d/4c/4d/2e/2|\"F\"=f/2A/2A/2B/2|cA\"G\"g/2d/2B/4c/4d/4B/4|g/2d/2B/4c/4d/4B/4|\"G\"g/2d/2B/4c/4d/4B/4|gd|\"G\"g/2d/2B/4c/4d/4B/4|g/2d/2B/4c/4d/4B/4|\"D\"a/4d/4A/2A/2B/2|\"D7\"cA|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:F\n",
      "|\"D\"|\"C\"|\"D\"|\"D\"|\"G\"\"A\"|\"D\"|\"G\"|\"D\"|\"E\"|\"A\"|\"G\"|\"D\"|\"G\"\"A\"|\"D\"|]\n",
      "a/2g/2|\"D\"fdfd|f/2af/2ag/2f/2|\"C\"e=cec|e/2ge/2ga/2g/2|\"D\"fdfd|\"D\"f/2af/\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "d2|\"G\"B3/2g/2d3/4e/4d/2B/2|\"G\"g/2d/2B/2G/2A/2|B3/4B/4B/2A/2|\"G\"G3/2|\"C\"E/2G/2D/2E/2G/2A/2|\"D\"B3/4B/4B/2A/2G/2|\"G\"G3/2B/2A/2G/2|\"C\"E/2G/2D/2E/2G/2A/2|\"D\"B3/2B/4B/4A/2G/2|\"G\"G2|]\n",
      "\n",
      "M:3/4\n",
      "L:1/4\n",
      "K:Gb\n",
      "|\"D\"|\"D\"|\"G\"|\"D\"|\"D\"|\"Em\"\"A\"|\"D\"|\"D\"|\"A\"|\"Bm\"|\"A7\"|\"D\"|\"A\"|\"E7\"|\"A\"|\"G\"|\"D\"|\"A\"|\"D\"|\"D\"|\"Em\"|\"A7\"|\"D\"|]\n",
      "|A|\"D\"f3/2e/2d|\"D\"AFA|\"G\"BGB|\"D\"AFA|\"D\"f3/2e/2d|\"D\"AFA|\"Em\"Be\"A\"c|\"D\"d2|A|\"D\"f2a|\"A\"e2a|\"Bm\"d3/2e/2d|\"A7\"cBA|\"D\"f2a|\"A\"e2a|\"E7\"^gfg|\"A\"a2a|\"G\"b2b|\"D\"a2a|\"A\"ggg|\"D\"fed|\"D\"f3/2e/2d|\"Em\"Bgf|\"A7\"edc|\"D\"d2\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"D\"f/2e/2f/2g/2a/2b/2|\"D\"c'/2a/2f/2dd|\"G\"g/2f/2g/2a/2b/2g/2e/2d/2|\"C\"c/2g/2f/2g/2a/2g/2e/2d/2c/2|\"G\"B/2g/2f/2g/2d/2g/2d/2B/2|\"D\"cAA|]\n",
      "\n",
      "M:4/4\n",
      "L:1/4\n",
      "K:G\n",
      "|\"G\"|\"G\"|\"G\"\"D7\"|\"G\"\"D7\"|\"G\"|\"D\"|\"G\n",
      "---------------\n",
      "M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]\n",
      "e/2|\"G\"gg/2a/2gd/2c/2|\"G\"B/2G/2A/2G/2[+GB][+GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][+GB]e/2f/2|\"G\"gg/2a/2g/2e/2d/2c/2|\"G\"B/2G/2A/2G/2[GB][GB]|\"D\"A/2G/2F/2E/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]|e/2f/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb/2e/2|\"D\"f/2e/2f/2g/2a/2f/2a/2f/2|\"G\"g/2f/2g/2a/2\"C\"g/2e/2d/2e/2|\"G\"gg/2a/2g/2e/2d/2e/2|g/2f/2g/2a/2bb|\"D\"d'd'\"D7\"e/2f3/2|\"G\"g3/2a/2gG/2E/2|\"G\"D/2B,/2D/2G/2D/2B,/2D/2G/2|\"C\"E/2[CE][C/2E/2][CE][CE][CE]|\"D\"A/2B/2A/2F/2D/2F/2A/2c/2|\"G\"B/2[GB][G/2B/2][GB]\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    " !python3 sample.py --out_dir=out-abc-char --start='M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
