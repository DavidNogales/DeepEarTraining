{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def load_dataframe(relative_path,dataframe_name):\n",
    "    df = pd.read_pickle(f'{relative_path}/{dataframe_name}.pkl')    \n",
    "    return df\n",
    "\n",
    "def read_file(relative_path,file_name):\n",
    "    text= \"\"\n",
    "    with open(f'{relative_path}/{file_name}.abc','r') as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_path =\"notebooks/data/final_dataset\"\n",
    "filename_name = 'clean_augmented_data'\n",
    "#filename_name = 'clean_original_training_data'\n",
    "#relative_path =\"notebooks/data/original_dataset\"\n",
    "training_data_df = load_dataframe(relative_path,filename_name)\n",
    "training_data_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df[\"clean_header\"].str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df[\"clean_body\"].str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodies = \"\"\n",
    "silences = 0\n",
    "for body in training_data_df[\"clean_body\"]:\n",
    "    if 'z' in body:\n",
    "        silences +=1 \n",
    "    bodies += body+\"\\n\"\n",
    "chars = sorted(list(set(bodies)))\n",
    "vocab_size = len(chars)\n",
    "print('vocab: ',''.join(chars))\n",
    "print('vocab_size',vocab_size)\n",
    "print(\"silences \",silences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_text = read_file(relative_path,filename_name)\n",
    "\n",
    "print(\"number of chars:\",len(training_data_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(training_data_text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import tiktoken\n",
    "\n",
    "print(wandb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import shlex\n",
    "import os\n",
    "nano_path = 'notebooks/nanoGPT'\n",
    "os.chdir(nano_path)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with multiple voices present\n",
    "#length of dataset in characters: 4,149,703\n",
    "#all the unique characters: \n",
    "#\"#'()+,-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
    "#vocab size: 46\n",
    "#train has 3,734,732 tokens\n",
    "#val has 414,971 tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Normal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 4,062,773\n",
      "all the unique characters: \n",
      "\"#'(),-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
      "vocab size: 45\n",
      "train has 3,656,495 tokens\n",
      "val has 406,278 tokens\n"
     ]
    }
   ],
   "source": [
    "!python3 data/abc_char/prepare.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 train.py config/train_abc_char.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Roman Numeral Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 4,051,724\n",
      "all the unique characters: \n",
      "\"#'(),-/12345689:=ABCDEFGIKLMV[]^_abcdefgimvz|~\n",
      "vocab size: 48\n",
      "train has 3,646,551 tokens\n",
      "val has 405,173 tokens\n"
     ]
    }
   ],
   "source": [
    "!python3 data/abc_roman_num_char/prepare.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding config with config/train_abc_char.py:\n",
      "# train a miniature character-level shakespeare model\n",
      "# good for debugging and playing on macbooks and such\n",
      "\n",
      "out_dir = 'out-abc-char'\n",
      "eval_interval = 10 # keep frequent because we'll overfit\n",
      "eval_iters = 500\n",
      "log_interval = 5 # don't print too too often\n",
      "\n",
      "# we expect to overfit on this small dataset, so only save when val improves\n",
      "always_save_checkpoint = False\n",
      "\n",
      "wandb_log = True # override via command line if you like\n",
      "wandb_project = 'abc-char'\n",
      "wandb_run_name = 'mini-char-gpt-hd-8-ly-12-bt-4-rn-data'\n",
      "\n",
      "dataset = 'abc_roman_num_char'\n",
      "batch_size = 4\n",
      "block_size = 512 # context of up to 512 previous characters\n",
      "\n",
      "# baby GPT model :)\n",
      "n_layer = 12\n",
      "n_head = 8\n",
      "n_embd = 384\n",
      "dropout = 0.2\n",
      "\n",
      "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
      "max_iters = 5000\n",
      "lr_decay_iters = 5000 # make equal to max_iters usually\n",
      "min_lr = 1e-4 # learning_rate / 10 usually\n",
      "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
      "\n",
      "warmup_iters = 5 # not super necessary potentially\n",
      "\n",
      "# on macbook also add\n",
      "# device = 'cpu'  # run on cpu only\n",
      "# compile = False # do not torch compile the model\n",
      "found vocab_size = 48 (inside data/abc_roman_num_char/meta.pkl)\n",
      "Initializing a new model from scratch\n",
      "number of parameters: 21.26M\n",
      "using fused AdamW: True\n",
      "compiling the model... (takes a ~minute)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavidnogales\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/pt-env/notebooks/nanoGPT/wandb/run-20230428_225936-2jtws1os\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmini-char-gpt-hd-8-ly-12-bt-4-rn-data\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char/runs/2jtws1os\u001b[0m\n",
      "step 0: train loss 3.8530, val loss 3.8476\n",
      "[2023-04-28 22:59:53,187] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 22:59:53,483] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 22:59:53,779] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 22:59:53,978] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 22:59:54,239] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 22:59:54,422] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 22:59:54,682] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 22:59:54,897] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 22:59:55,148] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 22:59:55,334] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 22:59:55,589] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 22:59:55,770] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 22:59:56,125] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 22:59:56,318] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 22:59:56,569] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 22:59:56,756] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 22:59:57,062] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 22:59:57,252] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 22:59:57,505] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 22:59:57,687] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 22:59:57,940] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 22:59:58,120] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 22:59:58,389] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-28 22:59:58,644] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "iter 0: loss 3.8446, time 25821.56ms, mfu -100.00%\n",
      "iter 5: loss 2.9705, time 1226.92ms, mfu 3.34%\n",
      "step 10: train loss 2.7492, val loss 2.8303\n",
      "saving checkpoint to out-abc-char\n",
      "iter 10: loss 2.8279, time 10850.62ms, mfu 3.04%\n",
      "iter 15: loss 2.4997, time 1230.28ms, mfu 3.07%\n",
      "step 20: train loss 2.2876, val loss 2.3488\n",
      "saving checkpoint to out-abc-char\n",
      "iter 20: loss 2.4851, time 10727.32ms, mfu 2.80%\n",
      "iter 25: loss 2.2421, time 1226.23ms, mfu 2.85%\n",
      "step 30: train loss 1.9822, val loss 2.0511\n",
      "saving checkpoint to out-abc-char\n",
      "iter 30: loss 1.9182, time 10706.96ms, mfu 2.61%\n",
      "iter 35: loss 2.2487, time 1226.48ms, mfu 2.68%\n",
      "step 40: train loss 1.9120, val loss 1.9599\n",
      "saving checkpoint to out-abc-char\n",
      "iter 40: loss 2.0580, time 10814.15ms, mfu 2.45%\n",
      "iter 45: loss 1.8732, time 1244.85ms, mfu 2.53%\n",
      "step 50: train loss 1.8428, val loss 1.8964\n",
      "saving checkpoint to out-abc-char\n",
      "iter 50: loss 1.9061, time 11154.33ms, mfu 2.32%\n",
      "iter 55: loss 1.8077, time 1236.73ms, mfu 2.42%\n",
      "step 60: train loss 1.8283, val loss 1.8801\n",
      "saving checkpoint to out-abc-char\n",
      "iter 60: loss 1.7808, time 10831.54ms, mfu 2.21%\n",
      "iter 65: loss 1.6467, time 1222.45ms, mfu 2.33%\n",
      "step 70: train loss 1.7465, val loss 1.7929\n",
      "saving checkpoint to out-abc-char\n",
      "iter 70: loss 1.9410, time 10725.03ms, mfu 2.13%\n",
      "iter 75: loss 1.5950, time 1225.39ms, mfu 2.25%\n",
      "step 80: train loss 1.6784, val loss 1.7061\n",
      "saving checkpoint to out-abc-char\n",
      "iter 80: loss 1.6825, time 10784.74ms, mfu 2.06%\n",
      "iter 85: loss 1.6663, time 1224.20ms, mfu 2.19%\n",
      "step 90: train loss 1.6321, val loss 1.6656\n",
      "saving checkpoint to out-abc-char\n",
      "iter 90: loss 1.5340, time 10708.79ms, mfu 2.01%\n",
      "iter 95: loss 1.7591, time 1229.75ms, mfu 2.14%\n",
      "step 100: train loss 1.5739, val loss 1.5929\n",
      "saving checkpoint to out-abc-char\n",
      "iter 100: loss 1.4969, time 10853.74ms, mfu 1.97%\n",
      "iter 105: loss 1.2251, time 1241.10ms, mfu 2.10%\n",
      "step 110: train loss 1.5371, val loss 1.5502\n",
      "saving checkpoint to out-abc-char\n",
      "iter 110: loss 1.3633, time 10662.08ms, mfu 1.93%\n",
      "iter 115: loss 1.4785, time 1259.81ms, mfu 2.06%\n",
      "step 120: train loss 1.5003, val loss 1.4854\n",
      "saving checkpoint to out-abc-char\n",
      "iter 120: loss 1.4768, time 10677.97ms, mfu 1.89%\n",
      "iter 125: loss 1.4812, time 1228.07ms, mfu 2.04%\n",
      "step 130: train loss 1.4757, val loss 1.4607\n",
      "saving checkpoint to out-abc-char\n",
      "iter 130: loss 1.4622, time 10697.21ms, mfu 1.87%\n",
      "iter 135: loss 1.5588, time 1228.03ms, mfu 2.02%\n",
      "step 140: train loss 1.4572, val loss 1.4695\n",
      "iter 140: loss 1.3829, time 10587.95ms, mfu 1.85%\n",
      "iter 145: loss 1.5020, time 1234.58ms, mfu 2.00%\n",
      "step 150: train loss 1.4383, val loss 1.4394\n",
      "saving checkpoint to out-abc-char\n",
      "iter 150: loss 1.4069, time 10806.01ms, mfu 1.84%\n",
      "iter 155: loss 1.5310, time 1240.61ms, mfu 1.98%\n",
      "step 160: train loss 1.4271, val loss 1.4254\n",
      "saving checkpoint to out-abc-char\n",
      "iter 160: loss 1.5885, time 10768.87ms, mfu 1.82%\n",
      "iter 165: loss 1.4052, time 1230.70ms, mfu 1.97%\n",
      "step 170: train loss 1.4206, val loss 1.4168\n",
      "saving checkpoint to out-abc-char\n",
      "iter 170: loss 1.3533, time 10845.22ms, mfu 1.81%\n",
      "iter 175: loss 1.3708, time 1229.07ms, mfu 1.97%\n",
      "step 180: train loss 1.4157, val loss 1.3950\n",
      "saving checkpoint to out-abc-char\n",
      "iter 180: loss 1.5461, time 10816.21ms, mfu 1.81%\n",
      "iter 185: loss 1.4669, time 1211.43ms, mfu 1.96%\n",
      "step 190: train loss 1.4048, val loss 1.3946\n",
      "saving checkpoint to out-abc-char\n",
      "iter 190: loss 1.3947, time 10776.14ms, mfu 1.81%\n",
      "iter 195: loss 1.3614, time 1206.80ms, mfu 1.96%\n",
      "step 200: train loss 1.3876, val loss 1.3920\n",
      "saving checkpoint to out-abc-char\n",
      "iter 200: loss 1.3813, time 10970.36ms, mfu 1.81%\n",
      "iter 205: loss 1.3293, time 1230.39ms, mfu 1.96%\n",
      "step 210: train loss 1.3838, val loss 1.3782\n",
      "saving checkpoint to out-abc-char\n",
      "iter 210: loss 1.3973, time 10741.32ms, mfu 1.80%\n",
      "iter 215: loss 1.5730, time 1230.68ms, mfu 1.95%\n",
      "step 220: train loss 1.3679, val loss 1.3547\n",
      "saving checkpoint to out-abc-char\n",
      "iter 220: loss 1.2953, time 10715.93ms, mfu 1.80%\n",
      "iter 225: loss 1.5179, time 1229.75ms, mfu 1.95%\n",
      "step 230: train loss 1.3741, val loss 1.3802\n",
      "iter 230: loss 1.2903, time 10450.35ms, mfu 1.79%\n",
      "iter 235: loss 1.5005, time 1228.78ms, mfu 1.95%\n",
      "step 240: train loss 1.3528, val loss 1.3446\n",
      "saving checkpoint to out-abc-char\n",
      "iter 240: loss 1.3894, time 11220.69ms, mfu 1.79%\n",
      "iter 245: loss 1.3939, time 1258.94ms, mfu 1.93%\n",
      "step 250: train loss 1.3232, val loss 1.3327\n",
      "saving checkpoint to out-abc-char\n",
      "iter 250: loss 1.5070, time 10619.02ms, mfu 1.78%\n",
      "iter 255: loss 1.3924, time 1224.60ms, mfu 1.94%\n",
      "step 260: train loss 1.3066, val loss 1.3046\n",
      "saving checkpoint to out-abc-char\n",
      "iter 260: loss 1.2501, time 10578.14ms, mfu 1.78%\n",
      "iter 265: loss 1.2771, time 1223.06ms, mfu 1.94%\n",
      "step 270: train loss 1.2819, val loss 1.2796\n",
      "saving checkpoint to out-abc-char\n",
      "iter 270: loss 1.1711, time 10694.53ms, mfu 1.78%\n",
      "iter 275: loss 1.2954, time 1235.89ms, mfu 1.94%\n",
      "step 280: train loss 1.2703, val loss 1.2578\n",
      "saving checkpoint to out-abc-char\n",
      "iter 280: loss 1.2774, time 10682.43ms, mfu 1.78%\n",
      "iter 285: loss 1.2999, time 1226.15ms, mfu 1.94%\n",
      "step 290: train loss 1.2876, val loss 1.2846\n",
      "iter 290: loss 1.1100, time 10366.70ms, mfu 1.78%\n",
      "iter 295: loss 1.3585, time 1222.82ms, mfu 1.94%\n",
      "step 300: train loss 1.2508, val loss 1.2441\n",
      "saving checkpoint to out-abc-char\n",
      "iter 300: loss 1.3066, time 10674.26ms, mfu 1.78%\n",
      "iter 305: loss 1.1612, time 1224.85ms, mfu 1.94%\n",
      "step 310: train loss 1.2339, val loss 1.2257\n",
      "saving checkpoint to out-abc-char\n",
      "iter 310: loss 1.3146, time 10658.39ms, mfu 1.78%\n",
      "iter 315: loss 1.2463, time 1223.32ms, mfu 1.94%\n",
      "step 320: train loss 1.2239, val loss 1.2194\n",
      "saving checkpoint to out-abc-char\n",
      "iter 320: loss 1.2325, time 10777.92ms, mfu 1.78%\n",
      "iter 325: loss 1.4399, time 1221.55ms, mfu 1.94%\n",
      "step 330: train loss 1.2073, val loss 1.1920\n",
      "saving checkpoint to out-abc-char\n",
      "iter 330: loss 1.0934, time 10728.69ms, mfu 1.78%\n",
      "iter 335: loss 1.1951, time 1225.45ms, mfu 1.94%\n",
      "step 340: train loss 1.1769, val loss 1.1873\n",
      "saving checkpoint to out-abc-char\n",
      "iter 340: loss 1.2247, time 10716.71ms, mfu 1.78%\n",
      "iter 345: loss 1.0828, time 1223.70ms, mfu 1.94%\n",
      "step 350: train loss 1.1622, val loss 1.1744\n",
      "saving checkpoint to out-abc-char\n",
      "iter 350: loss 1.2106, time 10682.56ms, mfu 1.78%\n",
      "iter 355: loss 1.2438, time 1225.72ms, mfu 1.94%\n",
      "step 360: train loss 1.1594, val loss 1.1547\n",
      "saving checkpoint to out-abc-char\n",
      "iter 360: loss 1.1170, time 10844.28ms, mfu 1.78%\n",
      "iter 365: loss 1.1343, time 1221.55ms, mfu 1.94%\n",
      "step 370: train loss 1.1428, val loss 1.1459\n",
      "saving checkpoint to out-abc-char\n",
      "iter 370: loss 1.3327, time 10657.73ms, mfu 1.78%\n",
      "iter 375: loss 1.2427, time 1223.55ms, mfu 1.94%\n",
      "step 380: train loss 1.1506, val loss 1.1354\n",
      "saving checkpoint to out-abc-char\n",
      "iter 380: loss 1.4463, time 10601.84ms, mfu 1.79%\n",
      "iter 385: loss 1.1743, time 1236.53ms, mfu 1.94%\n",
      "step 390: train loss 1.1176, val loss 1.1068\n",
      "saving checkpoint to out-abc-char\n",
      "iter 390: loss 1.1500, time 10661.44ms, mfu 1.78%\n",
      "iter 395: loss 1.0431, time 1222.56ms, mfu 1.94%\n",
      "step 400: train loss 1.1080, val loss 1.1046\n",
      "saving checkpoint to out-abc-char\n",
      "iter 400: loss 1.2707, time 10677.15ms, mfu 1.78%\n",
      "iter 405: loss 1.3283, time 1222.54ms, mfu 1.94%\n",
      "step 410: train loss 1.0999, val loss 1.1076\n",
      "iter 410: loss 1.2099, time 10436.02ms, mfu 1.79%\n",
      "iter 415: loss 1.1713, time 1226.98ms, mfu 1.94%\n",
      "step 420: train loss 1.1018, val loss 1.1080\n",
      "iter 420: loss 1.1223, time 10346.82ms, mfu 1.79%\n",
      "iter 425: loss 1.1474, time 1225.68ms, mfu 1.94%\n",
      "step 430: train loss 1.0865, val loss 1.0815\n",
      "saving checkpoint to out-abc-char\n",
      "iter 430: loss 1.3624, time 10700.49ms, mfu 1.79%\n",
      "iter 435: loss 1.0329, time 1224.65ms, mfu 1.94%\n",
      "step 440: train loss 1.0583, val loss 1.0692\n",
      "saving checkpoint to out-abc-char\n",
      "iter 440: loss 1.0959, time 10715.15ms, mfu 1.78%\n",
      "iter 445: loss 1.1968, time 1221.78ms, mfu 1.94%\n",
      "step 450: train loss 1.0619, val loss 1.0592\n",
      "saving checkpoint to out-abc-char\n",
      "iter 450: loss 1.0301, time 10652.72ms, mfu 1.79%\n",
      "iter 455: loss 0.9829, time 1225.53ms, mfu 1.94%\n",
      "step 460: train loss 1.0547, val loss 1.0438\n",
      "saving checkpoint to out-abc-char\n",
      "iter 460: loss 1.1208, time 10672.11ms, mfu 1.79%\n",
      "iter 465: loss 1.1311, time 1193.04ms, mfu 1.95%\n",
      "step 470: train loss 1.0523, val loss 1.0639\n",
      "iter 470: loss 1.1133, time 10378.34ms, mfu 1.79%\n",
      "iter 475: loss 1.2014, time 1227.11ms, mfu 1.95%\n",
      "step 480: train loss 1.0481, val loss 1.0396\n",
      "saving checkpoint to out-abc-char\n",
      "iter 480: loss 1.1167, time 10748.87ms, mfu 1.79%\n",
      "iter 485: loss 1.0507, time 1231.95ms, mfu 1.94%\n",
      "step 490: train loss 1.0407, val loss 1.0413\n",
      "iter 490: loss 1.1454, time 10396.25ms, mfu 1.79%\n",
      "iter 495: loss 1.0651, time 1226.10ms, mfu 1.94%\n",
      "step 500: train loss 1.0212, val loss 1.0343\n",
      "saving checkpoint to out-abc-char\n",
      "iter 500: loss 1.2393, time 10701.48ms, mfu 1.79%\n",
      "iter 505: loss 1.0076, time 1223.91ms, mfu 1.94%\n",
      "step 510: train loss 1.0184, val loss 1.0298\n",
      "saving checkpoint to out-abc-char\n",
      "iter 510: loss 1.0996, time 10570.41ms, mfu 1.79%\n",
      "iter 515: loss 0.8947, time 1221.53ms, mfu 1.94%\n",
      "step 520: train loss 1.0248, val loss 1.0263\n",
      "saving checkpoint to out-abc-char\n",
      "iter 520: loss 0.9820, time 10667.14ms, mfu 1.79%\n",
      "iter 525: loss 1.1732, time 1223.84ms, mfu 1.94%\n",
      "step 530: train loss 1.0081, val loss 1.0071\n",
      "saving checkpoint to out-abc-char\n",
      "iter 530: loss 1.1638, time 10994.99ms, mfu 1.79%\n",
      "iter 535: loss 1.0617, time 1225.16ms, mfu 1.94%\n",
      "step 540: train loss 0.9977, val loss 0.9905\n",
      "saving checkpoint to out-abc-char\n",
      "iter 540: loss 0.9089, time 10746.77ms, mfu 1.79%\n",
      "iter 545: loss 0.9768, time 1233.05ms, mfu 1.94%\n",
      "step 550: train loss 0.9938, val loss 0.9958\n",
      "iter 550: loss 1.1370, time 10517.97ms, mfu 1.78%\n",
      "iter 555: loss 1.0001, time 1240.87ms, mfu 1.94%\n",
      "step 560: train loss 0.9807, val loss 0.9814\n",
      "saving checkpoint to out-abc-char\n",
      "iter 560: loss 0.9307, time 10831.97ms, mfu 1.78%\n",
      "iter 565: loss 1.0201, time 1230.33ms, mfu 1.93%\n",
      "step 570: train loss 0.9771, val loss 0.9729\n",
      "saving checkpoint to out-abc-char\n",
      "iter 570: loss 0.9198, time 10750.30ms, mfu 1.78%\n",
      "iter 575: loss 0.9088, time 1227.76ms, mfu 1.93%\n",
      "step 580: train loss 0.9625, val loss 0.9690\n",
      "saving checkpoint to out-abc-char\n",
      "iter 580: loss 1.0281, time 10697.80ms, mfu 1.78%\n",
      "iter 585: loss 1.0044, time 1225.61ms, mfu 1.94%\n",
      "step 590: train loss 0.9638, val loss 0.9691\n",
      "iter 590: loss 0.8780, time 10518.07ms, mfu 1.78%\n",
      "iter 595: loss 1.0627, time 1225.90ms, mfu 1.94%\n",
      "step 600: train loss 0.9556, val loss 0.9648\n",
      "saving checkpoint to out-abc-char\n",
      "iter 600: loss 0.8252, time 10996.38ms, mfu 1.78%\n",
      "iter 605: loss 0.9232, time 1231.82ms, mfu 1.93%\n",
      "step 610: train loss 0.9547, val loss 0.9588\n",
      "saving checkpoint to out-abc-char\n",
      "iter 610: loss 0.9231, time 10780.69ms, mfu 1.78%\n",
      "iter 615: loss 0.9044, time 1229.53ms, mfu 1.93%\n",
      "step 620: train loss 0.9513, val loss 0.9542\n",
      "saving checkpoint to out-abc-char\n",
      "iter 620: loss 1.0024, time 10762.02ms, mfu 1.78%\n",
      "iter 625: loss 0.8192, time 1232.59ms, mfu 1.93%\n",
      "step 630: train loss 0.9329, val loss 0.9488\n",
      "saving checkpoint to out-abc-char\n",
      "iter 630: loss 0.9615, time 10725.82ms, mfu 1.78%\n",
      "iter 635: loss 0.9502, time 1227.96ms, mfu 1.93%\n",
      "step 640: train loss 0.9238, val loss 0.9354\n",
      "saving checkpoint to out-abc-char\n",
      "iter 640: loss 0.9713, time 10791.61ms, mfu 1.78%\n",
      "iter 645: loss 1.0276, time 1248.18ms, mfu 1.93%\n",
      "step 650: train loss 0.9273, val loss 0.9364\n",
      "iter 650: loss 0.9534, time 10718.48ms, mfu 1.77%\n",
      "iter 655: loss 0.8118, time 1230.15ms, mfu 1.93%\n",
      "step 660: train loss 0.9310, val loss 0.9364\n",
      "iter 660: loss 0.8788, time 10701.04ms, mfu 1.77%\n",
      "iter 665: loss 0.9581, time 1257.06ms, mfu 1.92%\n",
      "step 670: train loss 0.9044, val loss 0.9179\n",
      "saving checkpoint to out-abc-char\n",
      "iter 670: loss 0.7812, time 10924.09ms, mfu 1.77%\n",
      "iter 675: loss 0.8959, time 1238.92ms, mfu 1.92%\n",
      "step 680: train loss 0.8942, val loss 0.9196\n",
      "iter 680: loss 0.9177, time 10598.49ms, mfu 1.77%\n",
      "iter 685: loss 1.0255, time 1233.47ms, mfu 1.92%\n",
      "step 690: train loss 0.8960, val loss 0.9116\n",
      "saving checkpoint to out-abc-char\n",
      "iter 690: loss 0.9864, time 10863.24ms, mfu 1.77%\n",
      "iter 695: loss 0.9628, time 1262.28ms, mfu 1.92%\n",
      "step 700: train loss 0.8883, val loss 0.9013\n",
      "saving checkpoint to out-abc-char\n",
      "iter 700: loss 1.0948, time 10995.97ms, mfu 1.76%\n",
      "iter 705: loss 0.9462, time 1226.95ms, mfu 1.92%\n",
      "step 710: train loss 0.8827, val loss 0.8946\n",
      "saving checkpoint to out-abc-char\n",
      "iter 710: loss 0.9813, time 10967.96ms, mfu 1.76%\n",
      "iter 715: loss 0.8333, time 1262.24ms, mfu 1.91%\n",
      "step 720: train loss 0.8781, val loss 0.8947\n",
      "iter 720: loss 0.9511, time 10719.27ms, mfu 1.76%\n",
      "iter 725: loss 1.1219, time 1247.18ms, mfu 1.91%\n",
      "step 730: train loss 0.8542, val loss 0.8774\n",
      "saving checkpoint to out-abc-char\n",
      "iter 730: loss 0.9302, time 10837.62ms, mfu 1.76%\n",
      "iter 735: loss 0.9265, time 1244.75ms, mfu 1.91%\n",
      "step 740: train loss 0.8563, val loss 0.8712\n",
      "saving checkpoint to out-abc-char\n",
      "iter 740: loss 0.7676, time 10823.03ms, mfu 1.76%\n",
      "iter 745: loss 0.7876, time 1224.94ms, mfu 1.92%\n",
      "step 750: train loss 0.8440, val loss 0.8557\n",
      "saving checkpoint to out-abc-char\n",
      "iter 750: loss 0.7713, time 10924.05ms, mfu 1.76%\n",
      "iter 755: loss 0.7825, time 1218.71ms, mfu 1.92%\n",
      "step 760: train loss 0.8316, val loss 0.8489\n",
      "saving checkpoint to out-abc-char\n",
      "iter 760: loss 0.7946, time 10652.46ms, mfu 1.77%\n",
      "iter 765: loss 0.9202, time 1248.80ms, mfu 1.92%\n",
      "step 770: train loss 0.8180, val loss 0.8436\n",
      "saving checkpoint to out-abc-char\n",
      "iter 770: loss 0.7858, time 10812.97ms, mfu 1.76%\n",
      "iter 775: loss 0.8667, time 1226.17ms, mfu 1.92%\n",
      "step 780: train loss 0.8141, val loss 0.8325\n",
      "saving checkpoint to out-abc-char\n",
      "iter 780: loss 0.9005, time 10923.86ms, mfu 1.77%\n",
      "iter 785: loss 0.8150, time 1240.31ms, mfu 1.92%\n",
      "step 790: train loss 0.8108, val loss 0.8301\n",
      "saving checkpoint to out-abc-char\n",
      "iter 790: loss 0.8559, time 11356.31ms, mfu 1.76%\n",
      "iter 795: loss 0.8502, time 1225.53ms, mfu 1.92%\n",
      "step 800: train loss 0.7862, val loss 0.8081\n",
      "saving checkpoint to out-abc-char\n",
      "iter 800: loss 0.7465, time 10782.62ms, mfu 1.77%\n",
      "iter 805: loss 0.7846, time 1229.42ms, mfu 1.92%\n",
      "step 810: train loss 0.7752, val loss 0.8032\n",
      "saving checkpoint to out-abc-char\n",
      "iter 810: loss 0.7287, time 10756.18ms, mfu 1.77%\n",
      "iter 815: loss 0.7234, time 1218.30ms, mfu 1.93%\n",
      "step 820: train loss 0.7651, val loss 0.7942\n",
      "saving checkpoint to out-abc-char\n",
      "iter 820: loss 0.6656, time 10670.09ms, mfu 1.77%\n",
      "iter 825: loss 0.7202, time 1224.36ms, mfu 1.93%\n",
      "step 830: train loss 0.7543, val loss 0.7872\n",
      "saving checkpoint to out-abc-char\n",
      "iter 830: loss 1.0152, time 10673.22ms, mfu 1.78%\n",
      "iter 835: loss 0.7514, time 1222.63ms, mfu 1.93%\n",
      "step 840: train loss 0.7523, val loss 0.7796\n",
      "saving checkpoint to out-abc-char\n",
      "iter 840: loss 0.7670, time 10943.28ms, mfu 1.78%\n",
      "iter 845: loss 0.7268, time 1221.45ms, mfu 1.93%\n",
      "step 850: train loss 0.7432, val loss 0.7800\n",
      "iter 850: loss 0.6739, time 10439.15ms, mfu 1.78%\n",
      "iter 855: loss 0.6991, time 1219.44ms, mfu 1.94%\n",
      "step 860: train loss 0.7217, val loss 0.7504\n",
      "saving checkpoint to out-abc-char\n",
      "iter 860: loss 0.9245, time 10793.41ms, mfu 1.78%\n",
      "iter 865: loss 0.7917, time 1225.68ms, mfu 1.94%\n",
      "step 870: train loss 0.7127, val loss 0.7514\n",
      "iter 870: loss 0.6438, time 10647.90ms, mfu 1.78%\n",
      "iter 875: loss 0.8112, time 1231.30ms, mfu 1.94%\n",
      "step 880: train loss 0.6991, val loss 0.7314\n",
      "saving checkpoint to out-abc-char\n",
      "iter 880: loss 0.7912, time 10662.69ms, mfu 1.78%\n",
      "iter 885: loss 0.6421, time 1220.28ms, mfu 1.94%\n",
      "step 890: train loss 0.6974, val loss 0.7330\n",
      "iter 890: loss 0.9494, time 10523.46ms, mfu 1.78%\n",
      "iter 895: loss 0.8468, time 1224.23ms, mfu 1.94%\n",
      "step 900: train loss 0.6798, val loss 0.7194\n",
      "saving checkpoint to out-abc-char\n",
      "iter 900: loss 0.7193, time 10651.71ms, mfu 1.78%\n",
      "iter 905: loss 0.6352, time 1232.48ms, mfu 1.94%\n",
      "step 910: train loss 0.6679, val loss 0.7110\n",
      "saving checkpoint to out-abc-char\n",
      "iter 910: loss 0.7709, time 10640.11ms, mfu 1.78%\n",
      "iter 915: loss 0.7102, time 1226.20ms, mfu 1.94%\n",
      "step 920: train loss 0.6565, val loss 0.6965\n",
      "saving checkpoint to out-abc-char\n",
      "iter 920: loss 0.6355, time 10666.37ms, mfu 1.78%\n",
      "iter 925: loss 0.7710, time 1244.13ms, mfu 1.93%\n",
      "step 930: train loss 0.6542, val loss 0.6959\n",
      "saving checkpoint to out-abc-char\n",
      "iter 930: loss 0.6485, time 10782.82ms, mfu 1.78%\n",
      "iter 935: loss 0.7951, time 1240.00ms, mfu 1.93%\n",
      "step 940: train loss 0.6481, val loss 0.6908\n",
      "saving checkpoint to out-abc-char\n",
      "iter 940: loss 0.5696, time 10951.39ms, mfu 1.77%\n",
      "iter 945: loss 0.5903, time 1228.42ms, mfu 1.93%\n",
      "step 950: train loss 0.6359, val loss 0.6720\n",
      "saving checkpoint to out-abc-char\n",
      "iter 950: loss 0.7205, time 11107.48ms, mfu 1.77%\n",
      "iter 955: loss 0.5686, time 1243.31ms, mfu 1.93%\n",
      "step 960: train loss 0.6285, val loss 0.6726\n",
      "iter 960: loss 0.6100, time 10522.93ms, mfu 1.77%\n",
      "iter 965: loss 0.6975, time 1222.08ms, mfu 1.93%\n",
      "step 970: train loss 0.6265, val loss 0.6593\n",
      "saving checkpoint to out-abc-char\n",
      "iter 970: loss 0.6676, time 10703.59ms, mfu 1.78%\n",
      "iter 975: loss 0.5868, time 1232.38ms, mfu 1.93%\n",
      "step 980: train loss 0.6013, val loss 0.6446\n",
      "saving checkpoint to out-abc-char\n",
      "iter 980: loss 0.6241, time 10975.15ms, mfu 1.77%\n",
      "iter 985: loss 0.6001, time 1236.92ms, mfu 1.93%\n",
      "step 990: train loss 0.6051, val loss 0.6448\n",
      "iter 990: loss 0.4948, time 10762.55ms, mfu 1.77%\n",
      "iter 995: loss 0.6490, time 1231.87ms, mfu 1.93%\n",
      "step 1000: train loss 0.5910, val loss 0.6287\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1000: loss 0.6384, time 11053.16ms, mfu 1.77%\n",
      "iter 1005: loss 0.5982, time 1267.63ms, mfu 1.92%\n",
      "step 1010: train loss 0.5942, val loss 0.6324\n",
      "iter 1010: loss 0.5702, time 10712.40ms, mfu 1.76%\n",
      "iter 1015: loss 0.6852, time 1242.31ms, mfu 1.92%\n",
      "step 1020: train loss 0.5773, val loss 0.6265\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1020: loss 0.6433, time 11113.33ms, mfu 1.76%\n",
      "iter 1025: loss 0.6492, time 1255.10ms, mfu 1.91%\n",
      "step 1030: train loss 0.5700, val loss 0.6188\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1030: loss 0.5545, time 10960.00ms, mfu 1.76%\n",
      "iter 1035: loss 0.7206, time 1248.60ms, mfu 1.91%\n",
      "step 1040: train loss 0.5739, val loss 0.6135\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1040: loss 0.6099, time 11110.98ms, mfu 1.76%\n",
      "iter 1045: loss 0.4611, time 1244.70ms, mfu 1.91%\n",
      "step 1050: train loss 0.5748, val loss 0.6111\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1050: loss 0.5055, time 10821.53ms, mfu 1.76%\n",
      "iter 1055: loss 0.4937, time 1245.22ms, mfu 1.91%\n",
      "step 1060: train loss 0.5620, val loss 0.6018\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1060: loss 0.6273, time 10859.66ms, mfu 1.76%\n",
      "iter 1065: loss 0.7098, time 1244.31ms, mfu 1.91%\n",
      "step 1070: train loss 0.5445, val loss 0.5937\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1070: loss 0.5650, time 10893.06ms, mfu 1.76%\n",
      "iter 1075: loss 0.5325, time 1342.78ms, mfu 1.89%\n",
      "step 1080: train loss 0.5468, val loss 0.5909\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1080: loss 0.5818, time 11095.17ms, mfu 1.73%\n",
      "iter 1085: loss 0.5337, time 1291.31ms, mfu 1.88%\n",
      "step 1090: train loss 0.5418, val loss 0.5881\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1090: loss 0.6220, time 10861.99ms, mfu 1.73%\n",
      "iter 1095: loss 0.5533, time 1223.90ms, mfu 1.89%\n",
      "step 1100: train loss 0.5358, val loss 0.5819\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1100: loss 0.5879, time 10793.52ms, mfu 1.74%\n",
      "iter 1105: loss 0.5679, time 1224.36ms, mfu 1.90%\n",
      "step 1110: train loss 0.5236, val loss 0.5684\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1110: loss 0.5535, time 10610.59ms, mfu 1.75%\n",
      "iter 1115: loss 0.4956, time 1221.38ms, mfu 1.91%\n",
      "step 1120: train loss 0.5164, val loss 0.5755\n",
      "iter 1120: loss 0.5570, time 10457.99ms, mfu 1.76%\n",
      "iter 1125: loss 0.4092, time 1219.72ms, mfu 1.92%\n",
      "step 1130: train loss 0.5157, val loss 0.5607\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1130: loss 0.4732, time 10710.13ms, mfu 1.76%\n",
      "iter 1135: loss 0.6360, time 1219.86ms, mfu 1.92%\n",
      "step 1140: train loss 0.5092, val loss 0.5569\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1140: loss 0.4665, time 10725.59ms, mfu 1.77%\n",
      "iter 1145: loss 0.4982, time 1276.29ms, mfu 1.91%\n",
      "step 1150: train loss 0.5054, val loss 0.5557\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1150: loss 0.6112, time 10857.81ms, mfu 1.76%\n",
      "iter 1155: loss 0.5356, time 1248.14ms, mfu 1.91%\n",
      "step 1160: train loss 0.4965, val loss 0.5511\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1160: loss 0.5305, time 10749.28ms, mfu 1.76%\n",
      "iter 1165: loss 0.5644, time 1222.34ms, mfu 1.92%\n",
      "step 1170: train loss 0.4932, val loss 0.5523\n",
      "iter 1170: loss 0.5632, time 10367.66ms, mfu 1.76%\n",
      "iter 1175: loss 0.5803, time 1237.28ms, mfu 1.92%\n",
      "step 1180: train loss 0.4846, val loss 0.5397\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1180: loss 0.5399, time 10866.63ms, mfu 1.76%\n",
      "iter 1185: loss 0.6320, time 1224.06ms, mfu 1.92%\n",
      "step 1190: train loss 0.4799, val loss 0.5384\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1190: loss 0.4957, time 10825.78ms, mfu 1.77%\n",
      "iter 1195: loss 0.4599, time 1227.69ms, mfu 1.92%\n",
      "step 1200: train loss 0.4718, val loss 0.5246\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1200: loss 0.5238, time 10885.89ms, mfu 1.77%\n",
      "iter 1205: loss 0.5328, time 1248.95ms, mfu 1.92%\n",
      "step 1210: train loss 0.4617, val loss 0.5239\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1210: loss 0.4362, time 10838.96ms, mfu 1.77%\n",
      "iter 1215: loss 0.4800, time 1227.86ms, mfu 1.92%\n",
      "step 1220: train loss 0.4600, val loss 0.5213\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1220: loss 0.5768, time 10881.11ms, mfu 1.77%\n",
      "iter 1225: loss 0.4654, time 1222.61ms, mfu 1.93%\n",
      "step 1230: train loss 0.4532, val loss 0.5167\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1230: loss 0.5060, time 10908.16ms, mfu 1.77%\n",
      "iter 1235: loss 0.4654, time 1234.84ms, mfu 1.93%\n",
      "step 1240: train loss 0.4464, val loss 0.5107\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1240: loss 0.5007, time 10920.71ms, mfu 1.77%\n",
      "iter 1245: loss 0.4522, time 1223.46ms, mfu 1.93%\n",
      "step 1250: train loss 0.4471, val loss 0.5107\n",
      "iter 1250: loss 0.5367, time 10689.10ms, mfu 1.77%\n",
      "iter 1255: loss 0.4275, time 1226.08ms, mfu 1.93%\n",
      "step 1260: train loss 0.4364, val loss 0.4961\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1260: loss 0.4953, time 10782.34ms, mfu 1.77%\n",
      "iter 1265: loss 0.4229, time 1226.50ms, mfu 1.93%\n",
      "step 1270: train loss 0.4290, val loss 0.5018\n",
      "iter 1270: loss 0.4646, time 10568.97ms, mfu 1.78%\n",
      "iter 1275: loss 0.4563, time 1223.78ms, mfu 1.93%\n",
      "step 1280: train loss 0.4284, val loss 0.4953\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1280: loss 0.3706, time 10805.87ms, mfu 1.78%\n",
      "iter 1285: loss 0.4600, time 1224.85ms, mfu 1.93%\n",
      "step 1290: train loss 0.4225, val loss 0.4887\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1290: loss 0.5019, time 10893.97ms, mfu 1.78%\n",
      "iter 1295: loss 0.4965, time 1226.91ms, mfu 1.93%\n",
      "step 1300: train loss 0.4128, val loss 0.4805\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1300: loss 0.4623, time 10960.35ms, mfu 1.78%\n",
      "iter 1305: loss 0.4218, time 1236.47ms, mfu 1.93%\n",
      "step 1310: train loss 0.4071, val loss 0.4776\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1310: loss 0.4262, time 11026.96ms, mfu 1.78%\n",
      "iter 1315: loss 0.4161, time 1223.27ms, mfu 1.93%\n",
      "step 1320: train loss 0.3990, val loss 0.4692\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1320: loss 0.4742, time 10775.78ms, mfu 1.78%\n",
      "iter 1325: loss 0.4349, time 1225.41ms, mfu 1.93%\n",
      "step 1330: train loss 0.3940, val loss 0.4664\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1330: loss 0.4355, time 10853.74ms, mfu 1.78%\n",
      "iter 1335: loss 0.5286, time 1238.36ms, mfu 1.93%\n",
      "step 1340: train loss 0.3916, val loss 0.4649\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1340: loss 0.3981, time 11005.26ms, mfu 1.77%\n",
      "iter 1345: loss 0.4338, time 1251.00ms, mfu 1.92%\n",
      "step 1350: train loss 0.3858, val loss 0.4570\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1350: loss 0.4369, time 10809.43ms, mfu 1.77%\n",
      "iter 1355: loss 0.4706, time 1243.71ms, mfu 1.92%\n",
      "step 1360: train loss 0.3718, val loss 0.4445\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1360: loss 0.4473, time 11186.26ms, mfu 1.77%\n",
      "iter 1365: loss 0.4314, time 1223.03ms, mfu 1.92%\n",
      "step 1370: train loss 0.3694, val loss 0.4449\n",
      "iter 1370: loss 0.4341, time 10315.22ms, mfu 1.77%\n",
      "iter 1375: loss 0.3716, time 1195.36ms, mfu 1.94%\n",
      "step 1380: train loss 0.3681, val loss 0.4545\n",
      "iter 1380: loss 0.3913, time 10265.24ms, mfu 1.78%\n",
      "iter 1385: loss 0.4006, time 1198.90ms, mfu 1.95%\n",
      "step 1390: train loss 0.3595, val loss 0.4331\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1390: loss 0.4417, time 10606.59ms, mfu 1.79%\n",
      "iter 1395: loss 0.4236, time 1193.05ms, mfu 1.95%\n",
      "step 1400: train loss 0.3557, val loss 0.4341\n",
      "iter 1400: loss 0.4521, time 10398.72ms, mfu 1.80%\n",
      "iter 1405: loss 0.3575, time 1210.72ms, mfu 1.96%\n",
      "step 1410: train loss 0.3521, val loss 0.4329\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1410: loss 0.4745, time 10598.68ms, mfu 1.80%\n",
      "iter 1415: loss 0.3540, time 1199.77ms, mfu 1.96%\n",
      "step 1420: train loss 0.3448, val loss 0.4234\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1420: loss 0.3431, time 10804.94ms, mfu 1.80%\n",
      "iter 1425: loss 0.3896, time 1197.86ms, mfu 1.96%\n",
      "step 1430: train loss 0.3400, val loss 0.4148\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1430: loss 0.4115, time 10507.14ms, mfu 1.81%\n",
      "iter 1435: loss 0.3425, time 1226.40ms, mfu 1.96%\n",
      "step 1440: train loss 0.3288, val loss 0.4034\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1440: loss 0.3672, time 10693.64ms, mfu 1.80%\n",
      "iter 1445: loss 0.3085, time 1200.16ms, mfu 1.96%\n",
      "step 1450: train loss 0.3300, val loss 0.4077\n",
      "iter 1450: loss 0.3283, time 10268.30ms, mfu 1.81%\n",
      "iter 1455: loss 0.4123, time 1191.50ms, mfu 1.97%\n",
      "step 1460: train loss 0.3208, val loss 0.4007\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1460: loss 0.2763, time 10569.14ms, mfu 1.81%\n",
      "iter 1465: loss 0.3290, time 1192.47ms, mfu 1.97%\n",
      "step 1470: train loss 0.3154, val loss 0.4031\n",
      "iter 1470: loss 0.3616, time 10208.13ms, mfu 1.82%\n",
      "iter 1475: loss 0.3594, time 1198.16ms, mfu 1.98%\n",
      "step 1480: train loss 0.3076, val loss 0.3939\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1480: loss 0.3341, time 10468.02ms, mfu 1.82%\n",
      "iter 1485: loss 0.3445, time 1193.11ms, mfu 1.98%\n",
      "step 1490: train loss 0.3115, val loss 0.3988\n",
      "iter 1490: loss 0.3329, time 10355.04ms, mfu 1.82%\n",
      "iter 1495: loss 0.3364, time 1197.47ms, mfu 1.98%\n",
      "step 1500: train loss 0.2977, val loss 0.3824\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1500: loss 0.3545, time 10502.92ms, mfu 1.82%\n",
      "iter 1505: loss 0.3749, time 1209.35ms, mfu 1.98%\n",
      "step 1510: train loss 0.2919, val loss 0.3757\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1510: loss 0.3411, time 11051.94ms, mfu 1.82%\n",
      "iter 1515: loss 0.3113, time 1240.24ms, mfu 1.97%\n",
      "step 1520: train loss 0.2880, val loss 0.3723\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1520: loss 0.2656, time 10923.39ms, mfu 1.81%\n",
      "^C\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-4:\n",
      "Process ForkProcess-18:\n",
      "Process ForkProcess-16:\n",
      "Process ForkProcess-15:\n",
      "Process ForkProcess-14:\n",
      "Process ForkProcess-6:\n",
      "Process ForkProcess-2:\n",
      "Process ForkProcess-5:\n",
      "Process ForkProcess-13:\n",
      "Process ForkProcess-12:\n",
      "Process ForkProcess-3:\n",
      "Process ForkProcess-19:\n",
      "Process ForkProcess-11:\n",
      "Process ForkProcess-8:\n",
      "Process ForkProcess-10:\n",
      "Process ForkProcess-1:\n",
      "Process ForkProcess-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 289, in <module>\n",
      "    logits, loss = model(X, Y)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_dynamo/eval_frame.py\", line 82, in forward\n",
      "    return self.dynamo_ctx(self._orig_mod.forward)(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_dynamo/eval_frame.py\", line 209, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/pt-env/notebooks/nanoGPT/model.py\", line 188, in forward\n",
      "    x = block(x)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/pt-env/notebooks/nanoGPT/model.py\", line 111, in forward\n",
      "    x = x + self.attn(self.ln_1(x))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/pt-env/notebooks/nanoGPT/model.py\", line 72, in forward\n",
      "    y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout, is_causal=True)\n",
      "  File \"/pt-env/notebooks/nanoGPT/model.py\", line 72, in <graph break in forward>\n",
      "    y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout, is_causal=True)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_dynamo/eval_frame.py\", line 209, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 2819, in forward\n",
      "    return compiled_fn(full_args)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 1222, in g\n",
      "    return f(*args)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 2386, in debug_compiled_function\n",
      "    return compiled_function(*args)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 1898, in runtime_wrapper\n",
      "    all_outs = call_func_with_args(\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 1247, in call_func_with_args\n",
      "    out = normalize_as_list(f(args))\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 1222, in g\n",
      "    return f(*args)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/function.py\", line 506, in apply\n",
      "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 2151, in forward\n",
      "    fw_outs = call_func_with_args(\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 1247, in call_func_with_args\n",
      "    out = normalize_as_list(f(args))\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_inductor/compile_fx.py\", line 248, in run\n",
      "    return model(new_inputs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/tmp/torchinductor_root/v2/cv2f6quslybzu6efr2h3h7a6dxqtz6osx2izu3ek4xxvbjotbhe2.py\", line 88, in call\n",
      "    extern_kernels.mm(as_strided(primals_2, (2048, 384), (384, 1)), buf0, out=buf1)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 97, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Process ForkProcess-20:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Process ForkProcess-17:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 255).\u001b[0m Press Control-C to abort syncing.\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py config/train_abc_char.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./older_ckpt/hd-8-ly-12-bt-4-rn-data'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_name = 'hd-8-ly-12-bt-4-rn-data'\n",
    "examples_folder = f'./older_ckpt/{folder_name}'\n",
    "examples_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_start = {\n",
    "    'G':'M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]',\n",
    "    'C':'M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]',\n",
    "    'Am':'M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]'\n",
    "    }\n",
    "\n",
    "songs_roman_start = {\n",
    "    'G':'M:4/4L:1/4K:G|\"I\"|\"IV\"|\"V\"|\"V\"|\"I\"|\"IV\"|\"V\"|\"I\"|]',\n",
    "    'C':'M:4/4L:1/4K:C|\"I\"|\"IV\"|\"V\"|\"V\"|\"I\"|\"IV\"|\"V\"|\"I\"|]',\n",
    "    'Am':'M:4/4L:1/4K:Am|\"i\"|\"iv\"|\"V\"|\"V\"|\"i\"|\"iv\"|\"V\"|\"i\"|]'\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test key with most occurrences: G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M:4/4L:1/4K:G|\"I\"|\"IV\"|\"V\"|\"V\"|\"I\"|\"IV\"|\"V\"|\"I\"|]'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_start = songs_roman_start['G']\n",
    "song_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start={shlex.quote(song_start)} > {examples_folder}/examples_G.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test major key with low samples: C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M:4/4L:1/4K:C|\"I\"|\"IV\"|\"V\"|\"V\"|\"I\"|\"IV\"|\"V\"|\"I\"|]'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_start = songs_roman_start['C']\n",
    "song_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start={shlex.quote(song_start)} > {examples_folder}/examples_C.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test minor key with low samples: Am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M:4/4L:1/4K:Am|\"i\"|\"iv\"|\"V\"|\"V\"|\"i\"|\"iv\"|\"V\"|\"i\"|]'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_start = songs_roman_start['Am']\n",
    "song_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start={shlex.quote(song_start)} > {examples_folder}/examples_Am.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move checkpoint files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = './data/abc_char/meta.pkl'\n",
    "target_folder = examples_folder\n",
    "!mv {source} {target_folder}/meta.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = './out-abc-char/ckpt.pt'\n",
    "!mv {source} {target_folder}/ckpt.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = './config/train_abc_char.py'\n",
    "!cp {source} {target_folder}/config.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test older checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_start = songs_start['Am']\n",
    "!echo {shlex.quote(song_start)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " song_start = songs_start['Am']\n",
    " !python3 sample.py --out_dir=older_ckpt/m_voices --path_meta=older_ckpt/m_voices --start={shlex.quote(current_start)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
