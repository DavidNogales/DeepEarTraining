{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def load_dataframe(relative_path,dataframe_name):\n",
    "    df = pd.read_pickle(f'{relative_path}/{dataframe_name}.pkl')    \n",
    "    return df\n",
    "\n",
    "def read_file(relative_path,file_name):\n",
    "    text= \"\"\n",
    "    with open(f'{relative_path}/{file_name}.abc','r') as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_path =\"notebooks/data/final_dataset\"\n",
    "filename_name = 'clean_augmented_data'\n",
    "#filename_name = 'clean_original_training_data'\n",
    "#relative_path =\"notebooks/data/original_dataset\"\n",
    "training_data_df = load_dataframe(relative_path,filename_name)\n",
    "training_data_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df[\"clean_header\"].str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df[\"clean_body\"].str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodies = \"\"\n",
    "silences = 0\n",
    "for body in training_data_df[\"clean_body\"]:\n",
    "    if 'z' in body:\n",
    "        silences +=1 \n",
    "    bodies += body+\"\\n\"\n",
    "chars = sorted(list(set(bodies)))\n",
    "vocab_size = len(chars)\n",
    "print('vocab: ',''.join(chars))\n",
    "print('vocab_size',vocab_size)\n",
    "print(\"silences \",silences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_text = read_file(relative_path,filename_name)\n",
    "\n",
    "print(\"number of chars:\",len(training_data_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(training_data_text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import tiktoken\n",
    "\n",
    "print(wandb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import shlex\n",
    "import os\n",
    "nano_path = 'notebooks/nanoGPT'\n",
    "os.chdir(nano_path)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE      assets\t      data\t  out-abc-char\twandb\n",
      "README.md    config\t      model.py\t  sample.py\n",
      "__pycache__  configurator.py  older_ckpt  train.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with multiple voices present\n",
    "#length of dataset in characters: 4,149,703\n",
    "#all the unique characters: \n",
    "#\"#'()+,-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
    "#vocab size: 46\n",
    "#train has 3,734,732 tokens\n",
    "#val has 414,971 tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Normal Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 4,062,773\n",
      "all the unique characters: \n",
      "\"#'(),-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
      "vocab size: 45\n",
      "train has 3,656,495 tokens\n",
      "val has 406,278 tokens\n"
     ]
    }
   ],
   "source": [
    "!python3 data/abc_char/prepare.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding config with config/train_abc_char.py:\n",
      "# train a miniature character-level shakespeare model\n",
      "# good for debugging and playing on macbooks and such\n",
      "\n",
      "out_dir = 'out-abc-char'\n",
      "eval_interval = 10 # keep frequent because we'll overfit\n",
      "eval_iters = 500\n",
      "log_interval = 5 # don't print too too often\n",
      "\n",
      "# we expect to overfit on this small dataset, so only save when val improves\n",
      "always_save_checkpoint = False\n",
      "\n",
      "wandb_log = True # override via command line if you like\n",
      "wandb_project = 'abc-char'\n",
      "wandb_run_name = 'mini-char-gpt-hd-8-ly-12-bt4-ovrf'\n",
      "\n",
      "dataset = 'abc_char'\n",
      "batch_size = 4\n",
      "block_size = 512 # context of up to 512 previous characters\n",
      "\n",
      "# baby GPT model :)\n",
      "n_layer = 12\n",
      "n_head = 8\n",
      "n_embd = 384\n",
      "dropout = 0.2\n",
      "\n",
      "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
      "max_iters = 8000\n",
      "lr_decay_iters = 8000 # make equal to max_iters usually\n",
      "min_lr = 1e-4 # learning_rate / 10 usually\n",
      "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
      "\n",
      "warmup_iters = 5 # not super necessary potentially\n",
      "\n",
      "# on macbook also add\n",
      "# device = 'cpu'  # run on cpu only\n",
      "# compile = False # do not torch compile the model\n",
      "found vocab_size = 45 (inside data/abc_char/meta.pkl)\n",
      "Initializing a new model from scratch\n",
      "number of parameters: 21.26M\n",
      "using fused AdamW: True\n",
      "compiling the model... (takes a ~minute)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavidnogales\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/pt-env/notebooks/nanoGPT/wandb/run-20230430_202344-mvi15non\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmini-char-gpt-hd-8-ly-12-bt4-ovrf\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char/runs/mvi15non\u001b[0m\n",
      "step 0: train loss 3.9205, val loss 3.9148\n",
      "[2023-04-30 20:24:01,402] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-30 20:24:01,683] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-30 20:24:01,986] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-30 20:24:02,162] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-30 20:24:02,403] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-30 20:24:02,577] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-30 20:24:02,812] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-30 20:24:02,993] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-30 20:24:03,247] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-30 20:24:03,415] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-30 20:24:03,652] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-30 20:24:03,828] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-30 20:24:04,159] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-30 20:24:04,345] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-30 20:24:04,588] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-30 20:24:04,767] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-30 20:24:05,009] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-30 20:24:05,201] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-30 20:24:05,448] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-30 20:24:05,619] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-30 20:24:05,854] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-30 20:24:06,033] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-30 20:24:06,273] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-30 20:24:06,450] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "iter 0: loss 3.9414, time 24539.55ms, mfu -100.00%\n",
      "iter 5: loss 3.1432, time 1215.05ms, mfu 3.37%\n",
      "step 10: train loss 2.6232, val loss 2.6233\n",
      "saving checkpoint to out-abc-char\n",
      "iter 10: loss 2.6590, time 10020.31ms, mfu 3.07%\n",
      "iter 15: loss 2.2596, time 1205.19ms, mfu 3.10%\n",
      "step 20: train loss 2.2873, val loss 2.2900\n",
      "saving checkpoint to out-abc-char\n",
      "iter 20: loss 2.2938, time 10119.60ms, mfu 2.83%\n",
      "iter 25: loss 2.3448, time 1206.47ms, mfu 2.89%\n",
      "step 30: train loss 2.1258, val loss 2.1587\n",
      "saving checkpoint to out-abc-char\n",
      "iter 30: loss 2.1339, time 10072.07ms, mfu 2.64%\n",
      "iter 35: loss 2.1796, time 1206.99ms, mfu 2.72%\n",
      "step 40: train loss 2.0668, val loss 2.0852\n",
      "saving checkpoint to out-abc-char\n",
      "iter 40: loss 2.0922, time 10256.63ms, mfu 2.49%\n",
      "iter 45: loss 1.9258, time 1221.15ms, mfu 2.57%\n",
      "step 50: train loss 1.9881, val loss 2.0117\n",
      "saving checkpoint to out-abc-char\n",
      "iter 50: loss 2.0654, time 10456.01ms, mfu 2.35%\n",
      "iter 55: loss 2.0082, time 1218.66ms, mfu 2.45%\n",
      "step 60: train loss 1.8992, val loss 1.9533\n",
      "saving checkpoint to out-abc-char\n",
      "iter 60: loss 1.8577, time 10096.37ms, mfu 2.25%\n",
      "iter 65: loss 1.8577, time 1205.34ms, mfu 2.36%\n",
      "step 70: train loss 1.8214, val loss 1.8294\n",
      "saving checkpoint to out-abc-char\n",
      "iter 70: loss 1.6757, time 10090.65ms, mfu 2.17%\n",
      "iter 75: loss 1.7320, time 1207.05ms, mfu 2.29%\n",
      "step 80: train loss 1.7739, val loss 1.7950\n",
      "saving checkpoint to out-abc-char\n",
      "iter 80: loss 1.8220, time 10101.30ms, mfu 2.10%\n",
      "iter 85: loss 1.7658, time 1206.82ms, mfu 2.23%\n",
      "step 90: train loss 1.7114, val loss 1.7326\n",
      "saving checkpoint to out-abc-char\n",
      "iter 90: loss 1.7881, time 10165.95ms, mfu 2.05%\n",
      "iter 95: loss 1.5185, time 1211.27ms, mfu 2.18%\n",
      "step 100: train loss 1.6969, val loss 1.7378\n",
      "iter 100: loss 1.5110, time 10015.39ms, mfu 2.00%\n",
      "iter 105: loss 1.7548, time 1205.93ms, mfu 2.14%\n",
      "step 110: train loss 1.6504, val loss 1.6835\n",
      "saving checkpoint to out-abc-char\n",
      "iter 110: loss 1.5845, time 10345.60ms, mfu 1.97%\n",
      "iter 115: loss 1.4517, time 1223.29ms, mfu 2.11%\n",
      "step 120: train loss 1.6339, val loss 1.6650\n",
      "saving checkpoint to out-abc-char\n",
      "iter 120: loss 1.7998, time 10334.21ms, mfu 1.93%\n",
      "iter 125: loss 1.5144, time 1203.53ms, mfu 2.08%\n",
      "step 130: train loss 1.5910, val loss 1.6206\n",
      "saving checkpoint to out-abc-char\n",
      "iter 130: loss 1.5774, time 10190.89ms, mfu 1.91%\n",
      "iter 135: loss 1.4127, time 1204.65ms, mfu 2.06%\n",
      "step 140: train loss 1.5724, val loss 1.6112\n",
      "saving checkpoint to out-abc-char\n",
      "iter 140: loss 1.3761, time 10178.91ms, mfu 1.90%\n",
      "iter 145: loss 1.3500, time 1205.67ms, mfu 2.05%\n",
      "step 150: train loss 1.5539, val loss 1.5695\n",
      "saving checkpoint to out-abc-char\n",
      "iter 150: loss 1.4693, time 10239.56ms, mfu 1.88%\n",
      "iter 155: loss 1.5948, time 1204.89ms, mfu 2.03%\n",
      "step 160: train loss 1.5275, val loss 1.5462\n",
      "saving checkpoint to out-abc-char\n",
      "iter 160: loss 1.6846, time 10174.74ms, mfu 1.87%\n",
      "iter 165: loss 1.3221, time 1204.44ms, mfu 2.02%\n",
      "step 170: train loss 1.5092, val loss 1.5290\n",
      "saving checkpoint to out-abc-char\n",
      "iter 170: loss 1.3384, time 10125.95ms, mfu 1.86%\n",
      "iter 175: loss 1.5173, time 1204.07ms, mfu 2.01%\n",
      "step 180: train loss 1.4981, val loss 1.5330\n",
      "iter 180: loss 1.5402, time 9938.69ms, mfu 1.85%\n",
      "iter 185: loss 1.5852, time 1206.03ms, mfu 2.01%\n",
      "step 190: train loss 1.4862, val loss 1.5076\n",
      "saving checkpoint to out-abc-char\n",
      "iter 190: loss 1.3926, time 10057.77ms, mfu 1.85%\n",
      "iter 195: loss 1.3640, time 1206.06ms, mfu 2.00%\n",
      "step 200: train loss 1.4840, val loss 1.4968\n",
      "saving checkpoint to out-abc-char\n",
      "iter 200: loss 1.3612, time 10065.32ms, mfu 1.84%\n",
      "iter 205: loss 1.6405, time 1205.11ms, mfu 2.00%\n",
      "step 210: train loss 1.4736, val loss 1.4930\n",
      "saving checkpoint to out-abc-char\n",
      "iter 210: loss 1.6223, time 10149.75ms, mfu 1.84%\n",
      "iter 215: loss 1.3614, time 1208.30ms, mfu 1.99%\n",
      "step 220: train loss 1.4558, val loss 1.4781\n",
      "saving checkpoint to out-abc-char\n",
      "iter 220: loss 1.5253, time 10140.38ms, mfu 1.83%\n",
      "iter 225: loss 1.4819, time 1207.41ms, mfu 1.99%\n",
      "step 230: train loss 1.4544, val loss 1.4612\n",
      "saving checkpoint to out-abc-char\n",
      "iter 230: loss 1.3916, time 10076.45ms, mfu 1.83%\n",
      "iter 235: loss 1.5590, time 1206.09ms, mfu 1.99%\n",
      "step 240: train loss 1.4360, val loss 1.4630\n",
      "iter 240: loss 1.4058, time 9793.02ms, mfu 1.83%\n",
      "iter 245: loss 1.6408, time 1205.29ms, mfu 1.99%\n",
      "step 250: train loss 1.4350, val loss 1.4520\n",
      "saving checkpoint to out-abc-char\n",
      "iter 250: loss 1.4275, time 9822.25ms, mfu 1.83%\n",
      "iter 255: loss 1.2818, time 1176.29ms, mfu 2.00%\n",
      "step 260: train loss 1.4249, val loss 1.4377\n",
      "saving checkpoint to out-abc-char\n",
      "iter 260: loss 1.3301, time 10070.64ms, mfu 1.84%\n",
      "iter 265: loss 1.4701, time 1177.07ms, mfu 2.00%\n",
      "step 270: train loss 1.4161, val loss 1.4187\n",
      "saving checkpoint to out-abc-char\n",
      "iter 270: loss 1.4382, time 10000.32ms, mfu 1.84%\n",
      "iter 275: loss 1.3976, time 1177.42ms, mfu 2.00%\n",
      "step 280: train loss 1.4022, val loss 1.4018\n",
      "saving checkpoint to out-abc-char\n",
      "iter 280: loss 1.4482, time 10055.79ms, mfu 1.84%\n",
      "iter 285: loss 1.5348, time 1176.77ms, mfu 2.01%\n",
      "step 290: train loss 1.3579, val loss 1.3840\n",
      "saving checkpoint to out-abc-char\n",
      "iter 290: loss 1.4546, time 9897.28ms, mfu 1.85%\n",
      "iter 295: loss 1.3220, time 1177.26ms, mfu 2.01%\n",
      "step 300: train loss 1.3389, val loss 1.3589\n",
      "saving checkpoint to out-abc-char\n",
      "iter 300: loss 1.6670, time 9908.32ms, mfu 1.85%\n",
      "iter 305: loss 1.3981, time 1176.77ms, mfu 2.01%\n",
      "step 310: train loss 1.3330, val loss 1.3465\n",
      "saving checkpoint to out-abc-char\n",
      "iter 310: loss 1.1270, time 9982.18ms, mfu 1.85%\n",
      "iter 315: loss 1.3936, time 1176.65ms, mfu 2.02%\n",
      "step 320: train loss 1.3014, val loss 1.3298\n",
      "saving checkpoint to out-abc-char\n",
      "iter 320: loss 1.1930, time 10012.48ms, mfu 1.86%\n",
      "iter 325: loss 1.2833, time 1176.79ms, mfu 2.02%\n",
      "step 330: train loss 1.2704, val loss 1.3043\n",
      "saving checkpoint to out-abc-char\n",
      "iter 330: loss 1.1359, time 9912.42ms, mfu 1.86%\n",
      "iter 335: loss 1.3194, time 1176.44ms, mfu 2.02%\n",
      "step 340: train loss 1.2479, val loss 1.2876\n",
      "saving checkpoint to out-abc-char\n",
      "iter 340: loss 1.2878, time 9904.93ms, mfu 1.86%\n",
      "iter 345: loss 1.1412, time 1177.61ms, mfu 2.02%\n",
      "step 350: train loss 1.2406, val loss 1.2584\n",
      "saving checkpoint to out-abc-char\n",
      "iter 350: loss 1.0771, time 9931.63ms, mfu 1.86%\n",
      "iter 355: loss 1.3442, time 1176.96ms, mfu 2.02%\n",
      "step 360: train loss 1.2040, val loss 1.2449\n",
      "saving checkpoint to out-abc-char\n",
      "iter 360: loss 1.2795, time 9975.23ms, mfu 1.86%\n",
      "iter 365: loss 1.3971, time 1177.46ms, mfu 2.02%\n",
      "step 370: train loss 1.1871, val loss 1.2229\n",
      "saving checkpoint to out-abc-char\n",
      "iter 370: loss 1.3814, time 9804.53ms, mfu 1.86%\n",
      "iter 375: loss 1.1055, time 1176.92ms, mfu 2.02%\n",
      "step 380: train loss 1.1703, val loss 1.2097\n",
      "saving checkpoint to out-abc-char\n",
      "iter 380: loss 1.1206, time 9879.38ms, mfu 1.86%\n",
      "iter 385: loss 1.0477, time 1177.79ms, mfu 2.02%\n",
      "step 390: train loss 1.1584, val loss 1.1953\n",
      "saving checkpoint to out-abc-char\n",
      "iter 390: loss 1.2095, time 9843.13ms, mfu 1.86%\n",
      "iter 395: loss 1.0593, time 1177.79ms, mfu 2.02%\n",
      "step 400: train loss 1.1504, val loss 1.1848\n",
      "saving checkpoint to out-abc-char\n",
      "iter 400: loss 1.1045, time 9815.31ms, mfu 1.86%\n",
      "iter 405: loss 1.1323, time 1178.12ms, mfu 2.02%\n",
      "step 410: train loss 1.1169, val loss 1.1617\n",
      "saving checkpoint to out-abc-char\n",
      "iter 410: loss 1.2376, time 9815.77ms, mfu 1.86%\n",
      "iter 415: loss 1.1220, time 1176.58ms, mfu 2.03%\n",
      "step 420: train loss 1.1078, val loss 1.1416\n",
      "saving checkpoint to out-abc-char\n",
      "iter 420: loss 0.9976, time 9781.92ms, mfu 1.86%\n",
      "iter 425: loss 0.9434, time 1176.30ms, mfu 2.03%\n",
      "step 430: train loss 1.0967, val loss 1.1505\n",
      "iter 430: loss 1.1443, time 9534.66ms, mfu 1.87%\n",
      "iter 435: loss 1.0181, time 1176.75ms, mfu 2.03%\n",
      "step 440: train loss 1.0829, val loss 1.1144\n",
      "saving checkpoint to out-abc-char\n",
      "iter 440: loss 1.1164, time 10008.36ms, mfu 1.87%\n",
      "iter 445: loss 0.9064, time 1177.17ms, mfu 2.03%\n",
      "step 450: train loss 1.0776, val loss 1.1180\n",
      "iter 450: loss 1.0214, time 9832.06ms, mfu 1.87%\n",
      "iter 455: loss 1.0542, time 1176.76ms, mfu 2.03%\n",
      "step 460: train loss 1.0451, val loss 1.0777\n",
      "saving checkpoint to out-abc-char\n",
      "iter 460: loss 0.9404, time 10012.54ms, mfu 1.87%\n",
      "iter 465: loss 0.9932, time 1176.61ms, mfu 2.03%\n",
      "step 470: train loss 1.0268, val loss 1.0513\n",
      "saving checkpoint to out-abc-char\n",
      "iter 470: loss 1.1489, time 9866.66ms, mfu 1.87%\n",
      "iter 475: loss 1.0185, time 1177.01ms, mfu 2.03%\n",
      "step 480: train loss 1.0173, val loss 1.0504\n",
      "saving checkpoint to out-abc-char\n",
      "iter 480: loss 1.0154, time 9971.69ms, mfu 1.86%\n",
      "iter 485: loss 0.8509, time 1176.77ms, mfu 2.03%\n",
      "step 490: train loss 0.9821, val loss 1.0137\n",
      "saving checkpoint to out-abc-char\n",
      "iter 490: loss 1.0130, time 9893.48ms, mfu 1.86%\n",
      "iter 495: loss 0.9428, time 1177.09ms, mfu 2.03%\n",
      "step 500: train loss 0.9768, val loss 1.0255\n",
      "iter 500: loss 0.9536, time 9710.93ms, mfu 1.87%\n",
      "iter 505: loss 1.0218, time 1178.45ms, mfu 2.03%\n",
      "step 510: train loss 0.9790, val loss 1.0187\n",
      "iter 510: loss 1.0712, time 9736.04ms, mfu 1.87%\n",
      "iter 515: loss 0.9298, time 1176.91ms, mfu 2.03%\n",
      "step 520: train loss 0.9442, val loss 0.9723\n",
      "saving checkpoint to out-abc-char\n",
      "iter 520: loss 1.1803, time 9889.04ms, mfu 1.87%\n",
      "iter 525: loss 0.8902, time 1176.66ms, mfu 2.03%\n",
      "step 530: train loss 0.9382, val loss 0.9711\n",
      "saving checkpoint to out-abc-char\n",
      "iter 530: loss 0.9137, time 9917.54ms, mfu 1.87%\n",
      "iter 535: loss 1.0442, time 1176.57ms, mfu 2.03%\n",
      "step 540: train loss 0.9158, val loss 0.9528\n",
      "saving checkpoint to out-abc-char\n",
      "iter 540: loss 0.9294, time 9793.90ms, mfu 1.87%\n",
      "iter 545: loss 0.9187, time 1176.89ms, mfu 2.03%\n",
      "step 550: train loss 0.9144, val loss 0.9502\n",
      "saving checkpoint to out-abc-char\n",
      "iter 550: loss 0.8415, time 9837.37ms, mfu 1.87%\n",
      "iter 555: loss 0.9611, time 1175.88ms, mfu 2.03%\n",
      "step 560: train loss 0.9047, val loss 0.9393\n",
      "saving checkpoint to out-abc-char\n",
      "iter 560: loss 0.8447, time 9830.30ms, mfu 1.87%\n",
      "iter 565: loss 0.8974, time 1176.50ms, mfu 2.03%\n",
      "step 570: train loss 0.8853, val loss 0.9258\n",
      "saving checkpoint to out-abc-char\n",
      "iter 570: loss 0.9621, time 9807.23ms, mfu 1.87%\n",
      "iter 575: loss 0.9476, time 1177.34ms, mfu 2.03%\n",
      "step 580: train loss 0.8708, val loss 0.9183\n",
      "saving checkpoint to out-abc-char\n",
      "iter 580: loss 1.0824, time 9803.97ms, mfu 1.87%\n",
      "iter 585: loss 0.9597, time 1177.78ms, mfu 2.03%\n",
      "step 590: train loss 0.8570, val loss 0.8955\n",
      "saving checkpoint to out-abc-char\n",
      "iter 590: loss 0.9500, time 9765.29ms, mfu 1.87%\n",
      "iter 595: loss 0.9423, time 1178.41ms, mfu 2.03%\n",
      "step 600: train loss 0.8489, val loss 0.8918\n",
      "saving checkpoint to out-abc-char\n",
      "iter 600: loss 0.8612, time 9761.42ms, mfu 1.87%\n",
      "iter 605: loss 0.8859, time 1177.44ms, mfu 2.03%\n",
      "step 610: train loss 0.8380, val loss 0.8844\n",
      "saving checkpoint to out-abc-char\n",
      "iter 610: loss 0.9244, time 9844.53ms, mfu 1.87%\n",
      "iter 615: loss 0.8908, time 1176.43ms, mfu 2.03%\n",
      "step 620: train loss 0.8255, val loss 0.8783\n",
      "saving checkpoint to out-abc-char\n",
      "iter 620: loss 0.8581, time 9975.00ms, mfu 1.87%\n",
      "iter 625: loss 0.8417, time 1177.30ms, mfu 2.03%\n",
      "step 630: train loss 0.8048, val loss 0.8577\n",
      "saving checkpoint to out-abc-char\n",
      "iter 630: loss 0.7845, time 10032.81ms, mfu 1.86%\n",
      "iter 635: loss 0.8982, time 1176.79ms, mfu 2.03%\n",
      "step 640: train loss 0.8069, val loss 0.8530\n",
      "saving checkpoint to out-abc-char\n",
      "iter 640: loss 0.8124, time 9946.33ms, mfu 1.86%\n",
      "iter 645: loss 0.8980, time 1176.72ms, mfu 2.03%\n",
      "step 650: train loss 0.7893, val loss 0.8337\n",
      "saving checkpoint to out-abc-char\n",
      "iter 650: loss 0.7622, time 9887.57ms, mfu 1.86%\n",
      "iter 655: loss 0.9396, time 1175.96ms, mfu 2.03%\n",
      "step 660: train loss 0.7835, val loss 0.8327\n",
      "saving checkpoint to out-abc-char\n",
      "iter 660: loss 0.8241, time 9934.13ms, mfu 1.86%\n",
      "iter 665: loss 0.8444, time 1176.94ms, mfu 2.03%\n",
      "step 670: train loss 0.7564, val loss 0.8033\n",
      "saving checkpoint to out-abc-char\n",
      "iter 670: loss 0.8822, time 9942.97ms, mfu 1.86%\n",
      "iter 675: loss 0.7132, time 1177.06ms, mfu 2.03%\n",
      "step 680: train loss 0.7483, val loss 0.7969\n",
      "saving checkpoint to out-abc-char\n",
      "iter 680: loss 0.7472, time 9920.00ms, mfu 1.86%\n",
      "iter 685: loss 0.8540, time 1175.92ms, mfu 2.03%\n",
      "step 690: train loss 0.7359, val loss 0.7840\n",
      "saving checkpoint to out-abc-char\n",
      "iter 690: loss 0.8363, time 9859.36ms, mfu 1.87%\n",
      "iter 695: loss 0.7652, time 1177.00ms, mfu 2.03%\n",
      "step 700: train loss 0.7186, val loss 0.7730\n",
      "saving checkpoint to out-abc-char\n",
      "iter 700: loss 0.7949, time 9882.52ms, mfu 1.87%\n",
      "iter 705: loss 0.7846, time 1176.66ms, mfu 2.03%\n",
      "step 710: train loss 0.7119, val loss 0.7677\n",
      "saving checkpoint to out-abc-char\n",
      "iter 710: loss 0.7618, time 9831.30ms, mfu 1.87%\n",
      "iter 715: loss 0.7640, time 1176.42ms, mfu 2.03%\n",
      "step 720: train loss 0.7030, val loss 0.7510\n",
      "saving checkpoint to out-abc-char\n",
      "iter 720: loss 0.5988, time 9755.26ms, mfu 1.87%\n",
      "iter 725: loss 0.6721, time 1176.45ms, mfu 2.03%\n",
      "step 730: train loss 0.6961, val loss 0.7433\n",
      "saving checkpoint to out-abc-char\n",
      "iter 730: loss 0.6787, time 9876.83ms, mfu 1.87%\n",
      "iter 735: loss 0.5933, time 1177.50ms, mfu 2.03%\n",
      "step 740: train loss 0.6802, val loss 0.7288\n",
      "saving checkpoint to out-abc-char\n",
      "iter 740: loss 0.6627, time 9892.79ms, mfu 1.87%\n",
      "iter 745: loss 0.7851, time 1177.12ms, mfu 2.03%\n",
      "step 750: train loss 0.6661, val loss 0.7111\n",
      "saving checkpoint to out-abc-char\n",
      "iter 750: loss 0.7808, time 9820.87ms, mfu 1.87%\n",
      "iter 755: loss 0.6628, time 1176.88ms, mfu 2.03%\n",
      "step 760: train loss 0.6532, val loss 0.7078\n",
      "saving checkpoint to out-abc-char\n",
      "iter 760: loss 0.8119, time 9768.85ms, mfu 1.87%\n",
      "iter 765: loss 0.6643, time 1177.59ms, mfu 2.03%\n",
      "step 770: train loss 0.6497, val loss 0.7029\n",
      "saving checkpoint to out-abc-char\n",
      "iter 770: loss 0.6885, time 9800.34ms, mfu 1.87%\n",
      "iter 775: loss 0.8201, time 1176.83ms, mfu 2.03%\n",
      "step 780: train loss 0.6428, val loss 0.6849\n",
      "saving checkpoint to out-abc-char\n",
      "iter 780: loss 0.7246, time 9790.23ms, mfu 1.87%\n",
      "iter 785: loss 0.6000, time 1176.78ms, mfu 2.03%\n",
      "step 790: train loss 0.6332, val loss 0.6820\n",
      "saving checkpoint to out-abc-char\n",
      "iter 790: loss 0.5941, time 9997.41ms, mfu 1.87%\n",
      "iter 795: loss 0.6554, time 1177.09ms, mfu 2.03%\n",
      "step 800: train loss 0.6159, val loss 0.6685\n",
      "saving checkpoint to out-abc-char\n",
      "iter 800: loss 0.6652, time 9988.69ms, mfu 1.87%\n",
      "iter 805: loss 0.6527, time 1177.80ms, mfu 2.03%\n",
      "step 810: train loss 0.6127, val loss 0.6698\n",
      "iter 810: loss 0.7291, time 9786.87ms, mfu 1.87%\n",
      "iter 815: loss 0.5669, time 1178.17ms, mfu 2.03%\n",
      "step 820: train loss 0.6109, val loss 0.6613\n",
      "saving checkpoint to out-abc-char\n",
      "iter 820: loss 0.6032, time 9877.75ms, mfu 1.86%\n",
      "iter 825: loss 0.6916, time 1178.16ms, mfu 2.03%\n",
      "step 830: train loss 0.5961, val loss 0.6444\n",
      "saving checkpoint to out-abc-char\n",
      "iter 830: loss 0.5721, time 9926.81ms, mfu 1.86%\n",
      "iter 835: loss 0.6889, time 1176.50ms, mfu 2.03%\n",
      "step 840: train loss 0.5887, val loss 0.6425\n",
      "saving checkpoint to out-abc-char\n",
      "iter 840: loss 0.6698, time 9895.54ms, mfu 1.86%\n",
      "iter 845: loss 0.6152, time 1177.65ms, mfu 2.03%\n",
      "step 850: train loss 0.5852, val loss 0.6437\n",
      "iter 850: loss 0.5575, time 9653.44ms, mfu 1.87%\n",
      "iter 855: loss 0.5095, time 1177.69ms, mfu 2.03%\n",
      "step 860: train loss 0.5840, val loss 0.6315\n",
      "saving checkpoint to out-abc-char\n",
      "iter 860: loss 0.5989, time 9899.35ms, mfu 1.87%\n",
      "iter 865: loss 0.5497, time 1176.62ms, mfu 2.03%\n",
      "step 870: train loss 0.5668, val loss 0.6302\n",
      "saving checkpoint to out-abc-char\n",
      "iter 870: loss 0.6295, time 9889.43ms, mfu 1.87%\n",
      "iter 875: loss 0.6298, time 1176.56ms, mfu 2.03%\n",
      "step 880: train loss 0.5663, val loss 0.6232\n",
      "saving checkpoint to out-abc-char\n",
      "iter 880: loss 0.5270, time 9849.09ms, mfu 1.87%\n",
      "iter 885: loss 0.7046, time 1175.52ms, mfu 2.03%\n",
      "step 890: train loss 0.5558, val loss 0.6188\n",
      "saving checkpoint to out-abc-char\n",
      "iter 890: loss 0.5777, time 9807.40ms, mfu 1.87%\n",
      "iter 895: loss 0.5696, time 1176.65ms, mfu 2.03%\n",
      "step 900: train loss 0.5540, val loss 0.6126\n",
      "saving checkpoint to out-abc-char\n",
      "iter 900: loss 0.5955, time 9805.42ms, mfu 1.87%\n",
      "iter 905: loss 0.4883, time 1177.30ms, mfu 2.03%\n",
      "step 910: train loss 0.5456, val loss 0.6063\n",
      "saving checkpoint to out-abc-char\n",
      "iter 910: loss 0.6047, time 9828.85ms, mfu 1.87%\n",
      "iter 915: loss 0.4817, time 1177.80ms, mfu 2.03%\n",
      "step 920: train loss 0.5392, val loss 0.5985\n",
      "saving checkpoint to out-abc-char\n",
      "iter 920: loss 0.4505, time 9902.04ms, mfu 1.87%\n",
      "iter 925: loss 0.5462, time 1177.23ms, mfu 2.03%\n",
      "step 930: train loss 0.5335, val loss 0.5940\n",
      "saving checkpoint to out-abc-char\n",
      "iter 930: loss 0.6061, time 9776.67ms, mfu 1.87%\n",
      "iter 935: loss 0.6091, time 1178.08ms, mfu 2.03%\n",
      "step 940: train loss 0.5350, val loss 0.5909\n",
      "saving checkpoint to out-abc-char\n",
      "iter 940: loss 0.5019, time 9759.07ms, mfu 1.87%\n",
      "iter 945: loss 0.6717, time 1177.89ms, mfu 2.03%\n",
      "step 950: train loss 0.5231, val loss 0.5869\n",
      "saving checkpoint to out-abc-char\n",
      "iter 950: loss 0.5927, time 9764.02ms, mfu 1.87%\n",
      "iter 955: loss 0.5155, time 1176.47ms, mfu 2.03%\n",
      "step 960: train loss 0.5263, val loss 0.5878\n",
      "iter 960: loss 0.6244, time 9620.17ms, mfu 1.87%\n",
      "iter 965: loss 0.6257, time 1176.96ms, mfu 2.03%\n",
      "step 970: train loss 0.5096, val loss 0.5811\n",
      "saving checkpoint to out-abc-char\n",
      "iter 970: loss 0.4351, time 9989.30ms, mfu 1.87%\n",
      "iter 975: loss 0.5579, time 1176.14ms, mfu 2.03%\n",
      "step 980: train loss 0.5115, val loss 0.5806\n",
      "saving checkpoint to out-abc-char\n",
      "iter 980: loss 0.5379, time 10163.77ms, mfu 1.87%\n",
      "iter 985: loss 0.5407, time 1176.77ms, mfu 2.03%\n",
      "step 990: train loss 0.5091, val loss 0.5782\n",
      "saving checkpoint to out-abc-char\n",
      "iter 990: loss 0.4756, time 10107.52ms, mfu 1.86%\n",
      "iter 995: loss 0.5245, time 1176.75ms, mfu 2.03%\n",
      "step 1000: train loss 0.5044, val loss 0.5684\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1000: loss 0.5525, time 9873.42ms, mfu 1.86%\n",
      "iter 1005: loss 0.5139, time 1177.10ms, mfu 2.03%\n",
      "step 1010: train loss 0.4956, val loss 0.5638\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1010: loss 0.4843, time 9928.71ms, mfu 1.86%\n",
      "iter 1015: loss 0.4937, time 1177.18ms, mfu 2.03%\n",
      "step 1020: train loss 0.4866, val loss 0.5562\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1020: loss 0.5455, time 9943.84ms, mfu 1.86%\n",
      "iter 1025: loss 0.5565, time 1177.47ms, mfu 2.03%\n",
      "step 1030: train loss 0.4863, val loss 0.5629\n",
      "iter 1030: loss 0.5256, time 9684.83ms, mfu 1.87%\n",
      "iter 1035: loss 0.4492, time 1177.90ms, mfu 2.03%\n",
      "step 1040: train loss 0.4788, val loss 0.5528\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1040: loss 0.5374, time 9875.77ms, mfu 1.86%\n",
      "iter 1045: loss 0.4595, time 1177.06ms, mfu 2.03%\n",
      "step 1050: train loss 0.4747, val loss 0.5473\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1050: loss 0.4330, time 9866.64ms, mfu 1.87%\n",
      "iter 1055: loss 0.4682, time 1177.83ms, mfu 2.03%\n",
      "step 1060: train loss 0.4716, val loss 0.5489\n",
      "iter 1060: loss 0.4959, time 9633.37ms, mfu 1.87%\n",
      "iter 1065: loss 0.5661, time 1177.39ms, mfu 2.03%\n",
      "step 1070: train loss 0.4678, val loss 0.5456\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1070: loss 0.5012, time 9813.81ms, mfu 1.87%\n",
      "iter 1075: loss 0.4854, time 1176.59ms, mfu 2.03%\n",
      "step 1080: train loss 0.4652, val loss 0.5442\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1080: loss 0.4814, time 9872.53ms, mfu 1.87%\n",
      "iter 1085: loss 0.5357, time 1176.18ms, mfu 2.03%\n",
      "step 1090: train loss 0.4587, val loss 0.5415\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1090: loss 0.5736, time 9902.46ms, mfu 1.87%\n",
      "iter 1095: loss 0.4067, time 1176.36ms, mfu 2.03%\n",
      "step 1100: train loss 0.4561, val loss 0.5366\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1100: loss 0.6164, time 9821.89ms, mfu 1.87%\n",
      "iter 1105: loss 0.4802, time 1176.27ms, mfu 2.03%\n",
      "step 1110: train loss 0.4455, val loss 0.5333\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1110: loss 0.4585, time 9768.74ms, mfu 1.87%\n",
      "iter 1115: loss 0.4482, time 1177.33ms, mfu 2.03%\n",
      "step 1120: train loss 0.4454, val loss 0.5333\n",
      "iter 1120: loss 0.4659, time 9547.99ms, mfu 1.87%\n",
      "iter 1125: loss 0.4994, time 1176.67ms, mfu 2.03%\n",
      "step 1130: train loss 0.4377, val loss 0.5258\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1130: loss 0.4966, time 9770.76ms, mfu 1.87%\n",
      "iter 1135: loss 0.4627, time 1176.77ms, mfu 2.03%\n",
      "step 1140: train loss 0.4298, val loss 0.5189\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1140: loss 0.4788, time 10043.33ms, mfu 1.87%\n",
      "iter 1145: loss 0.4810, time 1177.26ms, mfu 2.03%\n",
      "step 1150: train loss 0.4331, val loss 0.5311\n",
      "iter 1150: loss 0.4195, time 9732.78ms, mfu 1.87%\n",
      "iter 1155: loss 0.5003, time 1177.35ms, mfu 2.03%\n",
      "step 1160: train loss 0.4228, val loss 0.5151\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1160: loss 0.4696, time 9953.61ms, mfu 1.87%\n",
      "iter 1165: loss 0.4127, time 1176.73ms, mfu 2.03%\n",
      "step 1170: train loss 0.4264, val loss 0.5191\n",
      "iter 1170: loss 0.4054, time 9604.49ms, mfu 1.87%\n",
      "iter 1175: loss 0.4412, time 1176.83ms, mfu 2.03%\n",
      "step 1180: train loss 0.4143, val loss 0.5081\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1180: loss 0.4109, time 9821.95ms, mfu 1.87%\n",
      "iter 1185: loss 0.4073, time 1176.68ms, mfu 2.03%\n",
      "step 1190: train loss 0.4055, val loss 0.5062\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1190: loss 0.4729, time 9888.62ms, mfu 1.87%\n",
      "iter 1195: loss 0.4024, time 1176.62ms, mfu 2.03%\n",
      "step 1200: train loss 0.4037, val loss 0.5013\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1200: loss 0.4239, time 9906.65ms, mfu 1.87%\n",
      "iter 1205: loss 0.3881, time 1176.50ms, mfu 2.03%\n",
      "step 1210: train loss 0.4000, val loss 0.5034\n",
      "iter 1210: loss 0.5351, time 9711.44ms, mfu 1.87%\n",
      "iter 1215: loss 0.3696, time 1177.30ms, mfu 2.03%\n",
      "step 1220: train loss 0.3999, val loss 0.5053\n",
      "iter 1220: loss 0.4807, time 9698.22ms, mfu 1.87%\n",
      "iter 1225: loss 0.4886, time 1177.28ms, mfu 2.03%\n",
      "step 1230: train loss 0.3909, val loss 0.5047\n",
      "iter 1230: loss 0.4012, time 9618.05ms, mfu 1.87%\n",
      "iter 1235: loss 0.4271, time 1176.84ms, mfu 2.03%\n",
      "step 1240: train loss 0.3812, val loss 0.4892\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1240: loss 0.3975, time 9821.74ms, mfu 1.87%\n",
      "iter 1245: loss 0.4292, time 1175.78ms, mfu 2.03%\n",
      "step 1250: train loss 0.3791, val loss 0.4861\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1250: loss 0.4702, time 9795.14ms, mfu 1.87%\n",
      "iter 1255: loss 0.4592, time 1176.09ms, mfu 2.03%\n",
      "step 1260: train loss 0.3697, val loss 0.4822\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1260: loss 0.4068, time 9854.59ms, mfu 1.87%\n",
      "iter 1265: loss 0.3751, time 1175.98ms, mfu 2.03%\n",
      "step 1270: train loss 0.3701, val loss 0.4766\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1270: loss 0.4049, time 9863.25ms, mfu 1.87%\n",
      "iter 1275: loss 0.4055, time 1178.12ms, mfu 2.03%\n",
      "step 1280: train loss 0.3637, val loss 0.4784\n",
      "iter 1280: loss 0.3682, time 9692.67ms, mfu 1.87%\n",
      "iter 1285: loss 0.3803, time 1177.50ms, mfu 2.03%\n",
      "step 1290: train loss 0.3595, val loss 0.4695\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1290: loss 0.4039, time 9763.82ms, mfu 1.87%\n",
      "iter 1295: loss 0.3966, time 1177.68ms, mfu 2.03%\n",
      "step 1300: train loss 0.3546, val loss 0.4689\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1300: loss 0.4445, time 9765.76ms, mfu 1.87%\n",
      "iter 1305: loss 0.3318, time 1176.71ms, mfu 2.03%\n",
      "step 1310: train loss 0.3473, val loss 0.4731\n",
      "iter 1310: loss 0.4125, time 9514.82ms, mfu 1.87%\n",
      "iter 1315: loss 0.5001, time 1176.52ms, mfu 2.03%\n",
      "step 1320: train loss 0.3466, val loss 0.4695\n",
      "iter 1320: loss 0.3652, time 9750.76ms, mfu 1.87%\n",
      "iter 1325: loss 0.4330, time 1178.22ms, mfu 2.03%\n",
      "step 1330: train loss 0.3390, val loss 0.4611\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1330: loss 0.3207, time 9980.22ms, mfu 1.87%\n",
      "iter 1335: loss 0.3925, time 1177.75ms, mfu 2.03%\n",
      "step 1340: train loss 0.3351, val loss 0.4624\n",
      "iter 1340: loss 0.3718, time 9852.82ms, mfu 1.87%\n",
      "iter 1345: loss 0.3955, time 1175.99ms, mfu 2.03%\n",
      "step 1350: train loss 0.3329, val loss 0.4525\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1350: loss 0.3382, time 9854.20ms, mfu 1.87%\n",
      "iter 1355: loss 0.3180, time 1176.58ms, mfu 2.03%\n",
      "step 1360: train loss 0.3248, val loss 0.4498\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1360: loss 0.3271, time 9899.75ms, mfu 1.87%\n",
      "iter 1365: loss 0.3801, time 1176.82ms, mfu 2.03%\n",
      "step 1370: train loss 0.3227, val loss 0.4469\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1370: loss 0.3333, time 9930.85ms, mfu 1.87%\n",
      "iter 1375: loss 0.2921, time 1176.43ms, mfu 2.03%\n",
      "step 1380: train loss 0.3226, val loss 0.4502\n",
      "iter 1380: loss 0.3313, time 9697.36ms, mfu 1.87%\n",
      "iter 1385: loss 0.3510, time 1177.18ms, mfu 2.03%\n",
      "step 1390: train loss 0.3105, val loss 0.4330\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1390: loss 0.3047, time 9872.11ms, mfu 1.87%\n",
      "iter 1395: loss 0.3490, time 1176.62ms, mfu 2.03%\n",
      "step 1400: train loss 0.3129, val loss 0.4373\n",
      "iter 1400: loss 0.3508, time 9632.99ms, mfu 1.87%\n",
      "iter 1405: loss 0.3235, time 1177.90ms, mfu 2.03%\n",
      "step 1410: train loss 0.3020, val loss 0.4349\n",
      "iter 1410: loss 0.2989, time 9667.46ms, mfu 1.87%\n",
      "iter 1415: loss 0.3644, time 1177.57ms, mfu 2.03%\n",
      "step 1420: train loss 0.2988, val loss 0.4371\n",
      "iter 1420: loss 0.3366, time 9590.53ms, mfu 1.87%\n",
      "iter 1425: loss 0.3119, time 1176.89ms, mfu 2.03%\n",
      "step 1430: train loss 0.2929, val loss 0.4364\n",
      "iter 1430: loss 0.3546, time 9580.97ms, mfu 1.87%\n",
      "iter 1435: loss 0.2816, time 1177.17ms, mfu 2.03%\n",
      "step 1440: train loss 0.2855, val loss 0.4229\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1440: loss 0.3269, time 9864.64ms, mfu 1.87%\n",
      "iter 1445: loss 0.3039, time 1177.42ms, mfu 2.03%\n",
      "step 1450: train loss 0.2841, val loss 0.4243\n",
      "iter 1450: loss 0.3273, time 9578.44ms, mfu 1.87%\n",
      "iter 1455: loss 0.3070, time 1177.69ms, mfu 2.03%\n",
      "step 1460: train loss 0.2839, val loss 0.4216\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1460: loss 0.3660, time 9791.69ms, mfu 1.87%\n",
      "iter 1465: loss 0.3175, time 1177.15ms, mfu 2.03%\n",
      "step 1470: train loss 0.2800, val loss 0.4271\n",
      "iter 1470: loss 0.3064, time 9543.85ms, mfu 1.87%\n",
      "iter 1475: loss 0.3360, time 1176.63ms, mfu 2.03%\n",
      "step 1480: train loss 0.2705, val loss 0.4188\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1480: loss 0.3252, time 9755.31ms, mfu 1.87%\n",
      "iter 1485: loss 0.3227, time 1176.87ms, mfu 2.03%\n",
      "step 1490: train loss 0.2722, val loss 0.4110\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1490: loss 0.3564, time 9779.89ms, mfu 1.87%\n",
      "iter 1495: loss 0.2685, time 1175.91ms, mfu 2.03%\n",
      "step 1500: train loss 0.2637, val loss 0.4073\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1500: loss 0.3437, time 10001.26ms, mfu 1.87%\n",
      "iter 1505: loss 0.3461, time 1175.84ms, mfu 2.03%\n",
      "step 1510: train loss 0.2604, val loss 0.3988\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1510: loss 0.2772, time 10014.33ms, mfu 1.87%\n",
      "iter 1515: loss 0.2588, time 1176.59ms, mfu 2.03%\n",
      "step 1520: train loss 0.2594, val loss 0.3994\n",
      "iter 1520: loss 0.3021, time 9729.57ms, mfu 1.87%\n",
      "iter 1525: loss 0.2834, time 1176.70ms, mfu 2.03%\n",
      "step 1530: train loss 0.2536, val loss 0.4015\n",
      "iter 1530: loss 0.3432, time 9639.11ms, mfu 1.87%\n",
      "iter 1535: loss 0.2784, time 1176.76ms, mfu 2.03%\n",
      "step 1540: train loss 0.2498, val loss 0.3965\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1540: loss 0.2938, time 9905.55ms, mfu 1.87%\n",
      "iter 1545: loss 0.3308, time 1176.45ms, mfu 2.03%\n",
      "step 1550: train loss 0.2435, val loss 0.3875\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1550: loss 0.3000, time 9959.96ms, mfu 1.87%\n",
      "iter 1555: loss 0.2810, time 1178.12ms, mfu 2.03%\n",
      "step 1560: train loss 0.2412, val loss 0.3878\n",
      "iter 1560: loss 0.3006, time 9693.64ms, mfu 1.87%\n",
      "iter 1565: loss 0.3004, time 1178.00ms, mfu 2.03%\n",
      "step 1570: train loss 0.2366, val loss 0.3900\n",
      "iter 1570: loss 0.2718, time 9621.21ms, mfu 1.87%\n",
      "iter 1575: loss 0.2801, time 1178.08ms, mfu 2.03%\n",
      "step 1580: train loss 0.2346, val loss 0.3741\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1580: loss 0.2572, time 9859.19ms, mfu 1.87%\n",
      "iter 1585: loss 0.2652, time 1177.04ms, mfu 2.03%\n",
      "step 1590: train loss 0.2318, val loss 0.3775\n",
      "iter 1590: loss 0.2717, time 9644.26ms, mfu 1.87%\n",
      "iter 1595: loss 0.2643, time 1177.47ms, mfu 2.03%\n",
      "step 1600: train loss 0.2263, val loss 0.3744\n",
      "iter 1600: loss 0.3325, time 9558.31ms, mfu 1.87%\n",
      "iter 1605: loss 0.2668, time 1176.70ms, mfu 2.03%\n",
      "step 1610: train loss 0.2241, val loss 0.3765\n",
      "iter 1610: loss 0.2705, time 9617.19ms, mfu 1.87%\n",
      "iter 1615: loss 0.3027, time 1177.20ms, mfu 2.03%\n",
      "step 1620: train loss 0.2199, val loss 0.3720\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1620: loss 0.2829, time 9846.27ms, mfu 1.87%\n",
      "iter 1625: loss 0.3252, time 1176.83ms, mfu 2.03%\n",
      "step 1630: train loss 0.2212, val loss 0.3673\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1630: loss 0.3131, time 9832.65ms, mfu 1.87%\n",
      "iter 1635: loss 0.2689, time 1176.28ms, mfu 2.03%\n",
      "step 1640: train loss 0.2171, val loss 0.3553\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1640: loss 0.2685, time 9793.17ms, mfu 1.87%\n",
      "iter 1645: loss 0.2358, time 1176.76ms, mfu 2.03%\n",
      "step 1650: train loss 0.2082, val loss 0.3638\n",
      "iter 1650: loss 0.2242, time 9559.13ms, mfu 1.87%\n",
      "iter 1655: loss 0.2678, time 1177.51ms, mfu 2.03%\n",
      "step 1660: train loss 0.2077, val loss 0.3555\n",
      "iter 1660: loss 0.2462, time 9549.17ms, mfu 1.87%\n",
      "iter 1665: loss 0.2337, time 1176.61ms, mfu 2.03%\n",
      "step 1670: train loss 0.2034, val loss 0.3535\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1670: loss 0.2339, time 9930.70ms, mfu 1.87%\n",
      "iter 1675: loss 0.2734, time 1176.85ms, mfu 2.03%\n",
      "step 1680: train loss 0.2040, val loss 0.3484\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1680: loss 0.2034, time 9964.48ms, mfu 1.87%\n",
      "iter 1685: loss 0.2246, time 1176.24ms, mfu 2.03%\n",
      "step 1690: train loss 0.1998, val loss 0.3495\n",
      "iter 1690: loss 0.1959, time 9767.39ms, mfu 1.87%\n",
      "iter 1695: loss 0.1780, time 1177.50ms, mfu 2.03%\n",
      "step 1700: train loss 0.1967, val loss 0.3508\n",
      "iter 1700: loss 0.2112, time 9604.04ms, mfu 1.87%\n",
      "iter 1705: loss 0.2535, time 1177.04ms, mfu 2.03%\n",
      "step 1710: train loss 0.1925, val loss 0.3452\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1710: loss 0.2377, time 9853.48ms, mfu 1.87%\n",
      "iter 1715: loss 0.2048, time 1177.34ms, mfu 2.03%\n",
      "step 1720: train loss 0.1929, val loss 0.3401\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1720: loss 0.2638, time 9931.99ms, mfu 1.87%\n",
      "iter 1725: loss 0.2206, time 1176.55ms, mfu 2.03%\n",
      "step 1730: train loss 0.1862, val loss 0.3307\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1730: loss 0.2312, time 9909.14ms, mfu 1.87%\n",
      "iter 1735: loss 0.2376, time 1176.21ms, mfu 2.03%\n",
      "step 1740: train loss 0.1821, val loss 0.3334\n",
      "iter 1740: loss 0.2231, time 9705.73ms, mfu 1.87%\n",
      "iter 1745: loss 0.2152, time 1176.58ms, mfu 2.03%\n",
      "step 1750: train loss 0.1813, val loss 0.3326\n",
      "iter 1750: loss 0.2049, time 9623.67ms, mfu 1.87%\n",
      "iter 1755: loss 0.2493, time 1176.29ms, mfu 2.03%\n",
      "step 1760: train loss 0.1844, val loss 0.3320\n",
      "iter 1760: loss 0.2682, time 9641.58ms, mfu 1.87%\n",
      "iter 1765: loss 0.2336, time 1176.00ms, mfu 2.03%\n",
      "step 1770: train loss 0.1811, val loss 0.3358\n",
      "iter 1770: loss 0.2266, time 9615.81ms, mfu 1.87%\n",
      "iter 1775: loss 0.2278, time 1176.87ms, mfu 2.03%\n",
      "step 1780: train loss 0.1743, val loss 0.3277\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1780: loss 0.1823, time 9786.09ms, mfu 1.87%\n",
      "iter 1785: loss 0.2002, time 1176.91ms, mfu 2.03%\n",
      "step 1790: train loss 0.1738, val loss 0.3355\n",
      "iter 1790: loss 0.2205, time 9641.22ms, mfu 1.87%\n",
      "iter 1795: loss 0.2352, time 1176.38ms, mfu 2.03%\n",
      "step 1800: train loss 0.1725, val loss 0.3301\n",
      "iter 1800: loss 0.2347, time 9598.79ms, mfu 1.87%\n",
      "iter 1805: loss 0.2283, time 1176.82ms, mfu 2.03%\n",
      "step 1810: train loss 0.1660, val loss 0.3092\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1810: loss 0.2360, time 9853.61ms, mfu 1.87%\n",
      "iter 1815: loss 0.2266, time 1176.37ms, mfu 2.03%\n",
      "step 1820: train loss 0.1690, val loss 0.3181\n",
      "iter 1820: loss 0.2122, time 9533.08ms, mfu 1.87%\n",
      "iter 1825: loss 0.2135, time 1176.09ms, mfu 2.03%\n",
      "step 1830: train loss 0.1617, val loss 0.3250\n",
      "iter 1830: loss 0.2114, time 9569.93ms, mfu 1.87%\n",
      "iter 1835: loss 0.1859, time 1176.50ms, mfu 2.03%\n",
      "step 1840: train loss 0.1614, val loss 0.3229\n",
      "iter 1840: loss 0.2006, time 9520.52ms, mfu 1.87%\n",
      "iter 1845: loss 0.2570, time 1176.44ms, mfu 2.03%\n",
      "step 1850: train loss 0.1642, val loss 0.3114\n",
      "iter 1850: loss 0.1885, time 9746.33ms, mfu 1.87%\n",
      "iter 1855: loss 0.2459, time 1176.51ms, mfu 2.03%\n",
      "step 1860: train loss 0.1574, val loss 0.3053\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1860: loss 0.1729, time 9971.86ms, mfu 1.87%\n",
      "iter 1865: loss 0.1451, time 1177.65ms, mfu 2.03%\n",
      "step 1870: train loss 0.1541, val loss 0.2954\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1870: loss 0.2068, time 9982.13ms, mfu 1.87%\n",
      "iter 1875: loss 0.1837, time 1177.62ms, mfu 2.03%\n",
      "step 1880: train loss 0.1540, val loss 0.3080\n",
      "iter 1880: loss 0.2299, time 9640.74ms, mfu 1.87%\n",
      "iter 1885: loss 0.2032, time 1177.22ms, mfu 2.03%\n",
      "step 1890: train loss 0.1500, val loss 0.2913\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1890: loss 0.1972, time 9926.95ms, mfu 1.87%\n",
      "iter 1895: loss 0.2163, time 1176.68ms, mfu 2.03%\n",
      "step 1900: train loss 0.1465, val loss 0.2957\n",
      "iter 1900: loss 0.1660, time 9654.21ms, mfu 1.87%\n",
      "iter 1905: loss 0.1709, time 1177.58ms, mfu 2.03%\n",
      "step 1910: train loss 0.1493, val loss 0.3071\n",
      "iter 1910: loss 0.1967, time 9647.58ms, mfu 1.87%\n",
      "iter 1915: loss 0.1790, time 1177.59ms, mfu 2.03%\n",
      "step 1920: train loss 0.1455, val loss 0.2983\n",
      "iter 1920: loss 0.1999, time 9644.88ms, mfu 1.87%\n",
      "iter 1925: loss 0.1657, time 1177.43ms, mfu 2.03%\n",
      "step 1930: train loss 0.1424, val loss 0.2994\n",
      "iter 1930: loss 0.2048, time 9652.91ms, mfu 1.87%\n",
      "iter 1935: loss 0.1897, time 1177.43ms, mfu 2.03%\n",
      "step 1940: train loss 0.1406, val loss 0.2981\n",
      "iter 1940: loss 0.1919, time 9590.10ms, mfu 1.87%\n",
      "iter 1945: loss 0.2124, time 1176.72ms, mfu 2.03%\n",
      "step 1950: train loss 0.1381, val loss 0.2865\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1950: loss 0.1797, time 9883.67ms, mfu 1.87%\n",
      "iter 1955: loss 0.1705, time 1177.01ms, mfu 2.03%\n",
      "step 1960: train loss 0.1373, val loss 0.2818\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1960: loss 0.1730, time 9811.80ms, mfu 1.87%\n",
      "iter 1965: loss 0.1922, time 1176.33ms, mfu 2.03%\n",
      "step 1970: train loss 0.1360, val loss 0.3030\n",
      "iter 1970: loss 0.1687, time 9605.06ms, mfu 1.87%\n",
      "iter 1975: loss 0.1571, time 1176.29ms, mfu 2.03%\n",
      "step 1980: train loss 0.1345, val loss 0.2888\n",
      "iter 1980: loss 0.2093, time 9666.21ms, mfu 1.87%\n",
      "iter 1985: loss 0.1615, time 1176.80ms, mfu 2.03%\n",
      "step 1990: train loss 0.1344, val loss 0.2950\n",
      "iter 1990: loss 0.1319, time 9642.68ms, mfu 1.87%\n",
      "iter 1995: loss 0.1746, time 1177.11ms, mfu 2.03%\n",
      "step 2000: train loss 0.1291, val loss 0.2851\n",
      "iter 2000: loss 0.1672, time 9557.00ms, mfu 1.87%\n",
      "iter 2005: loss 0.1655, time 1176.93ms, mfu 2.03%\n",
      "step 2010: train loss 0.1337, val loss 0.2961\n",
      "iter 2010: loss 0.1755, time 9540.98ms, mfu 1.87%\n",
      "iter 2015: loss 0.1560, time 1176.76ms, mfu 2.03%\n",
      "step 2020: train loss 0.1250, val loss 0.2875\n",
      "iter 2020: loss 0.1453, time 9541.79ms, mfu 1.87%\n",
      "iter 2025: loss 0.1861, time 1177.02ms, mfu 2.03%\n",
      "step 2030: train loss 0.1261, val loss 0.2794\n",
      "saving checkpoint to out-abc-char\n",
      "iter 2030: loss 0.1801, time 10101.33ms, mfu 1.87%\n",
      "iter 2035: loss 0.1516, time 1176.99ms, mfu 2.03%\n",
      "step 2040: train loss 0.1266, val loss 0.2876\n",
      "iter 2040: loss 0.1641, time 9778.65ms, mfu 1.87%\n",
      "iter 2045: loss 0.1566, time 1176.68ms, mfu 2.03%\n",
      "step 2050: train loss 0.1230, val loss 0.2876\n",
      "iter 2050: loss 0.1644, time 9741.87ms, mfu 1.87%\n",
      "iter 2055: loss 0.1693, time 1176.24ms, mfu 2.03%\n",
      "step 2060: train loss 0.1206, val loss 0.2845\n",
      "iter 2060: loss 0.1830, time 9682.53ms, mfu 1.87%\n",
      "iter 2065: loss 0.1560, time 1177.46ms, mfu 2.03%\n",
      "step 2070: train loss 0.1199, val loss 0.2671\n",
      "saving checkpoint to out-abc-char\n",
      "iter 2070: loss 0.1823, time 9893.98ms, mfu 1.87%\n",
      "iter 2075: loss 0.1540, time 1176.96ms, mfu 2.03%\n",
      "step 2080: train loss 0.1209, val loss 0.2664\n",
      "saving checkpoint to out-abc-char\n",
      "iter 2080: loss 0.1983, time 9890.25ms, mfu 1.87%\n",
      "iter 2085: loss 0.1563, time 1177.07ms, mfu 2.03%\n",
      "step 2090: train loss 0.1159, val loss 0.2743\n",
      "iter 2090: loss 0.1843, time 9681.52ms, mfu 1.87%\n",
      "iter 2095: loss 0.1435, time 1176.69ms, mfu 2.03%\n",
      "step 2100: train loss 0.1159, val loss 0.2815\n",
      "iter 2100: loss 0.1611, time 9685.50ms, mfu 1.87%\n",
      "iter 2105: loss 0.1335, time 1176.54ms, mfu 2.03%\n",
      "step 2110: train loss 0.1140, val loss 0.2594\n",
      "saving checkpoint to out-abc-char\n",
      "iter 2110: loss 0.1453, time 9901.78ms, mfu 1.87%\n",
      "iter 2115: loss 0.1686, time 1176.77ms, mfu 2.03%\n",
      "step 2120: train loss 0.1152, val loss 0.2752\n",
      "iter 2120: loss 0.1802, time 9634.18ms, mfu 1.87%\n",
      "iter 2125: loss 0.1869, time 1176.88ms, mfu 2.03%\n",
      "step 2130: train loss 0.1108, val loss 0.2646\n",
      "iter 2130: loss 0.1615, time 9555.67ms, mfu 1.87%\n",
      "iter 2135: loss 0.1284, time 1176.48ms, mfu 2.03%\n",
      "step 2140: train loss 0.1141, val loss 0.2777\n",
      "iter 2140: loss 0.1575, time 9601.07ms, mfu 1.87%\n",
      "iter 2145: loss 0.1626, time 1176.32ms, mfu 2.03%\n",
      "step 2150: train loss 0.1101, val loss 0.2616\n",
      "iter 2150: loss 0.1561, time 9669.29ms, mfu 1.87%\n",
      "iter 2155: loss 0.1374, time 1177.05ms, mfu 2.03%\n",
      "step 2160: train loss 0.1074, val loss 0.2597\n",
      "iter 2160: loss 0.1378, time 9700.49ms, mfu 1.87%\n",
      "iter 2165: loss 0.1361, time 1176.28ms, mfu 2.03%\n",
      "step 2170: train loss 0.1065, val loss 0.2614\n",
      "iter 2170: loss 0.1364, time 9589.62ms, mfu 1.87%\n",
      "iter 2175: loss 0.1578, time 1177.05ms, mfu 2.03%\n",
      "step 2180: train loss 0.1043, val loss 0.2651\n",
      "iter 2180: loss 0.1642, time 9551.95ms, mfu 1.87%\n",
      "iter 2185: loss 0.1351, time 1176.44ms, mfu 2.03%\n",
      "step 2190: train loss 0.1044, val loss 0.2659\n",
      "iter 2190: loss 0.1589, time 9545.13ms, mfu 1.87%\n",
      "iter 2195: loss 0.1575, time 1177.10ms, mfu 2.03%\n",
      "step 2200: train loss 0.1025, val loss 0.2518\n",
      "saving checkpoint to out-abc-char\n",
      "iter 2200: loss 0.1281, time 9891.08ms, mfu 1.87%\n",
      "iter 2205: loss 0.1480, time 1178.40ms, mfu 2.03%\n",
      "step 2210: train loss 0.1026, val loss 0.2635\n",
      "iter 2210: loss 0.1287, time 9770.72ms, mfu 1.87%\n",
      "iter 2215: loss 0.1183, time 1177.36ms, mfu 2.03%\n",
      "step 2220: train loss 0.1029, val loss 0.2640\n",
      "iter 2220: loss 0.1345, time 9778.70ms, mfu 1.87%\n",
      "iter 2225: loss 0.1204, time 1177.53ms, mfu 2.03%\n",
      "step 2230: train loss 0.1019, val loss 0.2519\n",
      "iter 2230: loss 0.1579, time 9659.58ms, mfu 1.87%\n",
      "iter 2235: loss 0.1267, time 1176.87ms, mfu 2.03%\n",
      "step 2240: train loss 0.0996, val loss 0.2628\n",
      "iter 2240: loss 0.1438, time 9628.50ms, mfu 1.87%\n",
      "iter 2245: loss 0.1510, time 1177.45ms, mfu 2.03%\n",
      "step 2250: train loss 0.0991, val loss 0.2501\n",
      "saving checkpoint to out-abc-char\n",
      "iter 2250: loss 0.1125, time 9918.57ms, mfu 1.87%\n",
      "iter 2255: loss 0.1443, time 1177.57ms, mfu 2.03%\n",
      "step 2260: train loss 0.0988, val loss 0.2725\n",
      "iter 2260: loss 0.1245, time 9657.56ms, mfu 1.87%\n",
      "iter 2265: loss 0.1168, time 1176.76ms, mfu 2.03%\n",
      "step 2270: train loss 0.0971, val loss 0.2546\n",
      "iter 2270: loss 0.1192, time 9654.30ms, mfu 1.87%\n",
      "iter 2275: loss 0.1181, time 1177.60ms, mfu 2.03%\n",
      "step 2280: train loss 0.0975, val loss 0.2497\n",
      "saving checkpoint to out-abc-char\n",
      "iter 2280: loss 0.1377, time 9959.33ms, mfu 1.87%\n",
      "iter 2285: loss 0.1279, time 1176.69ms, mfu 2.03%\n",
      "step 2290: train loss 0.0941, val loss 0.2557\n",
      "iter 2290: loss 0.1526, time 9642.74ms, mfu 1.87%\n",
      "iter 2295: loss 0.1040, time 1177.20ms, mfu 2.03%\n",
      "step 2300: train loss 0.0940, val loss 0.2643\n",
      "iter 2300: loss 0.1150, time 9602.22ms, mfu 1.87%\n",
      "iter 2305: loss 0.1657, time 1176.66ms, mfu 2.03%\n",
      "step 2310: train loss 0.0955, val loss 0.2385\n",
      "saving checkpoint to out-abc-char\n",
      "iter 2310: loss 0.1232, time 9821.21ms, mfu 1.87%\n",
      "iter 2315: loss 0.1455, time 1176.85ms, mfu 2.03%\n",
      "step 2320: train loss 0.0917, val loss 0.2476\n",
      "iter 2320: loss 0.1171, time 9643.35ms, mfu 1.87%\n",
      "iter 2325: loss 0.1270, time 1176.48ms, mfu 2.03%\n",
      "step 2330: train loss 0.0889, val loss 0.2391\n",
      "iter 2330: loss 0.1336, time 9639.81ms, mfu 1.87%\n",
      "iter 2335: loss 0.1529, time 1176.54ms, mfu 2.03%\n",
      "step 2340: train loss 0.0901, val loss 0.2431\n",
      "iter 2340: loss 0.1304, time 9653.38ms, mfu 1.87%\n",
      "iter 2345: loss 0.1132, time 1176.95ms, mfu 2.03%\n",
      "step 2350: train loss 0.0895, val loss 0.2263\n",
      "saving checkpoint to out-abc-char\n",
      "iter 2350: loss 0.1179, time 9753.84ms, mfu 1.87%\n",
      "iter 2355: loss 0.1110, time 1176.82ms, mfu 2.03%\n",
      "step 2360: train loss 0.0889, val loss 0.2303\n",
      "iter 2360: loss 0.1407, time 9560.53ms, mfu 1.87%\n",
      "iter 2365: loss 0.1061, time 1177.44ms, mfu 2.03%\n",
      "step 2370: train loss 0.0866, val loss 0.2395\n",
      "iter 2370: loss 0.1180, time 9556.19ms, mfu 1.87%\n",
      "iter 2375: loss 0.1198, time 1178.21ms, mfu 2.03%\n",
      "step 2380: train loss 0.0888, val loss 0.2366\n",
      "iter 2380: loss 0.1061, time 9721.92ms, mfu 1.87%\n",
      "iter 2385: loss 0.1317, time 1176.94ms, mfu 2.03%\n",
      "step 2390: train loss 0.0883, val loss 0.2253\n",
      "saving checkpoint to out-abc-char\n",
      "iter 2390: loss 0.1066, time 9923.71ms, mfu 1.87%\n",
      "iter 2395: loss 0.1049, time 1176.73ms, mfu 2.03%\n",
      "step 2400: train loss 0.0868, val loss 0.2287\n",
      "iter 2400: loss 0.1182, time 9793.69ms, mfu 1.87%\n",
      "iter 2405: loss 0.1518, time 1177.04ms, mfu 2.03%\n",
      "step 2410: train loss 0.0874, val loss 0.2431\n",
      "iter 2410: loss 0.1063, time 9619.91ms, mfu 1.87%\n",
      "iter 2415: loss 0.1480, time 1175.60ms, mfu 2.03%\n",
      "step 2420: train loss 0.0854, val loss 0.2251\n",
      "saving checkpoint to out-abc-char\n",
      "iter 2420: loss 0.1175, time 9825.82ms, mfu 1.87%\n",
      "iter 2425: loss 0.1230, time 1176.73ms, mfu 2.03%\n",
      "step 2430: train loss 0.0880, val loss 0.2333\n",
      "iter 2430: loss 0.1141, time 9650.95ms, mfu 1.87%\n",
      "iter 2435: loss 0.0962, time 1176.46ms, mfu 2.03%\n",
      "step 2440: train loss 0.0836, val loss 0.2422\n",
      "iter 2440: loss 0.1113, time 9724.23ms, mfu 1.87%\n",
      "iter 2445: loss 0.1382, time 1176.41ms, mfu 2.03%\n",
      "step 2450: train loss 0.0826, val loss 0.2346\n",
      "iter 2450: loss 0.1353, time 9675.88ms, mfu 1.87%\n",
      "iter 2455: loss 0.1352, time 1176.97ms, mfu 2.03%\n",
      "step 2460: train loss 0.0846, val loss 0.2325\n",
      "iter 2460: loss 0.1182, time 9702.65ms, mfu 1.87%\n",
      "iter 2465: loss 0.1171, time 1176.41ms, mfu 2.03%\n",
      "step 2470: train loss 0.0815, val loss 0.2258\n",
      "iter 2470: loss 0.1145, time 9659.87ms, mfu 1.87%\n",
      "iter 2475: loss 0.1041, time 1176.26ms, mfu 2.03%\n",
      "step 2480: train loss 0.0826, val loss 0.2276\n",
      "iter 2480: loss 0.1296, time 9611.29ms, mfu 1.87%\n",
      "iter 2485: loss 0.1047, time 1177.18ms, mfu 2.03%\n",
      "step 2490: train loss 0.0822, val loss 0.2246\n",
      "saving checkpoint to out-abc-char\n",
      "iter 2490: loss 0.1202, time 9776.11ms, mfu 1.87%\n",
      "iter 2495: loss 0.1190, time 1176.43ms, mfu 2.03%\n",
      "step 2500: train loss 0.0813, val loss 0.2385\n",
      "iter 2500: loss 0.1325, time 9618.72ms, mfu 1.87%\n",
      "iter 2505: loss 0.1097, time 1176.64ms, mfu 2.03%\n",
      "step 2510: train loss 0.0819, val loss 0.2315\n",
      "iter 2510: loss 0.1295, time 9638.46ms, mfu 1.87%\n",
      "iter 2515: loss 0.1080, time 1177.35ms, mfu 2.03%\n",
      "step 2520: train loss 0.0791, val loss 0.2348\n",
      "iter 2520: loss 0.1214, time 9572.11ms, mfu 1.87%\n",
      "iter 2525: loss 0.1158, time 1177.66ms, mfu 2.03%\n",
      "step 2530: train loss 0.0804, val loss 0.2563\n",
      "iter 2530: loss 0.0966, time 9525.27ms, mfu 1.87%\n",
      "iter 2535: loss 0.1150, time 1177.14ms, mfu 2.03%\n",
      "step 2540: train loss 0.0789, val loss 0.2473\n",
      "iter 2540: loss 0.1159, time 9548.74ms, mfu 1.87%\n",
      "iter 2545: loss 0.1531, time 1177.05ms, mfu 2.03%\n",
      "step 2550: train loss 0.0776, val loss 0.2184\n",
      "saving checkpoint to out-abc-char\n",
      "iter 2550: loss 0.1176, time 9775.41ms, mfu 1.87%\n",
      "iter 2555: loss 0.0896, time 1177.18ms, mfu 2.03%\n",
      "step 2560: train loss 0.0775, val loss 0.2284\n",
      "iter 2560: loss 0.1059, time 9755.23ms, mfu 1.87%\n",
      "iter 2565: loss 0.1084, time 1176.95ms, mfu 2.03%\n",
      "step 2570: train loss 0.0766, val loss 0.2285\n",
      "iter 2570: loss 0.1017, time 9758.03ms, mfu 1.87%\n",
      "iter 2575: loss 0.0878, time 1177.55ms, mfu 2.03%\n",
      "step 2580: train loss 0.0771, val loss 0.2246\n",
      "iter 2580: loss 0.0910, time 9798.65ms, mfu 1.87%\n",
      "iter 2585: loss 0.1019, time 1176.70ms, mfu 2.03%\n",
      "step 2590: train loss 0.0770, val loss 0.2481\n",
      "iter 2590: loss 0.1077, time 9642.45ms, mfu 1.87%\n",
      "iter 2595: loss 0.0961, time 1176.93ms, mfu 2.03%\n",
      "step 2600: train loss 0.0766, val loss 0.2178\n",
      "saving checkpoint to out-abc-char\n",
      "iter 2600: loss 0.1091, time 9869.78ms, mfu 1.87%\n",
      "iter 2605: loss 0.1037, time 1177.21ms, mfu 2.03%\n",
      "step 2610: train loss 0.0757, val loss 0.2057\n",
      "saving checkpoint to out-abc-char\n",
      "iter 2610: loss 0.1091, time 9881.83ms, mfu 1.87%\n",
      "iter 2615: loss 0.1075, time 1176.83ms, mfu 2.03%\n",
      "step 2620: train loss 0.0754, val loss 0.2105\n",
      "iter 2620: loss 0.0907, time 9640.79ms, mfu 1.87%\n",
      "iter 2625: loss 0.0924, time 1176.80ms, mfu 2.03%\n",
      "step 2630: train loss 0.0752, val loss 0.2300\n",
      "iter 2630: loss 0.1016, time 9645.91ms, mfu 1.87%\n",
      "iter 2635: loss 0.1170, time 1176.14ms, mfu 2.03%\n",
      "step 2640: train loss 0.0743, val loss 0.2162\n",
      "iter 2640: loss 0.1006, time 9640.33ms, mfu 1.87%\n",
      "iter 2645: loss 0.0859, time 1176.49ms, mfu 2.03%\n",
      "step 2650: train loss 0.0736, val loss 0.2368\n",
      "iter 2650: loss 0.0979, time 9724.30ms, mfu 1.87%\n",
      "iter 2655: loss 0.1378, time 1176.61ms, mfu 2.03%\n",
      "step 2660: train loss 0.0731, val loss 0.2369\n",
      "iter 2660: loss 0.0973, time 9580.91ms, mfu 1.87%\n",
      "iter 2665: loss 0.0827, time 1176.64ms, mfu 2.03%\n",
      "step 2670: train loss 0.0732, val loss 0.2173\n",
      "iter 2670: loss 0.1233, time 9558.81ms, mfu 1.87%\n",
      "iter 2675: loss 0.1062, time 1177.82ms, mfu 2.03%\n",
      "step 2680: train loss 0.0727, val loss 0.2268\n",
      "iter 2680: loss 0.0875, time 9696.07ms, mfu 1.87%\n",
      "iter 2685: loss 0.0946, time 1177.26ms, mfu 2.03%\n",
      "step 2690: train loss 0.0721, val loss 0.2233\n",
      "iter 2690: loss 0.1060, time 9648.58ms, mfu 1.87%\n",
      "iter 2695: loss 0.1125, time 1178.09ms, mfu 2.03%\n",
      "step 2700: train loss 0.0722, val loss 0.2036\n",
      "saving checkpoint to out-abc-char\n",
      "iter 2700: loss 0.1170, time 9817.70ms, mfu 1.87%\n",
      "iter 2705: loss 0.1182, time 1177.49ms, mfu 2.03%\n",
      "step 2710: train loss 0.0727, val loss 0.2183\n",
      "iter 2710: loss 0.1051, time 9597.64ms, mfu 1.87%\n",
      "iter 2715: loss 0.0907, time 1176.44ms, mfu 2.03%\n",
      "step 2720: train loss 0.0723, val loss 0.2261\n",
      "iter 2720: loss 0.1045, time 9590.29ms, mfu 1.87%\n",
      "iter 2725: loss 0.0924, time 1177.17ms, mfu 2.03%\n",
      "step 2730: train loss 0.0721, val loss 0.2232\n",
      "iter 2730: loss 0.1013, time 9572.56ms, mfu 1.87%\n",
      "iter 2735: loss 0.1142, time 1176.68ms, mfu 2.03%\n",
      "step 2740: train loss 0.0709, val loss 0.2251\n",
      "iter 2740: loss 0.1224, time 9715.33ms, mfu 1.87%\n",
      "iter 2745: loss 0.0877, time 1176.51ms, mfu 2.03%\n",
      "step 2750: train loss 0.0704, val loss 0.2157\n",
      "iter 2750: loss 0.0927, time 9798.07ms, mfu 1.87%\n",
      "iter 2755: loss 0.1101, time 1177.38ms, mfu 2.03%\n",
      "step 2760: train loss 0.0692, val loss 0.2223\n",
      "iter 2760: loss 0.1084, time 9786.54ms, mfu 1.87%\n",
      "iter 2765: loss 0.1159, time 1176.42ms, mfu 2.03%\n",
      "step 2770: train loss 0.0701, val loss 0.2116\n",
      "iter 2770: loss 0.1152, time 9678.69ms, mfu 1.87%\n",
      "iter 2775: loss 0.0928, time 1177.13ms, mfu 2.03%\n",
      "step 2780: train loss 0.0708, val loss 0.2170\n",
      "iter 2780: loss 0.0870, time 9695.69ms, mfu 1.87%\n",
      "iter 2785: loss 0.0993, time 1176.36ms, mfu 2.03%\n",
      "step 2790: train loss 0.0696, val loss 0.2120\n",
      "iter 2790: loss 0.1146, time 9666.41ms, mfu 1.87%\n",
      "iter 2795: loss 0.0879, time 1176.34ms, mfu 2.03%\n",
      "step 2800: train loss 0.0695, val loss 0.2243\n",
      "iter 2800: loss 0.0908, time 9700.26ms, mfu 1.87%\n",
      "iter 2805: loss 0.1066, time 1175.87ms, mfu 2.03%\n",
      "step 2810: train loss 0.0695, val loss 0.2147\n",
      "iter 2810: loss 0.1040, time 9663.86ms, mfu 1.87%\n",
      "iter 2815: loss 0.0894, time 1175.73ms, mfu 2.03%\n",
      "step 2820: train loss 0.0680, val loss 0.1897\n",
      "saving checkpoint to out-abc-char\n",
      "iter 2820: loss 0.1043, time 9872.61ms, mfu 1.87%\n",
      "iter 2825: loss 0.1029, time 1176.51ms, mfu 2.03%\n",
      "step 2830: train loss 0.0689, val loss 0.2163\n",
      "iter 2830: loss 0.0837, time 9700.19ms, mfu 1.87%\n",
      "iter 2835: loss 0.0985, time 1176.88ms, mfu 2.03%\n",
      "step 2840: train loss 0.0669, val loss 0.2142\n",
      "iter 2840: loss 0.0995, time 9567.45ms, mfu 1.87%\n",
      "iter 2845: loss 0.0878, time 1176.26ms, mfu 2.03%\n",
      "step 2850: train loss 0.0680, val loss 0.2120\n",
      "iter 2850: loss 0.0867, time 9579.66ms, mfu 1.87%\n",
      "iter 2855: loss 0.0905, time 1177.23ms, mfu 2.03%\n",
      "step 2860: train loss 0.0669, val loss 0.2054\n",
      "iter 2860: loss 0.0831, time 9656.76ms, mfu 1.87%\n",
      "iter 2865: loss 0.1030, time 1176.76ms, mfu 2.03%\n",
      "step 2870: train loss 0.0697, val loss 0.2081\n",
      "iter 2870: loss 0.0989, time 9588.19ms, mfu 1.87%\n",
      "iter 2875: loss 0.1204, time 1176.81ms, mfu 2.03%\n",
      "step 2880: train loss 0.0650, val loss 0.2136\n",
      "iter 2880: loss 0.0926, time 9611.27ms, mfu 1.87%\n",
      "iter 2885: loss 0.1067, time 1177.12ms, mfu 2.03%\n",
      "step 2890: train loss 0.0653, val loss 0.2012\n",
      "iter 2890: loss 0.0880, time 9571.35ms, mfu 1.87%\n",
      "iter 2895: loss 0.0722, time 1176.91ms, mfu 2.03%\n",
      "step 2900: train loss 0.0643, val loss 0.2167\n",
      "iter 2900: loss 0.1031, time 9555.81ms, mfu 1.87%\n",
      "iter 2905: loss 0.0875, time 1175.98ms, mfu 2.03%\n",
      "step 2910: train loss 0.0647, val loss 0.2129\n",
      "iter 2910: loss 0.1030, time 9621.62ms, mfu 1.87%\n",
      "iter 2915: loss 0.0892, time 1176.96ms, mfu 2.03%\n",
      "step 2920: train loss 0.0652, val loss 0.1962\n",
      "iter 2920: loss 0.0785, time 9725.91ms, mfu 1.87%\n",
      "iter 2925: loss 0.0955, time 1177.01ms, mfu 2.03%\n",
      "step 2930: train loss 0.0660, val loss 0.2056\n",
      "iter 2930: loss 0.1279, time 9791.94ms, mfu 1.87%\n",
      "iter 2935: loss 0.0859, time 1177.19ms, mfu 2.03%\n",
      "step 2940: train loss 0.0658, val loss 0.2052\n",
      "iter 2940: loss 0.1012, time 9708.89ms, mfu 1.87%\n",
      "iter 2945: loss 0.0716, time 1177.31ms, mfu 2.03%\n",
      "step 2950: train loss 0.0637, val loss 0.2152\n",
      "iter 2950: loss 0.0979, time 9658.12ms, mfu 1.87%\n",
      "iter 2955: loss 0.1030, time 1177.32ms, mfu 2.03%\n",
      "step 2960: train loss 0.0658, val loss 0.2019\n",
      "iter 2960: loss 0.0726, time 9686.45ms, mfu 1.87%\n",
      "iter 2965: loss 0.0763, time 1176.44ms, mfu 2.03%\n",
      "step 2970: train loss 0.0663, val loss 0.2095\n",
      "iter 2970: loss 0.1195, time 9655.04ms, mfu 1.87%\n",
      "iter 2975: loss 0.1406, time 1177.45ms, mfu 2.03%\n",
      "step 2980: train loss 0.0646, val loss 0.2096\n",
      "iter 2980: loss 0.1026, time 9686.01ms, mfu 1.87%\n",
      "iter 2985: loss 0.0934, time 1177.56ms, mfu 2.03%\n",
      "step 2990: train loss 0.0626, val loss 0.1990\n",
      "iter 2990: loss 0.0763, time 9650.39ms, mfu 1.87%\n",
      "iter 2995: loss 0.0908, time 1177.66ms, mfu 2.03%\n",
      "step 3000: train loss 0.0646, val loss 0.2207\n",
      "iter 3000: loss 0.1116, time 9679.11ms, mfu 1.87%\n",
      "iter 3005: loss 0.0688, time 1177.12ms, mfu 2.03%\n",
      "step 3010: train loss 0.0632, val loss 0.2231\n",
      "iter 3010: loss 0.0891, time 9642.74ms, mfu 1.87%\n",
      "iter 3015: loss 0.0811, time 1177.48ms, mfu 2.03%\n",
      "step 3020: train loss 0.0628, val loss 0.1968\n",
      "iter 3020: loss 0.0767, time 9592.01ms, mfu 1.87%\n",
      "iter 3025: loss 0.0840, time 1177.37ms, mfu 2.03%\n",
      "step 3030: train loss 0.0629, val loss 0.1937\n",
      "iter 3030: loss 0.0944, time 9618.64ms, mfu 1.87%\n",
      "iter 3035: loss 0.0839, time 1177.26ms, mfu 2.03%\n",
      "step 3040: train loss 0.0617, val loss 0.2051\n",
      "iter 3040: loss 0.0711, time 9625.91ms, mfu 1.87%\n",
      "iter 3045: loss 0.0917, time 1177.42ms, mfu 2.03%\n",
      "step 3050: train loss 0.0624, val loss 0.2039\n",
      "iter 3050: loss 0.0875, time 9549.37ms, mfu 1.87%\n",
      "iter 3055: loss 0.0835, time 1177.02ms, mfu 2.03%\n",
      "step 3060: train loss 0.0619, val loss 0.2021\n",
      "iter 3060: loss 0.0875, time 9525.45ms, mfu 1.87%\n",
      "iter 3065: loss 0.0839, time 1176.52ms, mfu 2.03%\n",
      "step 3070: train loss 0.0611, val loss 0.2196\n",
      "iter 3070: loss 0.0675, time 9550.76ms, mfu 1.87%\n",
      "iter 3075: loss 0.0748, time 1176.91ms, mfu 2.03%\n",
      "step 3080: train loss 0.0624, val loss 0.1985\n",
      "iter 3080: loss 0.0743, time 9527.97ms, mfu 1.87%\n",
      "iter 3085: loss 0.0910, time 1176.56ms, mfu 2.03%\n",
      "step 3090: train loss 0.0614, val loss 0.1830\n",
      "saving checkpoint to out-abc-char\n",
      "iter 3090: loss 0.0856, time 9969.72ms, mfu 1.87%\n",
      "iter 3095: loss 0.0833, time 1176.67ms, mfu 2.03%\n",
      "step 3100: train loss 0.0605, val loss 0.2001\n",
      "iter 3100: loss 0.0958, time 9666.12ms, mfu 1.87%\n",
      "iter 3105: loss 0.0864, time 1177.78ms, mfu 2.03%\n",
      "step 3110: train loss 0.0604, val loss 0.2108\n",
      "iter 3110: loss 0.1047, time 9922.03ms, mfu 1.87%\n",
      "iter 3115: loss 0.0882, time 1177.29ms, mfu 2.03%\n",
      "step 3120: train loss 0.0615, val loss 0.1967\n",
      "iter 3120: loss 0.0881, time 9625.02ms, mfu 1.87%\n",
      "iter 3125: loss 0.0760, time 1176.65ms, mfu 2.03%\n",
      "step 3130: train loss 0.0599, val loss 0.2096\n",
      "iter 3130: loss 0.0721, time 9646.94ms, mfu 1.87%\n",
      "iter 3135: loss 0.0959, time 1176.92ms, mfu 2.03%\n",
      "step 3140: train loss 0.0609, val loss 0.1942\n",
      "iter 3140: loss 0.0689, time 9658.33ms, mfu 1.87%\n",
      "iter 3145: loss 0.0870, time 1177.14ms, mfu 2.03%\n",
      "step 3150: train loss 0.0600, val loss 0.2024\n",
      "iter 3150: loss 0.0889, time 9680.64ms, mfu 1.87%\n",
      "iter 3155: loss 0.0977, time 1176.24ms, mfu 2.03%\n",
      "step 3160: train loss 0.0606, val loss 0.2320\n",
      "iter 3160: loss 0.0651, time 9673.56ms, mfu 1.87%\n",
      "iter 3165: loss 0.0877, time 1176.70ms, mfu 2.03%\n",
      "step 3170: train loss 0.0592, val loss 0.1883\n",
      "iter 3170: loss 0.0742, time 9673.64ms, mfu 1.87%\n",
      "iter 3175: loss 0.1005, time 1177.50ms, mfu 2.03%\n",
      "step 3180: train loss 0.0586, val loss 0.1944\n",
      "iter 3180: loss 0.0888, time 9688.78ms, mfu 1.87%\n",
      "iter 3185: loss 0.0734, time 1176.40ms, mfu 2.03%\n",
      "step 3190: train loss 0.0593, val loss 0.2081\n",
      "iter 3190: loss 0.0789, time 9650.57ms, mfu 1.87%\n",
      "iter 3195: loss 0.0855, time 1176.68ms, mfu 2.03%\n",
      "step 3200: train loss 0.0604, val loss 0.2122\n",
      "iter 3200: loss 0.0918, time 9586.59ms, mfu 1.87%\n",
      "iter 3205: loss 0.0847, time 1177.03ms, mfu 2.03%\n",
      "step 3210: train loss 0.0574, val loss 0.1815\n",
      "saving checkpoint to out-abc-char\n",
      "iter 3210: loss 0.0754, time 9888.20ms, mfu 1.87%\n",
      "iter 3215: loss 0.1106, time 1176.37ms, mfu 2.03%\n",
      "step 3220: train loss 0.0581, val loss 0.2074\n",
      "iter 3220: loss 0.0776, time 9624.23ms, mfu 1.87%\n",
      "iter 3225: loss 0.0821, time 1176.21ms, mfu 2.03%\n",
      "step 3230: train loss 0.0583, val loss 0.1918\n",
      "iter 3230: loss 0.0650, time 9628.34ms, mfu 1.87%\n",
      "iter 3235: loss 0.0777, time 1177.37ms, mfu 2.03%\n",
      "step 3240: train loss 0.0580, val loss 0.2003\n",
      "iter 3240: loss 0.0908, time 9596.74ms, mfu 1.87%\n",
      "iter 3245: loss 0.0808, time 1176.70ms, mfu 2.03%\n",
      "step 3250: train loss 0.0589, val loss 0.2020\n",
      "iter 3250: loss 0.0824, time 9560.39ms, mfu 1.87%\n",
      "iter 3255: loss 0.0775, time 1176.62ms, mfu 2.03%\n",
      "step 3260: train loss 0.0583, val loss 0.2020\n",
      "iter 3260: loss 0.0627, time 9556.33ms, mfu 1.87%\n",
      "iter 3265: loss 0.0629, time 1176.75ms, mfu 2.03%\n",
      "step 3270: train loss 0.0586, val loss 0.2139\n",
      "iter 3270: loss 0.0803, time 9758.42ms, mfu 1.87%\n",
      "iter 3275: loss 0.0885, time 1176.30ms, mfu 2.03%\n",
      "step 3280: train loss 0.0564, val loss 0.1885\n",
      "iter 3280: loss 0.0823, time 9797.38ms, mfu 1.87%\n",
      "iter 3285: loss 0.0696, time 1176.62ms, mfu 2.03%\n",
      "step 3290: train loss 0.0577, val loss 0.2018\n",
      "iter 3290: loss 0.0749, time 9763.01ms, mfu 1.87%\n",
      "iter 3295: loss 0.0818, time 1177.41ms, mfu 2.03%\n",
      "step 3300: train loss 0.0574, val loss 0.1861\n",
      "iter 3300: loss 0.0832, time 9737.98ms, mfu 1.87%\n",
      "iter 3305: loss 0.0803, time 1177.25ms, mfu 2.03%\n",
      "step 3310: train loss 0.0572, val loss 0.1831\n",
      "iter 3310: loss 0.0909, time 9702.43ms, mfu 1.87%\n",
      "iter 3315: loss 0.0605, time 1177.62ms, mfu 2.03%\n",
      "step 3320: train loss 0.0570, val loss 0.2070\n",
      "iter 3320: loss 0.0845, time 9703.58ms, mfu 1.87%\n",
      "iter 3325: loss 0.0777, time 1178.80ms, mfu 2.03%\n",
      "step 3330: train loss 0.0571, val loss 0.1775\n",
      "saving checkpoint to out-abc-char\n",
      "iter 3330: loss 0.0877, time 9904.16ms, mfu 1.87%\n",
      "iter 3335: loss 0.0889, time 1176.47ms, mfu 2.03%\n",
      "step 3340: train loss 0.0577, val loss 0.1975\n",
      "iter 3340: loss 0.0917, time 9640.74ms, mfu 1.87%\n",
      "iter 3345: loss 0.0701, time 1176.45ms, mfu 2.03%\n",
      "step 3350: train loss 0.0569, val loss 0.1939\n",
      "iter 3350: loss 0.0756, time 9626.68ms, mfu 1.87%\n",
      "iter 3355: loss 0.0784, time 1177.92ms, mfu 2.03%\n",
      "step 3360: train loss 0.0561, val loss 0.2026\n",
      "iter 3360: loss 0.0961, time 9775.36ms, mfu 1.87%\n",
      "iter 3365: loss 0.0714, time 1177.44ms, mfu 2.03%\n",
      "step 3370: train loss 0.0567, val loss 0.1997\n",
      "iter 3370: loss 0.0776, time 9593.94ms, mfu 1.87%\n",
      "iter 3375: loss 0.0794, time 1177.24ms, mfu 2.03%\n",
      "step 3380: train loss 0.0553, val loss 0.1840\n",
      "iter 3380: loss 0.0807, time 9570.38ms, mfu 1.87%\n",
      "iter 3385: loss 0.0882, time 1176.84ms, mfu 2.03%\n",
      "step 3390: train loss 0.0566, val loss 0.2019\n",
      "iter 3390: loss 0.0796, time 9610.94ms, mfu 1.87%\n",
      "iter 3395: loss 0.0644, time 1177.27ms, mfu 2.03%\n",
      "step 3400: train loss 0.0561, val loss 0.2019\n",
      "iter 3400: loss 0.0810, time 9607.57ms, mfu 1.87%\n",
      "iter 3405: loss 0.0877, time 1176.81ms, mfu 2.03%\n",
      "step 3410: train loss 0.0554, val loss 0.1743\n",
      "saving checkpoint to out-abc-char\n",
      "iter 3410: loss 0.0605, time 9777.98ms, mfu 1.87%\n",
      "iter 3415: loss 0.0853, time 1176.54ms, mfu 2.03%\n",
      "step 3420: train loss 0.0559, val loss 0.1926\n",
      "iter 3420: loss 0.0956, time 9522.04ms, mfu 1.87%\n",
      "iter 3425: loss 0.0779, time 1177.21ms, mfu 2.03%\n",
      "step 3430: train loss 0.0569, val loss 0.2298\n",
      "iter 3430: loss 0.0689, time 9499.18ms, mfu 1.87%\n",
      "iter 3435: loss 0.0790, time 1176.83ms, mfu 2.03%\n",
      "step 3440: train loss 0.0560, val loss 0.1871\n",
      "iter 3440: loss 0.0653, time 9510.37ms, mfu 1.87%\n",
      "iter 3445: loss 0.0866, time 1175.99ms, mfu 2.03%\n",
      "step 3450: train loss 0.0553, val loss 0.1843\n",
      "iter 3450: loss 0.0833, time 9738.15ms, mfu 1.87%\n",
      "iter 3455: loss 0.0715, time 1176.63ms, mfu 2.03%\n",
      "step 3460: train loss 0.0549, val loss 0.1973\n",
      "iter 3460: loss 0.0810, time 9823.85ms, mfu 1.87%\n",
      "iter 3465: loss 0.0676, time 1177.98ms, mfu 2.03%\n",
      "step 3470: train loss 0.0551, val loss 0.2038\n",
      "iter 3470: loss 0.1010, time 9854.04ms, mfu 1.87%\n",
      "iter 3475: loss 0.0708, time 1176.29ms, mfu 2.03%\n",
      "step 3480: train loss 0.0541, val loss 0.2014\n",
      "iter 3480: loss 0.0747, time 9677.97ms, mfu 1.87%\n",
      "iter 3485: loss 0.0745, time 1176.31ms, mfu 2.03%\n",
      "step 3490: train loss 0.0551, val loss 0.1984\n",
      "iter 3490: loss 0.0691, time 9701.56ms, mfu 1.87%\n",
      "iter 3495: loss 0.0721, time 1177.01ms, mfu 2.03%\n",
      "step 3500: train loss 0.0541, val loss 0.1854\n",
      "iter 3500: loss 0.0757, time 9699.07ms, mfu 1.87%\n",
      "iter 3505: loss 0.0715, time 1176.49ms, mfu 2.03%\n",
      "step 3510: train loss 0.0541, val loss 0.1858\n",
      "iter 3510: loss 0.0686, time 9699.78ms, mfu 1.87%\n",
      "iter 3515: loss 0.0805, time 1176.91ms, mfu 2.03%\n",
      "step 3520: train loss 0.0541, val loss 0.1995\n",
      "iter 3520: loss 0.0661, time 9649.08ms, mfu 1.87%\n",
      "iter 3525: loss 0.0793, time 1177.27ms, mfu 2.03%\n",
      "step 3530: train loss 0.0538, val loss 0.1821\n",
      "iter 3530: loss 0.0678, time 9649.71ms, mfu 1.87%\n",
      "iter 3535: loss 0.0664, time 1177.04ms, mfu 2.03%\n",
      "step 3540: train loss 0.0539, val loss 0.1928\n",
      "iter 3540: loss 0.0739, time 9636.38ms, mfu 1.87%\n",
      "iter 3545: loss 0.0742, time 1176.86ms, mfu 2.03%\n",
      "step 3550: train loss 0.0539, val loss 0.2038\n",
      "iter 3550: loss 0.0665, time 9554.67ms, mfu 1.87%\n",
      "iter 3555: loss 0.0642, time 1176.61ms, mfu 2.03%\n",
      "step 3560: train loss 0.0535, val loss 0.1949\n",
      "iter 3560: loss 0.0807, time 9569.91ms, mfu 1.87%\n",
      "iter 3565: loss 0.0757, time 1176.62ms, mfu 2.03%\n",
      "step 3570: train loss 0.0537, val loss 0.2049\n",
      "iter 3570: loss 0.0748, time 9644.88ms, mfu 1.87%\n",
      "iter 3575: loss 0.0772, time 1176.82ms, mfu 2.03%\n",
      "step 3580: train loss 0.0551, val loss 0.1762\n",
      "iter 3580: loss 0.0568, time 9580.39ms, mfu 1.87%\n",
      "iter 3585: loss 0.0720, time 1176.32ms, mfu 2.03%\n",
      "step 3590: train loss 0.0531, val loss 0.2050\n",
      "iter 3590: loss 0.0684, time 9567.38ms, mfu 1.87%\n",
      "iter 3595: loss 0.0802, time 1176.71ms, mfu 2.03%\n",
      "step 3600: train loss 0.0525, val loss 0.1773\n",
      "iter 3600: loss 0.0685, time 9577.22ms, mfu 1.87%\n",
      "iter 3605: loss 0.0674, time 1176.12ms, mfu 2.03%\n",
      "step 3610: train loss 0.0532, val loss 0.1983\n",
      "iter 3610: loss 0.0679, time 9544.12ms, mfu 1.87%\n",
      "iter 3615: loss 0.0583, time 1177.44ms, mfu 2.03%\n",
      "step 3620: train loss 0.0528, val loss 0.1837\n",
      "iter 3620: loss 0.0781, time 9611.14ms, mfu 1.87%\n",
      "iter 3625: loss 0.0637, time 1176.81ms, mfu 2.03%\n",
      "step 3630: train loss 0.0526, val loss 0.1925\n",
      "iter 3630: loss 0.0772, time 9711.55ms, mfu 1.87%\n",
      "iter 3635: loss 0.0606, time 1176.49ms, mfu 2.03%\n",
      "step 3640: train loss 0.0530, val loss 0.1986\n",
      "iter 3640: loss 0.0611, time 9800.77ms, mfu 1.87%\n",
      "iter 3645: loss 0.0641, time 1176.50ms, mfu 2.03%\n",
      "step 3650: train loss 0.0524, val loss 0.1944\n",
      "iter 3650: loss 0.0669, time 9722.16ms, mfu 1.87%\n",
      "iter 3655: loss 0.0862, time 1177.07ms, mfu 2.03%\n",
      "step 3660: train loss 0.0526, val loss 0.1879\n",
      "iter 3660: loss 0.0715, time 9692.03ms, mfu 1.87%\n",
      "iter 3665: loss 0.0795, time 1176.96ms, mfu 2.03%\n",
      "step 3670: train loss 0.0525, val loss 0.1871\n",
      "iter 3670: loss 0.0621, time 9659.69ms, mfu 1.87%\n",
      "iter 3675: loss 0.0586, time 1176.76ms, mfu 2.03%\n",
      "step 3680: train loss 0.0526, val loss 0.1955\n",
      "iter 3680: loss 0.0693, time 9716.47ms, mfu 1.87%\n",
      "iter 3685: loss 0.0717, time 1176.25ms, mfu 2.03%\n",
      "step 3690: train loss 0.0525, val loss 0.1728\n",
      "saving checkpoint to out-abc-char\n",
      "iter 3690: loss 0.0802, time 9971.37ms, mfu 1.87%\n",
      "iter 3695: loss 0.0637, time 1177.67ms, mfu 2.03%\n",
      "step 3700: train loss 0.0519, val loss 0.1923\n",
      "iter 3700: loss 0.0803, time 9642.29ms, mfu 1.87%\n",
      "iter 3705: loss 0.0558, time 1177.41ms, mfu 2.03%\n",
      "step 3710: train loss 0.0521, val loss 0.1806\n",
      "iter 3710: loss 0.0670, time 9609.58ms, mfu 1.87%\n",
      "iter 3715: loss 0.0760, time 1176.35ms, mfu 2.03%\n",
      "step 3720: train loss 0.0512, val loss 0.1875\n",
      "iter 3720: loss 0.0795, time 9560.85ms, mfu 1.87%\n",
      "iter 3725: loss 0.0728, time 1176.92ms, mfu 2.03%\n",
      "step 3730: train loss 0.0524, val loss 0.1776\n",
      "iter 3730: loss 0.0679, time 9524.81ms, mfu 1.87%\n",
      "iter 3735: loss 0.0621, time 1176.63ms, mfu 2.03%\n",
      "step 3740: train loss 0.0517, val loss 0.1900\n",
      "iter 3740: loss 0.0651, time 9649.57ms, mfu 1.87%\n",
      "iter 3745: loss 0.0662, time 1176.94ms, mfu 2.03%\n",
      "step 3750: train loss 0.0513, val loss 0.1775\n",
      "iter 3750: loss 0.0589, time 9691.89ms, mfu 1.87%\n",
      "iter 3755: loss 0.0565, time 1177.07ms, mfu 2.03%\n",
      "step 3760: train loss 0.0514, val loss 0.1829\n",
      "iter 3760: loss 0.0695, time 9584.11ms, mfu 1.87%\n",
      "iter 3765: loss 0.0736, time 1176.83ms, mfu 2.03%\n",
      "step 3770: train loss 0.0508, val loss 0.2057\n",
      "iter 3770: loss 0.0718, time 9565.14ms, mfu 1.87%\n",
      "iter 3775: loss 0.0717, time 1177.34ms, mfu 2.03%\n",
      "step 3780: train loss 0.0514, val loss 0.1870\n",
      "iter 3780: loss 0.0845, time 9573.91ms, mfu 1.87%\n",
      "iter 3785: loss 0.0585, time 1177.11ms, mfu 2.03%\n",
      "step 3790: train loss 0.0511, val loss 0.1749\n",
      "iter 3790: loss 0.0674, time 9513.46ms, mfu 1.87%\n",
      "iter 3795: loss 0.0640, time 1177.31ms, mfu 2.03%\n",
      "step 3800: train loss 0.0512, val loss 0.1881\n",
      "iter 3800: loss 0.0690, time 9759.97ms, mfu 1.87%\n",
      "iter 3805: loss 0.0506, time 1176.49ms, mfu 2.03%\n",
      "step 3810: train loss 0.0505, val loss 0.1883\n",
      "iter 3810: loss 0.0536, time 9773.72ms, mfu 1.87%\n",
      "iter 3815: loss 0.0604, time 1177.52ms, mfu 2.03%\n",
      "step 3820: train loss 0.0512, val loss 0.1887\n",
      "iter 3820: loss 0.0624, time 9748.84ms, mfu 1.87%\n",
      "iter 3825: loss 0.0741, time 1176.72ms, mfu 2.03%\n",
      "step 3830: train loss 0.0516, val loss 0.1762\n",
      "iter 3830: loss 0.0628, time 9663.29ms, mfu 1.87%\n",
      "iter 3835: loss 0.0592, time 1176.51ms, mfu 2.03%\n",
      "step 3840: train loss 0.0499, val loss 0.1785\n",
      "iter 3840: loss 0.0672, time 9594.93ms, mfu 1.87%\n",
      "iter 3845: loss 0.0698, time 1176.20ms, mfu 2.03%\n",
      "step 3850: train loss 0.0506, val loss 0.1891\n",
      "iter 3850: loss 0.0661, time 9693.94ms, mfu 1.87%\n",
      "iter 3855: loss 0.0537, time 1176.52ms, mfu 2.03%\n",
      "step 3860: train loss 0.0501, val loss 0.2038\n",
      "iter 3860: loss 0.0729, time 9734.99ms, mfu 1.87%\n",
      "iter 3865: loss 0.0723, time 1176.33ms, mfu 2.03%\n",
      "step 3870: train loss 0.0505, val loss 0.1912\n",
      "iter 3870: loss 0.0659, time 9682.73ms, mfu 1.87%\n",
      "iter 3875: loss 0.0701, time 1176.16ms, mfu 2.03%\n",
      "step 3880: train loss 0.0496, val loss 0.1775\n",
      "iter 3880: loss 0.0669, time 9662.74ms, mfu 1.87%\n",
      "iter 3885: loss 0.0687, time 1176.87ms, mfu 2.03%\n",
      "step 3890: train loss 0.0500, val loss 0.1624\n",
      "saving checkpoint to out-abc-char\n",
      "iter 3890: loss 0.0604, time 9866.46ms, mfu 1.87%\n",
      "iter 3895: loss 0.0565, time 1177.50ms, mfu 2.03%\n",
      "step 3900: train loss 0.0498, val loss 0.1912\n",
      "iter 3900: loss 0.0704, time 9612.34ms, mfu 1.87%\n",
      "iter 3905: loss 0.0623, time 1176.01ms, mfu 2.03%\n",
      "step 3910: train loss 0.0501, val loss 0.1890\n",
      "iter 3910: loss 0.0545, time 9530.72ms, mfu 1.87%\n",
      "iter 3915: loss 0.0534, time 1177.11ms, mfu 2.03%\n",
      "step 3920: train loss 0.0500, val loss 0.1955\n",
      "iter 3920: loss 0.0658, time 9657.65ms, mfu 1.87%\n",
      "iter 3925: loss 0.0621, time 1176.22ms, mfu 2.03%\n",
      "step 3930: train loss 0.0497, val loss 0.1715\n",
      "iter 3930: loss 0.0702, time 9633.27ms, mfu 1.87%\n",
      "iter 3935: loss 0.0727, time 1177.59ms, mfu 2.03%\n",
      "step 3940: train loss 0.0497, val loss 0.1840\n",
      "iter 3940: loss 0.0705, time 9676.04ms, mfu 1.87%\n",
      "iter 3945: loss 0.0576, time 1176.00ms, mfu 2.03%\n",
      "step 3950: train loss 0.0493, val loss 0.1847\n",
      "iter 3950: loss 0.0592, time 9506.21ms, mfu 1.87%\n",
      "iter 3955: loss 0.0517, time 1176.63ms, mfu 2.03%\n",
      "step 3960: train loss 0.0487, val loss 0.1707\n",
      "iter 3960: loss 0.0561, time 9519.35ms, mfu 1.87%\n",
      "iter 3965: loss 0.0595, time 1176.95ms, mfu 2.03%\n",
      "step 3970: train loss 0.0487, val loss 0.1721\n",
      "iter 3970: loss 0.0634, time 9548.49ms, mfu 1.87%\n",
      "iter 3975: loss 0.0590, time 1176.72ms, mfu 2.03%\n",
      "step 3980: train loss 0.0483, val loss 0.1840\n",
      "iter 3980: loss 0.0627, time 9813.05ms, mfu 1.87%\n",
      "iter 3985: loss 0.0525, time 1176.31ms, mfu 2.03%\n",
      "step 3990: train loss 0.0488, val loss 0.1956\n",
      "iter 3990: loss 0.0629, time 9841.01ms, mfu 1.87%\n",
      "iter 3995: loss 0.0800, time 1176.60ms, mfu 2.03%\n",
      "step 4000: train loss 0.0489, val loss 0.1799\n",
      "iter 4000: loss 0.0573, time 9895.50ms, mfu 1.87%\n",
      "iter 4005: loss 0.0763, time 1177.35ms, mfu 2.03%\n",
      "step 4010: train loss 0.0494, val loss 0.1734\n",
      "iter 4010: loss 0.0609, time 9629.21ms, mfu 1.87%\n",
      "iter 4015: loss 0.0646, time 1176.86ms, mfu 2.03%\n",
      "step 4020: train loss 0.0492, val loss 0.1830\n",
      "iter 4020: loss 0.0585, time 9649.12ms, mfu 1.87%\n",
      "iter 4025: loss 0.0570, time 1176.25ms, mfu 2.03%\n",
      "step 4030: train loss 0.0487, val loss 0.1663\n",
      "iter 4030: loss 0.0722, time 9647.10ms, mfu 1.87%\n",
      "iter 4035: loss 0.0671, time 1176.34ms, mfu 2.03%\n",
      "step 4040: train loss 0.0482, val loss 0.1718\n",
      "iter 4040: loss 0.0808, time 9683.68ms, mfu 1.87%\n",
      "iter 4045: loss 0.0505, time 1177.15ms, mfu 2.03%\n",
      "step 4050: train loss 0.0484, val loss 0.1727\n",
      "iter 4050: loss 0.0581, time 9660.28ms, mfu 1.87%\n",
      "iter 4055: loss 0.0641, time 1176.23ms, mfu 2.03%\n",
      "step 4060: train loss 0.0485, val loss 0.1900\n",
      "iter 4060: loss 0.0657, time 9660.60ms, mfu 1.87%\n",
      "iter 4065: loss 0.0460, time 1176.16ms, mfu 2.03%\n",
      "step 4070: train loss 0.0486, val loss 0.1783\n",
      "iter 4070: loss 0.0495, time 9611.06ms, mfu 1.87%\n",
      "iter 4075: loss 0.0735, time 1176.88ms, mfu 2.03%\n",
      "step 4080: train loss 0.0479, val loss 0.1659\n",
      "iter 4080: loss 0.0695, time 9572.33ms, mfu 1.87%\n",
      "iter 4085: loss 0.0666, time 1176.79ms, mfu 2.03%\n",
      "step 4090: train loss 0.0476, val loss 0.1677\n",
      "iter 4090: loss 0.0523, time 9572.86ms, mfu 1.87%\n",
      "iter 4095: loss 0.0673, time 1178.03ms, mfu 2.03%\n",
      "step 4100: train loss 0.0480, val loss 0.1539\n",
      "saving checkpoint to out-abc-char\n",
      "iter 4100: loss 0.0619, time 9917.13ms, mfu 1.87%\n",
      "iter 4105: loss 0.0621, time 1177.30ms, mfu 2.03%\n",
      "step 4110: train loss 0.0485, val loss 0.1633\n",
      "iter 4110: loss 0.0586, time 9620.66ms, mfu 1.87%\n",
      "iter 4115: loss 0.0639, time 1176.72ms, mfu 2.03%\n",
      "step 4120: train loss 0.0481, val loss 0.1752\n",
      "iter 4120: loss 0.0693, time 9668.49ms, mfu 1.87%\n",
      "iter 4125: loss 0.0648, time 1177.94ms, mfu 2.03%\n",
      "step 4130: train loss 0.0479, val loss 0.1847\n",
      "iter 4130: loss 0.0545, time 9560.00ms, mfu 1.87%\n",
      "iter 4135: loss 0.0669, time 1177.19ms, mfu 2.03%\n",
      "step 4140: train loss 0.0472, val loss 0.1673\n",
      "iter 4140: loss 0.0671, time 9535.57ms, mfu 1.87%\n",
      "iter 4145: loss 0.0496, time 1177.55ms, mfu 2.03%\n",
      "step 4150: train loss 0.0474, val loss 0.1765\n",
      "iter 4150: loss 0.0507, time 9562.58ms, mfu 1.87%\n",
      "iter 4155: loss 0.0622, time 1177.07ms, mfu 2.03%\n",
      "step 4160: train loss 0.0479, val loss 0.1894\n",
      "iter 4160: loss 0.0662, time 9751.09ms, mfu 1.87%\n",
      "iter 4165: loss 0.0621, time 1177.14ms, mfu 2.03%\n",
      "step 4170: train loss 0.0478, val loss 0.1554\n",
      "iter 4170: loss 0.0682, time 9765.78ms, mfu 1.87%\n",
      "iter 4175: loss 0.0518, time 1176.78ms, mfu 2.03%\n",
      "step 4180: train loss 0.0473, val loss 0.1713\n",
      "iter 4180: loss 0.0677, time 9837.90ms, mfu 1.87%\n",
      "iter 4185: loss 0.0629, time 1177.72ms, mfu 2.03%\n",
      "step 4190: train loss 0.0468, val loss 0.1691\n",
      "iter 4190: loss 0.0553, time 9665.60ms, mfu 1.87%\n",
      "iter 4195: loss 0.0603, time 1177.45ms, mfu 2.03%\n",
      "step 4200: train loss 0.0469, val loss 0.1645\n",
      "iter 4200: loss 0.0524, time 9661.41ms, mfu 1.87%\n",
      "iter 4205: loss 0.0595, time 1176.65ms, mfu 2.03%\n",
      "step 4210: train loss 0.0476, val loss 0.1937\n",
      "iter 4210: loss 0.0609, time 9654.95ms, mfu 1.87%\n",
      "iter 4215: loss 0.0478, time 1176.83ms, mfu 2.03%\n",
      "step 4220: train loss 0.0475, val loss 0.1737\n",
      "iter 4220: loss 0.0547, time 9709.04ms, mfu 1.87%\n",
      "iter 4225: loss 0.0576, time 1176.20ms, mfu 2.03%\n",
      "step 4230: train loss 0.0477, val loss 0.1786\n",
      "iter 4230: loss 0.0648, time 9670.25ms, mfu 1.87%\n",
      "iter 4235: loss 0.0541, time 1177.47ms, mfu 2.03%\n",
      "step 4240: train loss 0.0468, val loss 0.1785\n",
      "iter 4240: loss 0.0603, time 9657.64ms, mfu 1.87%\n",
      "iter 4245: loss 0.0553, time 1177.67ms, mfu 2.03%\n",
      "step 4250: train loss 0.0475, val loss 0.1622\n",
      "iter 4250: loss 0.0680, time 9613.94ms, mfu 1.87%\n",
      "iter 4255: loss 0.0717, time 1176.38ms, mfu 2.03%\n",
      "step 4260: train loss 0.0473, val loss 0.1849\n",
      "iter 4260: loss 0.0459, time 9617.25ms, mfu 1.87%\n",
      "iter 4265: loss 0.0653, time 1176.26ms, mfu 2.03%\n",
      "step 4270: train loss 0.0466, val loss 0.1767\n",
      "iter 4270: loss 0.0535, time 9544.95ms, mfu 1.87%\n",
      "iter 4275: loss 0.0653, time 1176.45ms, mfu 2.03%\n",
      "step 4280: train loss 0.0468, val loss 0.1424\n",
      "saving checkpoint to out-abc-char\n",
      "iter 4280: loss 0.0616, time 9843.02ms, mfu 1.87%\n",
      "iter 4285: loss 0.0663, time 1176.87ms, mfu 2.03%\n",
      "step 4290: train loss 0.0464, val loss 0.1646\n",
      "iter 4290: loss 0.0568, time 9592.96ms, mfu 1.87%\n",
      "iter 4295: loss 0.0675, time 1176.43ms, mfu 2.03%\n",
      "step 4300: train loss 0.0467, val loss 0.1818\n",
      "iter 4300: loss 0.0634, time 9575.98ms, mfu 1.87%\n",
      "iter 4305: loss 0.0547, time 1177.03ms, mfu 2.03%\n",
      "step 4310: train loss 0.0465, val loss 0.1698\n",
      "iter 4310: loss 0.0535, time 9567.02ms, mfu 1.87%\n",
      "iter 4315: loss 0.0486, time 1176.86ms, mfu 2.03%\n",
      "step 4320: train loss 0.0461, val loss 0.1697\n",
      "iter 4320: loss 0.0610, time 9530.27ms, mfu 1.87%\n",
      "iter 4325: loss 0.0644, time 1176.33ms, mfu 2.03%\n",
      "step 4330: train loss 0.0459, val loss 0.1732\n",
      "iter 4330: loss 0.0522, time 9531.65ms, mfu 1.87%\n",
      "iter 4335: loss 0.0590, time 1176.53ms, mfu 2.03%\n",
      "step 4340: train loss 0.0458, val loss 0.1772\n",
      "iter 4340: loss 0.0544, time 9766.22ms, mfu 1.87%\n",
      "iter 4345: loss 0.0590, time 1176.48ms, mfu 2.03%\n",
      "step 4350: train loss 0.0457, val loss 0.1839\n",
      "iter 4350: loss 0.0519, time 9815.18ms, mfu 1.87%\n",
      "iter 4355: loss 0.0580, time 1177.09ms, mfu 2.03%\n",
      "step 4360: train loss 0.0464, val loss 0.1742\n",
      "iter 4360: loss 0.0660, time 9741.94ms, mfu 1.87%\n",
      "iter 4365: loss 0.0595, time 1176.87ms, mfu 2.03%\n",
      "step 4370: train loss 0.0466, val loss 0.1718\n",
      "iter 4370: loss 0.0705, time 9643.98ms, mfu 1.87%\n",
      "iter 4375: loss 0.0538, time 1176.59ms, mfu 2.03%\n",
      "step 4380: train loss 0.0463, val loss 0.1738\n",
      "iter 4380: loss 0.0519, time 9710.50ms, mfu 1.87%\n",
      "iter 4385: loss 0.0712, time 1176.72ms, mfu 2.03%\n",
      "step 4390: train loss 0.0462, val loss 0.1675\n",
      "iter 4390: loss 0.0640, time 9695.51ms, mfu 1.87%\n",
      "iter 4395: loss 0.0505, time 1176.42ms, mfu 2.03%\n",
      "step 4400: train loss 0.0457, val loss 0.1867\n",
      "iter 4400: loss 0.0604, time 9681.06ms, mfu 1.87%\n",
      "iter 4405: loss 0.0530, time 1176.91ms, mfu 2.03%\n",
      "step 4410: train loss 0.0459, val loss 0.1785\n",
      "iter 4410: loss 0.0644, time 9669.67ms, mfu 1.87%\n",
      "iter 4415: loss 0.0519, time 1176.76ms, mfu 2.03%\n",
      "step 4420: train loss 0.0453, val loss 0.1775\n",
      "iter 4420: loss 0.0713, time 9653.10ms, mfu 1.87%\n",
      "iter 4425: loss 0.0583, time 1177.97ms, mfu 2.03%\n",
      "step 4430: train loss 0.0455, val loss 0.1772\n",
      "iter 4430: loss 0.0645, time 9608.89ms, mfu 1.87%\n",
      "iter 4435: loss 0.0469, time 1177.12ms, mfu 2.03%\n",
      "step 4440: train loss 0.0454, val loss 0.1686\n",
      "iter 4440: loss 0.0490, time 9587.70ms, mfu 1.87%\n",
      "iter 4445: loss 0.0456, time 1176.72ms, mfu 2.03%\n",
      "step 4450: train loss 0.0457, val loss 0.1829\n",
      "iter 4450: loss 0.0564, time 9590.39ms, mfu 1.87%\n",
      "iter 4455: loss 0.0502, time 1176.81ms, mfu 2.03%\n",
      "step 4460: train loss 0.0452, val loss 0.1750\n",
      "iter 4460: loss 0.0563, time 9615.44ms, mfu 1.87%\n",
      "iter 4465: loss 0.0481, time 1176.88ms, mfu 2.03%\n",
      "step 4470: train loss 0.0454, val loss 0.1839\n",
      "iter 4470: loss 0.0625, time 9591.93ms, mfu 1.87%\n",
      "iter 4475: loss 0.0494, time 1176.08ms, mfu 2.03%\n",
      "step 4480: train loss 0.0453, val loss 0.1932\n",
      "iter 4480: loss 0.0569, time 9563.02ms, mfu 1.87%\n",
      "iter 4485: loss 0.0623, time 1177.75ms, mfu 2.03%\n",
      "step 4490: train loss 0.0453, val loss 0.1552\n",
      "iter 4490: loss 0.0574, time 9547.09ms, mfu 1.87%\n",
      "iter 4495: loss 0.0534, time 1177.69ms, mfu 2.03%\n",
      "step 4500: train loss 0.0450, val loss 0.1627\n",
      "iter 4500: loss 0.0574, time 9589.58ms, mfu 1.87%\n",
      "iter 4505: loss 0.0515, time 1177.11ms, mfu 2.03%\n",
      "step 4510: train loss 0.0448, val loss 0.1909\n",
      "iter 4510: loss 0.0564, time 9773.42ms, mfu 1.87%\n",
      "iter 4515: loss 0.0610, time 1176.94ms, mfu 2.03%\n",
      "step 4520: train loss 0.0451, val loss 0.1727\n",
      "iter 4520: loss 0.0653, time 9753.21ms, mfu 1.87%\n",
      "iter 4525: loss 0.0494, time 1177.07ms, mfu 2.03%\n",
      "step 4530: train loss 0.0447, val loss 0.1840\n",
      "iter 4530: loss 0.0521, time 9748.16ms, mfu 1.87%\n",
      "iter 4535: loss 0.0715, time 1176.85ms, mfu 2.03%\n",
      "step 4540: train loss 0.0447, val loss 0.1784\n",
      "iter 4540: loss 0.0472, time 9699.34ms, mfu 1.87%\n",
      "iter 4545: loss 0.0523, time 1176.72ms, mfu 2.03%\n",
      "step 4550: train loss 0.0449, val loss 0.1553\n",
      "iter 4550: loss 0.0594, time 9600.13ms, mfu 1.87%\n",
      "iter 4555: loss 0.0615, time 1176.84ms, mfu 2.03%\n",
      "step 4560: train loss 0.0447, val loss 0.1690\n",
      "iter 4560: loss 0.0546, time 9732.36ms, mfu 1.87%\n",
      "iter 4565: loss 0.0659, time 1177.29ms, mfu 2.03%\n",
      "step 4570: train loss 0.0440, val loss 0.1501\n",
      "iter 4570: loss 0.0529, time 9690.40ms, mfu 1.87%\n",
      "iter 4575: loss 0.0534, time 1177.11ms, mfu 2.03%\n",
      "step 4580: train loss 0.0450, val loss 0.1705\n",
      "iter 4580: loss 0.0586, time 9694.00ms, mfu 1.87%\n",
      "iter 4585: loss 0.0643, time 1176.79ms, mfu 2.03%\n",
      "step 4590: train loss 0.0442, val loss 0.1675\n",
      "iter 4590: loss 0.0565, time 9628.64ms, mfu 1.87%\n",
      "iter 4595: loss 0.0469, time 1177.95ms, mfu 2.03%\n",
      "step 4600: train loss 0.0442, val loss 0.1913\n",
      "iter 4600: loss 0.0506, time 9639.51ms, mfu 1.87%\n",
      "iter 4605: loss 0.0561, time 1177.94ms, mfu 2.03%\n",
      "step 4610: train loss 0.0440, val loss 0.1563\n",
      "iter 4610: loss 0.0572, time 9650.08ms, mfu 1.87%\n",
      "iter 4615: loss 0.0559, time 1177.56ms, mfu 2.03%\n",
      "step 4620: train loss 0.0445, val loss 0.1550\n",
      "iter 4620: loss 0.0531, time 9611.41ms, mfu 1.87%\n",
      "iter 4625: loss 0.0585, time 1178.96ms, mfu 2.03%\n",
      "step 4630: train loss 0.0441, val loss 0.1600\n",
      "iter 4630: loss 0.0466, time 9630.71ms, mfu 1.87%\n",
      "iter 4635: loss 0.0643, time 1177.63ms, mfu 2.03%\n",
      "step 4640: train loss 0.0443, val loss 0.1641\n",
      "iter 4640: loss 0.0508, time 9673.96ms, mfu 1.87%\n",
      "iter 4645: loss 0.0504, time 1176.81ms, mfu 2.03%\n",
      "step 4650: train loss 0.0440, val loss 0.1619\n",
      "iter 4650: loss 0.0573, time 9649.10ms, mfu 1.87%\n",
      "iter 4655: loss 0.0497, time 1177.20ms, mfu 2.03%\n",
      "step 4660: train loss 0.0434, val loss 0.1476\n",
      "iter 4660: loss 0.0597, time 9578.37ms, mfu 1.87%\n",
      "iter 4665: loss 0.0461, time 1177.15ms, mfu 2.03%\n",
      "step 4670: train loss 0.0439, val loss 0.1683\n",
      "iter 4670: loss 0.0672, time 9584.56ms, mfu 1.87%\n",
      "iter 4675: loss 0.0623, time 1176.85ms, mfu 2.03%\n",
      "step 4680: train loss 0.0439, val loss 0.1660\n",
      "iter 4680: loss 0.0535, time 9514.52ms, mfu 1.87%\n",
      "iter 4685: loss 0.0510, time 1176.56ms, mfu 2.03%\n",
      "step 4690: train loss 0.0439, val loss 0.1525\n",
      "iter 4690: loss 0.0542, time 9752.05ms, mfu 1.87%\n",
      "iter 4695: loss 0.0625, time 1176.78ms, mfu 2.03%\n",
      "step 4700: train loss 0.0438, val loss 0.1668\n",
      "iter 4700: loss 0.0482, time 9840.31ms, mfu 1.87%\n",
      "iter 4705: loss 0.0634, time 1176.42ms, mfu 2.03%\n",
      "step 4710: train loss 0.0438, val loss 0.1648\n",
      "iter 4710: loss 0.0594, time 9783.93ms, mfu 1.87%\n",
      "iter 4715: loss 0.0649, time 1176.61ms, mfu 2.03%\n",
      "step 4720: train loss 0.0442, val loss 0.1643\n",
      "iter 4720: loss 0.0556, time 9625.40ms, mfu 1.87%\n",
      "iter 4725: loss 0.0414, time 1176.98ms, mfu 2.03%\n",
      "step 4730: train loss 0.0440, val loss 0.1662\n",
      "iter 4730: loss 0.0661, time 9655.83ms, mfu 1.87%\n",
      "iter 4735: loss 0.0566, time 1177.08ms, mfu 2.03%\n",
      "step 4740: train loss 0.0432, val loss 0.1741\n",
      "iter 4740: loss 0.0452, time 9656.64ms, mfu 1.87%\n",
      "iter 4745: loss 0.0534, time 1177.00ms, mfu 2.03%\n",
      "step 4750: train loss 0.0434, val loss 0.1804\n",
      "iter 4750: loss 0.0634, time 9661.20ms, mfu 1.87%\n",
      "iter 4755: loss 0.0494, time 1176.65ms, mfu 2.03%\n",
      "step 4760: train loss 0.0434, val loss 0.1931\n",
      "iter 4760: loss 0.0458, time 9647.93ms, mfu 1.87%\n",
      "iter 4765: loss 0.0589, time 1177.00ms, mfu 2.03%\n",
      "step 4770: train loss 0.0430, val loss 0.1618\n",
      "iter 4770: loss 0.0562, time 9643.94ms, mfu 1.87%\n",
      "iter 4775: loss 0.0525, time 1176.50ms, mfu 2.03%\n",
      "step 4780: train loss 0.0430, val loss 0.1608\n",
      "iter 4780: loss 0.0483, time 9651.60ms, mfu 1.87%\n",
      "iter 4785: loss 0.0481, time 1177.00ms, mfu 2.03%\n",
      "step 4790: train loss 0.0433, val loss 0.1638\n",
      "iter 4790: loss 0.0551, time 9631.66ms, mfu 1.87%\n",
      "iter 4795: loss 0.0684, time 1177.85ms, mfu 2.03%\n",
      "step 4800: train loss 0.0436, val loss 0.1645\n",
      "iter 4800: loss 0.0559, time 9611.44ms, mfu 1.87%\n",
      "iter 4805: loss 0.0630, time 1176.67ms, mfu 2.03%\n",
      "step 4810: train loss 0.0427, val loss 0.1714\n",
      "iter 4810: loss 0.0485, time 9608.44ms, mfu 1.87%\n",
      "iter 4815: loss 0.0571, time 1176.58ms, mfu 2.03%\n",
      "step 4820: train loss 0.0428, val loss 0.1589\n",
      "iter 4820: loss 0.0419, time 9663.20ms, mfu 1.87%\n",
      "iter 4825: loss 0.0666, time 1176.39ms, mfu 2.03%\n",
      "step 4830: train loss 0.0429, val loss 0.1589\n",
      "iter 4830: loss 0.0498, time 9633.89ms, mfu 1.87%\n",
      "iter 4835: loss 0.0519, time 1177.38ms, mfu 2.03%\n",
      "step 4840: train loss 0.0429, val loss 0.1601\n",
      "iter 4840: loss 0.0604, time 9556.37ms, mfu 1.87%\n",
      "iter 4845: loss 0.0489, time 1177.28ms, mfu 2.03%\n",
      "step 4850: train loss 0.0428, val loss 0.1580\n",
      "iter 4850: loss 0.0514, time 9587.51ms, mfu 1.87%\n",
      "iter 4855: loss 0.0512, time 1177.72ms, mfu 2.03%\n",
      "step 4860: train loss 0.0424, val loss 0.1604\n",
      "iter 4860: loss 0.0697, time 9546.11ms, mfu 1.87%\n",
      "iter 4865: loss 0.0503, time 1176.74ms, mfu 2.03%\n",
      "step 4870: train loss 0.0426, val loss 0.1549\n",
      "iter 4870: loss 0.0441, time 9702.44ms, mfu 1.87%\n",
      "iter 4875: loss 0.0546, time 1176.94ms, mfu 2.03%\n",
      "step 4880: train loss 0.0425, val loss 0.1513\n",
      "iter 4880: loss 0.0528, time 9838.33ms, mfu 1.87%\n",
      "iter 4885: loss 0.0547, time 1176.72ms, mfu 2.03%\n",
      "step 4890: train loss 0.0427, val loss 0.1769\n",
      "iter 4890: loss 0.0476, time 9734.33ms, mfu 1.87%\n",
      "iter 4895: loss 0.0482, time 1176.62ms, mfu 2.03%\n",
      "step 4900: train loss 0.0428, val loss 0.1680\n",
      "iter 4900: loss 0.0605, time 9656.76ms, mfu 1.87%\n",
      "iter 4905: loss 0.0604, time 1176.87ms, mfu 2.03%\n",
      "step 4910: train loss 0.0425, val loss 0.1627\n",
      "iter 4910: loss 0.0582, time 9723.82ms, mfu 1.87%\n",
      "iter 4915: loss 0.0660, time 1177.36ms, mfu 2.03%\n",
      "step 4920: train loss 0.0427, val loss 0.1648\n",
      "iter 4920: loss 0.0486, time 9736.01ms, mfu 1.87%\n",
      "iter 4925: loss 0.0514, time 1176.89ms, mfu 2.03%\n",
      "step 4930: train loss 0.0424, val loss 0.1603\n",
      "iter 4930: loss 0.0444, time 9680.53ms, mfu 1.87%\n",
      "iter 4935: loss 0.0544, time 1176.98ms, mfu 2.03%\n",
      "step 4940: train loss 0.0427, val loss 0.1609\n",
      "iter 4940: loss 0.0431, time 9651.32ms, mfu 1.87%\n",
      "iter 4945: loss 0.0543, time 1177.34ms, mfu 2.03%\n",
      "step 4950: train loss 0.0422, val loss 0.1653\n",
      "iter 4950: loss 0.0540, time 9666.05ms, mfu 1.87%\n",
      "iter 4955: loss 0.0527, time 1176.62ms, mfu 2.03%\n",
      "step 4960: train loss 0.0423, val loss 0.1615\n",
      "iter 4960: loss 0.0567, time 9657.73ms, mfu 1.87%\n",
      "iter 4965: loss 0.0510, time 1176.86ms, mfu 2.03%\n",
      "step 4970: train loss 0.0424, val loss 0.1522\n",
      "iter 4970: loss 0.0586, time 9565.80ms, mfu 1.87%\n",
      "iter 4975: loss 0.0463, time 1177.20ms, mfu 2.03%\n",
      "step 4980: train loss 0.0428, val loss 0.1647\n",
      "iter 4980: loss 0.0697, time 9572.52ms, mfu 1.87%\n",
      "iter 4985: loss 0.0544, time 1177.26ms, mfu 2.03%\n",
      "step 4990: train loss 0.0416, val loss 0.1490\n",
      "iter 4990: loss 0.0488, time 9673.88ms, mfu 1.87%\n",
      "iter 4995: loss 0.0559, time 1177.82ms, mfu 2.03%\n",
      "step 5000: train loss 0.0421, val loss 0.1734\n",
      "iter 5000: loss 0.0506, time 9648.16ms, mfu 1.87%\n",
      "iter 5005: loss 0.0466, time 1177.66ms, mfu 2.03%\n",
      "step 5010: train loss 0.0422, val loss 0.1647\n",
      "iter 5010: loss 0.0471, time 9593.38ms, mfu 1.87%\n",
      "iter 5015: loss 0.0561, time 1177.84ms, mfu 2.03%\n",
      "step 5020: train loss 0.0422, val loss 0.1650\n",
      "iter 5020: loss 0.0619, time 9606.51ms, mfu 1.87%\n",
      "iter 5025: loss 0.0594, time 1177.24ms, mfu 2.03%\n",
      "step 5030: train loss 0.0420, val loss 0.1681\n",
      "iter 5030: loss 0.0514, time 9572.26ms, mfu 1.87%\n",
      "iter 5035: loss 0.0516, time 1215.73ms, mfu 2.02%\n",
      "step 5040: train loss 0.0417, val loss 0.1686\n",
      "iter 5040: loss 0.0518, time 10096.20ms, mfu 1.86%\n",
      "iter 5045: loss 0.0498, time 1237.23ms, mfu 2.00%\n",
      "step 5050: train loss 0.0422, val loss 0.1611\n",
      "iter 5050: loss 0.0561, time 10133.44ms, mfu 1.84%\n",
      "iter 5055: loss 0.0496, time 1203.27ms, mfu 2.00%\n",
      "step 5060: train loss 0.0416, val loss 0.1555\n",
      "iter 5060: loss 0.0592, time 10031.36ms, mfu 1.84%\n",
      "iter 5065: loss 0.0512, time 1203.98ms, mfu 2.00%\n",
      "step 5070: train loss 0.0418, val loss 0.1674\n",
      "iter 5070: loss 0.0527, time 10005.25ms, mfu 1.84%\n",
      "iter 5075: loss 0.0462, time 1204.33ms, mfu 1.99%\n",
      "step 5080: train loss 0.0420, val loss 0.1743\n",
      "iter 5080: loss 0.0520, time 9945.34ms, mfu 1.84%\n",
      "iter 5085: loss 0.0485, time 1185.65ms, mfu 2.00%\n",
      "step 5090: train loss 0.0419, val loss 0.1734\n",
      "iter 5090: loss 0.0420, time 9775.12ms, mfu 1.84%\n",
      "iter 5095: loss 0.0561, time 1178.41ms, mfu 2.00%\n",
      "step 5100: train loss 0.0417, val loss 0.1519\n",
      "iter 5100: loss 0.0364, time 10030.60ms, mfu 1.84%\n",
      "iter 5105: loss 0.0512, time 1200.63ms, mfu 2.00%\n",
      "step 5110: train loss 0.0419, val loss 0.1551\n",
      "iter 5110: loss 0.0452, time 9935.84ms, mfu 1.84%\n",
      "iter 5115: loss 0.0494, time 1197.74ms, mfu 2.00%\n",
      "step 5120: train loss 0.0416, val loss 0.1674\n",
      "iter 5120: loss 0.0536, time 9971.38ms, mfu 1.84%\n",
      "iter 5125: loss 0.0443, time 1193.91ms, mfu 2.00%\n",
      "step 5130: train loss 0.0414, val loss 0.1650\n",
      "iter 5130: loss 0.0527, time 9768.56ms, mfu 1.84%\n",
      "iter 5135: loss 0.0558, time 1193.72ms, mfu 2.00%\n",
      "step 5140: train loss 0.0411, val loss 0.1568\n",
      "iter 5140: loss 0.0495, time 9791.47ms, mfu 1.84%\n",
      "iter 5145: loss 0.0511, time 1194.16ms, mfu 2.00%\n",
      "step 5150: train loss 0.0411, val loss 0.1426\n",
      "iter 5150: loss 0.0547, time 9768.63ms, mfu 1.84%\n",
      "iter 5155: loss 0.0554, time 1223.81ms, mfu 1.99%\n",
      "step 5160: train loss 0.0419, val loss 0.1572\n",
      "iter 5160: loss 0.0431, time 9949.74ms, mfu 1.83%\n",
      "iter 5165: loss 0.0592, time 1217.09ms, mfu 1.99%\n",
      "step 5170: train loss 0.0412, val loss 0.1592\n",
      "iter 5170: loss 0.0510, time 10014.81ms, mfu 1.83%\n",
      "iter 5175: loss 0.0524, time 1216.60ms, mfu 1.98%\n",
      "step 5180: train loss 0.0419, val loss 0.1594\n",
      "iter 5180: loss 0.0546, time 9917.79ms, mfu 1.83%\n",
      "iter 5185: loss 0.0490, time 1221.57ms, mfu 1.98%\n",
      "step 5190: train loss 0.0418, val loss 0.1540\n",
      "iter 5190: loss 0.0658, time 9923.33ms, mfu 1.82%\n",
      "iter 5195: loss 0.0541, time 1223.93ms, mfu 1.97%\n",
      "step 5200: train loss 0.0411, val loss 0.1493\n",
      "iter 5200: loss 0.0402, time 9979.03ms, mfu 1.82%\n",
      "iter 5205: loss 0.0460, time 1221.65ms, mfu 1.97%\n",
      "step 5210: train loss 0.0411, val loss 0.1615\n",
      "iter 5210: loss 0.0472, time 9972.17ms, mfu 1.81%\n",
      "iter 5215: loss 0.0617, time 1223.34ms, mfu 1.97%\n",
      "step 5220: train loss 0.0413, val loss 0.1522\n",
      "iter 5220: loss 0.0462, time 10100.75ms, mfu 1.81%\n",
      "iter 5225: loss 0.0496, time 1223.66ms, mfu 1.96%\n",
      "step 5230: train loss 0.0412, val loss 0.1509\n",
      "iter 5230: loss 0.0526, time 10280.90ms, mfu 1.81%\n",
      "iter 5235: loss 0.0536, time 1215.04ms, mfu 1.96%\n",
      "step 5240: train loss 0.0406, val loss 0.1597\n",
      "iter 5240: loss 0.0517, time 10049.74ms, mfu 1.81%\n",
      "iter 5245: loss 0.0501, time 1215.04ms, mfu 1.96%\n",
      "step 5250: train loss 0.0410, val loss 0.1586\n",
      "iter 5250: loss 0.0512, time 10019.72ms, mfu 1.81%\n",
      "iter 5255: loss 0.0588, time 1215.82ms, mfu 1.96%\n",
      "step 5260: train loss 0.0408, val loss 0.1637\n",
      "iter 5260: loss 0.0491, time 9987.15ms, mfu 1.81%\n",
      "iter 5265: loss 0.0382, time 1214.37ms, mfu 1.97%\n",
      "step 5270: train loss 0.0409, val loss 0.1621\n",
      "iter 5270: loss 0.0483, time 10052.90ms, mfu 1.81%\n",
      "iter 5275: loss 0.0491, time 1230.23ms, mfu 1.96%\n",
      "step 5280: train loss 0.0408, val loss 0.1574\n",
      "iter 5280: loss 0.0521, time 10123.55ms, mfu 1.81%\n",
      "iter 5285: loss 0.0549, time 1207.98ms, mfu 1.96%\n",
      "step 5290: train loss 0.0400, val loss 0.1641\n",
      "iter 5290: loss 0.0455, time 10078.34ms, mfu 1.81%\n",
      "iter 5295: loss 0.0586, time 1225.72ms, mfu 1.96%\n",
      "step 5300: train loss 0.0408, val loss 0.1622\n",
      "iter 5300: loss 0.0434, time 10106.45ms, mfu 1.81%\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 289, in <module>\n",
      "    logits, loss = model(X, Y)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_dynamo/eval_frame.py\", line 82, in forward\n",
      "    return self.dynamo_ctx(self._orig_mod.forward)(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_dynamo/eval_frame.py\", line 209, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/pt-env/notebooks/nanoGPT/model.py\", line 188, in forward\n",
      "    x = block(x)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "  File \"/pt-env/notebooks/nanoGPT/model.py\", line 111, in forward\n",
      "    x = x + self.attn(self.ln_1(x))\n",
      "  File \"/pt-env/notebooks/nanoGPT/model.py\", line 111, in <graph break in forward>\n",
      "    x = x + self.attn(self.ln_1(x))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_dynamo/eval_frame.py\", line 209, in _fn\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 2819, in forward\n",
      "    return compiled_fn(full_args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 1222, in g\n",
      "    return f(*args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 2386, in debug_compiled_function\n",
      "    return compiled_function(*args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 1898, in runtime_wrapper\n",
      "    all_outs = call_func_with_args(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 1247, in call_func_with_args\n",
      "    out = normalize_as_list(f(args))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 1222, in g\n",
      "    return f(*args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/function.py\", line 506, in apply\n",
      "    return super().apply(*args, **kwargs)  # type: ignore[misc]\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 2151, in forward\n",
      "    fw_outs = call_func_with_args(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_functorch/aot_autograd.py\", line 1247, in call_func_with_args\n",
      "    out = normalize_as_list(f(args))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_inductor/compile_fx.py\", line 248, in run\n",
      "    return model(new_inputs)\n",
      "  File \"/tmp/torchinductor_root/e5/ce5hbtto7dlgjsqvcklumneipan7gv3vkakbzcui7zoz5urslsod.py\", line 200, in call\n",
      "    buf0 = empty_strided((4, 512, 1), (512, 1, 2048), device='cuda', dtype=torch.float32)\n",
      "KeyboardInterrupt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 255).\u001b[0m Press Control-C to abort syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       iter ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         lr ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        mfu ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/loss ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val/loss ‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       iter 5300\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:         lr 0.00033\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        mfu 1.96106\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: train/loss 0.04077\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   val/loss 0.1622\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run \u001b[33mmini-char-gpt-hd-8-ly-12-bt4-ovrf\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char/runs/mvi15non\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230430_202344-mvi15non/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py config/train_abc_char.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Roman Numeral Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 data/abc_roman_num_char/prepare.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 train.py config/train_abc_char.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./older_ckpt/hd-8-ly-12-bt4-ovrf'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_name = 'hd-8-ly-12-bt4-rn-data-ovrf'\n",
    "examples_folder = f'./older_ckpt/{folder_name}'\n",
    "examples_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_start = {\n",
    "    'G':'M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]',\n",
    "    'C':'M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]',\n",
    "    'Am':'M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]'\n",
    "    }\n",
    "\n",
    "songs_roman_start = {\n",
    "    'G':'M:4/4L:1/4K:G|\"I\"|\"IV\"|\"V\"|\"V\"|\"I\"|\"IV\"|\"V\"|\"I\"|]',\n",
    "    'C':'M:4/4L:1/4K:C|\"I\"|\"IV\"|\"V\"|\"V\"|\"I\"|\"IV\"|\"V\"|\"I\"|]',\n",
    "    'Am':'M:4/4L:1/4K:Am|\"i\"|\"iv\"|\"V\"|\"V\"|\"i\"|\"iv\"|\"V\"|\"i\"|]'\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test key with most occurrences: G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_start = songs_roman_start['G']\n",
    "#song_start = songs_start['G']\n",
    "song_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start={shlex.quote(song_start)} > {examples_folder}/examples_G.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test major key with low samples: C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_start = songs_roman_start['C']\n",
    "#song_start = songs_start['C']\n",
    "song_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start={shlex.quote(song_start)} > {examples_folder}/examples_C.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test minor key with low samples: Am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_start = songs_roman_start['Am']\n",
    "#song_start = songs_start['Am']\n",
    "song_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start={shlex.quote(song_start)} > {examples_folder}/examples_Am.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Move checkpoint files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = './data/abc_roman_num_char/meta.pkl'\n",
    "#source = './data/abc_char/meta.pkl'\n",
    "target_folder = examples_folder\n",
    "!mv {source} {target_folder}/meta.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = './out-abc-char/ckpt.pt'\n",
    "!mv {source} {target_folder}/ckpt.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = './config/train_abc_char.py'\n",
    "!cp {source} {target_folder}/config.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test older checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_start = songs_start['Am']\n",
    "!echo {shlex.quote(song_start)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " song_start = songs_start['Am']\n",
    " !python3 sample.py --out_dir=older_ckpt/m_voices --path_meta=older_ckpt/m_voices --start={shlex.quote(current_start)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 --version\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
