{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def load_dataframe(relative_path,dataframe_name):\n",
    "    df = pd.read_pickle(f'{relative_path}/{dataframe_name}.pkl')    \n",
    "    return df\n",
    "\n",
    "def read_file(relative_path,file_name):\n",
    "    text= \"\"\n",
    "    with open(f'{relative_path}/{file_name}.abc','r') as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_path =\"notebooks/data/final_dataset\"\n",
    "filename_name = 'clean_augmented_data'\n",
    "#filename_name = 'clean_original_training_data'\n",
    "#relative_path =\"notebooks/data/original_dataset\"\n",
    "training_data_df = load_dataframe(relative_path,filename_name)\n",
    "training_data_df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df[\"clean_header\"].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_df[\"clean_body\"].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bodies = \"\"\n",
    "silences = 0\n",
    "for body in training_data_df[\"clean_body\"]:\n",
    "    if 'z' in body:\n",
    "        silences +=1 \n",
    "    bodies += body+\"\\n\"\n",
    "chars = sorted(list(set(bodies)))\n",
    "vocab_size = len(chars)\n",
    "print('vocab: ',''.join(chars))\n",
    "print('vocab_size',vocab_size)\n",
    "print(\"silences \",silences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_text = read_file(relative_path,filename_name)\n",
    "\n",
    "print(\"number of chars:\",len(training_data_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(training_data_text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import tiktoken\n",
    "\n",
    "print(wandb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "nano_path = 'notebooks/nanoGPT'\n",
    "os.chdir(nano_path)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LICENSE      assets\t      data\t  out-abc-char\twandb\n",
      "README.md    config\t      model.py\t  sample.py\n",
      "__pycache__  configurator.py  older_ckpt  train.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset with multiple voices present\n",
    "#length of dataset in characters: 4,149,703\n",
    "#all the unique characters: \n",
    "#\"#'()+,-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
    "#vocab size: 46\n",
    "#train has 3,734,732 tokens\n",
    "#val has 414,971 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 4,062,773\n",
      "all the unique characters: \n",
      "\"#'(),-/123456789:=ABCDEFGKLM[]^_abcdefgmz|~\n",
      "vocab size: 45\n",
      "train has 3,656,495 tokens\n",
      "val has 406,278 tokens\n"
     ]
    }
   ],
   "source": [
    "!python3 data/abc_char/prepare.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding config with config/train_abc_char.py:\n",
      "# train a miniature character-level shakespeare model\n",
      "# good for debugging and playing on macbooks and such\n",
      "\n",
      "out_dir = 'out-abc-char'\n",
      "eval_interval = 10 # keep frequent because we'll overfit\n",
      "eval_iters = 500\n",
      "log_interval = 5 # don't print too too often\n",
      "\n",
      "# we expect to overfit on this small dataset, so only save when val improves\n",
      "always_save_checkpoint = False\n",
      "\n",
      "wandb_log = True # override via command line if you like\n",
      "wandb_project = 'abc-char'\n",
      "wandb_run_name = 'mini-char-gpt-hd-8-ly-12-bt-8'\n",
      "\n",
      "dataset = 'abc_char'\n",
      "batch_size = 8\n",
      "block_size = 512 # context of up to 512 previous characters\n",
      "\n",
      "# baby GPT model :)\n",
      "n_layer = 12\n",
      "n_head = 8\n",
      "n_embd = 384\n",
      "dropout = 0.2\n",
      "\n",
      "learning_rate = 1e-3 # with baby networks can afford to go a bit higher\n",
      "max_iters = 5000\n",
      "lr_decay_iters = 5000 # make equal to max_iters usually\n",
      "min_lr = 1e-4 # learning_rate / 10 usually\n",
      "beta2 = 0.99 # make a bit bigger because number of tokens per iter is small\n",
      "\n",
      "warmup_iters = 5 # not super necessary potentially\n",
      "\n",
      "# on macbook also add\n",
      "# device = 'cpu'  # run on cpu only\n",
      "# compile = False # do not torch compile the model\n",
      "\n",
      "found vocab_size = 45 (inside data/abc_char/meta.pkl)\n",
      "Initializing a new model from scratch\n",
      "number of parameters: 21.26M\n",
      "using fused AdamW: True\n",
      "compiling the model... (takes a ~minute)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdavidnogales\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.15.0 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.14.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/pt-env/notebooks/nanoGPT/wandb/run-20230425_231053-ewstgdm7\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmini-char-gpt-hd-8-ly-12-bt-8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/davidnogales/abc-char/runs/ewstgdm7\u001b[0m\n",
      "step 0: train loss 3.9204, val loss 3.9150\n",
      "[2023-04-25 23:11:20,171] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-25 23:11:20,647] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-25 23:11:21,137] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-25 23:11:21,311] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-25 23:11:21,566] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-25 23:11:21,747] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-25 23:11:22,000] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-25 23:11:22,185] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-25 23:11:22,441] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-25 23:11:22,624] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-25 23:11:22,879] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-25 23:11:23,064] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-25 23:11:23,413] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-25 23:11:23,602] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-25 23:11:23,853] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-25 23:11:24,039] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-25 23:11:24,296] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-25 23:11:24,478] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-25 23:11:24,734] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-25 23:11:24,918] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-25 23:11:25,175] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-25 23:11:25,359] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-25 23:11:25,620] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "[2023-04-25 23:11:25,808] torch._inductor.utils: [WARNING] using triton random, expect difference from eager\n",
      "iter 0: loss 3.9353, time 36951.24ms, mfu -100.00%\n",
      "iter 5: loss 3.2172, time 2359.43ms, mfu 3.47%\n",
      "step 10: train loss 2.7101, val loss 2.6953\n",
      "saving checkpoint to out-abc-char\n",
      "iter 10: loss 2.7833, time 20419.58ms, mfu 3.16%\n",
      "iter 15: loss 2.6293, time 2372.20ms, mfu 3.19%\n",
      "step 20: train loss 2.3781, val loss 2.3554\n",
      "saving checkpoint to out-abc-char\n",
      "iter 20: loss 2.3171, time 20070.48ms, mfu 2.91%\n",
      "iter 25: loss 2.0975, time 2368.64ms, mfu 2.97%\n",
      "step 30: train loss 2.1382, val loss 2.1690\n",
      "saving checkpoint to out-abc-char\n",
      "iter 30: loss 2.1074, time 20066.43ms, mfu 2.71%\n",
      "iter 35: loss 2.2784, time 2371.45ms, mfu 2.79%\n",
      "step 40: train loss 2.0296, val loss 2.0603\n",
      "saving checkpoint to out-abc-char\n",
      "iter 40: loss 2.0974, time 20052.81ms, mfu 2.55%\n",
      "iter 45: loss 2.0494, time 2370.01ms, mfu 2.64%\n",
      "step 50: train loss 1.9894, val loss 2.0275\n",
      "saving checkpoint to out-abc-char\n",
      "iter 50: loss 2.1126, time 20128.18ms, mfu 2.42%\n",
      "iter 55: loss 2.0591, time 2370.25ms, mfu 2.52%\n",
      "step 60: train loss 1.9202, val loss 1.9424\n",
      "saving checkpoint to out-abc-char\n",
      "iter 60: loss 1.9034, time 20077.50ms, mfu 2.31%\n",
      "iter 65: loss 1.9226, time 2376.41ms, mfu 2.42%\n",
      "step 70: train loss 1.8490, val loss 1.8668\n",
      "saving checkpoint to out-abc-char\n",
      "iter 70: loss 1.9173, time 20016.30ms, mfu 2.22%\n",
      "iter 75: loss 2.0066, time 2365.25ms, mfu 2.34%\n",
      "step 80: train loss 1.7872, val loss 1.8007\n",
      "saving checkpoint to out-abc-char\n",
      "iter 80: loss 1.9479, time 20048.36ms, mfu 2.15%\n",
      "iter 85: loss 1.8498, time 2373.31ms, mfu 2.28%\n",
      "step 90: train loss 1.7484, val loss 1.7936\n",
      "saving checkpoint to out-abc-char\n",
      "iter 90: loss 1.5083, time 20094.51ms, mfu 2.09%\n",
      "iter 95: loss 1.9660, time 2373.79ms, mfu 2.23%\n",
      "step 100: train loss 1.7060, val loss 1.7371\n",
      "saving checkpoint to out-abc-char\n",
      "iter 100: loss 1.6509, time 20178.13ms, mfu 2.05%\n",
      "iter 105: loss 1.8283, time 2366.86ms, mfu 2.19%\n",
      "step 110: train loss 1.6719, val loss 1.7069\n",
      "saving checkpoint to out-abc-char\n",
      "iter 110: loss 1.5648, time 20035.51ms, mfu 2.01%\n",
      "iter 115: loss 1.6169, time 2363.93ms, mfu 2.15%\n",
      "step 120: train loss 1.6613, val loss 1.6939\n",
      "saving checkpoint to out-abc-char\n",
      "iter 120: loss 1.7636, time 20010.17ms, mfu 1.98%\n",
      "iter 125: loss 1.7475, time 2369.84ms, mfu 2.13%\n",
      "step 130: train loss 1.6180, val loss 1.6565\n",
      "saving checkpoint to out-abc-char\n",
      "iter 130: loss 1.5711, time 19934.07ms, mfu 1.96%\n",
      "iter 135: loss 1.6401, time 2356.03ms, mfu 2.11%\n",
      "step 140: train loss 1.6000, val loss 1.6387\n",
      "saving checkpoint to out-abc-char\n",
      "iter 140: loss 1.6091, time 20191.70ms, mfu 1.94%\n",
      "iter 145: loss 1.5997, time 2362.80ms, mfu 2.09%\n",
      "step 150: train loss 1.5821, val loss 1.6174\n",
      "saving checkpoint to out-abc-char\n",
      "iter 150: loss 1.6049, time 19996.46ms, mfu 1.92%\n",
      "iter 155: loss 1.5543, time 2369.70ms, mfu 2.08%\n",
      "step 160: train loss 1.5579, val loss 1.5945\n",
      "saving checkpoint to out-abc-char\n",
      "iter 160: loss 1.5247, time 20000.81ms, mfu 1.91%\n",
      "iter 165: loss 1.5918, time 2367.13ms, mfu 2.06%\n",
      "step 170: train loss 1.5544, val loss 1.5761\n",
      "saving checkpoint to out-abc-char\n",
      "iter 170: loss 1.5893, time 20029.82ms, mfu 1.90%\n",
      "iter 175: loss 1.5689, time 2368.58ms, mfu 2.05%\n",
      "step 180: train loss 1.5230, val loss 1.5580\n",
      "saving checkpoint to out-abc-char\n",
      "iter 180: loss 1.3800, time 19991.52ms, mfu 1.89%\n",
      "iter 185: loss 1.6673, time 2364.98ms, mfu 2.05%\n",
      "step 190: train loss 1.5101, val loss 1.5397\n",
      "saving checkpoint to out-abc-char\n",
      "iter 190: loss 1.5378, time 20210.18ms, mfu 1.88%\n",
      "iter 195: loss 1.4318, time 2441.11ms, mfu 2.03%\n",
      "step 200: train loss 1.5049, val loss 1.5339\n",
      "saving checkpoint to out-abc-char\n",
      "iter 200: loss 1.5987, time 20091.53ms, mfu 1.87%\n",
      "iter 205: loss 1.5565, time 2368.56ms, mfu 2.03%\n",
      "step 210: train loss 1.4892, val loss 1.5110\n",
      "saving checkpoint to out-abc-char\n",
      "iter 210: loss 1.4582, time 19648.00ms, mfu 1.87%\n",
      "iter 215: loss 1.4841, time 2337.24ms, mfu 2.03%\n",
      "step 220: train loss 1.4756, val loss 1.4945\n",
      "saving checkpoint to out-abc-char\n",
      "iter 220: loss 1.5956, time 19732.59ms, mfu 1.87%\n",
      "iter 225: loss 1.4641, time 2388.97ms, mfu 2.02%\n",
      "step 230: train loss 1.4628, val loss 1.4958\n",
      "iter 230: loss 1.4811, time 19563.39ms, mfu 1.86%\n",
      "iter 235: loss 1.4387, time 2345.08ms, mfu 2.03%\n",
      "step 240: train loss 1.4556, val loss 1.4592\n",
      "saving checkpoint to out-abc-char\n",
      "iter 240: loss 1.6505, time 19933.79ms, mfu 1.86%\n",
      "iter 245: loss 1.4812, time 2342.64ms, mfu 2.03%\n",
      "step 250: train loss 1.4352, val loss 1.4583\n",
      "saving checkpoint to out-abc-char\n",
      "iter 250: loss 1.3661, time 19626.34ms, mfu 1.87%\n",
      "iter 255: loss 1.4513, time 2340.01ms, mfu 2.03%\n",
      "step 260: train loss 1.4286, val loss 1.4436\n",
      "saving checkpoint to out-abc-char\n",
      "iter 260: loss 1.4760, time 19609.00ms, mfu 1.87%\n",
      "iter 265: loss 1.4015, time 2340.85ms, mfu 2.03%\n",
      "step 270: train loss 1.4110, val loss 1.4398\n",
      "saving checkpoint to out-abc-char\n",
      "iter 270: loss 1.4980, time 19651.35ms, mfu 1.87%\n",
      "iter 275: loss 1.5029, time 2377.09ms, mfu 2.03%\n",
      "step 280: train loss 1.4001, val loss 1.4228\n",
      "saving checkpoint to out-abc-char\n",
      "iter 280: loss 1.4646, time 19692.55ms, mfu 1.87%\n",
      "iter 285: loss 1.1755, time 2365.54ms, mfu 2.03%\n",
      "step 290: train loss 1.3923, val loss 1.4065\n",
      "saving checkpoint to out-abc-char\n",
      "iter 290: loss 1.4066, time 19662.69ms, mfu 1.86%\n",
      "iter 295: loss 1.3024, time 2337.42ms, mfu 2.03%\n",
      "step 300: train loss 1.3771, val loss 1.3835\n",
      "saving checkpoint to out-abc-char\n",
      "iter 300: loss 1.5157, time 19914.75ms, mfu 1.87%\n",
      "iter 305: loss 1.3847, time 2351.69ms, mfu 2.03%\n",
      "step 310: train loss 1.3525, val loss 1.3857\n",
      "iter 310: loss 1.3696, time 19639.90ms, mfu 1.87%\n",
      "iter 315: loss 1.3210, time 2356.96ms, mfu 2.03%\n",
      "step 320: train loss 1.3267, val loss 1.3343\n",
      "saving checkpoint to out-abc-char\n",
      "iter 320: loss 1.3781, time 19777.08ms, mfu 1.87%\n",
      "iter 325: loss 1.3517, time 2334.82ms, mfu 2.03%\n",
      "step 330: train loss 1.3062, val loss 1.3278\n",
      "saving checkpoint to out-abc-char\n",
      "iter 330: loss 1.3205, time 19757.23ms, mfu 1.87%\n",
      "iter 335: loss 1.3613, time 2354.91ms, mfu 2.03%\n",
      "step 340: train loss 1.2907, val loss 1.3161\n",
      "saving checkpoint to out-abc-char\n",
      "iter 340: loss 1.2346, time 19654.20ms, mfu 1.87%\n",
      "iter 345: loss 1.4031, time 2349.09ms, mfu 2.03%\n",
      "step 350: train loss 1.2536, val loss 1.2866\n",
      "saving checkpoint to out-abc-char\n",
      "iter 350: loss 1.3470, time 19879.33ms, mfu 1.87%\n",
      "iter 355: loss 1.2194, time 2335.76ms, mfu 2.03%\n",
      "step 360: train loss 1.2313, val loss 1.2665\n",
      "saving checkpoint to out-abc-char\n",
      "iter 360: loss 1.2868, time 19823.93ms, mfu 1.87%\n",
      "iter 365: loss 1.2178, time 2346.99ms, mfu 2.03%\n",
      "step 370: train loss 1.1890, val loss 1.2316\n",
      "saving checkpoint to out-abc-char\n",
      "iter 370: loss 1.2019, time 20093.55ms, mfu 1.87%\n",
      "iter 375: loss 1.0940, time 2435.33ms, mfu 2.02%\n",
      "step 380: train loss 1.1679, val loss 1.2049\n",
      "saving checkpoint to out-abc-char\n",
      "iter 380: loss 1.1830, time 19829.73ms, mfu 1.86%\n",
      "iter 385: loss 1.1076, time 2338.99ms, mfu 2.02%\n",
      "step 390: train loss 1.1685, val loss 1.1922\n",
      "saving checkpoint to out-abc-char\n",
      "iter 390: loss 1.1424, time 19895.23ms, mfu 1.86%\n",
      "iter 395: loss 1.3415, time 2348.57ms, mfu 2.02%\n",
      "step 400: train loss 1.1454, val loss 1.1712\n",
      "saving checkpoint to out-abc-char\n",
      "iter 400: loss 1.3241, time 20009.20ms, mfu 1.86%\n",
      "iter 405: loss 1.0858, time 2365.14ms, mfu 2.02%\n",
      "step 410: train loss 1.1324, val loss 1.1659\n",
      "saving checkpoint to out-abc-char\n",
      "iter 410: loss 1.1157, time 20029.12ms, mfu 1.86%\n",
      "iter 415: loss 1.0028, time 2384.20ms, mfu 2.02%\n",
      "step 420: train loss 1.1036, val loss 1.1433\n",
      "saving checkpoint to out-abc-char\n",
      "iter 420: loss 1.0943, time 20400.77ms, mfu 1.86%\n",
      "iter 425: loss 1.0757, time 2395.32ms, mfu 2.01%\n",
      "step 430: train loss 1.0925, val loss 1.1191\n",
      "saving checkpoint to out-abc-char\n",
      "iter 430: loss 1.0943, time 20418.42ms, mfu 1.85%\n",
      "iter 435: loss 1.1619, time 2412.27ms, mfu 2.01%\n",
      "step 440: train loss 1.0820, val loss 1.1080\n",
      "saving checkpoint to out-abc-char\n",
      "iter 440: loss 1.1283, time 20362.57ms, mfu 1.84%\n",
      "iter 445: loss 1.0780, time 2374.04ms, mfu 2.01%\n",
      "step 450: train loss 1.0618, val loss 1.0856\n",
      "saving checkpoint to out-abc-char\n",
      "iter 450: loss 1.0066, time 19612.17ms, mfu 1.85%\n",
      "iter 455: loss 0.9758, time 2307.00ms, mfu 2.02%\n",
      "step 460: train loss 1.0406, val loss 1.0817\n",
      "saving checkpoint to out-abc-char\n",
      "iter 460: loss 0.9879, time 19577.43ms, mfu 1.86%\n",
      "iter 465: loss 0.9546, time 2316.02ms, mfu 2.02%\n",
      "step 470: train loss 1.0200, val loss 1.0581\n",
      "saving checkpoint to out-abc-char\n",
      "iter 470: loss 1.0230, time 19543.73ms, mfu 1.86%\n",
      "iter 475: loss 1.0814, time 2337.05ms, mfu 2.03%\n",
      "step 480: train loss 1.0038, val loss 1.0473\n",
      "saving checkpoint to out-abc-char\n",
      "iter 480: loss 1.0282, time 19798.50ms, mfu 1.87%\n",
      "iter 485: loss 1.0233, time 2318.86ms, mfu 2.03%\n",
      "step 490: train loss 0.9896, val loss 1.0173\n",
      "saving checkpoint to out-abc-char\n",
      "iter 490: loss 1.0738, time 20066.21ms, mfu 1.87%\n",
      "iter 495: loss 0.9508, time 2336.08ms, mfu 2.03%\n",
      "step 500: train loss 0.9625, val loss 1.0040\n",
      "saving checkpoint to out-abc-char\n",
      "iter 500: loss 0.9301, time 19745.16ms, mfu 1.87%\n",
      "iter 505: loss 0.9382, time 2359.75ms, mfu 2.03%\n",
      "step 510: train loss 0.9485, val loss 0.9899\n",
      "saving checkpoint to out-abc-char\n",
      "iter 510: loss 0.9651, time 19661.37ms, mfu 1.87%\n",
      "iter 515: loss 0.9701, time 2331.55ms, mfu 2.03%\n",
      "step 520: train loss 0.9343, val loss 0.9721\n",
      "saving checkpoint to out-abc-char\n",
      "iter 520: loss 1.0211, time 19772.48ms, mfu 1.87%\n",
      "iter 525: loss 0.9863, time 2385.50ms, mfu 2.03%\n",
      "step 530: train loss 0.9299, val loss 0.9800\n",
      "iter 530: loss 0.9229, time 19586.57ms, mfu 1.87%\n",
      "iter 535: loss 0.9833, time 2330.18ms, mfu 2.03%\n",
      "step 540: train loss 0.9034, val loss 0.9468\n",
      "saving checkpoint to out-abc-char\n",
      "iter 540: loss 0.9683, time 20238.17ms, mfu 1.87%\n",
      "iter 545: loss 0.9206, time 2318.29ms, mfu 2.03%\n",
      "step 550: train loss 0.8998, val loss 0.9341\n",
      "saving checkpoint to out-abc-char\n",
      "iter 550: loss 0.7982, time 19749.79ms, mfu 1.87%\n",
      "iter 555: loss 0.8848, time 2313.88ms, mfu 2.04%\n",
      "step 560: train loss 0.8809, val loss 0.9225\n",
      "saving checkpoint to out-abc-char\n",
      "iter 560: loss 0.9081, time 19575.75ms, mfu 1.88%\n",
      "iter 565: loss 0.8669, time 2656.00ms, mfu 2.00%\n",
      "step 570: train loss 0.8695, val loss 0.9294\n",
      "iter 570: loss 0.8689, time 19701.14ms, mfu 1.84%\n",
      "iter 575: loss 0.8915, time 2329.39ms, mfu 2.01%\n",
      "step 580: train loss 0.8549, val loss 0.9048\n",
      "saving checkpoint to out-abc-char\n",
      "iter 580: loss 0.7457, time 19758.68ms, mfu 1.85%\n",
      "iter 585: loss 0.8468, time 2317.56ms, mfu 2.02%\n",
      "step 590: train loss 0.8460, val loss 0.8923\n",
      "saving checkpoint to out-abc-char\n",
      "iter 590: loss 0.8204, time 19513.14ms, mfu 1.86%\n",
      "iter 595: loss 0.8865, time 2333.11ms, mfu 2.02%\n",
      "step 600: train loss 0.8202, val loss 0.8625\n",
      "saving checkpoint to out-abc-char\n",
      "iter 600: loss 0.8714, time 19782.79ms, mfu 1.86%\n",
      "iter 605: loss 0.7958, time 2396.46ms, mfu 2.02%\n",
      "step 610: train loss 0.8103, val loss 0.8587\n",
      "saving checkpoint to out-abc-char\n",
      "iter 610: loss 0.9281, time 20234.65ms, mfu 1.86%\n",
      "iter 615: loss 0.8121, time 2333.93ms, mfu 2.02%\n",
      "step 620: train loss 0.8014, val loss 0.8500\n",
      "saving checkpoint to out-abc-char\n",
      "iter 620: loss 0.8382, time 19974.69ms, mfu 1.86%\n",
      "iter 625: loss 0.8546, time 2349.11ms, mfu 2.02%\n",
      "step 630: train loss 0.7862, val loss 0.8307\n",
      "saving checkpoint to out-abc-char\n",
      "iter 630: loss 0.8296, time 20004.45ms, mfu 1.86%\n",
      "iter 635: loss 0.8878, time 2324.60ms, mfu 2.03%\n",
      "step 640: train loss 0.7640, val loss 0.8074\n",
      "saving checkpoint to out-abc-char\n",
      "iter 640: loss 0.8417, time 20481.80ms, mfu 1.86%\n",
      "iter 645: loss 0.7303, time 2371.76ms, mfu 2.02%\n",
      "step 650: train loss 0.7552, val loss 0.8028\n",
      "saving checkpoint to out-abc-char\n",
      "iter 650: loss 0.8340, time 19646.76ms, mfu 1.86%\n",
      "iter 655: loss 0.8435, time 2308.92ms, mfu 2.03%\n",
      "step 660: train loss 0.7434, val loss 0.7992\n",
      "saving checkpoint to out-abc-char\n",
      "iter 660: loss 0.7512, time 19496.40ms, mfu 1.87%\n",
      "iter 665: loss 0.7037, time 2329.17ms, mfu 2.03%\n",
      "step 670: train loss 0.7303, val loss 0.7828\n",
      "saving checkpoint to out-abc-char\n",
      "iter 670: loss 0.7602, time 19657.56ms, mfu 1.87%\n",
      "iter 675: loss 0.7972, time 2321.39ms, mfu 2.04%\n",
      "step 680: train loss 0.7085, val loss 0.7655\n",
      "saving checkpoint to out-abc-char\n",
      "iter 680: loss 0.7560, time 19696.81ms, mfu 1.88%\n",
      "iter 685: loss 0.7593, time 2309.99ms, mfu 2.04%\n",
      "step 690: train loss 0.7008, val loss 0.7601\n",
      "saving checkpoint to out-abc-char\n",
      "iter 690: loss 0.7198, time 19689.81ms, mfu 1.88%\n",
      "iter 695: loss 0.7133, time 2317.02ms, mfu 2.04%\n",
      "step 700: train loss 0.6857, val loss 0.7311\n",
      "saving checkpoint to out-abc-char\n",
      "iter 700: loss 0.6700, time 19582.16ms, mfu 1.88%\n",
      "iter 705: loss 0.6523, time 2345.35ms, mfu 2.04%\n",
      "step 710: train loss 0.6727, val loss 0.7297\n",
      "saving checkpoint to out-abc-char\n",
      "iter 710: loss 0.6414, time 19678.79ms, mfu 1.88%\n",
      "iter 715: loss 0.6575, time 2309.10ms, mfu 2.05%\n",
      "step 720: train loss 0.6652, val loss 0.7146\n",
      "saving checkpoint to out-abc-char\n",
      "iter 720: loss 0.7324, time 19772.15ms, mfu 1.88%\n",
      "iter 725: loss 0.6735, time 2326.18ms, mfu 2.05%\n",
      "step 730: train loss 0.6507, val loss 0.7079\n",
      "saving checkpoint to out-abc-char\n",
      "iter 730: loss 0.6508, time 19761.63ms, mfu 1.88%\n",
      "iter 735: loss 0.6497, time 2328.06ms, mfu 2.05%\n",
      "step 740: train loss 0.6411, val loss 0.6978\n",
      "saving checkpoint to out-abc-char\n",
      "iter 740: loss 0.6924, time 19858.72ms, mfu 1.88%\n",
      "iter 745: loss 0.7551, time 2319.82ms, mfu 2.05%\n",
      "step 750: train loss 0.6330, val loss 0.6925\n",
      "saving checkpoint to out-abc-char\n",
      "iter 750: loss 0.6557, time 19570.29ms, mfu 1.88%\n",
      "iter 755: loss 0.6736, time 2321.77ms, mfu 2.05%\n",
      "step 760: train loss 0.6172, val loss 0.6720\n",
      "saving checkpoint to out-abc-char\n",
      "iter 760: loss 0.6234, time 19878.81ms, mfu 1.89%\n",
      "iter 765: loss 0.6374, time 2315.62ms, mfu 2.05%\n",
      "step 770: train loss 0.6156, val loss 0.6705\n",
      "saving checkpoint to out-abc-char\n",
      "iter 770: loss 0.5999, time 19750.71ms, mfu 1.89%\n",
      "iter 775: loss 0.6032, time 2320.93ms, mfu 2.05%\n",
      "step 780: train loss 0.6041, val loss 0.6651\n",
      "saving checkpoint to out-abc-char\n",
      "iter 780: loss 0.6177, time 19743.84ms, mfu 1.89%\n",
      "iter 785: loss 0.6929, time 2318.05ms, mfu 2.05%\n",
      "step 790: train loss 0.5981, val loss 0.6527\n",
      "saving checkpoint to out-abc-char\n",
      "iter 790: loss 0.6786, time 19623.51ms, mfu 1.89%\n",
      "iter 795: loss 0.6003, time 2333.90ms, mfu 2.05%\n",
      "step 800: train loss 0.5814, val loss 0.6464\n",
      "saving checkpoint to out-abc-char\n",
      "iter 800: loss 0.5903, time 19652.84ms, mfu 1.89%\n",
      "iter 805: loss 0.6421, time 2339.59ms, mfu 2.05%\n",
      "step 810: train loss 0.5795, val loss 0.6480\n",
      "iter 810: loss 0.6381, time 19451.96ms, mfu 1.89%\n",
      "iter 815: loss 0.6217, time 2332.31ms, mfu 2.05%\n",
      "step 820: train loss 0.5724, val loss 0.6351\n",
      "saving checkpoint to out-abc-char\n",
      "iter 820: loss 0.6605, time 19713.03ms, mfu 1.88%\n",
      "iter 825: loss 0.5965, time 2315.19ms, mfu 2.05%\n",
      "step 830: train loss 0.5573, val loss 0.6204\n",
      "saving checkpoint to out-abc-char\n",
      "iter 830: loss 0.5831, time 19924.82ms, mfu 1.89%\n",
      "iter 835: loss 0.6425, time 2311.85ms, mfu 2.05%\n",
      "step 840: train loss 0.5486, val loss 0.6166\n",
      "saving checkpoint to out-abc-char\n",
      "iter 840: loss 0.5572, time 19650.51ms, mfu 1.89%\n",
      "iter 845: loss 0.6312, time 2334.01ms, mfu 2.05%\n",
      "step 850: train loss 0.5477, val loss 0.6113\n",
      "saving checkpoint to out-abc-char\n",
      "iter 850: loss 0.6212, time 19645.11ms, mfu 1.89%\n",
      "iter 855: loss 0.5549, time 2336.89ms, mfu 2.05%\n",
      "step 860: train loss 0.5408, val loss 0.6151\n",
      "iter 860: loss 0.5853, time 19471.76ms, mfu 1.89%\n",
      "iter 865: loss 0.6018, time 2309.23ms, mfu 2.05%\n",
      "step 870: train loss 0.5322, val loss 0.6028\n",
      "saving checkpoint to out-abc-char\n",
      "iter 870: loss 0.5984, time 19570.73ms, mfu 1.89%\n",
      "iter 875: loss 0.5312, time 2329.39ms, mfu 2.05%\n",
      "step 880: train loss 0.5252, val loss 0.5936\n",
      "saving checkpoint to out-abc-char\n",
      "iter 880: loss 0.5131, time 19769.30ms, mfu 1.89%\n",
      "iter 885: loss 0.5363, time 2356.04ms, mfu 2.05%\n",
      "step 890: train loss 0.5235, val loss 0.5982\n",
      "iter 890: loss 0.5295, time 19376.42ms, mfu 1.88%\n",
      "iter 895: loss 0.4769, time 2319.67ms, mfu 2.05%\n",
      "step 900: train loss 0.5138, val loss 0.5913\n",
      "saving checkpoint to out-abc-char\n",
      "iter 900: loss 0.5409, time 19613.97ms, mfu 1.88%\n",
      "iter 905: loss 0.5508, time 2324.51ms, mfu 2.05%\n",
      "step 910: train loss 0.5044, val loss 0.5791\n",
      "saving checkpoint to out-abc-char\n",
      "iter 910: loss 0.5697, time 19979.77ms, mfu 1.88%\n",
      "iter 915: loss 0.5396, time 2394.26ms, mfu 2.04%\n",
      "step 920: train loss 0.5010, val loss 0.5754\n",
      "saving checkpoint to out-abc-char\n",
      "iter 920: loss 0.5024, time 20061.82ms, mfu 1.87%\n",
      "iter 925: loss 0.5358, time 2360.76ms, mfu 2.03%\n",
      "step 930: train loss 0.4903, val loss 0.5709\n",
      "saving checkpoint to out-abc-char\n",
      "iter 930: loss 0.5575, time 20049.94ms, mfu 1.87%\n",
      "iter 935: loss 0.5483, time 2364.70ms, mfu 2.03%\n",
      "step 940: train loss 0.4884, val loss 0.5686\n",
      "saving checkpoint to out-abc-char\n",
      "iter 940: loss 0.5532, time 19963.98ms, mfu 1.87%\n",
      "iter 945: loss 0.5440, time 2397.21ms, mfu 2.02%\n",
      "step 950: train loss 0.4844, val loss 0.5674\n",
      "saving checkpoint to out-abc-char\n",
      "iter 950: loss 0.5196, time 19851.90ms, mfu 1.86%\n",
      "iter 955: loss 0.5249, time 2285.56ms, mfu 2.03%\n",
      "step 960: train loss 0.4785, val loss 0.5623\n",
      "saving checkpoint to out-abc-char\n",
      "iter 960: loss 0.4658, time 19394.89ms, mfu 1.87%\n",
      "iter 965: loss 0.4823, time 2307.44ms, mfu 2.04%\n",
      "step 970: train loss 0.4658, val loss 0.5525\n",
      "saving checkpoint to out-abc-char\n",
      "iter 970: loss 0.4848, time 19589.82ms, mfu 1.88%\n",
      "iter 975: loss 0.5642, time 2314.55ms, mfu 2.04%\n",
      "step 980: train loss 0.4622, val loss 0.5574\n",
      "iter 980: loss 0.4868, time 19565.48ms, mfu 1.88%\n",
      "iter 985: loss 0.5072, time 2307.32ms, mfu 2.05%\n",
      "step 990: train loss 0.4541, val loss 0.5481\n",
      "saving checkpoint to out-abc-char\n",
      "iter 990: loss 0.4741, time 19769.97ms, mfu 1.88%\n",
      "iter 995: loss 0.5127, time 2333.42ms, mfu 2.05%\n",
      "step 1000: train loss 0.4482, val loss 0.5429\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1000: loss 0.4956, time 19452.23ms, mfu 1.88%\n",
      "iter 1005: loss 0.4796, time 2364.43ms, mfu 2.04%\n",
      "step 1010: train loss 0.4450, val loss 0.5446\n",
      "iter 1010: loss 0.5269, time 19467.21ms, mfu 1.88%\n",
      "iter 1015: loss 0.4404, time 2343.83ms, mfu 2.04%\n",
      "step 1020: train loss 0.4374, val loss 0.5394\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1020: loss 0.4236, time 19690.40ms, mfu 1.88%\n",
      "iter 1025: loss 0.4404, time 2343.41ms, mfu 2.04%\n",
      "step 1030: train loss 0.4316, val loss 0.5308\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1030: loss 0.4629, time 19919.60ms, mfu 1.88%\n",
      "iter 1035: loss 0.5020, time 2359.50ms, mfu 2.04%\n",
      "step 1040: train loss 0.4271, val loss 0.5301\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1040: loss 0.4775, time 19820.77ms, mfu 1.87%\n",
      "iter 1045: loss 0.4639, time 2339.81ms, mfu 2.04%\n",
      "step 1050: train loss 0.4160, val loss 0.5287\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1050: loss 0.4313, time 19771.51ms, mfu 1.87%\n",
      "iter 1055: loss 0.5115, time 2356.87ms, mfu 2.03%\n",
      "step 1060: train loss 0.4132, val loss 0.5229\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1060: loss 0.4523, time 19346.68ms, mfu 1.87%\n",
      "iter 1065: loss 0.4339, time 2324.42ms, mfu 2.04%\n",
      "step 1070: train loss 0.4030, val loss 0.5223\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1070: loss 0.4604, time 19153.94ms, mfu 1.88%\n",
      "iter 1075: loss 0.4588, time 2274.56ms, mfu 2.05%\n",
      "step 1080: train loss 0.4019, val loss 0.5167\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1080: loss 0.4430, time 19077.67ms, mfu 1.89%\n",
      "iter 1085: loss 0.4135, time 2272.37ms, mfu 2.06%\n",
      "step 1090: train loss 0.3938, val loss 0.5162\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1090: loss 0.4420, time 19215.72ms, mfu 1.90%\n",
      "iter 1095: loss 0.4385, time 2358.64ms, mfu 2.05%\n",
      "step 1100: train loss 0.3845, val loss 0.4972\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1100: loss 0.4112, time 19161.80ms, mfu 1.89%\n",
      "iter 1105: loss 0.3764, time 2273.37ms, mfu 2.06%\n",
      "step 1110: train loss 0.3796, val loss 0.4978\n",
      "iter 1110: loss 0.4008, time 18832.86ms, mfu 1.90%\n",
      "iter 1115: loss 0.3561, time 2275.95ms, mfu 2.07%\n",
      "step 1120: train loss 0.3729, val loss 0.4969\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1120: loss 0.4243, time 19012.59ms, mfu 1.90%\n",
      "iter 1125: loss 0.4038, time 2276.27ms, mfu 2.07%\n",
      "step 1130: train loss 0.3702, val loss 0.4981\n",
      "iter 1130: loss 0.4218, time 18917.26ms, mfu 1.91%\n",
      "iter 1135: loss 0.4243, time 2274.34ms, mfu 2.08%\n",
      "step 1140: train loss 0.3608, val loss 0.4940\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1140: loss 0.4211, time 19065.44ms, mfu 1.91%\n",
      "iter 1145: loss 0.4696, time 2383.02ms, mfu 2.07%\n",
      "step 1150: train loss 0.3613, val loss 0.4877\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1150: loss 0.4342, time 19257.92ms, mfu 1.90%\n",
      "iter 1155: loss 0.3769, time 2272.02ms, mfu 2.07%\n",
      "step 1160: train loss 0.3459, val loss 0.4834\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1160: loss 0.4027, time 19652.34ms, mfu 1.91%\n",
      "iter 1165: loss 0.3955, time 2297.80ms, mfu 2.07%\n",
      "step 1170: train loss 0.3427, val loss 0.4808\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1170: loss 0.3620, time 20149.40ms, mfu 1.91%\n",
      "iter 1175: loss 0.3958, time 2282.34ms, mfu 2.07%\n",
      "step 1180: train loss 0.3372, val loss 0.4705\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1180: loss 0.3835, time 19215.60ms, mfu 1.91%\n",
      "iter 1185: loss 0.3758, time 2275.53ms, mfu 2.08%\n",
      "step 1190: train loss 0.3268, val loss 0.4729\n",
      "iter 1190: loss 0.3968, time 19171.01ms, mfu 1.91%\n",
      "iter 1195: loss 0.3569, time 2275.91ms, mfu 2.08%\n",
      "step 1200: train loss 0.3246, val loss 0.4741\n",
      "iter 1200: loss 0.3894, time 19427.71ms, mfu 1.91%\n",
      "iter 1205: loss 0.3593, time 2343.39ms, mfu 2.07%\n",
      "step 1210: train loss 0.3163, val loss 0.4665\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1210: loss 0.3689, time 19611.49ms, mfu 1.91%\n",
      "iter 1215: loss 0.3810, time 2275.13ms, mfu 2.08%\n",
      "step 1220: train loss 0.3107, val loss 0.4581\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1220: loss 0.3870, time 19724.25ms, mfu 1.91%\n",
      "iter 1225: loss 0.3044, time 2315.47ms, mfu 2.07%\n",
      "step 1230: train loss 0.3073, val loss 0.4546\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1230: loss 0.3182, time 19420.09ms, mfu 1.91%\n",
      "iter 1235: loss 0.3696, time 2288.86ms, mfu 2.07%\n",
      "step 1240: train loss 0.2987, val loss 0.4536\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1240: loss 0.3041, time 19436.11ms, mfu 1.91%\n",
      "iter 1245: loss 0.3566, time 2330.87ms, mfu 2.07%\n",
      "step 1250: train loss 0.2918, val loss 0.4481\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1250: loss 0.3198, time 19263.75ms, mfu 1.90%\n",
      "iter 1255: loss 0.3124, time 2275.78ms, mfu 2.07%\n",
      "step 1260: train loss 0.2873, val loss 0.4381\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1260: loss 0.3192, time 19204.22ms, mfu 1.91%\n",
      "iter 1265: loss 0.3242, time 2276.08ms, mfu 2.08%\n",
      "step 1270: train loss 0.2802, val loss 0.4394\n",
      "iter 1270: loss 0.3477, time 18957.33ms, mfu 1.91%\n",
      "iter 1275: loss 0.3110, time 2274.66ms, mfu 2.08%\n",
      "step 1280: train loss 0.2774, val loss 0.4354\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1280: loss 0.3225, time 19193.32ms, mfu 1.92%\n",
      "iter 1285: loss 0.3299, time 2280.70ms, mfu 2.08%\n",
      "step 1290: train loss 0.2734, val loss 0.4387\n",
      "iter 1290: loss 0.3054, time 19000.03ms, mfu 1.92%\n",
      "iter 1295: loss 0.3366, time 2284.67ms, mfu 2.08%\n",
      "step 1300: train loss 0.2653, val loss 0.4323\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1300: loss 0.3376, time 19160.22ms, mfu 1.92%\n",
      "iter 1305: loss 0.3262, time 2351.53ms, mfu 2.08%\n",
      "step 1310: train loss 0.2558, val loss 0.4275\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1310: loss 0.3563, time 19213.52ms, mfu 1.91%\n",
      "iter 1315: loss 0.3269, time 2273.53ms, mfu 2.08%\n",
      "step 1320: train loss 0.2542, val loss 0.4218\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1320: loss 0.2947, time 19481.91ms, mfu 1.91%\n",
      "iter 1325: loss 0.3108, time 2288.18ms, mfu 2.08%\n",
      "step 1330: train loss 0.2518, val loss 0.4283\n",
      "iter 1330: loss 0.2794, time 19297.19ms, mfu 1.91%\n",
      "iter 1335: loss 0.2919, time 2401.28ms, mfu 2.06%\n",
      "step 1340: train loss 0.2476, val loss 0.4239\n",
      "iter 1340: loss 0.2458, time 19002.27ms, mfu 1.90%\n",
      "iter 1345: loss 0.2639, time 2273.09ms, mfu 2.07%\n",
      "step 1350: train loss 0.2407, val loss 0.4076\n",
      "saving checkpoint to out-abc-char\n",
      "iter 1350: loss 0.2867, time 19230.39ms, mfu 1.91%\n",
      "iter 1355: loss 0.2633, time 2271.02ms, mfu 2.08%\n",
      "step 1360: train loss 0.2357, val loss 0.4079\n",
      "iter 1360: loss 0.2604, time 19512.36ms, mfu 1.91%\n",
      "iter 1365: loss 0.2573, time 2357.18ms, mfu 2.07%\n",
      "^C\n",
      "Process ForkProcess-8:\n",
      "Process ForkProcess-18:\n",
      "Process ForkProcess-20:\n",
      "Process ForkProcess-11:\n",
      "Process ForkProcess-10:\n",
      "Process ForkProcess-13:\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-15:\n",
      "Process ForkProcess-9:\n",
      "Process ForkProcess-17:\n",
      "Process ForkProcess-19:\n",
      "Process ForkProcess-4:\n",
      "Process ForkProcess-16:\n",
      "Process ForkProcess-12:\n",
      "Process ForkProcess-2:\n",
      "Process ForkProcess-14:\n",
      "Process ForkProcess-6:\n",
      "Process ForkProcess-3:\n",
      "Process ForkProcess-5:\n",
      "Process ForkProcess-1:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 97, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 315, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.8/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.8/concurrent/futures/process.py\", line 233, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/usr/lib/python3.8/multiprocessing/queues.py\", line 96, in get\n",
      "    with self._rlock:\n",
      "  File \"/usr/lib/python3.8/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"train.py\", line 293, in <module>\n",
      "    scaler.scale(loss).backward()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\", line 487, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\", line 200, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[31m(failed 255).\u001b[0m Press Control-C to abort syncing.\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py config/train_abc_char.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test key with most occurrences: G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start='M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test major key with low samples: C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start='M:4/4L:1/4K:C|\"C\"|\"F\"|\"G\"|\"G\"|\"C\"|\"F\"|\"G\"|\"C\"|]'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test minor key with low samples: Am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 sample.py --out_dir=out-abc-char --start='M:4/4L:1/4K:Am|\"Am\"|\"Dm\"|\"E\"|\"E\"|\"Am\"|\"Dm\"|\"E\"|\"Am\"|]'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test older checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " !python3 sample.py --out_dir=older_ckpt/m_voices --path_meta=older_ckpt/m_voices --start='M:4/4L:1/4K:G|\"G\"|\"C\"|\"D\"|\"D\"|\"G\"|\"C\"|\"D\"|\"G\"|]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat older_ckpt/m_voices/ckpt.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l older_ckpt/m_voices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l out-abc-char/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!id"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
