{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "sns.set_style(\"dark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "global control_var\n",
    "control_var = True\n",
    "def get_tuneBooks_file_names(path):\n",
    "    tuneBook_filenames = []\n",
    "    \n",
    "    for tuneBook_name in os.listdir(path):\n",
    "        if tuneBook_name.endswith('.abc'):\n",
    "            tuneBook_filenames.append(tuneBook_name)\n",
    "    \n",
    "    #return [\"jigs.abc\"]\n",
    "    return tuneBook_filenames\n",
    "def split_abc_song(abc_song):\n",
    "    k_index = abc_song.find('K:')\n",
    "\n",
    "    split_index = abc_song.find('\\n', k_index)\n",
    "\n",
    "    header = abc_song[:split_index]\n",
    "    body = abc_song[split_index+1:]\n",
    "    return header, body\n",
    "\n",
    "def tuneBook_to_dataframe(tuneBook):\n",
    "    song_list = tuneBook.split(\"\\n\\n\")\n",
    "    song_list = [song.strip() for song in song_list]\n",
    "    songs_header_body_format = [split_abc_song(song) for song in song_list if song != '']\n",
    "    \"\"\"\n",
    "    for (h,b) in songs_header_body_format:\n",
    "        print(\"header\")\n",
    "        print(h)\n",
    "        print(\"*\"*10)\n",
    "        print(\"body\")\n",
    "        print(b)\n",
    "        print(\"\\n\")\n",
    "        print(\"-\"*50)\n",
    "        print(\"\\n\")\n",
    "    \"\"\"\n",
    "    \n",
    "    return pd.DataFrame(songs_header_body_format, columns=['header', 'body'])\n",
    "\n",
    "def get_attributes_from_song_header(tuneBook_df,tuneBook_name):\n",
    "    attributes_column = tuneBook_df[\"header\"]\n",
    "    attributes_list = list(attributes_column)\n",
    "    \n",
    "    data = []\n",
    "    for string in attributes_list:\n",
    "        song = {}\n",
    "        for line in string.split(\"\\n\"):\n",
    "            if not line.startswith(\"%\"):\n",
    "                if ':' in line:\n",
    "                    key, value = line.split(\":\", maxsplit=1)\n",
    "                    song[key.strip()] = value.strip()\n",
    "        data.append(song)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    descriptive_names = {\n",
    "                        'X': 'reference_number',\n",
    "                        'T': 'title',\n",
    "                        'S': 'source',\n",
    "                        'M': 'meter',\n",
    "                        'L': 'unit_note_length',\n",
    "                        'R': 'rhythm',\n",
    "                        'P': 'parts',\n",
    "                        'K': 'key',\n",
    "                        'F': 'file_name',\n",
    "                        'N': 'notes'\n",
    "                        }\n",
    "    df.rename(columns=descriptive_names, inplace=True)\n",
    "    df[\"tuneBook\"] = tuneBook_name\n",
    "    df[\"original_header\"] =  tuneBook_df[\"header\"]\n",
    "    df[\"original_body\"] =  tuneBook_df[\"body\"]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_chord_progression(song_body):\n",
    "    bars = song_body.split(\"|\")\n",
    "    chord_progression = \"|\"\n",
    "    for bar_content in bars:\n",
    "        match_chords = r'\"[^\"]*\"'\n",
    "        chords = re.findall(match_chords, bar_content)\n",
    "        bar_chords = ''.join(chords)\n",
    "        if bar_chords != \"\":\n",
    "            chord_progression += bar_chords +'|'\n",
    "    return chord_progression\n",
    "\n",
    "def get_chord_occurrences(song_body):\n",
    "    bars = song_body.split(\"|\")\n",
    "    chord_progression = \"|\"\n",
    "    match_chords = r'\"[^\"]*\"'\n",
    "    chords = [re.findall(match_chords, bar_content)  for bar_content in bars if bar_content]\n",
    "    chords = [chord for bar_chords in chords for chord in bar_chords]\n",
    "    chord_occurrences = dict(Counter(chords))\n",
    "    return chord_occurrences\n",
    "\n",
    "def get_chords_data(song_body=\"\"):\n",
    "    #song_body = 'P:A\\nD|\"Gm\"GB2G|\"D7\"^Fd2D|\"Gm\"GB2G|\"D7\"^FA2D|\"Gm\"GB2G|\"D\"^Fg -\"Cm\"gc|\\\\\\n\"Gm/d\"B2 \"D7\"A2|\"Gm\"G3:|\\nP:B\\nd|\"Gm\"dg2d|\"Gm\"gb2d|\"F\"cf2c|\"F\"fa2c|\"Eb\"Be2d/2c/2|\"Gm\"dg -\"Cm\"gc|\\\\\\n\"Gm/d\"B2 \"D7\"A2|\"Gm\"G3:|'\n",
    "    clean_body_song = \"\"\n",
    "    match_pattern = \"\"\n",
    "    for line in song_body.splitlines():\n",
    "        #if not line.startswith(\"%\"):\n",
    "            #if not \"P:\" in line:\n",
    "        if not line.startswith(('P:', 'M:', '%', \"L:\")):\n",
    "            #print(\"Header detected!!!\",line)\n",
    "            new_line = line.strip(\"\\\\\")\n",
    "            match_pattern = r\"[: ]\"\n",
    "            new_line = re.sub(match_pattern, \"\", new_line)\n",
    "            clean_body_song = clean_body_song+new_line\n",
    "            if('||||' in clean_body_song):\n",
    "                match_pattern = r'\\|\\|\\|\\|'\n",
    "                clean_body_song = re.sub(match_pattern, \"|\", clean_body_song)\n",
    "                print(\"new line\",clean_body_song)\n",
    "                print(\"old line\",line)\n",
    "                print(\"-\"*10)\n",
    "    \n",
    "    chord_progression = get_chord_progression(clean_body_song)\n",
    "    chords_data = get_chord_occurrences(clean_body_song)\n",
    "    chords_data[\"chord_progression\"] = chord_progression\n",
    "    chords_data[\"clean_body\"] = clean_body_song\n",
    "    return chords_data\n",
    "\n",
    "### treat strings line by line to ignore comments and parts!!!!!\n",
    "def get_song_characteristics_from_body(tuneBook_df, header_col_name=\"original_body\"):\n",
    "    songs_bodies=tuneBook_df[header_col_name]\n",
    "    #global control_var\n",
    "    #print(songs_bodies)\n",
    "    #if(control_var):\n",
    "        #control_var = False\n",
    "    #df = tuneBook_df.join(songs_bodies.apply(get_chords_data))\n",
    "    new_data = songs_bodies.apply(get_chords_data)\n",
    "    chords_df = new_data.apply(pd.Series)\n",
    "    chords = chords_df['chord_progression']\n",
    "    chords_df = chords_df.drop('chord_progression', axis=1)\n",
    "    chords_df[\"chord_progression\"] = chords\n",
    "    tuneBook_df = tuneBook_df.join(chords_df)\n",
    "    #print(tuneBook_df.columns)\n",
    "    #print(\"*\"*20)   \n",
    "    # get anacrusis bool to see that the dataset is balanced\n",
    "    #tuneBook[\"num_notes_per_bar\"] # count num -> useless? to measure intensity?\n",
    "    #tuneBook[\"num_bars\"] # count number of || ins song -> to detect possible outliers?\n",
    "    #tuneBook[\"num_notes_in_song\"] # count a,b,c,d...in string, match regex \"a\"   \n",
    "    #tuneBook[\"chord_progression\"] #string \"|\"C\"|\"Dm\"|\" -> to count chords and to have a \"Tree view of common chord progressions\"\n",
    "    #tuneBook[\"multiple_parts\"] #bool -> to treat songs with multiple parts\n",
    "    ##  Count types of notes in each song to see the proportion of notes for a given key\n",
    "    ## Maybe by chord also?\n",
    "    return tuneBook_df\n",
    "def get_songs_metadata(songs_dataframe, tuneBook_name):\n",
    "    #songs_dataframe[\"number_in_tunebook\"] = get_attributes_from_song_header(songs_dataframe)\n",
    "    df = get_attributes_from_song_header(songs_dataframe,tuneBook_name)\n",
    "    df = get_song_characteristics_from_body(df)\n",
    "    return df\n",
    "\n",
    "def get_chord_columns_as_occurrences(songs_df):\n",
    "    chords_names = songs_df.columns[songs_df.columns.str.contains('\"[^\"]*\"')]\n",
    "    chords_occurrences = songs_df[chords_names].sum()\n",
    "    return chords_occurrences\n",
    "\n",
    "\n",
    "\n",
    "def drop_rows_by_chord_occurrence(songs_df,drop_threshold=15):\n",
    "    \n",
    "    chords_occurrences = get_chord_columns_as_occurrences(songs_df)\n",
    "    ## Gets the names of the chords that appear less times than the threshold.\n",
    "    chords_names_least_occurrences = chords_occurrences[chords_occurrences<drop_threshold].index.to_list()\n",
    "    print(\"number chords least occurrences: \",len(chords_names_least_occurrences))\n",
    "    print(\"chords least occurrences\",chords_names_least_occurrences)\n",
    "\n",
    "    ## Applies a logical OR to the selected columns in order to drop the rows that have a value in the corresponding column\n",
    "    mask_drop_songs_with_low_chords_sample = songs_df[chords_names_least_occurrences].apply(lambda row: row>0).any(axis=1)\n",
    "    drop_num = mask_drop_songs_with_low_chords_sample.value_counts()\n",
    "    print(\"number of values to be dropped:\\n\",drop_num)\n",
    "\n",
    "    ##Apply the negative mask to preserve the rows that don't have occurrences of the selected chords\n",
    "    clean_songs_df = songs_df[~mask_drop_songs_with_low_chords_sample]\n",
    "\n",
    "    ##Drop columns of useless chords\n",
    "    clean_songs_df = clean_songs_df.drop(chords_names_least_occurrences, axis=1)\n",
    "    clean_songs_df = clean_songs_df.reset_index(drop=True)\n",
    "\n",
    "    return clean_songs_df\n",
    "\n",
    "def drop_rows_by_extended_chords(songs_df,chords_to_drop=[]):\n",
    "    \n",
    "    chords_occurrences = get_chord_columns_as_occurrences(songs_df)\n",
    "\n",
    "    ## Gets the names of the chords that have '/' \n",
    "    extended_chords_names = songs_df.columns[songs_df.columns.str.contains(\"/\")].to_list()\n",
    "    extended_chords_names = extended_chords_names + chords_to_drop\n",
    "\n",
    "    ## Applies a logical OR to the selected columns in order to drop the rows that have a value in the corresponding column\n",
    "    mask_drop_songs_with_extended_chords = songs_df[extended_chords_names].apply(lambda row: row>0).any(axis=1)\n",
    "    drop_num = mask_drop_songs_with_extended_chords.value_counts()\n",
    "    print(\"number of values to be dropped:\\n\",drop_num)\n",
    "\n",
    "    ##Apply the negative mask to preserve the rows that don't have occurrences of the selected chords\n",
    "    clean_songs_df = songs_df[~mask_drop_songs_with_extended_chords]\n",
    "\n",
    "    ##Drop columns of useless chords\n",
    "    clean_songs_df = clean_songs_df.drop(extended_chords_names, axis=1)\n",
    "    clean_songs_df = clean_songs_df.reset_index(drop=True)\n",
    "\n",
    "    return clean_songs_df\n",
    "\n",
    "\n",
    "def count_bars_in_songs(songs_df):\n",
    "    return 0\n",
    "\n",
    "def calculate_note_length(songs_df_row,col_name=\"unit_note_length\"):\n",
    "    new_note_length = \"\"\n",
    "    ## See: https://abcnotation.com/wiki/abc:standard:v2.1#lunit_note_length \n",
    "    map_meter_to_note_length = {\n",
    "        \"4/4\":\"1/8\",\n",
    "        \"6/8\":\"1/8\",\n",
    "        \"3/4\":\"1/8\",\n",
    "        \"2/4\":\"1/16\",\n",
    "        \"9/8\":\"1/8\",\n",
    "        \"2/2\":\"1/8\",\n",
    "        \"3/2\":\"1/8\",\n",
    "        \"6/4\":\"1/8\"\n",
    "    }\n",
    "    if(pd.isna(songs_df_row[col_name])):\n",
    "        print(\"NA detected!\")\n",
    "        meter = songs_df_row[\"meter\"]\n",
    "        new_note_length = map_meter_to_note_length[meter]\n",
    "    else:\n",
    "        new_note_length = songs_df_row[col_name]\n",
    "\n",
    "    return new_note_length\n",
    "\n",
    "def fill_missing_note_length(songs_df):\n",
    "    col_with_na = \"unit_note_length\"\n",
    "    songs_df[col_with_na] = songs_df.apply(calculate_note_length,axis=1)\n",
    "    return songs_df\n",
    "\n",
    "def drop_useless_columns(df,drop_columns=[\"Y\",\"notes\",\"parts\",\"rhythm\",\"source\"]):\n",
    "    clean_df = df\n",
    "    df_columns = clean_df.columns\n",
    "    for useless_column in drop_columns:\n",
    "        if(useless_column in df_columns):\n",
    "            clean_df = clean_df.drop(useless_column, axis=1)\n",
    "    return clean_df\n",
    "\n",
    "\n",
    "def prepare_dataset_for_EDA(relative_path=\"\",drop_by_occurrences=True, drop_by_extended_chord=True, min_chord_progression_length=20):\n",
    "    absolute_path = os.getcwd()\n",
    "    #relative_path = \"notebooks/data/NottinghamData/nottingham_database\"\n",
    "    relative_path = \"notebooks/data/NottinghamCleaned/nottingham_match/python/data/nottingham_jukedeck/ABC_cleaned\"\n",
    "    absolute_path = os.path.join(absolute_path, relative_path)\n",
    "    songs_df = pd.DataFrame()\n",
    "    list_tuneBooks = get_tuneBooks_file_names(absolute_path)\n",
    "    for abc_tuneBook_filename in list_tuneBooks:\n",
    "        file_path = os.path.join(absolute_path, abc_tuneBook_filename)\n",
    "        \n",
    "        with open(file_path) as tuneBook:\n",
    "            contents = tuneBook.read()\n",
    "            df = tuneBook_to_dataframe(contents)\n",
    "            df1 = get_songs_metadata(df,abc_tuneBook_filename)\n",
    "            songs_df = pd.concat([songs_df, df1], ignore_index=True)\n",
    "\n",
    "    ## Sets chords columns as int types\n",
    "    chords_names = songs_df.columns[songs_df.columns.str.contains('\"[^\"]*\"')]\n",
    "    songs_df[chords_names] = songs_df[chords_names].fillna(0).astype(int)\n",
    "\n",
    "\n",
    "    chords_occurrences = songs_df[chords_names].sum().sort_values(ascending=True)\n",
    "\n",
    "    chords_occurrences = chords_occurrences.reset_index(drop=True)\n",
    "    chords_occurrences = chords_occurrences.reset_index()\n",
    "    chords_occurrences_before_drop = chords_occurrences.rename({0:\"count\",\"index\":\"chords\"},axis=1)\n",
    "    \n",
    "    clean_songs_df = songs_df\n",
    "    clean_songs_df = drop_useless_columns(clean_songs_df)\n",
    "\n",
    "    if(drop_by_occurrences):\n",
    "        clean_songs_df = drop_rows_by_chord_occurrence(clean_songs_df)\n",
    "\n",
    "\n",
    "    if(drop_by_extended_chord):\n",
    "        clean_songs_df = drop_rows_by_extended_chords(clean_songs_df)\n",
    "\n",
    "    ## Drops rows that don't have the minimum chord progression length\n",
    "    mask_no_chord_progression = clean_songs_df[\"chord_progression\"].str.len()>min_chord_progression_length\n",
    "    clean_songs_df = clean_songs_df[mask_no_chord_progression]\n",
    "    clean_songs_df = clean_songs_df.reset_index(drop=True)\n",
    "\n",
    "    ## X: 102 meter appears after they key so its meter is dropped in the cleaning.\n",
    "    ## its the only song with this format\n",
    "    clean_songs_df.loc[clean_songs_df[\"meter\"].isna(),\"meter\"] = \"6/8\"\n",
    "    \n",
    "    ## Fill empty values of note_length according to the meter of the song\n",
    "    clean_songs_df = fill_missing_note_length(clean_songs_df)\n",
    "\n",
    "    #for song in clean_songs_df[\"chord_progression\"]:\n",
    "    #    print(song)\n",
    "    #    print(\"**\"*10)\n",
    "    return songs_df, clean_songs_df, chords_occurrences_before_drop\n",
    "\n",
    "songs_df, clean_songs_df,chords_occurrences = prepare_dataset_for_EDA()\n",
    "#chords_occurrences[\"count\"] = chords_occurrences[\"count\"].apply(np.log)\n",
    "sns.barplot(data=chords_occurrences,y=\"count\", x='chords',edgecolor='none',color=\"magenta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_df[\"original_body\"].str.contains(\"P:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chords_names = clean_songs_df.columns[clean_songs_df.columns.str.contains('\"[^\"]*\"')]\n",
    "\n",
    "chords_occurrences_df = clean_songs_df[chords_names].sum().sort_values(ascending=False).reset_index()\n",
    "print(chords_occurrences_df.columns)\n",
    "sns.barplot(data=chords_occurrences_df,y=\"index\", x=0,edgecolor='none',color=\"magenta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(songs_df[\"key\"].astype(\"category\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig, ax = plt.subplots()\n",
    "ax = sns.histplot(songs_df[\"key\"].astype(\"category\"),label=\"abc\")\n",
    "ax = sns.histplot(clean_songs_df[\"key\"].astype(\"category\"), ax=ax,label=\"something 2\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_songs_df.columns[clean_songs_df.columns.str.contains('\"[\\(]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chord_names = clean_songs_df.columns[clean_songs_df.columns.str.contains('\"')].to_list()\n",
    "sum_chords = clean_songs_df[chord_names].sum().sort_values().reset_index()\n",
    "chords = \"|\"\n",
    "for chord_name,chord_count in zip(sum_chords[\"index\"],sum_chords[0]):\n",
    "    chords = chords+chord_name+'|'\n",
    "    print(chord_name,chord_count)\n",
    "print(chords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_songs_df[\"chord_progression\"].str.contains(\"segno\").value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(songs_df[\"chord_progression\"].str.contains(\"segno\").value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for song,title,book in zip(clean_songs_df[\"clean_body\"],clean_songs_df[\"title\"],clean_songs_df[\"tuneBook\"]):\n",
    "    print(title,\" \", book)\n",
    "    print(song)\n",
    "    print(\"**\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptive_names = {\n",
    "                        'X': 'reference_number',\n",
    "                        'T': 'title',\n",
    "                        'S': 'source',\n",
    "                        'M': 'meter',\n",
    "                        'L': 'unit_note_length',\n",
    "                        'R': 'rhythm',\n",
    "                        'P': 'parts',\n",
    "                        'K': 'key',\n",
    "                        'F': 'file_name',\n",
    "                        'N': 'notes'\n",
    "                        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_name = \"meter\"\n",
    "category_value_counts = clean_songs_df[category_name].astype(\"category\").value_counts()\n",
    "print(category_value_counts)\n",
    "print(\"\\nSum of values:\",category_value_counts.sum())\n",
    "print(\"\\nNaN values:\",clean_songs_df[category_name].isna().sum())\n",
    "sns.histplot(clean_songs_df[category_name].astype(\"category\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_name = \"rhythm\"\n",
    "category_value_counts = songs_df[category_name].astype(\"category\").value_counts()\n",
    "print(category_value_counts)\n",
    "print(\"\\nSum of values:\",category_value_counts.sum())\n",
    "print(\"\\nNaN values:\",songs_df[category_name].isna().sum())\n",
    "sns.histplot(songs_df[category_name].astype(\"category\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_name = \"unit_note_length\"\n",
    "category_value_counts = clean_songs_df[category_name].astype(\"category\").value_counts()\n",
    "print(category_value_counts)\n",
    "print(\"\\nSum of values:\",category_value_counts.sum())\n",
    "print(\"\\nNaN values:\",clean_songs_df[category_name].isna().sum())\n",
    "sns.histplot(clean_songs_df[category_name].astype(\"category\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_name = \"key\"\n",
    "category_value_counts = clean_songs_df[category_name].astype(\"category\").value_counts()\n",
    "print(category_value_counts)\n",
    "print(\"\\nSum of values:\",category_value_counts.sum())\n",
    "print(\"\\nNaN values:\",clean_songs_df[category_name].isna().sum())\n",
    "sns.histplot(clean_songs_df[category_name].astype(\"category\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_name = \"tuneBook\"\n",
    "category_value_counts = clean_songs_df[category_name].astype(\"category\").value_counts()\n",
    "print(category_value_counts)\n",
    "print(\"\\nSum of values:\",category_value_counts.sum())\n",
    "print(\"\\nNaN values:\",clean_songs_df[category_name].isna().sum())\n",
    "sns.histplot(clean_songs_df, y=category_name)\n",
    "sns.histplot(songs_df, y=category_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_songs_df[\"meter\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_songs_df[\"meter\"].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clean_songs_df[\"unit_note_length\"].value_counts())\n",
    "print(clean_songs_df[\"unit_note_length\"].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_songs_df.columns.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of NaN in the entire dataset:\",clean_songs_df.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_clean_header(songs_df,for_training=False):\n",
    "    descriptive_name_to_code = {\n",
    "                        'reference_number':'X',\n",
    "                        'title':'T',\n",
    "                        'source':'S',\n",
    "                        'meter':'M',\n",
    "                        'unit_note_length':'L',\n",
    "                        'rhythm':'R',\n",
    "                        'parts':'P',\n",
    "                        'key':'K',\n",
    "                        'file_name':'F',\n",
    "                        'notes':'N',\n",
    "                        }\n",
    "    header_cols = []\n",
    "    if for_training:\n",
    "        header_cols = [\"meter\",\"unit_note_length\",\"key\"]\n",
    "    else:\n",
    "        print(\"not for training\")\n",
    "        header_cols = [\"reference_number\",\"title\",\"meter\",\"unit_note_length\",\"key\"]\n",
    "\n",
    "    compose_header_codes_and_values = lambda row: [f'{descriptive_name_to_code[col_name]}:{row[col_name]}' for col_name in header_cols]\n",
    "    songs_df[\"clean_header\"] = songs_df[header_cols].apply(lambda row: ('\\n'.join(compose_header_codes_and_values(row))), axis=1)\n",
    "    if for_training:\n",
    "        append_chord_prog = lambda row: f'{row[\"clean_header\"]}\\n{row[\"chord_progression\"]}\\n'\n",
    "        songs_df[\"clean_header\"] = songs_df[[\"clean_header\",\"chord_progression\"]].apply(append_chord_prog, axis=1)\n",
    "\n",
    "    return songs_df\n",
    "\n",
    "def generate_clean_songs(songs_df,for_training=False):\n",
    "    clean_songs_df = generate_clean_header(songs_df,for_training)\n",
    "    additional_line =  \"\\n\" if not for_training else \"\"\n",
    "    append_body_to_header = lambda row: f'{row[\"clean_header\"]}{additional_line}{row[\"clean_body\"]}\\n'\n",
    "    clean_songs_df[\"clean_song\"] = clean_songs_df.apply(append_body_to_header, axis=1)\n",
    "    return clean_songs_df\n",
    "\n",
    "for song in generate_clean_songs(clean_songs_df,for_training=False)[\"clean_song\"]:\n",
    "    print(song)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
